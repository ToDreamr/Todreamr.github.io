
[{"content":"你好，我是春江花朝秋月夜我是这个博客的作者。 我关心后端技术，也喜欢做一些前端效果。我偶尔写一些笔记和心得并且定期分享到\r哔哩哔哩 和我的 语雀频道 如果你喜欢新海诚，宫崎骏，今敏，也许我们会有相似的爱好和性格。 当然，如果你好奇我\r目前在做的事情,也可以了解更多\r关于我的信息。\n","date":"30 April 2024","externalUrl":null,"permalink":"/","section":"","summary":"你好，我是春江花朝秋月夜我是这个博客的作者。 我关心后端技术，也喜欢做一些前端效果。我偶尔写一些笔记和心得并且定期分享到\r哔哩哔哩 和我的 语雀频道 如果你喜欢新海诚，宫崎骏，今敏，也许我们会有相似的爱好和性格。 当然，如果你好奇我\r目前在做的事情,也可以了解更多\r关于我的信息。","title":"","type":"page"},{"content":"\r如何使用Hugo+Blowfish? #\r新建文章 #\r使用命令新建文章，新建文章生成在content目录下 将会使用archrtypes/default.md格式添加新文件头部配置键。\nPS D:\\JavaWork\\qvisl9.github.io\u0026gt; hugo new help/index.md Content \u0026#34;D:\\\\JavaWork\\\\qvisl9.github.io\\\\content\\\\help\\\\index.md\u0026#34; created PS D:\\JavaWork\\qvisl9.github.io\u0026gt; 分类 #\rblowfish的分类相对来说不是很完善效果如下：\n实现方式很简单，需在头部配置键中添加tags项\n就像这样子：\n主题将会识别配置键并自动检索所有带有此项的文章生成分类页面\n系列 #\rblowfish的是带有系列配置项的，效果如下：\n类似上述的操作，需要添加头部配置项：\n注意！！！请将文件命名为index.md，否则博客主题将无法自动为文章进行分类和添加相应的功能\n图标 #\r添加自己的图标和文章图片，放在assets目录下，icon作为 图标文件夹，添加相应图标后可显示对应的图片，如下：\ni18n国际化 #\rhugo.toml文件下：\ntheme = \u0026#34;blowfish\u0026#34; # UNCOMMENT THIS LINE # baseURL = \u0026#34;https://your_domain.com/\u0026#34; defaultContentLanguage = \u0026#34;zh-CN\u0026#34; 添加并编辑相对于的文件：\n添加特定翻译：\n例如：\narticle: anchor_label: \u0026#34;锚点\u0026#34; date: \u0026#34;{{ .Date }}\u0026#34; date_updated: \u0026#34;Updated: {{ .Date }}\u0026#34; draft: \u0026#34;草稿\u0026#34; edit_title: \u0026#34;编辑内容\u0026#34; reading_time: other: \u0026#34;{{ .Count }} 分钟\u0026#34; reading_time_title: \u0026#34;预计阅读\u0026#34; # table_of_contents: \u0026#34;Table of Contents\u0026#34; word_count: one: \u0026#34;{{ .Count }} 字\u0026#34; other: \u0026#34;{{ .Count }} 字\u0026#34; part_of_series: \u0026#34;这是系列文章之一.\u0026#34; part: \u0026#34;部分\u0026#34; this_article: \u0026#34;本文\u0026#34; related_articles: \u0026#34;相关文章\u0026#34; 自定义 #\r在params.toml文件中编辑自己的配置键值，下面举一些常见例子\n例如下面两种效果：\n短代码 #\rblowfish是支持自定义化和自己编写短代码实现自己的扩展功能的，例如：\n在index.md中，我添加了一行段代码：\n(list limit=1000 title=\u0026#34;全部文章\u0026#34;) 其实际对应主题中的这个文件，功能是将文章或这对应的给定参数进行 排列，排列样式取决于前面提到的params.toml的配置键\n自定义添加自己的短代码 #\r例如在自己的博客目录中，我们可以添加自己的layouts目录，blowfish将会覆盖原有的layouts目录 也就是优先级更高。\n就像这样子：\n其他可评论\u0026hellip;.\n","date":"30 April 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/help/","section":"笔记s","summary":"如何使用Hugo+Blowfish? #\r新建文章 #\r使用命令新建文章，新建文章生成在content目录下 将会使用archrtypes/default.md格式添加新文件头部配置键。\nPS D:\\JavaWork\\qvisl9.github.io\u0026gt; hugo new help/index.md Content \u0026#34;D:\\\\JavaWork\\\\qvisl9.github.io\\\\content\\\\help\\\\index.md\u0026#34; created PS D:\\JavaWork\\qvisl9.github.io\u0026gt; 分类 #\rblowfish的分类相对来说不是很完善效果如下：\n实现方式很简单，需在头部配置键中添加tags项\n就像这样子：\n主题将会识别配置键并自动检索所有带有此项的文章生成分类页面\n系列 #\rblowfish的是带有系列配置项的，效果如下：\n类似上述的操作，需要添加头部配置项：\n注意！！！请将文件命名为index.md，否则博客主题将无法自动为文章进行分类和添加相应的功能\n图标 #\r添加自己的图标和文章图片，放在assets目录下，icon作为 图标文件夹，添加相应图标后可显示对应的图片，如下：","title":"Help","type":"笔记"},{"content":"","date":"30 April 2024","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"30 April 2024","externalUrl":null,"permalink":"/tags/%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/","section":"Tags","summary":"","title":"帮助文档","type":"tags"},{"content":"","date":"30 April 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/","section":"笔记s","summary":"","title":"笔记s","type":"笔记"},{"content":"","date":"19 March 2024","externalUrl":null,"permalink":"/entire-note/","section":"Entire-notes","summary":"","title":"Entire-notes","type":"entire-note"},{"content":"\r算法合辑\r✈️✈️去到算法目录✈️✈️\r2024年3月19日\r· 12:01\n","date":"19 March 2024","externalUrl":null,"permalink":"/entire-note/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95-%E7%AE%97%E6%B3%95/","section":"Entire-notes","summary":"算法合辑\r✈️✈️去到算法目录✈️✈️\r2024年3月19日\r· 12:01","title":"代码随想录算法合辑","type":"entire-note"},{"content":"","date":"19 March 2024","externalUrl":null,"permalink":"/tags/%E7%AE%97%E6%B3%95/","section":"Tags","summary":"","title":"算法","type":"tags"},{"content":"\r链表 ，队列和二叉树 #\r尝试使用cpp实现二叉树，下面是粗劣的代码： #\r指针和引用传递的区别：\n//如果传递引用： void List_Init(List \u0026amp;list) { // 防止访问空指针 if (list.next != NULL) { list.next = NULL; list.node_count = 0; } } //如果传递指针： void List_Init(List *list) { // 防止访问空指针 if (list-\u0026gt;next != NULL) { list-\u0026gt;next = NULL; list-\u0026gt;node_count = 0; } } //如果不想用指针，想用引用： List \u0026amp;tmp = *list; 使用类模板：\n类模板使用只能用显示指定类型方式 类模板中的模板参数列表可以有默认参数\ntemplate\u0026lt;class NameType\u0026gt; #include \u0026#34;stdio.h\u0026#34; #include \u0026#34;stdlib.h\u0026#34; #include \u0026#34;iostream\u0026#34; using namespace std; // 定义一个链表 typedef struct list { int item; bool isEmpty; // 是否空链表 int node_count; // 节点数 list *next; // 下一节点 } List; // 定义一个二叉树ADT typedef struct tree { list node; tree *tree; } Tree; void List_Init(List \u0026amp;list) { // 防止访问空指针 if (list.next != NULL) { list.next = NULL; list.node_count = 0; } } bool List_IsEmpty(List \u0026amp;list) { return list.isEmpty; } bool Add_List_Item(List \u0026amp;list, int \u0026amp;new_item) { if (list.next != NULL) { // 加入元素 List *tp = (List *)malloc(sizeof(List)); List \u0026amp;tmp = *tp; if (tmp.next != NULL) { // tmp.item = new_item; tmp.next = NULL; tmp.isEmpty = false; tmp.node_count++; list.next = tmp.next; } return true; } return false; } void Travel_List(List \u0026amp;list) { while (list.next != NULL) { cout \u0026lt;\u0026lt; \u0026#34;元素是：\u0026#34; \u0026lt;\u0026lt; list.item \u0026lt;\u0026lt; endl; list = *list.next; } cout \u0026lt;\u0026lt; \u0026#34;元素是：\u0026#34; \u0026lt;\u0026lt; list.item \u0026lt;\u0026lt; endl; } int main(int argc, char const *argv[]) { List *test = (List *)malloc(sizeof(List)); List \u0026amp;res = *test; List_Init(res); int item = 12; for (int i = 0; i \u0026lt; 12; i++) { Add_List_Item(res, item); } while (true) { Travel_List(res); } return 0; } 二叉树的基本知识： #\r参考文章\n满二叉树：\n所有元素全部占满，必定是完全二叉树 只有最下层才有叶子节点 非叶子节点的度为 2 完全二叉树：\n叶子结点只能出现在最下两层； 最下层的叶子结点一定集中在左边并且连续； 若结点度为1，则该节点只有左子节点；\n遍历二叉树 #\r①、前序遍历：\r定义：先访问根节点，然后访问左子树，再访问右子树；\n按照定义遍历的顺序遍历结果为：A B D H I E J C F K G\n②、中序遍历：\n定义：先访问左子树，再访问根节点，最后访问右子树；\n按照定义遍历的顺序遍历结果为：H D I B E J A F K C G\n③、后序遍历：\n定义：先访问左子树，再访问右子树，最后访问根节点；\n按照定义遍历的顺序遍历结果为：H I D J E B K F G C A\n④、层次遍历：\n定义：逐层的从根节点开始，每层从左至右遍历；\n按照定义遍历的顺序遍历结果为：A B C D E F G H I J K\n经常使用的库：\n// // Created by Rainy-Heights on 2024/3/19. // #ifndef CARL_CODE_UNION_H #define CARL_CODE_UNION_H #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; //链表ADT struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} ListNode(int x) : val(x), next(nullptr) {} ListNode(int x, ListNode *next) : val(x), next(next) {} void initNode(ListNode *listNode,int len){ ListNode *head=listNode; int index=0; while (index\u0026lt;len){ head-\u0026gt;next=new ListNode; head-\u0026gt;val=0; head=head-\u0026gt;next; index++; } } }; //树ADT struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {} }; #endif //CARL_CODE_UNION_H ","date":"18 March 2024","externalUrl":null,"permalink":"/entire-note/%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%92%8C%E6%A0%91/","section":"Entire-notes","summary":"链表 ，队列和二叉树 #\r尝试使用cpp实现二叉树，下面是粗劣的代码： #\r指针和引用传递的区别：\n//如果传递引用： void List_Init(List \u0026amp;list) { // 防止访问空指针 if (list.next != NULL) { list.next = NULL; list.node_count = 0; } } //如果传递指针： void List_Init(List *list) { // 防止访问空指针 if (list-\u0026gt;next !","title":"抽象数据类型ADT","type":"entire-note"},{"content":"","date":"18 March 2024","externalUrl":null,"permalink":"/tags/%E8%A6%81%E6%B1%82%E7%86%9F%E8%AE%B0/","section":"Tags","summary":"","title":"要求熟记","type":"tags"},{"content":"\rRedis详解 #\r1. Redis简介 #\r使用C语言开发的内存数据库，读写速度快，广泛用于缓存方向 可以用于分布式锁，甚至是消息队列 提供多种数据类型来支持不同的业务场景 支持事务、持久化、Lua脚本、多种集群方案 2. Redis 和 Memcached 对比 #\r2.1 相同点 #\r都基于内存，一般都是用来当缓存使用 都有过期策略 两者性能都非常高 2.2 区别 #\rRedis 支持更丰富的数据类型【key-value类型、提供l ist set zset hash等数据结构的存储】、更复杂的应用场景。Memcached只支持简单的 key-value 类型； Redis支持数据的持久化，有灾难恢复机制，Memcached不支持； Redis在服务器内存不足时，可以将不用的数据放到磁盘上；Memcached则直接报异常； Redis原生支持集群模式，Memcached原生不支持，需要依靠客户端实现往集群分片写入数据； Memcached是多线程的非阻塞IO复用的网络模型，Redis使用单线程的多路IO复用模型【6.0以后引入了多线程】 Redis支持发布订阅模型、Lua脚本、事务等功能，而Memcached不支持。并且，Redis支持更多的编程语言 Memcached过期数据只使用惰性删除，而Redis同时使用惰性删除和定期删除 3. 缓存数据处理流程 #\r若用户请求的数据在缓存中则直接返回 若缓存中不存在，则查询数据库 若数据库中存在，则更新缓存 若数据库不存在，则返回空数据 4. 为什么使用Redis #\r4.1 高性能考虑 #\r用户每次请求都查询数据库，涉及磁盘IO操作，速度慢。 若把高频访问且不经常改变的数据放入缓存，能极大提高查询速度。 注意要保持数据库和缓存中的数据的一致性。如果数据库中的对应数据改变，需要同步改变缓存中的数据 4.2 高并发考虑 #\r如MySQL数据库的QPS大概在1w左右【4核8G】，但是使用Redis缓存之后，很容易能达到10w+，甚至最高能到达30w+【单机情况】 故，直接操作缓存能承受更多的请求，进而提供系统的并发能力 5. Redis常见数据结构及应用场景 #\r5.1 string #\rstring数据结构是简单的 key-value类型，是Redis自行构建的动态字符串。可以保存文本数据、二进制数据，获取长度的复杂度为O(1)，不会造成缓冲区溢出 常用命令：set, get, strlen, exists, decr, incr, setex 应用场景：需要计数的场景，如用户访问次数、热点文章的点赞转发数量等等 5.1.1 基本操作 #\r127.0.0.1:6379\u0026gt; set key value #设置 key-value 类型的值\rOK\r127.0.0.1:6379\u0026gt; get key # 根据 key 获得对应的 value\r\u0026#34;value\u0026#34;\r127.0.0.1:6379\u0026gt; exists key # 判断某个 key 是否存在\r(integer) 1\r127.0.0.1:6379\u0026gt; strlen key # 返回 key 所储存的字符串值的长度。\r(integer) 5\r127.0.0.1:6379\u0026gt; del key # 删除某个 key 对应的值\r(integer) 1\r127.0.0.1:6379\u0026gt; get key\r(nil)\r127.0.0.1:6379\u0026gt; mset key1 value1 key2 value2 # 批量设置 key-value 类型的值\rOK\r127.0.0.1:6379\u0026gt; mget key1 key2 # 批量获取多个 key 对应的 value\r1) \u0026#34;value1\u0026#34;\r2) \u0026#34;value2\u0026#34; 5.1.2 计数器 #\r127.0.0.1:6379\u0026gt; set number 1\rOK\r127.0.0.1:6379\u0026gt; incr number # 将 key 中储存的数字值增一\r(integer) 2\r127.0.0.1:6379\u0026gt; get number\r\u0026#34;2\u0026#34;\r127.0.0.1:6379\u0026gt; decr number # 将 key 中储存的数字值减一\r(integer) 1\r127.0.0.1:6379\u0026gt; get number\r\u0026#34;1\u0026#34; 5.1.3 过期时间设置 #\r127.0.0.1:6379\u0026gt; expire key 60 # 数据在 60s 后过期\r(integer) 1\r127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)\rOK\r127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期\r(integer) 56 5.2 list #\rRedis自行实现了自己的链表结构，为双向链表 常用命令：rpush, lpop, lpush, rpop, lrange, llen 应用场景：发布订阅【消息队列】，慢查询 通过rpush/lpop实现队列 #\r127.0.0.1:6379\u0026gt; rpush myList value1 # 向 list 的最右边添加元素\r(integer) 1\r127.0.0.1:6379\u0026gt; rpush myList value2 value3 # 向list的最右边添加多个元素\r(integer) 3\r127.0.0.1:6379\u0026gt; lpop myList # 将 list的最左边元素取出\r\u0026#34;value1\u0026#34;\r127.0.0.1:6379\u0026gt; lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end\r1) \u0026#34;value2\u0026#34;\r2) \u0026#34;value3\u0026#34;\r127.0.0.1:6379\u0026gt; lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一\r1) \u0026#34;value2\u0026#34;\r2) \u0026#34;value3\u0026#34;\r127.0.0.1:6379\u0026gt; llen myList # 查看链表长度\r(integer) 2 5.3 hash #\r内部实现为【数组 + 链表】 适合存储对象，可以直接仅仅修改这个对象中某个字段的值。如，存储用户信息、商品信息 常用命令：hset, hmset, hget, hgetall, hkeys, hvals 应用场景：系统中对象数据的存储 127.0.0.1:6379\u0026gt; hmset userInfoKey name \u0026#34;guide\u0026#34; description \u0026#34;dev\u0026#34; age \u0026#34;24\u0026#34;\rOK\r127.0.0.1:6379\u0026gt; hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。\r(integer) 1\r127.0.0.1:6379\u0026gt; hget userInfoKey name # 获取存储在哈希表中指定字段的值。\r\u0026#34;guide\u0026#34;\r127.0.0.1:6379\u0026gt; hget userInfoKey age\r\u0026#34;24\u0026#34;\r127.0.0.1:6379\u0026gt; hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值\r1) \u0026#34;name\u0026#34;\r2) \u0026#34;guide\u0026#34;\r3) \u0026#34;description\u0026#34;\r4) \u0026#34;dev\u0026#34;\r5) \u0026#34;age\u0026#34;\r6) \u0026#34;24\u0026#34;\r127.0.0.1:6379\u0026gt; hkeys userInfoKey # 获取 key 列表\r1) \u0026#34;name\u0026#34;\r2) \u0026#34;description\u0026#34;\r3) \u0026#34;age\u0026#34;\r127.0.0.1:6379\u0026gt; hvals userInfoKey # 获取 value 列表\r1) \u0026#34;guide\u0026#34;\r2) \u0026#34;dev\u0026#34;\r3) \u0026#34;24\u0026#34;\r127.0.0.1:6379\u0026gt; hset userInfoKey name \u0026#34;GuideGeGe\u0026#34; # 修改某个字段对应的值\r127.0.0.1:6379\u0026gt; hget userInfoKey name\r\u0026#34;GuideGeGe\u0026#34; 5.4 set #\r存储无重复元素 容易实现交集、并集、差集操作。实现如共同关注、共同粉丝、共同喜好等功能 常用命令：sadd, spop, smembers, sismembers, scard, sinterstore, sunion 应用场景：需要存放的数据不能重复、需要获取多个数据源交集和并集等场景 127.0.0.1:6379\u0026gt; sadd mySet value1 value2 # 添加元素进去\r(integer) 2\r127.0.0.1:6379\u0026gt; sadd mySet value1 # 不允许有重复元素\r(integer) 0\r127.0.0.1:6379\u0026gt; smembers mySet # 查看 set 中所有的元素\r1) \u0026#34;value1\u0026#34;\r2) \u0026#34;value2\u0026#34;\r127.0.0.1:6379\u0026gt; scard mySet # 查看 set 的长度\r(integer) 2\r127.0.0.1:6379\u0026gt; sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素\r(integer) 1\r127.0.0.1:6379\u0026gt; sadd mySet2 value2 value3\r(integer) 2\r127.0.0.1:6379\u0026gt; sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中\r(integer) 1\r127.0.0.1:6379\u0026gt; smembers mySet3\r1) \u0026#34;value2\u0026#34; 5.5 sorted set #\r介绍：和 set比，增加了一个权重参数 score，使得集合中的元素能够按score进行有序排序，也可通过score的范围来获取元素的列表。 常用命令：zadd, zcard, zscore, zrange, zreverange, zrem 应用场景：需要根据权重对数据进行排序的场景。如，直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息等信息 127.0.0.1:6379\u0026gt; zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重\r(integer) 1\r127.0.0.1:6379\u0026gt; zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素\r(integer) 2\r127.0.0.1:6379\u0026gt; zcard myZset # 查看 sorted set 中的元素数量\r(integer) 3\r127.0.0.1:6379\u0026gt; zscore myZset value1 # 查看某个 value 的权重\r\u0026#34;3\u0026#34;\r127.0.0.1:6379\u0026gt; zrange myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素\r1) \u0026#34;value3\u0026#34;\r2) \u0026#34;value2\u0026#34;\r3) \u0026#34;value1\u0026#34;\r127.0.0.1:6379\u0026gt; zrange myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start 1 为 stop\r1) \u0026#34;value3\u0026#34;\r2) \u0026#34;value2\u0026#34;\r127.0.0.1:6379\u0026gt; zrevrange myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start 1 为 stop\r1) \u0026#34;value1\u0026#34;\r2) \u0026#34;value2\u0026#34; 5.6 bitmap #\r介绍：bitmap存储连续二进制数字【0和 1】，一个二进制位对应某个元素的值或者状态，key 对应元素本身。 能极大节省存储空间 常用命令：setbit, getbit, bitcount, bitop 应用场景：适合需要保存状态信息并需要进一步对这些信息进行分析的场景。如，用户签到、活跃用户行为统计【如是否点赞过某个视频】 # SETBIT 会返回之前位的值（默认是 0）这里会生成 7 个位\r127.0.0.1:6379\u0026gt; setbit mykey 7 1\r(integer) 0\r127.0.0.1:6379\u0026gt; setbit mykey 7 0\r(integer) 1\r127.0.0.1:6379\u0026gt; getbit mykey 7\r(integer) 0\r127.0.0.1:6379\u0026gt; setbit mykey 6 1\r(integer) 0\r127.0.0.1:6379\u0026gt; setbit mykey 8 1\r(integer) 0\r# 通过 bitcount 统计被被设置为 1 的位的数量。\r127.0.0.1:6379\u0026gt; bitcount mykey\r(integer) 2 5.6.1 使用场景一 #\r用户行为分析\n# 记录你喜欢过 001 号小姐姐\r127.0.0.1:6379\u0026gt; setbit beauty_girl_001 uid 1 5.6.2 使用场景二 #\r统计活跃用户\n# 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。\r# BITOP 命令支持 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种参数\rBITOP operation destkey key [key ...] 使用时间作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1\n初始化数据：\n127.0.0.1:6379\u0026gt; setbit 20210308 1 1\r(integer) 0\r127.0.0.1:6379\u0026gt; setbit 20210308 2 1\r(integer) 0\r127.0.0.1:6379\u0026gt; setbit 20210309 1 1\r(integer) 0 统计 20210308~20210309 总活跃用户数: 1\n127.0.0.1:6379\u0026gt; bitop and desk1 20210308 20210309\r(integer) 1\r127.0.0.1:6379\u0026gt; bitcount desk1\r(integer) 1 统计 20210308~20210309 在线活跃用户数: 2\n127.0.0.1:6379\u0026gt; bitop or desk2 20210308 20210309\r(integer) 1\r127.0.0.1:6379\u0026gt; bitcount desk2\r(integer) 2 5.6.3 使用场景三\n对于获取或者统计用户在线状态，使用 bitmap 是一个节约空间效率又高的一种方法。\n只需要一个 key，然后用户 ID 为 offset，如果在线就设置为 1，不在线就设置为 0。\n6. Redis单线程模型详解 #\rRedis 基于 Reactor 模式来设计开发一套高效的事件处理模型，这套事件处理模型对应的是Redis中的文件事件处理器。 由于文件事件处理器是单线程运行的，所以一般都说Redis是单线程模型 Redis通过IO多路复用程序来监听来自客户端的大量连接【监听多个socket】，将特定的事件及类型【读、写】注册到内核中并监听每个事件是否发生 IO多路复用技术使得Redis不需要额外创建多余的线程来监听客户端的大量连接，降低资源的消耗 Redis服务器是一个事件驱动程序，服务器需要处理两类事件：文件事件 和 时间事件 Redis基于Reactor模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器。该处理器使用IO多路复用程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。\n当前被监听的套接字准备好执行连接应答【accept】、读取【read】、写入【read】、关闭【close】等操作时，若与操作相对应的文件事件产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。\n虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。\n文件事件处理器主要包含四部分：\n多个socket IO多路复用程序 文件事件分派器 事件处理器 7. Redis 6.0 之前为什么不使用多线程 #\r实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持 不过，Redis 4.0 增加的多线程主要是针对一些大键值对的删除操作的命令，使用这些命令就会使用主处理之外的其他线程来“异步处理” 大体上来说，Redis 6.0 之前主要还是单线程处理 Redis 6.0 之前为什么不使用多线程：\n单线程编程容易且易于维护 Redis的性能瓶颈不在CPU，主要在内存和网络 多线程存在死锁、线程上下文切换等问题，有可能会影响性能 8. Redis 6.0 之后为什么引入多线程 #\r为了提高网络IO读写性能，这是Redis的一个性能瓶颈之一 Redis的多线程只是在网络数据的读写这一类耗时较多的操作上使用，执行命令时仍然是单线程执行，故也不需要担心线程安全问题 Redis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis 配置文件 redis.conf ：\nio-threads-do-reads yes 开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 redis 配置文件 redis.conf :\nio-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程 9. Redis 过期时间的作用 #\r服务器内存有限，若缓存的所有数据都一直保存，最终将导致OOM\nRedis自带了给缓存数据设置过期时间的功能：\n127.0.0.1:6379\u0026gt; exp key 60 # 数据在 60s 后过期\r(integer) 1\r127.0.0.1:6379\u0026gt; setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)\rOK\r127.0.0.1:6379\u0026gt; ttl key # 查看数据还有多久过期\r(integer) 56 * Redis 中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间\r* 某些业务场景需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效 10. Redis 如何判断数据是否过期 #\rRedis通过一个叫做 过期字典【相当于 hash 表】 的结构来保存数据过期时间。 过期字典的建指向Redis数据库中的某个 key 过期字典的值是一个 long long类型的整数，保存了 key 所指向的数据库建的过期时间【毫秒精度的UNIX时间戳】 过期字典是存储在 redisDb 这个结构里的：\ntypedef struct redisDb { ... dict *dict; //数据库键空间,保存着数据库中所有键值对 dict *expires // 过期字典,保存着键的过期时间 ... } redisDb; 11. 过期的数据的删除策略 #\r常用的过期数据删除从策略：\n惰性删除：只会在取出 key 的时候才对数据进行过期检查。对 CPU 友好，但是可能会造成过多的过期数据堆积 定期删除：每隔一段时间抽取一批 key 执行删除过期数据操作。Redis底层会通过限制删除操作执行的时长和频率来减少对 CPU 的影响 定期删除对内存友好，惰性删除对 CPU 友好。Redis 采用定期删除 + 惰性删除\n12. 内存淘汰机制 #\r采用 定期删除 + 惰性删除 仍有可能导致 OOM。解决策略是：内存淘汰机制\nRedis 提供 6 种数据淘汰策略：\nvolatile-lru【least recently used】：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 valatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集中任意挑选数据淘汰 allkeys-lru【least recently used】：当内存不足以容纳新写入数据时，在建空间中，移除最近最少使用的 key allkeys-random：从数据集中任意选择数据淘汰 no-eviction：禁止驱逐数据，也就是当前内存不足以容纳新写入数据时，新写入操作会报错。 4.0 版本新增加以下两种：\nvalatile-lfu【least frequently used】：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰 allkeys-lfu【least frequently used】：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key 13. Redis 持久化机制 #\r13.1 两种持久化方式 #\r快照持久化（RDB）和追加文件持久化（AOF）\nRedis支持两种持久化方式：\n快照持久化【RDB】 只追加文件【AOF】 13.1.1 快照持久化 #\r快照持久化：\nRedis 通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。 快照创建后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本【Redis主从结构，主要用来提高Redis性能】 可以将快照留在原地以便重启服务器的时候使用。 快照持久化时Redis 默认采用的持久化方式，在Redis.conf配置文件中默认有以下配置：\nsave 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\rsave 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。\rsave 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 13.1.2 AOF持久化 #\rAOF【append-only file】持久化\n与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：\nappendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。\n在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：\nappendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度\rappendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘\rappendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃， 用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。\n13.2 Redis 4.0 对于持久化机制的优化 #\rRedis 4.0 开始支持RDB和AOF的混合持久化【默认关闭，可以通过配置项 aof-use-rdb-preamble开启】\n混合持久化在 AOF重写的时候就直接把RDB的内容写到AOF文件开头。好处是可以结合RDB和AOF优点，快速加载的同时避免丢失过多的数据。缺点：AOF里的RDB部分是压缩格式而不再是AOF格式，可读性较差。\n13.3 AOF重写 #\rAOF重写可以产生一个新的AOF文件，这个新文件和原有AOF文件所保存的数据库状态一样，但体积更小 AOF重写通过读取数据库的键值对来实现，程序无需对现有AOF文件进行任何读入、分析或者写入操作 在执行　ＢＧＲＥＷＲＩＴＥＡＯＦ　命令时，Ｒｅｄｉｓ服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建新的AOF文件期间，记录服务器执行的所有写命令。当紫禁城完成创建新AOF文件的工作之后，服务器会将重写缓冲区所有内容追加到新的AOF文件的末尾，使得新旧的两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。 14.　Ｒｅｄｉｓ事务 #\rＲｅｄｉｓ可以通过MULTI, EXEC, DISCARD, WATCH等命令来实现事务功能\n\u0026gt; MULTI\rOK\r\u0026gt; SET USER \u0026#34;张三\rQUEUED\r\u0026gt; GET USER\rQUEUED\r\u0026gt; EXEC\r1) OK\r2) \u0026#34;张三\u0026#34; 使用 MULTI命令后可以输入多个命令。Redis不会立即执行这些命令。而是将它放到队列，当调用EXEC命令，将执行队列中所有命令。\n过程如下：\n开始事务【MULTI】 命令入队【先进先出顺序执行】 执行事务【EXEC】 DISCARD命令可以取消一个事务，将清空该事务对应队列所保存的命令\n\u0026gt; MULTI\rOK\r\u0026gt; SET USER \u0026#34;张三\u0026#34;\rQUEUED\r\u0026gt; GET USER\rQUEUED\r\u0026gt; DISCARD\rOK WATCH命令用于监听指定的键，当调用EXEC命令执行事务时，如果发现被监听键被修改时，整个事务将执行失败。\n\u0026gt; WATCH USER\rOK\r\u0026gt; MULTI\r\u0026gt; SET USER \u0026#34;张三\u0026#34;\rOK\r\u0026gt; GET USER\r张三\r\u0026gt; EXEC\rERR EXEC without MULTI Redis 不支持回滚，不满足一般事务定义的原子性和持久性\n15. 缓存穿透 #\r15.1 简介 #\r大量请求的 key 不存在缓存中，导致请求全部落在了数据库上。\n15.2 解决方案 #\r15.2.1 做好参数校验 #\r​\t一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。\n15.2.2 缓存无效的 key #\r如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下： SET key value EX 10086 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n一般情况下我 key 的格式： 表名:列名:主键名:主键值 。\n15.2.3 布隆过滤器 #\r15.2.3.1 简介 #\r可以方便地判断一个给定的数据是否存在于海量的数据中，即判断 key 是否合法。 具体操作：把所有可能存在的请求值都存放在布隆过滤器，当用户请求过来时，先判断用户发来的请求的值是否存在与布隆过滤器。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会正常执行业务流程。 布隆过滤器认为某元素存在时，有小概率会误判；但是认为某元素不存在时，则该元素一定不存在。 15.2.3.2 布隆过滤器原理 #\r当一个元素加入布隆过滤器时：\n使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值【有几个哈希 函数就得到几个哈希值】 根据哈希值，在位数组中把对应下标的值置为 1 当需要判断一个元素是否存在与布隆过滤器时：\n对给定元素再次进行相同的哈希计算 得到值后，判断位数组中的每一个元素是否都为 1，如果值都为 1，说明这个值在布隆过滤器，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 若不同的字符串哈希出来的位置相同，则会造成布隆过滤器的误判，但是概率比较小。可以适当增加位数组大小或者调整哈希函数来降低概率\n16. 缓存雪崩 #\r16.1 简介 #\r缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受了大量的请求。 例子：秒杀开始 1 个小时前，统一存放了一批商品到 Redis 中，设置的缓存过期时间也是 1 个小时，秒杀开始时，这些秒杀的商品的访问直接失效。导致相应的请求直接就落到了数据库上，就像雪崩一样可怕。 16.2 解决方案 #\r16.2.1 服务器不可用情况 #\r采用Redis集群，避免单机出现问题导致整个缓存服务器无法使用 限流，避免同时处理大量的请求 16.2.2 热点缓存失效情况 #\r设置不同的失效时间，如随机设置缓存的失效时间 缓存永不失效 17. 如何保证缓存和数据库的数据一致性 #\r17.1 数据不一致情况 #\r读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现缓存(Redis)和数据库（MySQL）间的数据一致性问题。不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况。\n举一个例子： 1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。 2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。 因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。\n17.2 解决方案 #\r17.2.1 采用延时双删策略 #\r在写库前后都进行redis.del(key)操作，并且设定合理的超时时间。\n伪代码如下：\npublic void write(String key,Object data){ redis.delKey(key); db.updateData(data); Thread.sleep(500); redis.delKey(key); } 具体的步骤就是：\n先删除缓存； 再写数据库； 休眠500毫秒； 再次删除缓存。 那么，这个500毫秒怎么确定的，具体该休眠多久呢？\n需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。\n当然这种策略还要考虑redis和数据库主从同步的耗时。最后的的写数据的休眠时间：则在读数据业务逻辑的耗时基础上，加几百ms即可。比如：休眠1秒。\n设置缓存过期时间\n从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。\n该方案的弊端\n结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。\n17.2.2 异步更新缓存【基于订阅binlog的同步机制】 #\r技术整体思路：\nMySQL binlog增量订阅消费+消息队列+增量数据更新到redis\n读Redis：热数据基本都在Redis 写MySQL:增删改都是操作MySQL 更新Redis数据：MySQ的数据操作binlog，来更新到Redis Redis更新\n1）数据操作主要分为两大块：\n一个是全量(将全部数据一次写入到redis) 一个是增量（实时更新） 这里说的是增量,指的是mysql的update、insert、delate变更数据。\n2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。\n这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。\n其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。\n这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。\n当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。\n认识 #\r有序集合和普通集合set很相似，是一个没有重复元素的字符串集合。\n每个成员都关联了一个评分（score），这个评分被用来按照最低分到最高分的方式排序集合种的成员。集合的成员是唯一的，但是分数可以重复\n底层： #\rRedis提供的一个非常特别的数据结构，一方面它等价于java的数据结构Map\u0026lt;String, double\u0026gt;，可以给每一个元素value赋予一个权重score， 另一方面它又类似于TreeSet，内部的元素会按照权重进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表\n实现：\nhash；hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到score 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表\n相同分数的时候\n有序集合里面的成员是不能重复的都是唯一的，但是，不同成员间有可能有相同的分数。当多个成员有相同的分数时，他们将是有序的字典（ordered lexicographically）（仍由分数作为第一排序条件，然后，相同分数的成员按照字典规则相对排序）。\n字典顺序排序用的是二进制，它比较的是字符串的字节数组。\nMysql索引 #\rMySQL索引详解 #\r1. 什么是索引 #\r索引是一种用于快速查询和检索数据的数据结构。常见的索引结构有: B 树， B+树和 Hash 2. 索引优缺点 #\r优点：\n能极大提高查询效率 创建唯一索引可以保证数据库表中每一行数据的唯一性 缺点：\n创建和维护索引比较耗时，当数据表频繁增删改时，对应的索引也要动态改变，会降低SQL执行效率 索引需要使用物理文件存储，会耗费一定存储空间 大多数情况下，索引查询都比全表扫描快。但是数据库数据量不大的话，使用索引不一定能提升查询效率\n3. 索引底层数据结构 #\r3.1 MySQL为何不使用Hash作为索引 #\rHash存在哈希冲突 Hash索引不支持顺序查找和范围查找 3.2 B树 和 B+树 #\rB 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。 B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点 B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显 在 MySQL 中，MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是，两者的实现方式不太一样。 MyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。 InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引【回表】。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。 4. 索引类型 #\r4.1 主键索引 #\r数据表的主键列使用的就是主键索引 一张数据表有且只能有一个主键，并且主键不能为 null，不能重复 在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。 4.2 辅助索引 #\r二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。 唯一索引，普通索引，前缀索引等索引属于二级索引 \u0026gt; * 唯一索引(Unique Key) ：唯一索引也是一种约束。唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率 普通索引(Index) ：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL 前缀索引(Prefix) ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符 全文索引(Full Text) ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引 5. 聚集索引和非聚集索引 #\r5.1 聚集索引 #\r索引结构和数据一起存放的索引。主键索引属于聚集索引 在 Mysql 中，InnoDB 引擎的表的 .ibd文件就包含了该表的索引和数据，对于 InnoDB 引擎表来说，该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据 优点：聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。 缺点： \u0026gt; * 依赖于有序的数据 ，因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，整型数据还好，若类似于字符串或 UUID 这种又长又难比较的数据，会造成主索引频繁分裂，插入或查找的速度肯定比较慢 更新代价大，如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的 5.2 非聚集索引 #\r即索引结构和数据分开存放的索引 二级索引属于非聚集索引 MYISAM 引擎的表的.MYI 文件包含了表的索引， 该表的索引(B+树)的每个叶子非叶子节点存储索引， 叶子节点存储索引和索引对应数据的指针，指向.MYD 文件的数据。 非聚集索引的叶子节点并不一定存放数据的指针， 因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。 优点：更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的 缺点： \u0026gt; * 非聚集索引也依赖于有序的数据 可能会二次查询(回表) : 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。 6. 覆盖索引 #\r一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引” 在 InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是要通过主键再查找一次。这样就会比较慢 覆盖索引就是把要查询出的列和索引是对应的，不做回表操作 7. 创建索引注意事项 #\r选择合适的字段创建索引： \u0026gt; * 不为 NULL 的字段 ：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。 被频繁查询的字段 ：我们创建索引的字段应该是查询操作非常频繁的字段。 被作为条件查询的字段 ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。 频繁需要排序的字段 ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。 被经常频繁用于连接的字段 ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。 被频繁更新的字段应该慎重建立索引。 尽可能的考虑建立联合索引而不是单列索引。因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升 注意避免冗余索引。冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引 考虑在字符串类型的字段上使用前缀索引代替普通索引。前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引 8. 使用索引的注意事项 #\r对于中到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引 避免 where 子句中对字段施加函数，这会造成无法命中索引 在使用 InnoDB 时使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务主键 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 schema_unused_indexes 视图来查询哪些索引从未被使用 在使用 limit offset 查询缓慢时，可以借助索引来提高性能 9. MySQL如何为表字段添加索引 #\r添加主键索引 alter table table_name add primary key(column) 添加唯一索引 alter table table_name add unique(column) 添加普通索引 alter table table_name add index index_name(column) 添加全部索引 alter table table_name add fulltext(column) 添加多列索引 alter table table_name add index index_name(column1, column2, column3) 10. 最左前缀匹配 #\r在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。 MySQL创建联合索引的规则是首先会对联合索引的最左边第一个字段排序，在第一个字段的排序基础上，然后在对第二个字段进行排序。 ","date":"15 March 2024","externalUrl":null,"permalink":"/entire-note/%E9%9D%A2%E8%AF%95%E9%A2%98/sql-redis-db/","section":"Entire-notes","summary":"Redis详解 #\r1. Redis简介 #\r使用C语言开发的内存数据库，读写速度快，广泛用于缓存方向 可以用于分布式锁，甚至是消息队列 提供多种数据类型来支持不同的业务场景 支持事务、持久化、Lua脚本、多种集群方案 2. Redis 和 Memcached 对比 #\r2.1 相同点 #\r都基于内存，一般都是用来当缓存使用 都有过期策略 两者性能都非常高 2.2 区别 #\rRedis 支持更丰富的数据类型【key-value类型、提供l ist set zset hash等数据结构的存储】、更复杂的应用场景。Memcached只支持简单的 key-value 类型； Redis支持数据的持久化，有灾难恢复机制，Memcached不支持； Redis在服务器内存不足时，可以将不用的数据放到磁盘上；Memcached则直接报异常； Redis原生支持集群模式，Memcached原生不支持，需要依靠客户端实现往集群分片写入数据； Memcached是多线程的非阻塞IO复用的网络模型，Redis使用单线程的多路IO复用模型【6.","title":"Mysql-Redis","type":"entire-note"},{"content":"","date":"15 March 2024","externalUrl":null,"permalink":"/tags/%E4%B8%BB%E4%BB%8E%E9%83%A8%E5%88%86/","section":"Tags","summary":"","title":"主从部分","type":"tags"},{"content":"经过我的不懈努力，RedmiBook终于变成了Mac Book⬇️⬇️\n参考笔记 参考视频 #\r目前看起来还行：\n不得不说这个文件夹样式效果真好：\n偶尔出现卡顿，之后记录\n","date":"14 March 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/mac%E4%BD%93%E9%AA%8C%E7%89%88bushi/","section":"笔记s","summary":"经过我的不懈努力，RedmiBook终于变成了Mac Book⬇️⬇️\n参考笔记 参考视频 #\r目前看起来还行：\n不得不说这个文件夹样式效果真好：\n偶尔出现卡顿，之后记录","title":"Mac体验版","type":"笔记"},{"content":"","date":"14 March 2024","externalUrl":null,"permalink":"/tags/%E7%AC%94%E8%AE%B0/","section":"Tags","summary":"","title":"笔记","type":"tags"},{"content":"\r目的：使用爬虫爬取都应指定视频下方的所有评论 #\r接电商小公司的面试需求\n参考视频\n知道了爬虫的基本原理是模仿正常用户的操作获取相关信息，下面是实际操作的记录\n过程：\n先是去抖音网站获取评论的api接口，拉取下来后使用ApiPost测试发现返回\u0026quot;block\u0026quot;阻塞信息 而后添加了相关请求头，发现加入User-Agent是关键信息 然而每次获取不同的视频发现有更改的参数：XBogus，这个参数是网站后台通过函数循环调用自己生成的（反爬） 遂通过浏览器断点调试最终追踪堆栈到生成函数： function _0x5a8f25(_0x48914f, _0xa771aa) { return (\u0026#39;undefined\u0026#39; == typeof window ? global : window)[\u0026#39;_$webrt_1668687510\u0026#39;](args) } 于是通过Node调试js文件，模拟循环过程生成参数 window = global; document = { refferer:\u0026#39;https://www.baidu.com/\u0026#39; } document.addEventListener=function (){} navigator={ userAgent:\u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\u0026#39; } document.addEventListener=function (){} window.rainy=_0x5a8f25; 其实这里就已经涉及到js逆向的知识了，当时不知道 于是在python中编写代码如下 import csv import execjs import requests # 执行js脚本 ctx = execjs.compile(open(\u0026#39;js/Run.js\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;gbk\u0026#39;).read()) # 2个必须加入的参数 header = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 \u0026#39; \u0026#39;Safari/537.36\u0026#39;, \u0026#39;Referer\u0026#39;: \u0026#39;https://www.douyin.com/\u0026#39; } # 测试发现最多只能查询50页 cursor = input(\u0026#34;输入起始查询分页数\u0026#34;) count = input(\u0026#34;输入终止查询分页数\u0026#34;) url = (\u0026#39;https://www.douyin.com/aweme/v1/web/comment/list/?\u0026#39;) # 比较发现三个参数 需要单独分析 # x-bos,token,cursor # aweme_id为作品id arg1 = (\u0026#39;device_platform=webapp\u0026amp;aid=6383\u0026amp;channel=channel_pc_web\u0026amp;aweme_id=7331940186147933474cursor=\u0026#39; + str(cursor) + \u0026#39;\u0026amp;count=\u0026#39; + str(count) + \u0026#39;\u0026amp;item_type=0\u0026amp;insert_ids=\u0026amp;whale_cut_token=\u0026amp;cut_version=1\u0026amp;rcFT=\u0026amp;pc_client_type=1\u0026amp;version_code=170400\u0026#39; \u0026#39;\u0026amp;version_name=17.4.0\u0026amp;cookie_enabled=true\u0026amp;screen_width=1707\u0026amp;screen_height=1067\u0026amp;browser_language=zh-CN\u0026#39; \u0026#39;\u0026amp;browser_platform=Win32\u0026amp;browser_name=Chrome\u0026amp;browser_version=122.0.0.0\u0026amp;browser_online=true\u0026amp;engine_name=Blink\u0026#39; \u0026#39;\u0026amp;engine_version=122.0.0.0\u0026amp;os_name=Windows\u0026amp;os_version=10\u0026amp;cpu_core_num=8\u0026amp;device_memory=8\u0026amp;platform=PC\u0026amp;downlink\u0026#39; \u0026#39;=1.35\u0026amp;effective_type=3g\u0026amp;round_trip_time=550\u0026amp;webid=7331622910048732683\u0026amp;msToken=hqxyFiEvhisE9d09ik0BsoXlpZs49u8r\u0026#39; \u0026#39;-WVP6f7rWmZs8QtFKXsKT2V7jPuo0x3IgvGbFDdvE6gAb1VCZWFYN_0qL_8qP8jSFGVaBJKqbC8noxhnjfdXLDQ1ofFR\u0026amp;\u0026#39;) xb = arg1 + \u0026#39;\u0026amp;XBogus=\u0026#39; + ctx.call(\u0026#39;window.rainy\u0026#39;, arg1) url += xb print(url) response = requests.request(\u0026#39;GET\u0026#39;, url, headers=header) json_data = response.json() # 获取json数据 text = json_data[\u0026#39;comments\u0026#39;] #类型为list # print(type(text)) # 遍历 list集合 user = [] columns = [\u0026#39;用户\u0026#39;, \u0026#39;评论\u0026#39;] data = { \u0026#39;用户\u0026#39;: [], \u0026#39;评论\u0026#39;: [] } with open(\u0026#39;results/comment.csv\u0026#39;, \u0026#39;w\u0026#39;, newline=\u0026#39;\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as file: writer = csv.writer(file) # 写入标题行，只包含指定的列 writer.writerow([col for col in columns]) for item in text: data[\u0026#39;评论\u0026#39;].append(item[\u0026#39;text\u0026#39;]) print(item[\u0026#39;text\u0026#39;]) # 获取评论用户 user.append(item[\u0026#39;user\u0026#39;]) for item in user: data[\u0026#39;用户\u0026#39;].append(item[\u0026#39;nickname\u0026#39;]) print(item[\u0026#39;nickname\u0026#39;]) for row in zip(*(data[col] for col in columns)): writer.writerow(row) 测试结果：\n其他调试过程：\n测试视频\n爬取测试对象：\n测试链接\n发现在断点处生成了xbox\n日志断点打印找到了xbogs\n获取成功：\n这种方式的爬取效率太低，遂尝试\rgithub项目爬取 #\r负责人要求爬取推荐关键词的爬取，同时提到了代理这个说法，貌似是一个加大爬取量的东西，恰好这个项目里面有\n发现效果非常好：\n甚至模拟了扫码登陆这样的功能，不过看原理应该是使用python的内置浏览器模拟方法。后续有时间继续研究代理方法（不过需要付费看起来）\n","date":"13 March 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E7%88%AC%E8%99%AB/","section":"笔记s","summary":"目的：使用爬虫爬取都应指定视频下方的所有评论 #\r接电商小公司的面试需求\n参考视频\n知道了爬虫的基本原理是模仿正常用户的操作获取相关信息，下面是实际操作的记录\n过程：\n先是去抖音网站获取评论的api接口，拉取下来后使用ApiPost测试发现返回\u0026quot;block\u0026quot;阻塞信息 而后添加了相关请求头，发现加入User-Agent是关键信息 然而每次获取不同的视频发现有更改的参数：XBogus，这个参数是网站后台通过函数循环调用自己生成的（反爬） 遂通过浏览器断点调试最终追踪堆栈到生成函数： function _0x5a8f25(_0x48914f, _0xa771aa) { return (\u0026#39;undefined\u0026#39; == typeof window ? global : window)[\u0026#39;_$webrt_1668687510\u0026#39;](args) } 于是通过Node调试js文件，模拟循环过程生成参数 window = global; document = { refferer:\u0026#39;https://www.","title":"爬虫浅记","type":"笔记"},{"content":"\rWaline博客网站评论 #\r注册账号 #\r注册账号✈️\n创建应用✈️\n创建仓库-》用于存放评论\n创建好之后，去到settings里面修改Environment三个参数\nLEAN_ID：AppId LEAN_KEY：App_key LEAN_MASTER_KEY：Master_KEY\n添加好之后，刷新工作流\n通过HTML部署\n导入样式文件和js脚本文件\n通过Waline的配置键添加自定义的东西\n注：\r借鉴自金圣浩\n\u0026lt;br/\u0026gt; \u0026lt;span style=\u0026#34;color:rgba(var(--color-neutral-400),var(--tw-text-opacity));\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;post-meta-item-text\u0026#34; \u0026gt;\u0026amp;nbsp;\u0026amp;nbsp;{{i18n \u0026#34;article.page_views\u0026#34;}}: \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;waline-pageview-count\u0026#34;\u0026gt;⏳\u0026lt;/span\u0026gt;\u0026lt;div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; document.getElementByClassName(\u0026#34;aline-pageview-count\u0026#34;)[0].data-path = window.location.pathname; \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#39;/waline/waline.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt;\u0026lt;!-- @v2.18 --\u0026gt; \u0026lt;link href=\u0026#39;/waline/waline.css\u0026#39; rel=\u0026#39;stylesheet\u0026#39; /\u0026gt; \u0026lt;div id=\u0026#34;vcomments\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; if ({{i18n \u0026#34;lanString\u0026#34;}}==\u0026#34;zh-CN\u0026#34;) { Waline.init({ el: \u0026#39;#vcomments\u0026#39;, serverURL: \u0026#39;你的评论网站服务器\u0026#39;, emoji: [\u0026#39;https://valine-emoji.bili33.top/bilibilitv\u0026#39;,\u0026#39;https://valine-emoji.bili33.top/bilibiliHotKey\u0026#39;,\u0026#39;https://valine-emoji.bili33.top/Tieba-New\u0026#39;,\u0026#39;https://valine-emoji.bili33.top/weibo\u0026#39;,], meta:[\u0026#39;nick\u0026#39;, \u0026#39;mail\u0026#39;, \u0026#39;link\u0026#39;], pageview: true, reaction: true, lang: \u0026#34;zh-CN\u0026#34;, /* 下面的可以自定义 */ locale: { reactionTitle: \u0026#39;•畅所欲言——这里是开放区•\u0026#39;, comment: \u0026#39;留言板\u0026#39;, placeholder: \u0026#39;点击下方登录后再评论，会有惊喜哦~\u0026#39;, gifSearchPlaceholder: \u0026#39;搜索表情包...\u0026#39;, admin: \u0026#39;作者\u0026#39;, sofa: \u0026#39;还没有人评论，快来抢沙发吧\u0026#39;, anonymous: \u0026#39;匿名者\u0026#39; } }); } else { Waline.init({ el: \u0026#39;#vcomments\u0026#39;, serverURL: \u0026#39;你的评论网站服务器\u0026#39;, emoji: [\u0026#39;https://valine-emoji.bili33.top/bilibilitv\u0026#39;,\u0026#39;https://valine-emoji.bili33.top/bilibiliHotKey\u0026#39;,\u0026#39;https://valine-emoji.bili33.top/Tieba-New\u0026#39;,\u0026#39;https://valine-emoji.bili33.top/weibo\u0026#39;,], meta:[\u0026#39;nick\u0026#39;, \u0026#39;mail\u0026#39;], pageview: true, reaction: true, // lang:{{i18n \u0026#34;lanString\u0026#34;}}, lang: \u0026#34;zh-CN\u0026#34;, locale: { reactionTitle: \u0026#39;•畅所欲言——这里是开放区•\u0026#39;, comment: \u0026#39;留言板\u0026#39;, placeholder: \u0026#39;点击下方登录后再评论，会有惊喜哦~\u0026#39;, gifSearchPlaceholder: \u0026#39;搜索表情包...\u0026#39;, admin: \u0026#39;作者\u0026#39;, sofa: \u0026#39;还没有人评论，快来抢沙发吧\u0026#39;, anonymous: \u0026#39;匿名者\u0026#39; } }); } document.getElementsByClassName(\u0026#39;wl-power\u0026#39;)[0].style.display = \u0026#39;none\u0026#39;; document.querySelector(\u0026#34;.wl-actions a\u0026#34;).style.display = \u0026#39;none\u0026#39; \u0026lt;/script\u0026gt; \u0026lt;style type=\u0026#34;text/css\u0026#34;\u0026gt; :root{ --waline-color: var(--tw-prose-quotes); --waline-info-color: var(--tw-prose-quotes); --waline-info-bgcolor: var(--tw-ring-color); --waline-theme-color: rgba(var(--color-primary-400)); --waline-bgcolor: transparent; --waline-border-color: #747474; } .wl-editor:focus, .wl-input:focus { background: transparent; } .wl-editor,.wl-input{ max-width:88%; } .wl-reaction-item.active .wl-reaction-votes { color: white; } \u0026lt;/style\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var pagect = document.getElementById(\u0026#39;pagec\u0026#39;); var observer = new MutationObserver(function(){ var itl,itll; var element = document.getElementById(\u0026#34;pagec\u0026#34;); observer.disconnect(); itl = element.innerText; itll = Number(itl).toLocaleString(); document.getElementById(\u0026#39;pagec\u0026#39;).innerHTML = itll; }); var article = document.getElementById(\u0026#39;pagec\u0026#39;); var options = { \u0026#39;childList\u0026#39;: true, \u0026#39;subtree\u0026#39;: true }; observer.observe(article, options); \u0026lt;/script\u0026gt; ","date":"11 March 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E6%80%8E%E4%B9%88%E8%AF%84%E8%AE%BA/","section":"笔记s","summary":"Waline博客网站评论 #\r注册账号 #\r注册账号✈️\n创建应用✈️\n创建仓库-》用于存放评论\n创建好之后，去到settings里面修改Environment三个参数\nLEAN_ID：AppId LEAN_KEY：App_key LEAN_MASTER_KEY：Master_KEY\n添加好之后，刷新工作流\n通过HTML部署\n导入样式文件和js脚本文件\n通过Waline的配置键添加自定义的东西\n注：\r借鉴自金圣浩\n\u0026lt;br/\u0026gt; \u0026lt;span style=\u0026#34;color:rgba(var(--color-neutral-400),var(--tw-text-opacity));\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;post-meta-item-text\u0026#34; \u0026gt;\u0026amp;nbsp;\u0026amp;nbsp;{{i18n \u0026#34;article.page_views\u0026#34;}}: \u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;waline-pageview-count\u0026#34;\u0026gt;⏳\u0026lt;/span\u0026gt;\u0026lt;div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; document.","title":"Waline评论系统","type":"笔记"},{"content":"\r基础知识 #\rHash是什么，有哪些常见的hash定址法 #\r散列表算法希望能尽量做到不经过任何比较，通过一次存取就能得到所查找的数据元素 ，因而必 须要在数据元素的存储位置和它的关键字（可用 key 表示）之间建立一个确定的对应关系，使每个 关键字和散列表中一个唯一的存储位置相对应。因此在查找时，只要根据这个对应关系找到给定 关键字在散列表中的位置即可。这种对应关系被称为散列函数(可用 h(key)表示)。\n1）直接定址法： 取关键字或关键字的某个线性函数值为散列地址。 即：h(key) = key 或 h(key) = a * key + b，其中 a 和 b 为常数。 （2）数字分析法 （3）平方取值法： 取关键字平方后的中间几位为散列地址。 （4）折叠法：将关键字分割成位数相同的几部分，然后取这几部分的叠加和作为散列地址。 （5）除留余数法：取关键字被某个不大于散列表表长 m 的数 p 除后所得的余数为散列地址， 即：h(key) = key MOD p p ≤ m （6）随机数法：选择一个随机函数，取关键字的随机函数值为它的散列地址， 即：h(key) = random(key) 什么是排序二叉树 #\r首先如果普通二叉树每个节点满足：左子树所有节点值小于它的根节点值，且右子树所有节点值 大于它的根节点值，则这样的二叉树就是排序二叉树\n为什么要重写hashcode和equals方法 #\r回答：因为类本省的这两个方法调用时都只是去比较对象的内存地址，当我们new两个相同内容的对象，本来是要比较返回true的但是不重写的话比较 内存返回false，造成错误，故而需要重写这两个方法\n什么是深拷贝和浅拷贝 #\r浅拷贝：简单的赋值拷贝操作\n深拷贝：在堆区重新申请空间，进行拷贝操作\nArrayList和LinkedList区别 #\r回答都实现了List接口作为数据存储管理的容器，场景上Arraylist内部通过动态数组实现，实现快速的随机访问，适用于频繁的读取操作，移动操作性能低， 不支持同步，线程不安全。LinkedList内部双向链表实现，适合插入删除操作，支持作为队列使用（因为实现了Deque接口），同样线程不安全，单线程性能较好。\nHashMap缺点 #\r在JDK1.7和JDK1.8中的HashMap的默认初始容量为16，loadFactor均为0.75。\n参考文章\n回答线程不安全，没有内置读写锁，头插产生死循环，put会覆盖，并发情况put/get可能为空\n头插法/尾插法 #\r（jdk1.7）头插在尾部追加元素，（jdk1.8）尾插法，链表长度大于等于8转化红黑树，判断Map键值对数量超过64\nHashTable为什么线程安全 #\r回答remove，put，get都是同步的方法（synchronized关键字），底层通过数组+链表实现，只允许一个线程对其进行某种操作，所以并发性比ConcurrnetHashMap差\nConcurrentHashMap线程安全原因 #\rjdk1.7对每个segment（段）加分段锁（ReentrantLock）实现段隔离保证并发安全 ，最多存在16个段\njdk1.8不再使用段，使用结点（Node）和CAS，Synchronized保证线程安全\nConcurrentHashMap能保证多个线程同时进行put操作后数据不会错乱，而HashMap在多个线程同时进行put操作后数据会错乱结果无法预知。但是多线程同时操作get方法和put方式时，就无法保证并发线程安全。\ntoken无感刷新 #\r用户登录成功后，服务器会生成一个Token，并将其颁发给客户端。 前端会保存这个Token，并在每次请求时将其添加到请求头中，通常是Authorization字段。 后端服务器使用密钥对Token进行签名，以确保其真实性和完整性。 如果Token即将过期，后端服务器会在响应中返回一个新的Token，并将其作为响应头的一部分。 前端的拦截器会检查响应中是否存在新的Token，并将它保存在本地。 在后续的请求中，前端会继续使用最新的Token进行身份验证 双Token机制 #\rAccess Token：用于获取访问资源或执行操作的授权，有效期短。客户端发送请求时，在请求头携带此accessToken。 Refresh Token：用来验证用户的身份，刷新accessToken，有效期长。当accessToken过期时，向服务端传递refreshToken来刷新accessToken。 布隆过滤器 #\r名叫 Bloom 的人提出了一种来检索元素是否在给定大集合中的数据结构，这种数据结构是高效且性能很好的，但缺点是具有一定的错误识别率和删除难度。并且，理论情况下，添加到集合中的元素越多，误报的可能性就越大。\n参考文章\nMq使用场景 #\r异步解耦： 耗时而且不需要即时返回结果的操作。将这些操作可以做为「异步处理」，这样可以大大的加快请求的响应时间\n微服务解耦：独立服务作为微服务，通过Mq实现App通信。\n流量削峰填谷：MQ，可以将需要处理的消息全部放入其中，系统按照最大处理能力，去获取消息进行消费，这样就可以将一瞬间过来的请求，分散到一段时间内进行处理，避免了系统的崩溃。\n消息分发：监听服务自己需要的消息\n分布式事务的数据一致性：已被Seata取代\n算法 #\r1.\r前序遍历二叉树\n强化八股文的方向，感谢\r学院同学的帮助：\n原文链接\nvolatile 关键字 保证变量的可见性 #\r带了这个关键字的变量JMM会把该线程本地内存中的变量强制刷新到主内存中去，并且这个写会操作会导致其他线程中的volatile变量缓存无效，这样，另一个线程修改了这个变时，当前线程会立即得知，并将工作内存中的变量更新为最新的版本\n底层实现：内存屏障\n内存屏障（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个：\n保证特定操作的顺序 保证某些变量的内存可见性（volatile的内存可见性，其实就是依靠这个实现的） 由于编译器和处理器都能执行指令重排的优化，如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序。\n所以volatile能够保证，之前的指令一定全部执行，之后的指令一定都没有执行，并且前面语句的结果对后面的语句可见。\n最后我们来总结一下volatile关键字的三个特性：\n原子性：其实之前讲过很多次了，就是要做什么事情要么做完，要么就不做，不存在做一半的情况。 可见性：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：即程序执行的顺序按照代码的先后顺序执行。\n保证可见性 不保证原子性 防止指令重排 最容易理解：\nprivate static volatile int a = 0; public static void main(String[] args) throws InterruptedException { new Thread(() -\u0026gt; { while (a == 0); System.out.println(\u0026#34;线程结束！\u0026#34;); }).start(); Thread.sleep(1000); System.out.println(\u0026#34;正在修改a的值...\u0026#34;); a = 1; } 线程池： #\r类：ThreadPoolExecutor\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 七个参数的实际意义：\ncorePoolSize：核心线程池大小，我们每向线程池提交一个多线程任务时，都会创建一个新的核心线程，无论是否存在其他空闲线程，直到到达核心线程池大小为止，之后会尝试复用线程资源。当然也可以在一开始就全部初始化好，调用prestartAllCoreThreads()即可。 maximumPoolSize：最大线程池大小，当目前线程池中所有的线程都处于运行状态，并且等待队列已满，那么就会直接尝试继续创建新的非核心线程运行，但是不能超过最大线程池大小。 keepAliveTime：线程最大空闲时间，当一个非核心线程空闲超过一定时间，会自动销毁。 unit：线程最大空闲时间的时间单位 workQueue：线程等待队列，当线程池中核心线程数已满时，就会将任务暂时存到等待队列中，直到有线程资源可用为止，这里可以使用我们上一章学到的阻塞队列。 threadFactory：线程创建工厂，我们可以干涉线程池中线程的创建过程，进行自定义。 handler：拒绝策略，当等待队列和线程池都没有空间了，真的不能再来新的任务时，来了个新的多线程任务，那么只能拒绝了，这时就会根据当前设定的拒绝策略进行处理。 比如我们可以自定也这样的一个线程：\nThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, //2个核心线程，最大线程数为4个 3, TimeUnit.SECONDS, //最大空闲时间为3秒钟 new ArrayBlockingQueue\u0026lt;\u0026gt;(2)); //这里使用容量为2的ArrayBlockingQueue队列 如何实现定时任务？ #\r回答可以通过Spring自带的Scheduled定时计划和juc里面的Timertask\n线程池能不能执行定时任务呢？我们之前如果需要执行一个定时任务，那么肯定会用到Timer和TimerTask， 但是它只会创建一个线程处理我们的定时任务，无法实现多线程调度，并且它无法处理异常情况一旦抛出未捕获异常那么会直接终止，显然我们需要一个更加强大的定时器。\nJDK5之后，我们可以使用ScheduledThreadPoolExecutor来提交定时任务，它继承自ThreadPoolExecutor，并且所有的构造方法都必须要求最大线程池容量为Integer.MAX_VALUE，并且都是采用的DelayedWorkQueue作为等待队列。\n如何使用线程并发工具类CountDownLatch？ #\r说一下双亲委派机制 #\r当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父 类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中， 只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的 Class），子类加载器才会尝试自己去加载。 采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载 器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载 器最终得到的都是同样一个 Object 对象。\n线程的生命周期 #\r线程经历五个生命周期：创建，就绪，运行，阻塞，消亡\n创建：线程的new方法\n就绪：调用start方法之后，将被JVM进行初始化\n运行：调用run方法\n阻塞：线程主动放弃对线程资源的掌控\n消亡：直接调用该线程的 stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用\n线程操作的基本方法：线程相关的基本方法有 wait，notify，notifyAll，sleep，join，yield 等\nSpring事务传播机制： #\r事务传播的定义： #\r事务传播行为主要用来描述由某一个事务传播行为修饰的方法被嵌套进另一个方法的事务中，该 事务如何传播。这个概述可能不好理解，换句话就是当一个事务方法被另一个事务方法调用时，这个事务方法应该如何进行。\nspring中的事务级别#\nREQUIRED #\rREQUIRED是Spring默认的传播机制。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新事务。 REQUIRED传播机制最常用的情况是在一个事务 中进行多个操作，要么全部成功，要么全部失败。如果其中一个操作失败，整个事务都将被回滚。\nSUPPORTS #\rSUPPORTS传播机制表示当前方法如果在一个事务中被调用，则加入该事务； 否则，以非事务的方式运行。SUPPORTS传播机制适用于对事务要求不高的操作，例如读取操作。\nMANDATORY #\rMANDATORY传播机制表示当前方法必须在一个事务中被调用，否则将抛出异常。 MANDATORY传播机制适用于在需要事务的情况下调用方法。\nREQUIRES_NEW #\rREQUIRES_NEW传播机制表示当前方法必须开启一个新事务运行，如果当前存在事务，则挂起该事务。 REQUIRES_NEW传播机制适用于对事务要求较高的操作，例如更新操作。\nNOT_SUPPORTED #\rNOT_SUPPORTED传播机制表示当前方法不应该在事务中运行，如果存在事务，则挂起该事务。 NOT_SUPPORTED传播机制适用于对事务没有要求的操作，例如日志记录等。\nNEVER #\rNEVER传播机制表示当前方法不应该在事务中运行，如果存在事务，则抛出异常。 NEVER传播机制适用于禁止在事务中运行的操作，例如安全检查等。\nNESTED #\rNESTED传播机制表示当前方法必须在一个嵌套事务中运行，如果当前存在事务，则在该事务内开启一个嵌套事务；如果当前没有事务，则创建一个新事务。 NESTED传播机制适用于需要分步操作的场景，例如订单中创建订单和订单项的操作。\n除了事务传播机制，Spring还提供了事务隔离级别和超时设置等事务管理功能，可以更加细粒度地控制事务。例如，可以根据业务需求选择适当的事务隔离级别， 避免数据不一致等问题；也可以设置事务超时时间，避免长时间占用数据库资源。\nSpring配置声明式事务 #\r配置DataSource 配置事务管理器 事务的传播特性 那些类那些方法使用事务 DataSource、TransactionManager这两部分只是会根据数据访问方式有所变化，比如使用Hibernate进行数据访问 时，DataSource实际为SessionFactory，TransactionManager的实现为 HibernateTransactionManager。\n根据代理机制的不同，Spring事务的配置又有几种不同的方式：\n第一种方式：每个Bean都有一个代理 * 第二种方式：所有Bean共享一个代理基类 * 第三种方式：使用拦截器 * 第四种方式：使用tx标签配置的拦截器 * 第五种方式：全注解 1、spring事务控制放在service层，在service方法中一个方法调用service中的另一个方法，默认开启几个事务？\nspring的事务传播方式默认是PROPAGATION_REQUIRED，判断当前是否已开启一个新事务，有则加入当前事务，否则新开一个事务（如果没有就开启一个新事务），所以答案是开启了一个事务。\n2、spring 什么情况下进行事务回滚？\nSpring、EJB的声明式事务默认情况下都是在抛出unchecked exception后才会触发事务的回滚\nunchecked异常,即运行时异常runntimeException 回滚事务;\nchecked异常,即Exception可try{}捕获的不会回滚.当然也可配置spring参数让其回滚.\nspring的事务边界是在调用业务方法之前开始的，业务方法执行完毕之后来执行commit or rollback(Spring默认取决于是否抛出runtime异常). 如果抛出runtime exception 并在你的业务方法中没有catch到的话，事务会回滚。 一般不需要在业务方法中catch异常，如果非要catch，在做完你想做的工作后（比如关闭文件等）一定要抛出runtime exception，否则spring会将你的操作commit,这样就会产生脏数据.所以你的catch代码是画蛇添足。\nMysql中数据隔离机制 #\r数据隔离机制 脏读 不可重复读 幻读 串行化 不会 不会 不会 可重复读 不会 不会 会 读已提交 不会 会 会 读未提交 会 会 会 此外，添加DEFAULT 使用数据库设置的隔离级别 ( 默认 ) ，由 DBA 默认的设置来决定隔离级别.这就组成了Spring的事务隔离机制\n注意：\n脏读 :所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。\n不可重复读 ：不可重复读字面含义已经很明了了，比如事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。\n幻读: 事务A首先根据条件索引得到10条数据，然后事务B改变了数据库一条数据，导致也符合事务A当时的搜索条件，这样事务A再次搜索发现有11条数据了，就产生了幻读。\n说一下Java里面你认识的锁 #\r乐观锁：\n乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为 别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数 据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新）， 如果失败则要重复读-比较-写的操作。 java 中的乐观锁基本都是通过 CAS 操作实现的，CAS 是一种更新的原子操作，比较当前值跟传入 值是否一样，一样则更新，否则失败\n悲观锁：\n悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人 会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会 block 直到拿到锁。 java 中的悲观锁就是 Synchronized,AQS 框架下的锁则是先尝试 cas 乐观锁去获取锁，获取不到， 才会转换为悲观锁，如 RetreenLock。\n自旋锁：\n如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁 的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋）， 等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。\n优点：一定程度上减少了线程阻塞拥堵的情况\n缺点：cpu无用功\n计算机网络TCP #\r说一下一次完整的HTTP请求过程包含的步骤？\n进行域名解析 发起TCP3次握手建立连接 客户端发起http请求 服务器响应请求，返回HTML代码 客户端解析代码，并请求HTML代码中包含的资源【JS、CSS、图片等】 浏览器对页面进行渲染 4次挥手断开连接 什么是dns？\nDNS即域名系统，是IP地址与域名相互映射的分布式数据库。主要功能是域名解析，即能根据域名解析出对应的IP地址。DNS属于应用层协议，使用UDP进行通信。\n为什么dns使用的是udp协议？\n因为UDP工作方式简单方便，只需一次请求、一次响应即可完成解析工作。 而使用TCP需要三次握手建立连接、请求与应答、四次挥手等操作，复杂且耗时长。 UDP传输内容最大不能超过512字节，但是对于域名解析来说已经足够。\n五层协议 ：物理层，数据链路层，网路层，传输层，应用层\n停止等待协议信道利用率：\n数据分组发送时延TD\n确认分组发送时延TA\n收发双方（单程发送时延x2）RTT\n信道利用率=（TD）/(TD+RTT+TA)\n为了提升信道传输效率，接收方不必每次接收数据都发送ACK接收\n回退N帧协议（滑动窗口协议）：使用指针动态调整窗口大小，滑动向前或者回退，限制窗口大小之类的 当发现出错的数据时将会退回已发送的N个数据分组\n发生超时重传，或者接收方接收到误码主动丢弃需要发送方再次发送之后才会继续滑动窗口\n网络适配器（网卡）：实现了串行通信和并行通信的转换，网络与主机，主机内部的通信是并行高速通信，但到达物理层应该使用的串行通信到局域网\nmac地址：硬件地址或者叫物理地址 ，固化在网卡里面\n网际协议（IP）：作为TCP/IP体系结构网络层里面的核心协议-IPv4\n配套的四个协议：\n地址解析协议，逆地址解析协议，网际控制报文协议，网际组管理协议\nIPv4地址编址方式：\n分类编址：\n网络号，主机号，分为A-E五类\n说明线程和进程之间的区别 #\r进程是执行的应用程序，线程是进程内部的执行序列，线程又称为轻量级进程\n区别：\n进程之间相互独立，进程内的线程独立共享，进程外则隔离 进程间通信IPC，线程之间可以直接读写 进程数据段实现通信 线程上下文切换比进程上下文切换更快 多线程OS中，进程不是一个可执行的实体。 线程的几个状态：\n同步方法和同步代码块的区别是什么？\n同步方法默认用this或者当前类class对象作为锁； 同步代码块可以选择以什么来加锁，比同步方法要更细颗粒度，我们可以选择只同步会发生同步问题的部分代码而不是整个方法； 同步方法使用关键字 synchronized修饰方法，而同步代码块主要是修饰需要进行同步的代码，用 synchronized（object）{代码内容}进行修饰；\n关于二叉树\n存储方式：\n链式存储： 线性存储：第i歌元素的子节点-\u0026gt; 左孩子为2i+1,右孩子为2i+2\n","date":"9 March 2024","externalUrl":null,"permalink":"/entire-note/%E9%9D%A2%E8%AF%95%E9%A2%98/%E9%9D%A2%E8%AF%95/","section":"Entire-notes","summary":"基础知识 #\rHash是什么，有哪些常见的hash定址法 #\r散列表算法希望能尽量做到不经过任何比较，通过一次存取就能得到所查找的数据元素 ，因而必 须要在数据元素的存储位置和它的关键字（可用 key 表示）之间建立一个确定的对应关系，使每个 关键字和散列表中一个唯一的存储位置相对应。因此在查找时，只要根据这个对应关系找到给定 关键字在散列表中的位置即可。这种对应关系被称为散列函数(可用 h(key)表示)。\n1）直接定址法： 取关键字或关键字的某个线性函数值为散列地址。 即：h(key) = key 或 h(key) = a * key + b，其中 a 和 b 为常数。 （2）数字分析法 （3）平方取值法： 取关键字平方后的中间几位为散列地址。 （4）折叠法：将关键字分割成位数相同的几部分，然后取这几部分的叠加和作为散列地址。 （5）除留余数法：取关键字被某个不大于散列表表长 m 的数 p 除后所得的余数为散列地址， 即：h(key) = key MOD p p ≤ m （6）随机数法：选择一个随机函数，取关键字的随机函数值为它的散列地址， 即：h(key) = random(key) 什么是排序二叉树 #\r首先如果普通二叉树每个节点满足：左子树所有节点值小于它的根节点值，且右子树所有节点值 大于它的根节点值，则这样的二叉树就是排序二叉树","title":"计算机科学基础","type":"entire-note"},{"content":"","date":"6 March 2024","externalUrl":null,"permalink":"/tags/nio/","section":"Tags","summary":"","title":"nio","type":"tags"},{"content":"\r通过NIO非阻塞式模型我们可以搭建一个Reactor-SubReactor-Handler的消息服务器 #\rnetty的三大基本组件是：buffer，channel，selector\n目的：\n主要目的是利用Selector选择器实现IO多路复用\n先来编写一下客户端，简单起见，只需要建立一个SocketChannel获取管道流传输数据\n/** * @author 春江花朝秋月夜 */ public class ClientReactor { public static void main(String[] args) { // 创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel =SocketChannel.open(newInetSocketAddress(\u0026#34;localhost\u0026#34;, 9000)); Scanner scanner = new Scanner(System.in)) { System.out.println(\u0026#34;已连接到服务端！\u0026#34;); while (true) { // 咱给它套个无限循环，这样就能一直发消息了 System.out.println(\u0026#34;请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); // 直接向通道中写入数据 channel.write(ByteBuffer.wrap(text.getBytes(StandardCharsets.UTF_8))); System.out.println(\u0026#34;已发送！\u0026#34;); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); // 直接从通道中读取数据 buffer.flip(); System.out.println(\u0026#34;收到服务器返回：\u0026#34; + new String(buffer.array(), 0, buffer.remaining())); } } catch (IOException e) { throw new RuntimeException(e); } } } 现在来考虑一下服务端模型\n由于是主从模式，先是有一个主Reactor作为请求接收器件，然后将任务代理给Sub-Reactor\n","date":"6 March 2024","externalUrl":null,"permalink":"/entire-note/netty/","section":"Entire-notes","summary":"通过NIO非阻塞式模型我们可以搭建一个Reactor-SubReactor-Handler的消息服务器 #\rnetty的三大基本组件是：buffer，channel，selector\n目的：\n主要目的是利用Selector选择器实现IO多路复用\n先来编写一下客户端，简单起见，只需要建立一个SocketChannel获取管道流传输数据\n/** * @author 春江花朝秋月夜 */ public class ClientReactor { public static void main(String[] args) { // 创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel =SocketChannel.open(newInetSocketAddress(\u0026#34;localhost\u0026#34;, 9000)); Scanner scanner = new Scanner(System.","title":"使用主从模式搭建一个Socket网络通信模型","type":"entire-note"},{"content":"","date":"5 March 2024","externalUrl":null,"permalink":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","section":"Tags","summary":"","title":"微服务","type":"tags"},{"content":"\r基于SpringCloudAlibaba+Nacos+Feign+Seata+Sentinel作为微服务路线叙述 #\r前言：本次SpringCloud微服务学习涉及NetFlix和Alibaba两不同版本，主要对应关系为：\n微服务原则：所有的服务都需要保证职责的单一原则\nSpringCloud作为一系列框架的有序集合，是SOA的延续\nSpringCloud Alibaba 是遵循SpringCloud来开发的套件，Nacos亦然\n服务注册和发现 #\rEureka #\rEureka能够自动注册并发现微服务，然后对服务的状态、信息进行集中管理，这样当我们需要获取其他服务的信息时，我们只需要向Eureka进行查询就可以了。\n通过Eureka服务器进行服务注册与发现，那么现在我们来看看，它的负载均衡到底是如何实现的，实际上之前演示的负载均衡是依靠LoadBalancer实现的。\n在2020年前的SpringCloud版本是采用Ribbon作为负载均衡实现，但是2020年的版本之后SpringCloud把Ribbon移除了，进而用自己编写的LoadBalancer替代。\n如何找到服务？\nNacos #\rNacos注册中心 #\r功能：\n服务注册发现 配置中心 服务元数据/实例元数据：可以用于流量控制（在实例的metadata（元数据）中加上标签信息。通过IRule获取Server列表并根据这些Server中元数据的标签信息决定路由情况） 局域网内服务信息传输快 服务集群分级模式\n服务-集群-实例\n修改yml：\nspring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: ClUSTER-01 对指定服务进行配置\n必须重写负载均衡的轮询规则才可以改变负载均衡规则（实现方式为注入Bean或yml配置）\n@Configuration @LoadBalancerClient(value = \u0026#34;userservice\u0026#34;, //指定为 userservice 服务，只要是调用此服务都会使用我们指定的策略 configuration = LoadBalancerConfig.class) //指定我们刚刚定义好的配置类 public class BeanConfig { @Bean @LoadBalanced RestTemplate template(){ return new RestTemplate(); } } 这样子就实现了对服务的指定负载均衡策略配置\n集群优先\nNacos优先访问本地集群，当本地集群宕机时，会发生跨集群访问，确定实例之后，会在本地实例中随机轮询\n权重负载均衡\n和Nginx差不多，通过更改集群中实例权重改变负载策略\n利用：将服务实例权重调为0~0.01,放入少量请求实现服务升级\n环境隔离\nnamespace\n相关度高时可以放入同一组\n不同namespace之间不可通过RPC相互调用！\n心跳检测\n临时实例挂掉直接剔除，非临时实例（主动检测）挂掉时，Nacos将会询问健康状况，同时挂起直到实例重启，同时主动发送服务实例变更消息 给服务调用方。Nacos采用CP，Eureka采用AP\nNacos配置管理 #\rData-ID：ServiceName-dev/pro.yaml\n依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 一般只在有热更新需求的配置加入 Nacos配置中心\n统一配置管理\n添加bootstrap.yml\n实现热更新\n注解@Refreshed\n配置文件根据不同环境，具有共享配置和dev/test配置文件等，配置优先级为远端\u0026gt;服务名\u0026gt;本地环境\n统一配置中心\n作为远端配置统一管理，本地可以直接fetch然后使用，提高维护性\n依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 负载均衡 #\rSpring实现了一套自己的负载均衡LoadBalancer. 实际上在进行负载均衡的时候，会向Eureka发起请求，选择一个可用的对应服务，然后会返回此服务的主机地址等信息,然后才进行实际的服务调用。\n负载均衡策略\n轮询策略 权重策略 随机策略 最小连接数策略（选择连接数最小的的服务实例） 重试策略（当服务实例尝试失败之后，尝试继续获取，若多次失败返回null） 可用性敏感策略（随机轮询，判断是否可用） 区域敏感策略（可用和不可用相互的分区中选取可用分区中的实例） 限流方案\nGuava RateLimiter：基于令牌桶算法限流，单机的。 Sentinel：基于滑动窗口、漏桶、令牌桶限流，支持单机，也支持集群。 Redission RateLimiter：令牌桶，支持单机，也支持集群。 添加依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-loadbalancer\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 自定义负载均衡策略 LoadBalancer默认提供了两种负载均衡策略：\nRandomLoadBalancer - 随机分配策略 (默认) RoundRobinLoadBalancer - 轮询分配策略\n服务名称-》 LoadBalancerInterceptor-\u0026gt; execute -》 通过轮询规则选择服务 -》返回服务名称以供调用\nRibbion懒加载\u0026amp;饥饿加载\n第一次加载耗时很长，然后将数据缓存\n配置饥饿加载\nribbon: eager-load: enabled: true clients: -service1 -service2 RPC远程调用 #\rFeign和RestTemplate一样，也是HTTP客户端请求工具，但是它的使用方式更加便捷。首先是依赖：\n不同于RestTemplate,Feign是自动集成Ribbon的，同时默认不重试\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; feign配置部分：\n添加接口：\n@FeignClient(\u0026#34;cloud_service\u0026#34;) public interface RoleClient { // List\u0026lt;Role\u0026gt; listRole=restTemplate.getForObject(\u0026#34;http://localhost:8066/cache/role/list?key=\u0026#34;+key,List.class); @GetMapping List\u0026lt;Role\u0026gt; getRoleCache(@RequestParam String key); } 性能优化解决方案\n使用HTTP连接池 关闭日志 @FeignClient(\u0026#34;cloud_service\u0026#34;) public interface RoleClient { @GetMapping List\u0026lt;Role\u0026gt; getRoleCache(@RequestParam String key); } Feign的最佳实践方式\n继承方式 RPC到达controller，声明方式和controller必须一样，注意实际开发在Feign调用中可能会对请求头中加入相关的鉴权信息\n一般不推荐继承方式，因为定义了同一接口，造成了紧耦合\n抽取Feign 独立出feign-api，模块 负责实体，配置等服务\n服务网关 #\r统一网关GateWay(基于WebFlux实现，有响应式编程的优势)\n服务网关是微服务架构中一个非常关键的角色，作为后端服务的统一入口，负责统筹和管理后端服务。能够提供的功能有路由功能、 负载均衡、安全认证、流量染色、灰度发布、限流熔断、协议转换、日志收集等\n基本作用：认证，校验，路由微服务请求，负载均衡，限流,路由过滤器\n工作原理：\n客户端向Spring Cloud Gateway发出请求。然后在Gateway Handler Mapping中找到与请求相匹配的路由， 将其发送到Gateway Web Handler。Gateway Web Handler再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。\n配置方法：\n\u0026lt;!-- 引入Gateway --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-gateway\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; spring: cloud: gateway: routes: - id: auth-center uri: lb://auth-center #加上lb代表负载均衡 predicates: - Path=/oauth #谓词判断依据 lb：固定格式，指的是从Nacos中按照名称获取微服务，并遵循负载均衡策略 service-name：Nacos注册中心的服务名称 通过重写过滤器实现自定义GateWay过滤器\n断言：\n简单架构：\n搭建网关\n适配器模式：将多个不同的接口实现顶级，变成希望的类或者属性\n过滤器执行顺序：\n装饰者模式\n网关跨域问题：\n实际上就是RPC的codec层面\n断路器 #\r微服务存在雪崩问题，也就是说一个微服务出现问题，有可能导致整个链路直接不可用，这种时候我们就需要进行及时的熔断和降级\nHystrix #\rHystrix断路器，已经停止维护\n依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-hystrix\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.10.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 服务失败转为服务降级，而后当服务多次调用失败后，将会发生服务熔断\nSentinel #\r随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点， 从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 可以实现的监控事项有：\n时间点、QPS(每秒查询率)、响应时间等数据。\n三种限流策略\n方案一：快速拒绝，既然不再接受新的请求，那么我们可以直接返回一个拒绝信息，告诉用户访问频率过高。 方案二：预热，依然基于方案一，但是由于某些情况下高并发请求是在某一时刻突然到来，我们可以缓慢地将阈值提高到指定阈值，形成一个缓冲保护。 方案三：排队等待，不接受新的请求，但是也不直接拒绝，而是进队列先等一下，如果规定时间内能够执行，那么就执行，要是超时就算了。 流量阈值的判断，这里我们提4种算法：\n漏桶算法，令牌桶算法，固定时间窗口算法，滑动时间窗口算法\n限流时，如果发生异常，可以有替代方案；\n注解:\n@SentinelResource(value = \u0026#34;test\u0026#34;, fallback = \u0026#34;except\u0026#34;, //fallback指定出现异常时的替代方案 exceptionsToIgnore = IOException.class) 思考： 服务降级时，新来的请求就会导致线程数不断地增加，这样，CPU的资源很快就会被耗尽。\n解决办法：\n对feign开启断路器\nfeign: sentinel: enabled: true 分布式事务 #\r单点登录 #\r参考文章：\rSpringSecurity-Oauth基于Spring3.x\n名词解释（UA）：user account and authentication\n请求流程图：\n客户端模式：\n密码模式：\n隐式授权模式\n授权码模式（目前采用的主流方案）：\n第三方登录Oauth2示意图：\n使用jwt存储Token\n官网：https://jwt.io\nJSON Web Token令牌（JWT）是一个开放标准（RFC 7519），它定义了一种紧凑和自成一体的方式，用于在各方之间作为JSON对象安全地传输信息。这些信息可以被验证和信任，因为它是数字签名的。 JWT可以使用密钥（使用HMAC算法）或使用RSA或ECDSA进行公钥/私钥对进行签名。 实际上，我们之前都是携带Token向资源服务器发起请求后，资源服务器由于不知道我们Token的用户信息，所以需要向验证服务器询问此Token的认证信息， 这样才能得到Token代表的用户信息，但是各位是否考虑过，如果每次用户请求都去查询用户信息，那么在大量请求下，验证服务器的压力可能会非常的大。而使用JWT之后，Token中会直接保存用户信息， 这样资源服务器就不再需要询问验证服务器，自行就可以完成解析，我们的目标是不联系验证服务器就能直接完成验证。 一个JWT令牌由3部分组成：标头(Header)、有效载荷(Payload)和签名(Signature)。在传输的时候，会将JWT的3部分分别进行Base64编码后用.进行连接形成最终需要传输的字符串。 标头：包含一些元数据信息，比如JWT签名所使用的加密算法，还有类型，这里统一都是JWT。 有效载荷：包括用户名称、令牌发布时间、过期时间、JWT ID等，当然我们也可以自定义添加字段，我们的用户信息一般都在这里存放。 签名：首先需要指定一个密钥，该密钥仅仅保存在服务器中，保证不能让其他用户知道。然后使用Header中指定的算法对Header和Payload进行base64加密之后的结果通过密钥计算哈希值，然后就得出一个签名哈希。这个会用于之后验证内容是否被篡改。 Base64（不是加密算法而是编码方式）： 就是包括小写字母a-z、大写字母A-Z、数字0-9、符号\u0026#34;+\u0026#34;、\u0026#34;/\u0026#34;一共64个字符的字符集（末尾还有1个或多个=用来凑够字节数），任何的符号都可以转换成这个字符集中的字符， 这个转换过程就叫做Base64编码，编码之后会生成只包含上述64个字符的字符串。相反，如果需要原本的内容，我们也可以进行Base64解码，回到原有的样子。 加密算法： 加密算法分为对称加密和非对称加密，其中**对称加密（Symmetric Cryptography）**比较好理解，就像一把锁配了两把钥匙一样，这两把钥匙你和别人都有一把，然后你们直接传递数据，都会把数据用锁给锁上， 就算传递的途中有人把数据窃取了，也没办法解密，因为钥匙只有你和对方有，没有钥匙无法进行解密，但是这样有个问题，既然解密的关键在于钥匙本身，那么如果有人不仅窃取了数据，而且对方那边的治安也不好， 于是顺手就偷走了钥匙，那你们之间发的数据不就凉凉了吗。 因此，**非对称加密（Asymmetric Cryptography）**算法出现了，它并不是直接生成一把钥匙，而是生成一个公钥和一个私钥，私钥只能由你保管，而公钥交给对方或是你要发送的任何人都行，现在你需要把数据传给对方， 那么就需要使用私钥进行加密，但是，这个数据只能使用对应的公钥进行解密，相反，如果对方需要给你发送数据，那么就需要用公钥进行加密，而数据只能使用私钥进行解密，这样的话就算对方的公钥被窃取，那么别人发给你的数据也没办法解密出来， 因为需要私钥才能解密，而只有你才有私钥。 因此，非对称加密的安全性会更高一些，包括HTTPS的隐私信息正是使用非对称加密来保障传输数据的安全（当然HTTPS并不是单纯地使用非对称加密完成的，感兴趣的可以去了解一下） 对称加密和非对称加密都有很多的算法，比如对称加密，就有：DES、IDEA、RC2，非对称加密有：RSA、DAS、ECC 不可逆加密算法： 常见的不可逆加密算法有MD5, HMAC, SHA-1, SHA-224, SHA-256, SHA-384, 和SHA-512, 其中SHA-224、SHA-256、SHA-384，和SHA-512我们可以统称为SHA2加密算法， SHA加密算法的安全性要比MD5更高，而SHA2加密算法比SHA1的要高，其中SHA后面的数字表示的是加密后的字符串长度，SHA1默认会产生一个160位的信息摘要。经过不可逆加密算法得到的加密结果，是无法解密回去的， 也就是说加密出来是什么就是什么了。本质上，其就是一种哈希函数，用于对一段信息产生摘要，以防止被篡改。 实际上这种算法就常常被用作信息摘要计算，同样的数据通过同样的算法计算得到的结果肯定也一样，而如果数据被修改，那么计算的结果肯定就不一样了。 ","date":"5 March 2024","externalUrl":null,"permalink":"/entire-note/spring/","section":"Entire-notes","summary":"基于SpringCloudAlibaba+Nacos+Feign+Seata+Sentinel作为微服务路线叙述 #\r前言：本次SpringCloud微服务学习涉及NetFlix和Alibaba两不同版本，主要对应关系为：\n微服务原则：所有的服务都需要保证职责的单一原则\nSpringCloud作为一系列框架的有序集合，是SOA的延续\nSpringCloud Alibaba 是遵循SpringCloud来开发的套件，Nacos亦然\n服务注册和发现 #\rEureka #\rEureka能够自动注册并发现微服务，然后对服务的状态、信息进行集中管理，这样当我们需要获取其他服务的信息时，我们只需要向Eureka进行查询就可以了。\n通过Eureka服务器进行服务注册与发现，那么现在我们来看看，它的负载均衡到底是如何实现的，实际上之前演示的负载均衡是依靠LoadBalancer实现的。\n在2020年前的SpringCloud版本是采用Ribbon作为负载均衡实现，但是2020年的版本之后SpringCloud把Ribbon移除了，进而用自己编写的LoadBalancer替代。\n如何找到服务？\nNacos #\rNacos注册中心 #\r功能：\n服务注册发现 配置中心 服务元数据/实例元数据：可以用于流量控制（在实例的metadata（元数据）中加上标签信息。通过IRule获取Server列表并根据这些Server中元数据的标签信息决定路由情况） 局域网内服务信息传输快 服务集群分级模式\n服务-集群-实例\n修改yml：\nspring: cloud: nacos: server-addr: localhost:8848 discovery: cluster-name: ClUSTER-01 对指定服务进行配置","title":"微服务基础知识","type":"entire-note"},{"content":"","date":"2 March 2024","externalUrl":null,"permalink":"/tags/oauth2/","section":"Tags","summary":"","title":"Oauth2","type":"tags"},{"content":"\r微信登录 #\r参考文章：\nVue生成二维码\n构建微信登录服务器 验证后端\n微信开发公众平台\n效果展示： #\r通过前端生成的二维码：\n前端部分（使用Dom来创建script节点）： #\rcreateWxLoginQrCode(){ const script=document.createElement(\u0026#39;script\u0026#39;); script.type=\u0026#39;text/javascript\u0026#39;; script.src=\u0026#39;https://res.wx.qq.com/connect/zh_CN/htmledition/js/wxLogin.js\u0026#39;; const wxElement = document.body.appendChild(script) wxElement.onload = function () { var obj = new WxLogin({ id: \u0026#39;wxLoginCode\u0026#39;, // 需要显示的容器id appid: \u0026#39;\u0026#39;,// 公众号appid wx******* scope: \u0026#39;snsapi_login\u0026#39;, // 网页默认即可 redirect_uri: encodeURIComponent(\u0026#39; \u0026#39;), // 授权成功后回调的url state: Math.ceil(Math.random() * 1000), // 可设置为简单的随机数加session用来校验 style: \u0026#39;black\u0026#39;, // 提供\u0026#34;black\u0026#34;、\u0026#34;white\u0026#34;可选。二维码的样式 href: \u0026#39;\u0026#39; // 外部css文件url，需要https }) } } }, mounted(){ this.createQrcode(); this.createWxLoginQrCode(); } } 微信服务器验证部分 #\r/** * WeiXinLoginController 关于微信登录以及二维码返回的所有控制路由 * * @author 春江花朝秋月夜 * @since 2024/3/2 23:19 */ @Slf4j @RestController @RequestMapping(\u0026#34;/weixin\u0026#34;) public class WeiXinLoginController { @Resource WeXinConfigProperties weXinConfigProperties; @GetMapping(\u0026#34;/wxLogin\u0026#34;) public void wxLoginPage(HttpServletResponse response) throws Exception{ String hostAddr = weXinConfigProperties.getHOST_ADDR(); String redirectUrl = URLEncoder.encode(hostAddr+\u0026#34;/weixin/wxCallBack\u0026#34;, StandardCharsets.UTF_8); //该请求用于获取code，获取code之后会重定向到redirectUrl获取token String url = \u0026#34;https://open.weixin.qq.com/connect/oauth2/authorize?appid=wxd10c3f9e60b4e00b\u0026amp;redirect_uri=\u0026#34; +redirectUrl+\u0026#34;\u0026amp;response_type=code\u0026amp;scope=snsapi_userinfo\u0026amp;state=STATE#wechat_redirect\u0026#34;; response.setContentType(\u0026#34;image/png\u0026#34;); //Hutool用于生成登录二维码 QrCodeUtil.generate(url,300,300,\u0026#34;jpg\u0026#34;,response.getOutputStream()); } @Resource WeiXinUtil weiXinUtil; //用上一步获取的code去获取token //代理的路径，实际处理code是在WeiXinLoginUser userInfo = weiXinUtil.getUserInfo(code);方法中 @GetMapping(\u0026#34;/wxCallBack\u0026#34;) public String pcCallback(String code, String state, HttpServletRequest request, HttpServletResponse response, HttpSession session) throws IOException { log.info(\u0026#34;登录跳转请求：{}\u0026#34;,request.getRequestURI()); WeiXinLoginUser userInfo = weiXinUtil.getUserInfo(code); return JSONUtil.toJsonStr(userInfo); } //微信检查方案： // 开发者通过检验signature对请求进行校验（下面有校验方式）。若确认此次GET请求来自微信服务器，请原样返回echostr参数内容，则接入生效，成为开发者成功，否则接入失败。加密/校验流程如下： // //1）将token、timestamp、nonce三个参数进行字典序排序 // //2）将三个参数字符串拼接成一个字符串进行sha1加密 // //3）开发者获得加密后的字符串可与signature对比，标识该请求来源于微信 @RequestMapping(\u0026#34;/wxCheck\u0026#34;) public String wxSignatureCheck( @RequestParam(value = \u0026#34;signature\u0026#34;) String signature, @RequestParam(value = \u0026#34;timestamp\u0026#34;) String timestamp, @RequestParam(value = \u0026#34;nonce\u0026#34;) String nonce, @RequestParam(value = \u0026#34;echostr\u0026#34;) String echostr) throws NoSuchAlgorithmException { log.info(\u0026#34;收到微信校验请求，echostr:{}\u0026#34;,echostr); String token=\u0026#34;Rainy-Heights\u0026#34;; String[] str = new String[]{token, timestamp, nonce}; //排序 Arrays.sort(str); //拼接字符串 StringBuilder buffer = new StringBuilder(); for (String s : str) { buffer.append(s); } MessageDigest messageDigest=MessageDigest.getInstance(\u0026#34;SHA-1\u0026#34;); //利用SHA-1加密算法对字符串加密： byte[] digest = messageDigest.digest(buffer.toString().getBytes(StandardCharsets.UTF_8));//加密好的盐 buffer.setLength(0);//清空数据 for (byte bit:digest){ String hex=Integer.toHexString(0xff\u0026amp;bit); if (hex.length()==1) { buffer.append(\u0026#39;0\u0026#39;); } else { buffer.append(hex); } } //与签名一致时返回 if (buffer.toString().equals(signature)){ return echostr; } else { return \u0026#34;404\u0026#34;; } } } 处理回调逻辑，代理方法\n/** * WeiXinUtil * * @author 春江花朝秋月夜 * @since 2024/3/2 23:51 */ @Slf4j @Component public class WeiXinUtil { @Resource WeXinConfigProperties weXinConfigProperties; //具体获取token的操作 public WeiXinLoginUser getUserInfo(String code) throws IOException { String APP_ID= weXinConfigProperties.getAPP_ID(); String APP_SECRET= weXinConfigProperties.getAPP_SECRET(); String responseResult = \u0026#34;\u0026#34;; log.info(\u0026#34;回调获取code：{}\u0026#34;,code); //创建可关闭http链接客户端 CloseableHttpClient httpClient = HttpClients.createDefault(); String tokenUrl =\u0026#34;https://api.weixin.qq.com/sns/oauth2/access_token?appid=\u0026#34;+APP_ID+\u0026#34;\u0026amp;secret=\u0026#34; +APP_SECRET+\u0026#34;\u0026amp;code=\u0026#34;+code+\u0026#34;\u0026amp;grant_type=authorization_code\u0026#34;; HttpGet request = new HttpGet(tokenUrl); CloseableHttpResponse response = httpClient.execute(request); if (response.getStatusLine().getStatusCode() == 200){ responseResult = EntityUtils.toString(response.getEntity(),\u0026#34;UTF-8\u0026#34;); } log.info(\u0026#34;获取到responseResult：{}\u0026#34;,responseResult); WeiXinTokenInfo tokenInfo = JSONUtil.toBean(responseResult,WeiXinTokenInfo.class); String userInfoURL = \u0026#34;https://api.weixin.qq.com/sns/userinfo?access_token=\u0026#34;+tokenInfo.getAccessToken()+\u0026#34;\u0026amp;openid=\u0026#34; +tokenInfo.getOpenid()+\u0026#34;\u0026amp;lang=zh_CN\u0026#34;; HttpGet request1 = new HttpGet(userInfoURL); CloseableHttpResponse response1 = httpClient.execute(request1); if (response1.getStatusLine().getStatusCode() == 200){ responseResult = EntityUtils.toString(response1.getEntity(),\u0026#34;UTF-8\u0026#34;); } log.info(\u0026#34;获取到userInfoResult：{}\u0026#34;,responseResult); WeiXinLoginUser userInfo = JSONUtil.toBean(responseResult, WeiXinLoginUser.class); return userInfo; } } 登录用户实体（微信登录成功后返回的信息 ）\n/** * WeiXinLoginUser * * @author 春江花朝秋月夜 * @since 2024/3/2 23:17 */ @Data public class WeiXinLoginUser { /** * 微信扫码登录后台返回的是json数据 * 例如: * { \u0026#34;openid\u0026#34;:\u0026#34;OPENID\u0026#34;, \u0026#34;nickname\u0026#34;:\u0026#34;NICKNAME\u0026#34;, \u0026#34;sex\u0026#34;:1, \u0026#34;province\u0026#34;:\u0026#34;PROVINCE\u0026#34;, \u0026#34;city\u0026#34;:\u0026#34;CITY\u0026#34;, \u0026#34;country\u0026#34;:\u0026#34;COUNTRY\u0026#34;, \u0026#34;headimgurl\u0026#34;: \u0026#34;http://wx.qlogo.cn/mmopen/g3MonUZtNHkdmzicIlibx6iaFqAc56vxLSUfpb6n5WKSYVY0ChQKkiaJSgQ1dZuTOgvLLrhJbERQQ4eMsv84eavHiaiceqxibJxCfHe/0\u0026#34;, \u0026#34;privilege\u0026#34;:[ \u0026#34;PRIVILEGE1\u0026#34;, \u0026#34;PRIVILEGE2\u0026#34; ], \u0026#34;unionid\u0026#34;: \u0026#34; o6_bmasdasdsad6_2sgVt7hMZOPfL\u0026#34; } */ private String openid; private String nickname; private Integer sex; private String province; private String city; private String country; private String headimgurl; private String privilege; private String unionid; } vue页面代码部分\n\u0026lt;script\u0026gt; import QRcode from \u0026#34;qrcodejs2\u0026#34; export default { data() { return {} }, methods: { // 生成二维码 createQrcode() { new QRcode(this.$refs[\u0026#39;qrcode-config\u0026#39;], { text: \u0026#34; https://open.weixin.qq.com/connect/oauth2/authorize?appid=wxd10c3f9e60b4e00b\u0026amp;redirect_uri=https%3A%2F%2F6bbb1c69.r6.cpolar.top%2Fweixin%2FwxCallBack\u0026amp;response_type=code\u0026amp;scope=snsapi_userinfo\u0026amp;state=STATE#wechat_redirect\u0026#34;, // 扫二维码后获得的信息 width: 400, // 图片宽90px，左右padding各4px，边框各1px， 100-8px-2px height: 400, // 图片高90px，上下padding各4px，边框各1px， 100-8px-2px }) }, //生成微信登录的二维码，采用操作dom的方式，非插件，参考链接：https://huaweicloud.csdn.net/654a0c1634bf9e25c799cae9.html?dp_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpZCI6MTQ4MjI4OSwiZXhwIjoxNzEwMDAzNjgyLCJpYXQiOjE3MDkzOTg4ODIsInVzZXJuYW1lIjoicmFpbnloZWlnaHRzIn0.4jltqP2tCDn4xh25GWz11fMFOOa-xqGugND8f8Iqo5U createWxLoginQrCode() { const script = document.createElement(\u0026#39;script\u0026#39;); script.type = \u0026#39;text/javascript\u0026#39;; script.src = \u0026#39;https://res.wx.qq.com/connect/zh_CN/htmledition/js/wxLogin.js\u0026#39;; const wxElement = document.body.appendChild(script) wxElement.onload = function () { var obj = new WxLogin({ id: \u0026#39;wxLoginCode-\u0026#39;, // 需要显示的容器id appid: \u0026#39;wxd10c3f9e60b4e00b\u0026#39;,// 公众号appid wx******* scope: \u0026#39;snsapi_login\u0026#39;, // 网页默认即可 redirect_uri: encodeURIComponent(\u0026#39;https://2e79fece.r21.cpolar.top/weixin/wxCallBack\u0026#39;), // 授权成功后回调的url state: Math.ceil(Math.random() * 1000), // 可设置为简单的随机数加session用来校验 style: \u0026#39;black\u0026#39;, //提供\u0026#34;black\u0026#34;、\u0026#34;white\u0026#34;可选。二维码的样式 href: \u0026#39;\u0026#39; // 外部css文件url，需要https }) } } }, mounted() { this.createQrcode(); this.createWxLoginQrCode(); } } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;wxLogin\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;扫码登录，二维码 1 分钟内有效\u0026lt;/h3\u0026gt; \u0026lt;!-- \u0026lt;login-code :size=\u0026#34;400\u0026#34; :text=\u0026#34;二维码\u0026#34;/\u0026gt; --\u0026gt; \u0026lt;div class=\u0026#34;img-box\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;qrcode-config\u0026#34; ref=\u0026#34;qrcode-config\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;img class=\u0026#34;qrcode-logo\u0026#34; width=\u0026#34;27\u0026#34; src=\u0026#34;../../assets/wx.jpg\u0026#34; alt=\u0026#34;配置服务器\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;wxLoginCode\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style scoped\u0026gt; .wxLogin { align-content: center; text-align: center; margin-top: 50px; /* 二维码图片容器,包括二维码 + logo + 边框 */ .img-box { margin-left: 40%; align-items: center; text-align: center; padding-bottom: 8px; width: 400px; height: 400px; box-sizing: border-box; position: relative; } /* qrcodejs2 生成的二维码的容器，纯二维码*/ .qrcode-config { margin-top: 300px; align-items: center; border: 1px solid #e5e5e6; padding: 4px; border-radius: 4px; width: 400px; height: 400px; box-sizing: border-box; img { box-sizing: border-box; } } /*二维码中间的logo*/ .qrcode-logo { position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%); width: 70px; } } \u0026lt;/style\u0026gt; 目前尚未完成的部分：\n二维码扫描完成后返回码位10003，推测可能是微信开放平台没有做好，吐槽：微信开放平台的网站太多了，一会儿小程序一会儿网站应用，分辨不清，不想写\n完成登录后的授权码模式获取用户信息并授权部分\n","date":"2 March 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/wexin-oauth/","section":"笔记s","summary":"微信登录 #\r参考文章：\nVue生成二维码\n构建微信登录服务器 验证后端\n微信开发公众平台\n效果展示： #\r通过前端生成的二维码：\n前端部分（使用Dom来创建script节点）： #\rcreateWxLoginQrCode(){ const script=document.createElement(\u0026#39;script\u0026#39;); script.type=\u0026#39;text/javascript\u0026#39;; script.src=\u0026#39;https://res.wx.qq.com/connect/zh_CN/htmledition/js/wxLogin.js\u0026#39;; const wxElement = document.body.appendChild(script) wxElement.onload = function () { var obj = new WxLogin({ id: \u0026#39;wxLoginCode\u0026#39;, // 需要显示的容器id appid: \u0026#39;\u0026#39;,// 公众号appid wx******* scope: \u0026#39;snsapi_login\u0026#39;, // 网页默认即可 redirect_uri: encodeURIComponent(\u0026#39; \u0026#39;), // 授权成功后回调的url state: Math.","title":"微信登录","type":"笔记"},{"content":"Java 选手为什么用 Vscode 了？\n答：苦于 IDEA 的启动速度，本人的电脑带不动了很多了，就算改了索引和 Maven，经常还是要编辑 js，vue，html 文件，小全栈辣鸡吧，故而转战 Vscode。并不完全弃坑 IDEA\n目前调教 Vscode 还算挺好哒哈哈，好用呀！！！\n这里我选择了本地的 Maven 和用于日语的字体()，主题选用的是：Default Dark Modern，目前看起来还行，经典就是好，配合我的背景图片很搭!\n当选择编写 Spring 应用程序时可选用 Idea 主题，较为接近 Jetbrains 家族的 Idea,字体选用的是 JetBrains 家族的 JetBrains Mono，normal 版；\n由于添加了适用于 Idea 的快捷键插件，平替 Idea 非常丝滑。\n背景主题插件：（Background-kasute）\n文件图标主题：\n背景图：\r黄昏时刻-道口时刻\n贴一下 json，做个备份\n{ \u0026#34;markdown-image.github.repository\u0026#34;: \u0026#34;https://github.com/ToDreamr/img-cloud.git\u0026#34;, \u0026#34;markdown-image.github.cdn\u0026#34;: \u0026#34;https://cdn.jsdelivr.net/gh/Todreamr/img-cloud\u0026#34;, \u0026#34;markdown-image.github.token\u0026#34;: \u0026#34;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\u0026#34;, \u0026#34;RainbowBrackets.depreciation-notice\u0026#34;: false, \u0026#34;java.configuration.maven.userSettings\u0026#34;: \u0026#34;D://Program Files//apache-maven-3.9.4//conf//settings.xml\u0026#34;, \u0026#34;java.configuration.maven.globalSettings\u0026#34;: \u0026#34;D://Program Files//apache-maven-3.9.4//conf//settings.xml\u0026#34;, \u0026#34;maven.executable.path\u0026#34;: \u0026#34;D://Program Files//apache-maven-3.9.4//bin//mvn\u0026#34;, \u0026#34;workbench.iconTheme\u0026#34;: \u0026#34;eq-material-theme-icons-ocean\u0026#34;, \u0026#34;editor.mouseWheelZoom\u0026#34;: true, \u0026#34;editor.fontLigatures\u0026#34;: false, \u0026#34;editor.fontFamily\u0026#34;: \u0026#34;\u0026#39;JetBrains Mono\u0026#39;,\u0026#39;汉仪孟庆江行书 W\u0026#39;\u0026#34;, \u0026#34;terminal.integrated.fontFamily\u0026#34;: \u0026#34;JetBrains Mono\u0026#34;, \u0026#34;files.trimTrailingWhitespace\u0026#34;: true, \u0026#34;vue.format.script.initialIndent\u0026#34;: true, \u0026#34;vue.format.style.initialIndent\u0026#34;: true, \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;workbench.settings.useSplitJSON\u0026#34;: true, \u0026#34;rest-client.fontWeight\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;editor.fontWeight\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;terminal.integrated.fontWeight\u0026#34;: \u0026#34;bold\u0026#34;, \u0026#34;files.autoSave\u0026#34;: \u0026#34;onFocusChange\u0026#34;, \u0026#34;workbench.editor.doubleClickTabToToggleEditorGroupSizes\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;latex-workshop.view.pdf.tab.editorGroup\u0026#34;: \u0026#34;current\u0026#34;, \u0026#34;editor.renderWhitespace\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;editor.codeActionsOnSave\u0026#34;: {}, \u0026#34;diffEditor.hideUnchangedRegions.enabled\u0026#34;: true, \u0026#34;workbench.preferredDarkColorTheme\u0026#34;: \u0026#34;Default Dark+\u0026#34;, \u0026#34;workbench.preferredHighContrastColorTheme\u0026#34;: \u0026#34;Default Dark+\u0026#34;, \u0026#34;workbench.editor.autoLockGroups\u0026#34;: { \u0026#34;mainThreadWebview-markdown.preview\u0026#34;: true }, \u0026#34;background.autoInstall\u0026#34;: true, \u0026#34;background.smoothImageRendering\u0026#34;: true, \u0026#34;background.backgroundBlur\u0026#34;: [ \u0026#34;0\u0026#34;, \u0026#34;300\u0026#34;, \u0026#34;300\u0026#34;, \u0026#34;300\u0026#34; ], \u0026#34;background.backgroundChangeTime\u0026#34;: [ 720, 720, 720, 720 ], \u0026#34;background.renderContentAboveBackground\u0026#34;: true, \u0026#34;editor.fontVariations\u0026#34;: false, \u0026#34;background.windowBackgrounds\u0026#34;: [ \u0026#34;https://pic3.zhimg.com/80/v2-e0c90dbe7ca8559256e37522f28b060e_1440w.webp\u0026#34;, \u0026#34;https://picx.zhimg.com/80/v2-479a753c747307bd93ad989bee373147_1440w.webp?source=2c26e567\u0026#34;, \u0026#34;https://pic1.zhimg.com/80/v2-6987babba6c51f77e73ec0134d4c53d0_1440w.webp\u0026#34;, \u0026#34;https://picx.zhimg.com/80/v2-01cb93ee2cc66a3d47d942725b240b4e_1440w.webp?source=1def8aca\u0026#34;, \u0026#34;https://pic2.zhimg.com/80/v2-b3f0b28e5d82fd34294b03bfc9cb6779_1440w.webp\u0026#34;, \u0026#34;https://pic2.zhimg.com/80/v2-c4386ee2d2c068c80792a7925d6b1607_1440w.webp\u0026#34;, \u0026#34;https://pic4.zhimg.com/80/v2-3df07d0898aab88f5cd6306c7ec25c8f_1440w.webp\u0026#34;, \u0026#34;https://pic4.zhimg.com/80/v2-d10e3a9e78d72d42f404eb6984bfe32b_1440w.webp\u0026#34; ], \u0026#34;[jsonc]\u0026#34;: { \u0026#34;editor.defaultFormatter\u0026#34;: \u0026#34;vscode.json-language-features\u0026#34; }, \u0026#34;cSpell.userWords\u0026#34;: [ \u0026#34;qrcodejs\u0026#34; ], \u0026#34;files.associations\u0026#34;: { \u0026#34;*.vue\u0026#34;: \u0026#34;vue\u0026#34; }, \u0026#34;workbench.tree.enableStickyScroll\u0026#34;: false, \u0026#34;workbench.editor.defaultBinaryEditor\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;terminal.integrated.defaultProfile.windows\u0026#34;: \u0026#34;PowerShell\u0026#34;, \u0026#34;terminal.integrated.enableVisualBell\u0026#34;: true, \u0026#34;terminal.integrated.localEchoStyle\u0026#34;: \u0026#34;dim\u0026#34;, \u0026#34;terminal.integrated.cursorBlinking\u0026#34;: true, \u0026#34;scm.defaultViewMode\u0026#34;: \u0026#34;tree\u0026#34;, \u0026#34;terminal.integrated.tabs.showActiveTerminal\u0026#34;: \u0026#34;singleTerminal\u0026#34; } maven 一切正常：\n","date":"2 March 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/vscode/","section":"笔记s","summary":"Java 选手为什么用 Vscode 了？\n答：苦于 IDEA 的启动速度，本人的电脑带不动了很多了，就算改了索引和 Maven，经常还是要编辑 js，vue，html 文件，小全栈辣鸡吧，故而转战 Vscode。并不完全弃坑 IDEA\n目前调教 Vscode 还算挺好哒哈哈，好用呀！！！\n这里我选择了本地的 Maven 和用于日语的字体()，主题选用的是：Default Dark Modern，目前看起来还行，经典就是好，配合我的背景图片很搭!\n当选择编写 Spring 应用程序时可选用 Idea 主题，较为接近 Jetbrains 家族的 Idea,字体选用的是 JetBrains 家族的 JetBrains Mono，normal 版；","title":"自用的Vscode个人觉得还算耐看的主题和字体以及编码习惯","type":"笔记"},{"content":"","date":"23 February 2024","externalUrl":null,"permalink":"/tags/spring/","section":"Tags","summary":"","title":"spring","type":"tags"},{"content":"\r基于Spring6+JDK18的SpringSecurity环境的项目DEMO #\r项目地址：\nToDreamr/backend-base\r基于 Spring6+Vue+Jwt+JDK18环境的SecurityDemo\rJava 0\r0\r基本实现的功能 #\rSecurity通过数据库实现自定义登录 通过自己添加的过滤器链完成JWT+Token的请求权限认证 Token加入Redis做无状态无Session处理 邮箱验证码收发功能 注意事项 #\rsql执行脚本在项目doc文件目录下，Security在Spring6下已经废除\n通过WebSecurityAdaptor来实现HttpSecurity这个Bean的配置注入。\n目前只支持Lamda表达式。\n请在application.yml中自行配置自己的邮箱SMTP服务\n配置案例：\n@Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { return http .authorizeHttpRequests(conf-\u0026gt;conf .requestMatchers(\u0026#34;/**\u0026#34;).permitAll() ) .formLogin(conf -\u0026gt; conf .loginProcessingUrl(\u0026#34;/auth/login\u0026#34;).permitAll() .successHandler(new LoginSuccessHandler(accountService,jwtUtils,stringRedisTemplate)) .failureHandler(new LoginFailureHandler()) ) .addFilterBefore(jwtAuthenticationFilter, UsernamePasswordAuthenticationFilter.class) .csrf(AbstractHttpConfigurer::disable)//关闭跨域漏洞防御配置 .logout(conf-\u0026gt;conf .logoutUrl(\u0026#34;/auth/logout\u0026#34;) .logoutSuccessHandler(new LogOutHandler(redisTemplate,jwtUtils))) .exceptionHandling(conf-\u0026gt;conf.accessDeniedHandler((request, response, accessDeniedException) -\u0026gt; System.out.println(\u0026#34;当前异常的登录信息：\u0026#34;+accessDeniedException))) .build(); } 搭建要点 #\r登录用户实体必须实现UserDetails接口，数据层，业务层（实际处理登录逻辑，俗称Impl）必须实现\nUserDetailsService接口，同时重写\npublic UserDetails loadUserByUsername(String username) 方法；\n例如：\nImpl @Resource UserMapper userMapper; @Override public UserDetails loadUserByUsername(String username){ User user = userMapper.loadUserByUsername(username); if (user==null){ throw new UsernameNotFoundException(\u0026#34;用户名不存在！\u0026#34;); } User userDetails = new User(); userDetails.setUsername(username); userDetails.setPassword(user.getPassword()); return userDetails; } 通过自定义的Filter同时继承 OncePerRequestFilter 类，类似于网关处理Request+Response\n控制非登录的资源请求权限认证。\n范围\t描述\nicon\t要在时间线视觉效果中使用的图标。\nheader\t每个条目的标题\nbadge\t放置在右上角徽章内的文本\nsubheader\t条目的副标题\nTodreamr Repo\r我的代码仓库\rToDreamr/todreamr.github.io\rHTML 0\r0\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r头部标题 标签\r副标题\r样式测试\rJava\rPython\rLatex\r图集 二次元赛高\r此生无悔二次元\r","date":"23 February 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/security/","section":"笔记s","summary":"基于Spring6+JDK18的SpringSecurity环境的项目DEMO #\r项目地址：\nToDreamr/backend-base\r基于 Spring6+Vue+Jwt+JDK18环境的SecurityDemo\rJava 0\r0\r基本实现的功能 #\rSecurity通过数据库实现自定义登录 通过自己添加的过滤器链完成JWT+Token的请求权限认证 Token加入Redis做无状态无Session处理 邮箱验证码收发功能 注意事项 #\rsql执行脚本在项目doc文件目录下，Security在Spring6下已经废除\n通过WebSecurityAdaptor来实现HttpSecurity这个Bean的配置注入。\n目前只支持Lamda表达式。\n请在application.yml中自行配置自己的邮箱SMTP服务\n配置案例：\n@Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { return http .","title":"Spring-Security","type":"笔记"},{"content":"\rDocker镜像基本命令 #\rsystemctl stop firewalld systemctl disable firewalld 启动Docker\nsystemctl start docker systemctl restart docker docker -v 配置镜像\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;- \u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://n0dwetq.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 镜像操作\n拉取镜像：\ndocker pull images %拉取镜像 docker rmi %删除镜像 docker save %保存镜像 docker load %加载镜像 docker build %打包镜像 docker save -o nginx.tar nginx:latest docker rmi naginx:latest docker load -i nginx.tar Docker容器基本操作 #\rdocker ps：查看所有的容器状态\rdocker logs 查看容器的运行日志\rdocker rm 删除容器\rdocker exec 进入容器 运行在固定端口 #\r-name 命名\n-p 端口映射：这是比较有意思的，由于容器隔离，需要将容器映射到服务端口\n-p[宿主机端口]：[容器端口]\n-d 后台运行\n进入容器内部(将会进入运行容器的Linux隔离环境) #\rdocker exec -it image-name bash\rdocker stop image-name 数据卷（Volume） #\r为了解决耦合，创建的文件关联系统，想象量子纠缠\n实现关联的操作称为挂载\n数据卷可实现新旧数据共享\n命令： #\rdocker volume create volume-name #创建数据卷 数据卷挂载（-v） #\r比如：\ndocker run --name my-nginx -v volume-nginx:/root/html -p 80:80 nginx 之后对容器内文件的修改即可通过数据卷文件和SFTP文件系统操作软件Temius/XShell修改了。\n构建DockerFile #\r镜像结构 #\r从结构看出，构建镜像需要从下往上逐层构建。\nDockerFile编写 #\rfrom ubuntu:20.04 #构建基础镜像，可以是Linux，也可以是制作好的镜像 ENV JAVA_DIR=/usr/loval COPY ./jdk8.tar.gz $JAVA_DIR/ COPY ./docker-build.jar /tmp/application.jar RUN cd $JAVA_DIR \u0026amp;\u0026amp; tar -xf ./jdk8.tar.gz \\ \u0026amp;\u0026amp; mv ./jdk1.8.0_144 ./java8 ENV JAVA_HOME=${JAVA_HOME}$ ENV PATH=${JAVA_HOME/bin}$ EXPOSE 8081 ENTRYPOINT java -jar /tmp/application.jar docker build -t name:version . #\u0026#34;.\u0026#34;代表DockerFile路径 DockerCompose #\rDocker Compose是基于Compose文件（yml文件）来帮助快速部署的分布式应用。\n","date":"8 February 2024","externalUrl":null,"permalink":"/docker/","section":"","summary":"Docker镜像基本命令 #\rsystemctl stop firewalld systemctl disable firewalld 启动Docker\nsystemctl start docker systemctl restart docker docker -v 配置镜像\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;- \u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;:[\u0026#34;https://n0dwetq.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker 镜像操作","title":"Docker","type":"page"},{"content":"\r搭建本站音乐 #\r搭建过程绕了一些弯子，吃了前端的亏，主要借鉴了\r金圣皓，得知了目前主流的博客音乐依托于APlayer\u0026amp;Meting JS,前者是嵌入HTML的音乐组件库，后者是可用通过网易，QQ音乐等网站的音乐插件，本网站作为静态页面，故只需通过CDN引入即可\n网站搭建主题为Blowfish，在blog/layouts/shortcodes文件夹下添加album.html文件\n这里采用的是网易音乐的歌单，获取歌单id自行从\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r网易云音乐歌单中获取\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/color-thief@2.2.5/js/color-thief.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;span style=\u0026#34;color:#111827\u0026#34;\u0026gt; \u0026lt;!--{{.Get 0}}作为歌单参数由引用组件处添加--\u0026gt; \u0026lt;meting-js server=\u0026#34;netease\u0026#34; type=\u0026#34;playlist\u0026#34; id=\u0026#34;{{.Get 0}}\u0026#34; autoplay=\u0026#34;true\u0026#34; listFolded=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/meting-js\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;hr/\u0026gt; 在博客笔记中添加md文件 #\r效果： #\r","date":"7 February 2024","externalUrl":null,"permalink":"/entire-note/music_build/","section":"Entire-notes","summary":"搭建本站音乐 #\r搭建过程绕了一些弯子，吃了前端的亏，主要借鉴了\r金圣皓，得知了目前主流的博客音乐依托于APlayer\u0026amp;Meting JS,前者是嵌入HTML的音乐组件库，后者是可用通过网易，QQ音乐等网站的音乐插件，本网站作为静态页面，故只需通过CDN引入即可\n网站搭建主题为Blowfish，在blog/layouts/shortcodes文件夹下添加album.html文件\n这里采用的是网易音乐的歌单，获取歌单id自行从\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r网易云音乐歌单中获取\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/color-thief@2.2.5/js/color-thief.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;span style=\u0026#34;color:#111827\u0026#34;\u0026gt; \u0026lt;!--{{.Get 0}}作为歌单参数由引用组件处添加--\u0026gt; \u0026lt;meting-js server=\u0026#34;netease\u0026#34; type=\u0026#34;playlist\u0026#34; id=\u0026#34;{{.","title":"Music","type":"entire-note"},{"content":"\r搭建本站音乐 #\r搭建过程绕了一些弯子，吃了前端的亏，主要借鉴了\r金圣皓，得知了目前主流的博客音乐依托于APlayer\u0026amp;Meting JS,前者是嵌入HTML的音乐组件库，后者是可用通过网易，QQ音乐等网站的音乐插件，本网站作为静态页面，故只需通过CDN引入即可\nMeting Js参数,\r官方文档\n\u0026lt;!--MetingJS参数详情--\u0026gt; \u0026lt;!-- id=\u0026#39;外链播放器id\u0026#39;,必须参数 type=[song=单曲, playlist=歌单, album=专辑, search=搜索结果, artist=艺术家],必须参数 server=[netease=网易云音乐, tencent=QQ音乐, kugou=酷狗音乐, xiami=虾米音乐, baidu=百度音乐],必须参数 fixed=启用固定模式，固定在左下角,默认false mini=启用迷你模式,默认false preload=[none,metadata,auto] mutex=[互斥锁，默认true],默认false order=[random=随机播放,list=列表播放] loop=[all=全部循环, one=循环一次 ,none=不循环] volume=[音量，默认0.7] lrc-type=[歌词类型，默认0] list-folded=[列表是否折叠，默认false] list-max-height=列表最大高度,默认340px storage-name=本地存储存储密钥，用于存储播放器设置,默认metingjs --\u0026gt; 网站搭建主题为Blowfish，在blog/layouts/shortcodes文件夹下添加album.html文件\n这里采用的是网易音乐的歌单，获取歌单id自行从\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r网易云音乐歌单中获取\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/meting@2.0.1/dist/Meting.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/color-thief@2.2.5/js/color-thief.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;span style=\u0026#34;color:#111827\u0026#34;\u0026gt; \u0026lt;!--{{.Get 0}}作为歌单参数由引用组件处添加--\u0026gt; \u0026lt;meting-js server=\u0026#34;netease\u0026#34; type=\u0026#34;playlist\u0026#34; id=\u0026#34;{{.Get 0}}\u0026#34; autoplay=\u0026#34;true\u0026#34; listFolded=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/meting-js\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;hr/\u0026gt; 在博客笔记中添加md文件 #\r效果： #\r","date":"7 February 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/music/","section":"笔记s","summary":"搭建本站音乐 #\r搭建过程绕了一些弯子，吃了前端的亏，主要借鉴了\r金圣皓，得知了目前主流的博客音乐依托于APlayer\u0026amp;Meting JS,前者是嵌入HTML的音乐组件库，后者是可用通过网易，QQ音乐等网站的音乐插件，本网站作为静态页面，故只需通过CDN引入即可\nMeting Js参数,\r官方文档\n\u0026lt;!--MetingJS参数详情--\u0026gt; \u0026lt;!-- id=\u0026#39;外链播放器id\u0026#39;,必须参数 type=[song=单曲, playlist=歌单, album=专辑, search=搜索结果, artist=艺术家],必须参数 server=[netease=网易云音乐, tencent=QQ音乐, kugou=酷狗音乐, xiami=虾米音乐, baidu=百度音乐],必须参数 fixed=启用固定模式，固定在左下角,默认false mini=启用迷你模式,默认false preload=[none,metadata,auto] mutex=[互斥锁，默认true],默认false order=[random=随机播放,list=列表播放] loop=[all=全部循环, one=循环一次 ,none=不循环] volume=[音量，默认0.","title":"本站Music搭建相关","type":"笔记"},{"content":"\r","date":"29 January 2024","externalUrl":null,"permalink":"/music/","section":"","summary":"\r","title":"音乐","type":"page"},{"content":"Spring Cloud Netflix 介绍\rNetflix套件中有Eureka、Ribbon、Hystrix、Zuul、Feign五个非常知名的开源项目，分别被用于服务治理、负载均衡、服务容错、服务网关、服务通信。\n2018年，Netflix套件中的开源项目陆续进入了维护模式。\n2020年12月22日，Spring Cloud 2020.0.0版本发布，该版本中移除了Netflix套件中的相关依赖。\nSpring Cloud Alibaba 介绍\r2018年7月，Spring Cloud Alibaba正式开源，进入Spring Cloud孵化器。2018年10月，Spring Cloud Alibaba发布开源后的第一个版本。\nSpring Cloud Alibaba提供的组件如下：\nSentinel：阿里巴巴开源产品，不仅仅可以作为断路器，也支持流量控制和服务降级。\rNacos：阿里巴巴开源产品，服务注册与服务发现，同时也可以作为配置中心。\rRocketMQ：阿里巴巴开源的分布式消息和流计算平台。\rDubbo：阿里巴巴开源产品，高性能Java RPC框架，服务通信组件。\rSeata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。\rAlibaba Cloud ACM：其前身为淘宝内部配置中心Diamond，是一款应用配置中心产品，需付费。\rAlibaba Cloud OSS：阿里云对象存储OSS是一款海量、安全、低成本、高可靠的云存储服务，需付费。\rAlibaba Cloud SMS：阿里云短信服务，需付费。\rAlibaba Cloud SchedulerX：阿里中间件自研的基于Akka架构的新一代分布式任务调度平台，需付费。\rspring-cloud 和 spring-cloud-alibaba 的区别\rSpring Cloud：Spring 官方提供的分布式应用开发的一套共用模式，也可以理解成一套微服务开发的统一的抽象编程模型。\rSpring Cloud Netflix：基于 Spring Cloud 编程模型实现的微服务框架，是最早期的微服务框架。近年来，Netflix 宣布大多数组件停止维护。\rSpring Cloud Alibaba：Alibaba 提供的基于 Spring Cloud 编程模型实现的微服务框架，其所有组件都来自于阿里巴巴微服务技术，无论是解决方案完整性、技术成熟度、社区还是文档资料等都对国内开发者非常友好。\rspring-cloud是Spring官方提供的微服务开发工具。它基于Spring Boot构建，提供了一系列框架和工具帮助我们快速构建分布式系统中的微服务架构。spring-cloud主要包含以下组件:\nEureka:服务注册中心,用于服务注册与发现。\rRibbon:负载均衡器,在服务调用方进行负载均衡。\rFeign:声明式 REST 客户端,简化 RESTful API 的调用。\rHystrix:熔断器,容错管理工具,防止分布式系统中级联故障。\rConfig:配置中心,通过 Git 仓库统一管理应用配置。\rBus:事件总线,用于广播配置文件变更事件。\rSleuth:调用链监控系统,用于跟踪微服务中的调用链信息。\rStream:消息驱动微服务,简化消息系统的使用。\rZuul:API 网关,用于认证、监控和路由转发等功能。\rGateway:新的 API 网关,取代 Zuul。\r除此之外，spring-cloud还支持与第三方组件的整合，如:\nKubernetes:容器编排平台的整合。\rNetflix组件:Ribbon、Hystrix、Zuul 等。\rZookeeper:服务注册发现与配置中心的支持。\rConsul:服务注册发现与配置中心的支持。\rspring-cloud-alibaba是阿里巴巴开源的组件，主要包含了阿里巴巴在微服务方面的若干开源产品，spring-cloud-alibaba中的主要组件有:\nNacos:一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\rDubbo:阿里巴巴开源的一个高性能 Java RPC 框架。\rRocketMQ:一款开源的分布式消息系统,基于高可用分布式集群技术,提供低延时的、高可靠的消息发布与订阅服务。\rSeata:阿里巴巴开源产品,一个易于使用的高性能微服务分布式事务解决方案。\rSentinel:阿里巴巴开源产品,一个控制微服务流量的开源框架。\r除此之外，spring-cloud-alibaba还整合了Spring Cloud与上述组件，提供了更加完善的微服务解决方案，主要包含:\nService Discovery:包含 Nacos 与 Eureka 的发现组件。\rConfiguration:Nacos 配置中心组件。\rMessaging:RocketMQ 消息中间件的整合。\rDistributed Transaction:Seata 的分布式事务支持。\rCircuit Breaker:Sentinel 的熔断与限流支持。\rGateway:与 Spring Cloud Gateway 的整合。\rSpring Cloud Dubbo 从 2021.0.1.0 起已被移除出主干，不再随主干演进。\n","date":"26 January 2024","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%BC%94%E8%BF%9B/","section":"笔记s","summary":"Spring Cloud Netflix 介绍\rNetflix套件中有Eureka、Ribbon、Hystrix、Zuul、Feign五个非常知名的开源项目，分别被用于服务治理、负载均衡、服务容错、服务网关、服务通信。\n2018年，Netflix套件中的开源项目陆续进入了维护模式。\n2020年12月22日，Spring Cloud 2020.0.0版本发布，该版本中移除了Netflix套件中的相关依赖。\nSpring Cloud Alibaba 介绍\r2018年7月，Spring Cloud Alibaba正式开源，进入Spring Cloud孵化器。2018年10月，Spring Cloud Alibaba发布开源后的第一个版本。\nSpring Cloud Alibaba提供的组件如下：\nSentinel：阿里巴巴开源产品，不仅仅可以作为断路器，也支持流量控制和服务降级。\rNacos：阿里巴巴开源产品，服务注册与服务发现，同时也可以作为配置中心。\rRocketMQ：阿里巴巴开源的分布式消息和流计算平台。\rDubbo：阿里巴巴开源产品，高性能Java RPC框架，服务通信组件。\rSeata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。\rAlibaba Cloud ACM：其前身为淘宝内部配置中心Diamond，是一款应用配置中心产品，需付费。\rAlibaba Cloud OSS：阿里云对象存储OSS是一款海量、安全、低成本、高可靠的云存储服务，需付费。\rAlibaba Cloud SMS：阿里云短信服务，需付费。\rAlibaba Cloud SchedulerX：阿里中间件自研的基于Akka架构的新一代分布式任务调度平台，需付费。\rspring-cloud 和 spring-cloud-alibaba 的区别\rSpring Cloud：Spring 官方提供的分布式应用开发的一套共用模式，也可以理解成一套微服务开发的统一的抽象编程模型。\rSpring Cloud Netflix：基于 Spring Cloud 编程模型实现的微服务框架，是最早期的微服务框架。近年来，Netflix 宣布大多数组件停止维护。\rSpring Cloud Alibaba：Alibaba 提供的基于 Spring Cloud 编程模型实现的微服务框架，其所有组件都来自于阿里巴巴微服务技术，无论是解决方案完整性、技术成熟度、社区还是文档资料等都对国内开发者非常友好。\rspring-cloud是Spring官方提供的微服务开发工具。它基于Spring Boot构建，提供了一系列框架和工具帮助我们快速构建分布式系统中的微服务架构。spring-cloud主要包含以下组件:","title":"NetFlix和SpringCloudAlibaba","type":"笔记"},{"content":"","date":"15 November 2023","externalUrl":null,"permalink":"/life-about/","section":"Life-abouts","summary":"","title":"Life-abouts","type":"life-about"},{"content":"","date":"15 November 2023","externalUrl":null,"permalink":"/tags/%E7%94%9F%E6%B4%BB/","section":"Tags","summary":"","title":"生活","type":"tags"},{"content":"\r今天是我的生日 #\r其实早上起来都不记得我的生日了，但是微信还是有女朋友和妈妈和爸爸还有姐姐的关心问候。\n下雨的天气，在女朋友的催促下去拿了北校的快递，是花，我猜到了，但是打开还是惊艳到我了，白玫瑰真的太漂亮了！！！谢谢你我最爱的Miss Liu\n回来的时候，把花花立起来了，黄灯照起来真的太有氛围感了。\n最后收到了朋友的蛋糕，实在感动，但没说上几句话，很感动，谢谢大家😸🦢\n朋友送的蛋糕\n在雨中，我途径北校的荷塘。\n","date":"15 November 2023","externalUrl":null,"permalink":"/life-about/birth/","section":"Life-abouts","summary":"今天是我的生日 #\r其实早上起来都不记得我的生日了，但是微信还是有女朋友和妈妈和爸爸还有姐姐的关心问候。\n下雨的天气，在女朋友的催促下去拿了北校的快递，是花，我猜到了，但是打开还是惊艳到我了，白玫瑰真的太漂亮了！！！谢谢你我最爱的Miss Liu\n回来的时候，把花花立起来了，黄灯照起来真的太有氛围感了。\n最后收到了朋友的蛋糕，实在感动，但没说上几句话，很感动，谢谢大家😸🦢\n朋友送的蛋糕\n在雨中，我途径北校的荷塘。","title":"我的生日","type":"life-about"},{"content":"","date":"14 November 2023","externalUrl":null,"permalink":"/algorithm/","section":"Algorithms","summary":"","title":"Algorithms","type":"algorithm"},{"content":"","date":"14 November 2023","externalUrl":null,"permalink":"/tags/leetcode/","section":"Tags","summary":"","title":"leetcode","type":"tags"},{"content":"\r计算区间之间的所有数的个位数之和 #\r思路： 总体用数学办法，45循环，补齐不全的区间\n#include \u0026#34;class/head.h\u0026#34; //导入万能依赖 long long Sum(long long left,long long right,long long len) { long long left_sum=0,right_sum=0; long long left_len,right_len; left_len=right_len=0; if(left!=0)//计算左补齐 { left_sum=((left-1)*left)/2.0; left_len=left; } if(right!=9)//计算右补齐 { right_sum=((right+10)*(9-right))/2.0; right_len=9-right; } long long cnt=0;//表示有多少个45， cnt=(len+left_len+right_len)/10;//算总个数 long long sum=0; sum=cnt*45-left_sum-right_sum; return sum; } int main() { long long m,n; scanf(\u0026#34;%lld %lld\u0026#34;,\u0026amp;m,\u0026amp;n); //通过补位来求 long long left=m%10,right=n%10; long long sum=0; if(m\u0026gt;=0) sum=Sum(left,right,n-m+1); else if(n\u0026lt;=0) sum=Sum(-right,-left,n-m+1); else sum=Sum(0,right,n+1)+Sum(0,-left,-m+1); printf(\u0026#34;%lld\u0026#34;,sum); return 0; } ","date":"14 November 2023","externalUrl":null,"permalink":"/algorithm/%E7%AE%97%E6%B3%95/%E6%95%B0%E5%AD%A6/","section":"Algorithms","summary":"计算区间之间的所有数的个位数之和 #\r思路： 总体用数学办法，45循环，补齐不全的区间\n#include \u0026#34;class/head.h\u0026#34; //导入万能依赖 long long Sum(long long left,long long right,long long len) { long long left_sum=0,right_sum=0; long long left_len,right_len; left_len=right_len=0; if(left!=0)//计算左补齐 { left_sum=((left-1)*left)/2.0; left_len=left; } if(right!","title":"区间个位和","type":"algorithm"},{"content":"题目：\n两数之和\n三数之和\nclass Main{ //两数之和 public static int[] twoSum(int[] nums, int target) { //找出和为target的数组中元素的下标： HashMap\u0026lt;Integer,Integer\u0026gt; dic=new HashMap\u0026lt;\u0026gt;();//和 int index=0; int dicIndex=0; int len=nums.length; Set\u0026lt;Integer\u0026gt; list=new HashSet\u0026lt;\u0026gt;(); for (int i=0;i\u0026lt;len;i++){ dic.put(i,nums[i]); } while(index\u0026lt;len\u0026amp;\u0026amp;dicIndex\u0026lt;len){ //3,2,4 if (nums[index]+dic.get(dicIndex)==target\u0026amp;\u0026amp;index!=dicIndex){ list.add(index); list.add(dicIndex); } index++; if (index==len){ dicIndex++; index=0; } } int[]res=new int[list.size()]; index=0; for (Integer item:list){ res[index]=item; index++; } return res; } //三数之和，返回加起来等于0的三元数组 public static List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] nums) { Arrays.sort(nums);//先排序再二分 int len = nums.length; //nums = [-1,0,1,2,-1,-4] //输出：[[-1,-1,2],[-1,0,1]] List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res=new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; len; i++) { if (nums[i]\u0026gt;0){ return res; } if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) continue; int left=i+1; int right=len-1; //二分法： while (right\u0026gt;left){ if (nums[i]+nums[left]+nums[right]\u0026gt;0){ right--; } else if (nums[i] + nums[left] + nums[right] \u0026lt; 0) { left++; } else { ArrayList\u0026lt;Integer\u0026gt; tmpList = new ArrayList\u0026lt;\u0026gt;(); tmpList.add(nums[i]); tmpList.add(nums[left]); tmpList.add(nums[right]); res.add(tmpList); while (right\u0026gt;left\u0026amp;\u0026amp;nums[right]==nums[right-1]){ right--; } while (right\u0026gt;left\u0026amp;\u0026amp;nums[left]==nums[left+1]){ left++; } right--; left++; } } } return res; } public static void main(String[] args) { int []arr={2,7,11,15}; Arrays.stream(twoSum(arr, 9)).forEach(System.out::println); } } ","date":"14 November 2023","externalUrl":null,"permalink":"/algorithm/%E7%AE%97%E6%B3%95/%E6%95%B0%E4%B9%8B%E5%92%8C/","section":"Algorithms","summary":"题目：\n两数之和\n三数之和\nclass Main{ //两数之和 public static int[] twoSum(int[] nums, int target) { //找出和为target的数组中元素的下标： HashMap\u0026lt;Integer,Integer\u0026gt; dic=new HashMap\u0026lt;\u0026gt;();//和 int index=0; int dicIndex=0; int len=nums.length; Set\u0026lt;Integer\u0026gt; list=new HashSet\u0026lt;\u0026gt;(); for (int i=0;i\u0026lt;len;i++){ dic.","title":"数之和","type":"algorithm"},{"content":"整个项目很简单，主要需要注意版本的问题,这也是微服务的主要问题\n启动成功\n还是贴一下maven好\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;eureka\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;eureka\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;eureka\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2022.0.1\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- spring cloud 默认配置启动器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- spring cloud Eureka Server 启动器 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-netflix-eureka-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; ","date":"11 November 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/eureka/","section":"笔记s","summary":"整个项目很简单，主要需要注意版本的问题,这也是微服务的主要问题\n启动成功\n还是贴一下maven好\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.2\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;eureka\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;eureka\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;eureka\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.","title":"Eureka","type":"笔记"},{"content":"","date":"11 November 2023","externalUrl":null,"permalink":"/tags/%E9%9A%8F%E6%9C%BA/","section":"Tags","summary":"","title":"随机","type":"tags"},{"content":"懒得点点了，写个脚本维护笔记\n目前来看效果还行\n","date":"11 November 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E6%8E%A8%E9%80%81%E7%AC%94%E8%AE%B0/","section":"笔记s","summary":"懒得点点了，写个脚本维护笔记\n目前来看效果还行","title":"写点脚本","type":"笔记"},{"content":"由于之前Vscode误删这个博客的笔记了，现在又要从仓库拉原来的笔记，实在是烦心。\n现在总算知道备份的重要性了。\n开科技也不行，github是真慢啊！！！又要先fetch再push了。。。。\n龟祖宗，好了没啊！！！\n总算好咯\n","date":"11 November 2023","externalUrl":null,"permalink":"/life-about/%E9%9A%8F%E8%AE%B0/","section":"Life-abouts","summary":"由于之前Vscode误删这个博客的笔记了，现在又要从仓库拉原来的笔记，实在是烦心。\n现在总算知道备份的重要性了。\n开科技也不行，github是真慢啊！！！又要先fetch再push了。。。。\n龟祖宗，好了没啊！！！\n总算好咯","title":"没备份笔记的后果","type":"life-about"},{"content":"","date":"11 November 2023","externalUrl":null,"permalink":"/tags/%E9%9A%8F%E8%AE%B0/","section":"Tags","summary":"","title":"随记","type":"tags"},{"content":"\r认识RabbitMQ #\r环境：ubangtu #\r访问协议： amqp\n了解安装（反正也记不住）：\nsudo apt install erlang sudo apt install rabbitmq-server sudo rabbitmqctl status sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_user 用户名 密码 sudo rabbitmqctl set_user_tags admin administrator 设计架构图：\n**生产者（Publisher）和消费者（Consumer）：**不用多说了吧。 **Channel：**我们的客户端连接都会使用一个Channel，再通过Channel去访问到RabbitMQ服务器，注意通信协议不是http，而是amqp协议。 **Exchange：**类似于交换机一样的存在，会根据我们的请求，转发给相应的消息队列，每个队列都可以绑定到Exchange上，这样Exchange就可以将数据转发给队列了，可以存在很多个，不同的Exchange类型可以用于实现不同消息的模式。 **Queue：**消息队列本体，生产者所有的消息都存放在消息队列中，等待消费者取出。 **Virtual Host：**有点类似于环境隔离，不同环境都可以单独配置一个Virtual Host，每个Virtual Host可以包含很多个Exchange和Queue，每个Virtual Host相互之间不影响。\n交换机 #\r交换机有持久化和短暂区分\n默认交换机：AMQP default，查找方法：根据名称来确定 普通直连交换机：让某个队列直接绑定，查找方法：routingKey指定哪一个队列 创建队列 #\r获取消息模式 Ack Mode #\r拒绝消息：Nack mq true\n确认应答：Ack mq false\n拒绝消息：Reject mq true/false\nRabbitMq整合SpringBoot #\r创建队列： #\r@Configuration public class RabbitConfiguration { @Bean(\u0026#34;directExchange\u0026#34;) //定义交换机Bean，可以很多个 public Exchange exchange(){ return ExchangeBuilder.directExchange(\u0026#34;amq.direct\u0026#34;).build(); } @Bean(\u0026#34;yydsQueue\u0026#34;) //定义消息队列 public Queue queue(){ return QueueBuilder .nonDurable(\u0026#34;my-rainy\u0026#34;) //非持久化类型 .build(); } @Bean(\u0026#34;binding\u0026#34;) public Binding binding(@Qualifier(\u0026#34;directExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue\u0026#34;) Queue queue){ //将我们刚刚定义的交换机和队列进行绑定 return BindingBuilder .bind(queue) //绑定队列 .to(exchange) //到交换机 .with(\u0026#34;rainy\u0026#34;) //使用自定义的routingKey .noargs(); } //转换为Json实体数据 @Bean(name = \u0026#34;Jackson2JsonMessageConverter\u0026#34;) public Jackson2JsonMessageConverter jsonMessageConverter(){ return new Jackson2JsonMessageConverter(); } } 在上面的配置中，创建了队列并且绑定了routingkey和对应的交换机，同时加入了自定义的json转换器件\n发送消息 #\r——\u0026gt; 借助RabbitTemplate\n@SpringBootTest @Import(RabbitConfiguration.class) class RabbitmqDemoApplicationTests { //消息解释器 @Resource RabbitTemplate template; @Test void publisher() { //使用convertAndSend方法一步到位，参数基本和之前是一样的 //最后一个消息本体可以是Object类型，真是大大的方便 template.convertAndSend(\u0026#34;amq.direct\u0026#34;, \u0026#34;rainy\u0026#34;, \u0026#34;Hello World!\u0026#34;);//发送消息 //如何知道发送的消息是否经过处理了？ Object ackMsg = template.convertSendAndReceive(\u0026#34;amq.direct\u0026#34;, \u0026#34;rainy\u0026#34;, \u0026#34;Hello World!\u0026#34;); } } 处理消息 #\r/** * TestListener * 监听器，实际上作为消费者 * @author 春江花朝秋月夜 * @since 2023/11/10 0:12 */ @Component //注册为Bean,作为接受消息同时处理返回的监听器 public class TestListener { @RabbitListener(queues = \u0026#34;rainy\u0026#34;) //定义此方法为队列rainy的监听器，一旦监听到新的消息，就会接受并处理 public void test(Message message){ System.out.println(new String(message.getBody()));//打印消息体,消息payload可以自动转换成消息实体 } @RabbitListener(queues = \u0026#34;rainy\u0026#34;) //定义此方法为队列rainy的监听器，一旦监听到新的消息，就会接受并处理，同时还要返回响应信息 public String ackMsg(Message message){ System.out.println(new String(message.getBody()));//打印消息体,消息payload可以自动转换成消息实体 return \u0026#34;响应成功！\u0026#34;; } @RabbitListener(queues = \u0026#34;rainy\u0026#34;,messageConverter = \u0026#34;Jackson2JsonMessageConverter\u0026#34;) //定义此方法为队列rainy的监听器，一旦监听到新的消息，就会接受并处理，同时还要返回响应信息 public String ackDTOMsg(Account message){ System.out.println(message);//打印消息体,使用定义好的json转换器来转换消息中的json数据 return \u0026#34;响应成功！\u0026#34;; } } 消息队列 #\r死信队列 #\r判定死信：\n消息被拒绝 消息TTL过期 队列达到最大长度，相当于被拒绝reject 死信队列创建和监听和正常队列差不多\nRabbitMQ支持将超过一定时间没被消费的消息自动删除，这需要消息队列设定TTL值，如果消息的存活时间超过了Time To Live值，就会被自动删除，自动删除后的消息如果有死信队列，那么就会进入到死信队列中。\n如果到达队列长度限制，那么每次插入都会把位于队首的消息丢进死信队列，来腾出空间给新来的消息。\n工作队列模式 #\r轮询分发消息：默认交替分发消息，但每个消费者都有一个预先获取数量，最开始一次性获取数量不一定是1\n配置消费者预获取数量：\n@Resource private CachingConnectionFactory connectionFactory; @Bean(name = \u0026#34;listenerContainer\u0026#34;) public SimpleRabbitListenerContainerFactory listenerContainer(){ SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setPrefetchCount(1); //将PrefetchCount设定为1表示一次只能取一个 return factory; } 配置监听器：\n//指定的监听器工厂和消费者数量 @RabbitListener(queues = \u0026#34;rainy\u0026#34;,containerFactory = \u0026#34;listenerContainer\u0026#34;,concurrency = \u0026#34;10\u0026#34;) public void listenMsg(Message message){ System.out.println(message); } 发布订阅模式 #\r注意这时候交换机已经发生变化了，直连交换机不可行，需要使用channel-exchange一对多也就是amq.finout，扇出类型\n路由模式 #\r通过路由来确定绑定到哪些队列里面去\n通过指定不同的routingkey来实现\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;fanoutExchange\u0026#34;) public Exchange exchange(){ //注意这里是fanoutExchange return ExchangeBuilder.fanoutExchange(\u0026#34;amq.fanout\u0026#34;).build(); } @Bean(\u0026#34;yydsQueue1\u0026#34;) public Queue queue(){ return QueueBuilder.nonDurable(\u0026#34;yyds1\u0026#34;).build(); } @Bean(\u0026#34;binding\u0026#34;) public Binding binding(@Qualifier(\u0026#34;fanoutExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue1\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;yyds1\u0026#34;) .noargs(); } @Bean(\u0026#34;yydsQueue2\u0026#34;) public Queue queue2(){ return QueueBuilder.nonDurable(\u0026#34;yyds2\u0026#34;).build(); } @Bean(\u0026#34;binding2\u0026#34;) public Binding binding2(@Qualifier(\u0026#34;fanoutExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue2\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;yyds2\u0026#34;) .noargs(); } } 主题模式 trace #\r通过routingKey的模糊匹配来实现，帮助进行日志追踪\n第四种交换机类型（使用头部信息来实现路由消息到队列中） #\r已经介绍了三种交换机类型，现在来介绍一下第四种交换机类型header，它是根据头部信息来决定的， 在我们发送的消息中是可以携带一些头部信息的（类似于HTTP），我们可以根据这些头部信息来决定路由到哪一个消息队列中。\n搭建集群 #\rsudo rabbitmqctl stop_app sudo rabbitmqctl join_cluster rabbit@ubuntu-server sudo rabbitmqctl start_app SpringCloud消息组件 #\rKafKa?RabbitMq?\n尝试搭建微服务项目\n","date":"7 November 2023","externalUrl":null,"permalink":"/entire-note/mq/","section":"Entire-notes","summary":"认识RabbitMQ #\r环境：ubangtu #\r访问协议： amqp\n了解安装（反正也记不住）：\nsudo apt install erlang sudo apt install rabbitmq-server sudo rabbitmqctl status sudo rabbitmq-plugins enable rabbitmq_management sudo rabbitmqctl add_user 用户名 密码 sudo rabbitmqctl set_user_tags admin administrator 设计架构图：","title":"RabbitMq","type":"entire-note"},{"content":"","date":"7 November 2023","externalUrl":null,"permalink":"/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","section":"Tags","summary":"","title":"消息队列","type":"tags"},{"content":"","date":"4 November 2023","externalUrl":null,"permalink":"/tags/vue/","section":"Tags","summary":"","title":"vue","type":"tags"},{"content":"\rVue3 响应式Api开发笔记 #\r目录结构： #\r用vite构建的Vue3目录结构：\nsrc:\n这里是我们要开发的目录，基本上要做的事情都在这个目录里。里面包含了几个目录及文件：\nassets: 放置一些图片，如logo等。 components: 目录里面放了一个组件文件，可以不用。 App.vue: 项目入口文件，我们也可以直接将组件写这里，而不使用 components 目录。 main.js: 项目的核心文件。 index.css: 样式文件。 static\t静态资源目录，如图片、字体等。\npublic\t公共资源目录。\npackage.json\t项目配置文件。\nvue3创建应用 #\r实际案例 #\r语法： const app = Vue.createApp({ /* 选项 */ }) 传递给 createApp 的选项用于配置根组件。在使用 mount() 挂载应用时，该组件被用作渲染的起点。\n案例：\nVue.createApp(HelloVueApp).mount(\u0026#39;#hello-vue\u0026#39;) //createApp 的参数是根组件（HelloVueApp），在挂载应用时，该组件是渲染的起点。 一个应用需要被挂载到一个 DOM 元素中，以上代码使用 mount(\u0026rsquo;#hello-vue\u0026rsquo;) 将 Vue 应用 HelloVueApp 挂载到 中。\n也就是说vue3是把应用程序挂载到mount下面的节点上的，作为渲染页面的起点\ndata选项 #\rdata 选项是一个函数。Vue 在创建新组件实例的过程中调用此函数。它应该返回一个对象，然后 Vue 会通过响应性系统将其包裹起来，并以 $data 的形式存储在组件实例中。\nsetup选项 #\rsetup创建非常前面：\n因此在setup中将不能使用this关键字\n\u0026lt;script \u0026gt; import {ref,reactive} from \u0026#34;vue\u0026#34;; export default { name:\u0026#39;HelloWorld\u0026#39;, setup(){ let msg=\u0026#39;Hello World\u0026#39; let color=\u0026#39;red\u0026#39; let age=ref(20) //声明对象： let Person=reactive({ name:\u0026#34;小明\u0026#34;, age:20, school:\u0026#39;HNUST\u0026#39; }) return{msg,color,age,Person} }, } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h1 style=\u0026#34;color: red;text-align: center\u0026#34;\u0026gt;{{msg}},我今年{{age}}岁啦！\u0026lt;/h1\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;h2\u0026gt;{{Person}}\u0026lt;/h2\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style scoped\u0026gt; \u0026lt;/style\u0026gt; 所有的变量（数据或者函数）都必须返回出去才可以使用\nsetup语法糖 #\r\u0026lt;script setup\u0026gt; //不需要手动return，写入内部将会自动return \u0026lt;/script\u0026gt; reactive和ref #\r默认情况下，数据并不是响应式的数据，需要通过这两个关键字来声明响应式数据\n对象类型：reactive返回响应式对象\n基本数据：ref包了一层对象，访问数据需要通过.value,template访问时不需要\n建议声明数据用ref，无论对象还是原始数据\n\u0026lt;script xmlns=\u0026#34;http://www.w3.org/1999/html\u0026#34; setup\u0026gt; import {ref, reactive, watch} from \u0026#34;vue\u0026#34;; name=\u0026#39;WatchParam\u0026#39; const count=ref(0); const clickTimes=ref(0); function button(){ clickTimes.value++; console.log(clickTimes) } //监听普通变量： watch(clickTimes,(newV,OldV)=\u0026gt;{ count.value=newV console.log(count) }) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;button @click=\u0026#34;button\u0026#34;\u0026gt;点击这个 +1\u0026lt;/button\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;h3\u0026gt;{{clickTimes}}\u0026lt;/h3\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;h3\u0026gt;{{count}}\u0026lt;/h3\u0026gt; \u0026lt;/template\u0026gt; 组合式API-computed #\r\u0026lt;script setup\u0026gt; //计算属性 import {computed, ref} from \u0026#34;vue\u0026#34;; const list=ref([1,2,3,4,5,6,7,8]) //基于list派生数据 const res=computed(()=\u0026gt;{ return list.value.filter(item =\u0026gt;item\u0026gt;4) }) const arr=ref([]) const additem=()=\u0026gt;{ arr.value.push(\u0026#34;科目三必过\u0026#34;) } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;h3\u0026gt;{{list}}\u0026lt;/h3\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;h3\u0026gt;{{res}}\u0026lt;/h3\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;h3\u0026gt;{{arr}}\u0026lt;/h3\u0026gt; \u0026lt;br/\u0026gt; \u0026lt;button @click=\u0026#34;additem\u0026#34;\u0026gt;点击添加数据\u0026lt;/button\u0026gt; \u0026lt;/template\u0026gt; 要求：计算属性不要去处理请求和修稿dom树\nwatch函数 #\r侦察单个元素或者一个对象，同时侦听多个数据也可\n\u0026lt;script setup\u0026gt; watch([clickTimes,count],(newV,OldV)=\u0026gt;{ count.value=newV console.log(OldV) console.log(count) }) \u0026lt;/script\u0026gt; 立即执行：immediate:true #\r深层监视：deep:true 所有属性都将会被监听 #\r修改才出发监听的回调函数： #\rwatch(()=\u0026gt;count,(newV,OldV)=\u0026gt;{ count.value=newV console.log(OldV) console.log(count) }) 生命周期函数 #\rcreated和onMounted\n对应关系\n\u0026lt;script setup\u0026gt; import {onMounted} from \u0026#34;vue\u0026#34;; onMounted(()=\u0026gt;{ console.log(\u0026#34;生命周期函数1\u0026#34;) }) onMounted(()=\u0026gt;{ console.log(\u0026#34;生命周期函数2\u0026#34;) }) \u0026lt;/script\u0026gt; 父子通信 #\r父组件绑定属性传值给子组件，子组件通过props接收属性\n编译器宏：defineProps\n父组件动态动态传值：v-model\n父组件形态：\n这张图片里面，所有的遗传属性需要在引用子组件的时候中声明，子组件定义的通信函数也要在引用时用**@+函数名**的方法声明！\n子组件形态：\n\u0026lt;script setup\u0026gt; import Son from \u0026#34;@/components/heredity/Son.vue\u0026#34;; import {ref} from \u0026#34;vue\u0026#34;; const money=ref(100); const earnMoney=()=\u0026gt;{ money.value+=100 } \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div\u0026gt;\u0026lt;h3\u0026gt;我是父组件\u0026lt;/h3\u0026gt;\u0026lt;button @click=\u0026#34;earnMoney\u0026#34;\u0026gt;赚钱给孩子们\u0026lt;/button\u0026gt;\u0026lt;son car=\u0026#34;宝马车\u0026#34; :money=\u0026#34;money\u0026#34;/\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script setup\u0026gt; //编译器宏组件 const props=defineProps({ car: String, money:String }) \u0026lt;/script\u0026gt; \u0026lt;template\u0026gt; \u0026lt;div class=\u0026#34;son\u0026#34;\u0026gt;我是子组件\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;son\u0026#34;\u0026gt;遗产{{car}}\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;son\u0026#34;\u0026gt;父亲的遗产{{money}}\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;style scoped\u0026gt; .son{ border: 1px solid black; padding: 30px; } \u0026lt;/style\u0026gt; 子组件传递事件给父组件 #\r理论上来讲，子组件修改父组件的值是可以的，但是由于父组件的可以引用多个子组件，其中一个子组件改了父组件的值后， 其他的子组件的数据可能会有问题，所以不推荐使用子组件修改父组件的值，而是在父组件中定义属性和方法，在子组件中修改。\n子组件内部通过emit触发事件，前提是子组件通过编译器宏声明了事件\n子组件部分传递事件：\nconst emit=defineEmits([\u0026#39;consumeMoney\u0026#39;]) const consume=()=\u0026gt;{ emit(\u0026#39;consumeMoney\u0026#39;,5) } 父组件部分接受事件：\n//传入参数也可以接收 const lessMoney=(args)=\u0026gt;{ money.value-=args; } \u0026lt;son car=\u0026#34;宝马车\u0026#34; :money=\u0026#34;money\u0026#34; @consumeMoney=\u0026#34;lessMoney\u0026#34;/\u0026gt;\u0026lt;/div\u0026gt; 模板引用 #\rref标识获取dom或者组件实例\n创建-\u0026gt;绑定-\u0026gt;使用\n","date":"4 November 2023","externalUrl":null,"permalink":"/entire-note/vue/","section":"Entire-notes","summary":"Vue3 响应式Api开发笔记 #\r目录结构： #\r用vite构建的Vue3目录结构：\nsrc:\n这里是我们要开发的目录，基本上要做的事情都在这个目录里。里面包含了几个目录及文件：\nassets: 放置一些图片，如logo等。 components: 目录里面放了一个组件文件，可以不用。 App.vue: 项目入口文件，我们也可以直接将组件写这里，而不使用 components 目录。 main.js: 项目的核心文件。 index.css: 样式文件。 static\t静态资源目录，如图片、字体等。\npublic\t公共资源目录。\npackage.json\t项目配置文件。\nvue3创建应用 #\r实际案例 #\r语法： const app = Vue.","title":"Vue3 响应式Api开发笔记","type":"entire-note"},{"content":"\r通过GitHub+PicGo+CDN搭建自己的图床 #\r图床一般是指储存图片的服务器，有国内和国外之分。国外的图床由于有 空间距离等因素决定访问速度很慢影响图片显示速度。国内也分为单线空间、 多线空间和cdn加速三种。# CDN 是构建在数据网络上的一种分布式的内容分发网。 CDN 的作用是采用 流媒体服务器 集群技术，克服单机系统输出带宽及并发能力不足的缺点，可极大提升系统支持的 并发流数目，减少或避免 单点失效带来的不良影响。# github搭建仓库\n下载 PicGO 配置 CDN\n创建仓库 #\rPICGO #\r配置加速\n如何配置token？\n首先到github上选择生成自己的token：\n点击首页选择设置：\n下拉到develop settings\n选择下方生成GitHub token：\n输入GitHub 账户密码之后得到token\n将token保存好，粘贴到PicGo里面即可。\n","date":"3 November 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%BA%8A/","section":"笔记s","summary":"通过GitHub+PicGo+CDN搭建自己的图床 #\r图床一般是指储存图片的服务器，有国内和国外之分。国外的图床由于有 空间距离等因素决定访问速度很慢影响图片显示速度。国内也分为单线空间、 多线空间和cdn加速三种。# CDN 是构建在数据网络上的一种分布式的内容分发网。 CDN 的作用是采用 流媒体服务器 集群技术，克服单机系统输出带宽及并发能力不足的缺点，可极大提升系统支持的 并发流数目，减少或避免 单点失效带来的不良影响。# github搭建仓库\n下载 PicGO 配置 CDN\n创建仓库 #\rPICGO #\r配置加速\n如何配置token？\n首先到github上选择生成自己的token：\n点击首页选择设置：\n下拉到develop settings\n选择下方生成GitHub token：","title":"搭建图床","type":"笔记"},{"content":"","date":"3 November 2023","externalUrl":null,"permalink":"/tags/%E6%9D%82%E8%AE%B0/","section":"Tags","summary":"","title":"杂记","type":"tags"},{"content":"\rC++实现数据结构和初步的认识 #\r鉴于未来数据结构和算法的实现我想通过 C++来实现，现在简要总结下 C++的常用方法和数据结构类型\n头文件和方法声明 #\r等同于 C 语言\n标准输入输出函数 #\rstd::cout \u0026lt;\u0026lt; \u0026#34;Hello, World!\u0026#34; \u0026lt;\u0026lt; std::endl; 引入 using namespace std;这可以避免函数要不断的添加前缀\nusing namespace std; ... int input; cout\u0026lt;\u0026lt;\u0026#34;Hello world\u0026#34;\u0026lt;\u0026lt;endl;//输出函数 cin\u0026gt;\u0026gt;input; printf(\u0026#34;%d\u0026#34;,input); ... 传递函数的不同方式 #\rconst 修饰指针 #\r修饰常量 修饰指针 修饰常量和指针 int main() { int a = 10; int b = 10; //const修饰的是指针，指针指向可以改，指针指向的值不可以更改 const int * p1 = \u0026amp;a; p1 = \u0026amp;b; //正确 //*p1 = 100; 报错 //const修饰的是常量，指针指向不可以改，指针指向的值可以更改 int * const p2 = \u0026amp;a; //p2 = \u0026amp;b; //错误 *p2 = 100; //正确 //const既修饰指针又修饰常量 const int * const p3 = \u0026amp;a; //p3 = \u0026amp;b; //错误 //*p3 = 100; //错误 system(\u0026#34;pause\u0026#34;); return 0; } 空指针和野指针 #\rNUll Point #\rint main() { //指针变量p指向内存地址编号为0的空间 int * p = NULL; //访问空指针报错 //内存编号0 ~255为系统占用内存，不允许用户访问 cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; } Wild Point #\rint main() { //指针变量p指向内存地址编号为0x1100的空间 int * p = (int *)0x1100; //访问野指针报错 cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; } 数组作为函数展示： #\rvoid array_print(int arr[],int len){ for (int i = 0; i \u0026lt; len; ++i) { cout\u0026lt;\u0026lt;arr[i]\u0026lt;\u0026lt;endl; } } void bubble_sort_(int * arr,int len){ for (int i = 0; i \u0026lt; len; ++i) { for (int j = i; j \u0026lt; len; ++j) { if (arr[i]\u0026gt;=arr[j]){ int tmp=arr[j]; arr[j]=arr[i]; arr[i]=tmp; } } } } int main(){ int arr[]={10,2,4,4,3,5,9,1,3}; bubble_sort_(arr,8); array_print(arr,8); } 当数组名传入到函数作为参数时，被退化为指向首元素的指针\n删除数组元素空间 #\rint arr[] = new[10];//声明数组 delete[] arr;//释放数组空间 内存发生取消和回收：\nint *a=new int [10]; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;endl; int *p=a; delete[] a; int *m=p; cout\u0026lt;\u0026lt;p\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;m\u0026lt;\u0026lt;endl; 引用 #\r语法： 数据类型 \u0026amp;别名 = 原名\n例子：\nint a = 10; int b = 20; //int \u0026amp;c; //错误，引用必须初始化 int \u0026amp;c = a; //一旦初始化后，就不可以更改 c = b; //这是赋值操作，不是更改引用 函数传参： #\r//1. 值传递 void mySwap01(int a, int b) { int temp = a; a = b; b = temp; } //2. 地址传递 void mySwap02(int* a, int* b) { int temp = *a; *a = *b; *b = temp; } //3. 引用传递 void mySwap03(int\u0026amp; a, int\u0026amp; b) { int temp = a; a = b; b = temp; } 引用传参：\nclass RainyInteger { friend ostream \u0026amp;operator\u0026lt;\u0026lt;(ostream\u0026amp; out,RainyInteger rainyInteger); public: RainyInteger(){ //初始化数据： this-\u0026gt;rainy_num=0; } void speak(RainyInteger *r){ cout\u0026lt;\u0026lt;r-\u0026gt;rainy_num\u0026lt;\u0026lt;endl; } private: int rainy_num; }; main(){ RainyInteger integer; integer.speak(\u0026amp; integer); //传入引用而不是指针，否则报错 } 类 #\r注意事项 #\r在 C++中实例化一个类不需要用 new。也可以用 new，但是区别是：不使用 new，开辟栈空间，使用 new 开辟的空间为堆空间。这显然是因为程序员只操作堆空间的原因使然\n与 C 语言结构体的区别\n访问控制符是唯一区别，所有的结构体默认 public，但是类则是 private\n类的构造函数，析构函数和拷贝构造函数\n静态变量和成员变量 #\r静态变量语法：static 数据类型 变量名\n类里面：类::变量名\n成员变量语法：数据类型 变量名\n静态方法类似，同时在头文件里面定义的时候可以具有方法体\n代码如下：\nPeople.h using namespace std; class People { public: People(int age,string name){ this-\u0026gt;age=age; this-\u0026gt;name=name; } //作用函数 void speak(People *p){ cout\u0026lt;\u0026lt;p-\u0026gt;name\u0026lt;\u0026lt;endl;//相当于this.name cout\u0026lt;\u0026lt;p-\u0026gt;age\u0026lt;\u0026lt;endl; } int age; string name; static string defaultName; static void defaultFunc(); }; People.cpp #include \u0026#34;People.h\u0026#34; //静态变量 string People::defaultName; void People::defaultFunc() { } 构造函数（Constructor） #\r构造函数语法：类名(){}\n在定义有参构造函数后，不再提供无参构造函数\n#####析构函数（Destructor），通 Java,可重载，释放内存时使用\n析构函数语法：~类名(){}\n构造函数，没有返回值也不写 void 函数名称与类名相同 构造函数可以有参数，因此可以发生重载 程序在调用对象时候会自动调用构造，无须手动调用,而且只会调用一次 拷贝构造函数 #\r如果属性有在堆区开辟的，一定要自己提供拷贝构造函数，防止浅拷贝带来的问题\n// // Created by Rainy-Heights on 2023/10/27. // #ifndef OBJECT_C_STUDENT_H #define OBJECT_C_STUDENT_H #include \u0026lt;iostream\u0026gt; using namespace std; class Student { public: Student(){ cout\u0026lt;\u0026lt;\u0026#34;这是无构造函数\u0026#34;\u0026lt;\u0026lt;endl; } Student(int age,string name){ cout\u0026lt;\u0026lt;\u0026#34;这是有参构造函数\u0026#34;\u0026lt;\u0026lt;endl; _stu_age=new int [age]; _stu_name=name; } //拷贝构造 函数 Student(const Student \u0026amp;student){ cout\u0026lt;\u0026lt;\u0026#34;拷贝构造函数\u0026#34;\u0026lt;\u0026lt;endl; _stu_name=student._stu_name; _stu_age=new int [*student._stu_age];//指向对象的值，这里还是实现了值的拷贝 } ~Student(){ cout\u0026lt;\u0026lt;\u0026#34;析构函数\u0026#34;\u0026lt;\u0026lt;endl; } public: int *_stu_age; string _stu_name; }; #endif //OBJECT_C_STUDENT_H ==如果用户定义有参构造函数，c++不在提供默认无参构造==，但是会提供默认拷贝构造\n==如果用户定义拷贝构造函数，c++不会再提供其他构造函数==\nthis 指针 #\r成员函数访问时候的隐形的 this 指针变量\nthis 对于类来说就是自己的地址\n例如：\nRainyInteger * getAddr(){ return this; } 友元 #\r相当于内部标志为 friend 即可访问私有成员\n全局函数作为友元： class StrictBoy{ friend void func(StrictBoy * strictBoy); public: StrictBoy(){ this-\u0026gt;girlFriend=\u0026#34;女朋友\u0026#34;; this-\u0026gt;money=520; } private: String girlFriend; public: int money; void func(StrictBoy * strictBoy){ cout\u0026lt;\u0026lt;strictBoy.girlFriend\u0026lt;\u0026lt;endl;//可以访问私有的变量了，牛头人既视感 } }; 类作为友元 class Building; class goodGay { public: goodGay(); void visit(); private: Building *building; }; class Building { //告诉编译器 goodGay类是Building类的好朋友，可以访问到Building类中私有内容 friend class goodGay; public: Building(); public: string m_SittingRoom; //客厅 private: string m_BedRoom;//卧室 }; Building::Building() { this-\u0026gt;m_SittingRoom = \u0026#34;客厅\u0026#34;; this-\u0026gt;m_BedRoom = \u0026#34;卧室\u0026#34;; } goodGay::goodGay() { building = new Building; } void goodGay::visit() { cout \u0026lt;\u0026lt; \u0026#34;好基友正在访问\u0026#34; \u0026lt;\u0026lt; building-\u0026gt;m_SittingRoom \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;好基友正在访问\u0026#34; \u0026lt;\u0026lt; building-\u0026gt;m_BedRoom \u0026lt;\u0026lt; endl; } void test01() { goodGay gg; gg.visit(); } int main(){ test01(); system(\u0026#34;pause\u0026#34;); return 0; } 成员函数作为友元： class Building; class goodGay { public: goodGay(); void visit(); //只让visit函数作为Building的好朋友，可以发访问Building中私有内容 void visit2(); private: Building *building; }; class Building { //告诉编译器 goodGay类中的visit成员函数 是Building好朋友，可以访问私有内容 friend void goodGay::visit(); public: Building(); public: string m_SittingRoom; //客厅 private: string m_BedRoom;//卧室 }; Building::Building() { this-\u0026gt;m_SittingRoom = \u0026#34;客厅\u0026#34;; this-\u0026gt;m_BedRoom = \u0026#34;卧室\u0026#34;; } goodGay::goodGay() { building = new Building; } void goodGay::visit() { cout \u0026lt;\u0026lt; \u0026#34;好基友正在访问\u0026#34; \u0026lt;\u0026lt; building-\u0026gt;m_SittingRoom \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;好基友正在访问\u0026#34; \u0026lt;\u0026lt; building-\u0026gt;m_BedRoom \u0026lt;\u0026lt; endl; } void goodGay::visit2() { cout \u0026lt;\u0026lt; \u0026#34;好基友正在访问\u0026#34; \u0026lt;\u0026lt; building-\u0026gt;m_SittingRoom \u0026lt;\u0026lt; endl; //cout \u0026lt;\u0026lt; \u0026#34;好基友正在访问\u0026#34; \u0026lt;\u0026lt; building-\u0026gt;m_BedRoom \u0026lt;\u0026lt; endl; } void test01() { goodGay gg; gg.visit(); } int main(){ test01(); system(\u0026#34;pause\u0026#34;); return 0; } 运算符重载： #\r作用：实现对类变量的自定义运算方法\n可实现重载的运算符：\n加号运算符 左移运算符 递增运算符 赋值运算符 关系运算符 函数调用运算符 //这里是表示对输出流里面的操作符实现重载 ostream\u0026amp; operator-(ostream\u0026amp; out,Person\u0026amp; p){ out\u0026lt;\u0026lt;\u0026#34;通过友元实现对私有变量的访问\u0026#34;\u0026lt;\u0026lt;p.m_A\u0026lt;\u0026lt;p.m_B; } 表示的意义就是对符号进行了自定义\n案例\n实现自己的数据类型 #\r雨山的整型数据 class RainyInteger { friend ostream \u0026amp;operator\u0026lt;\u0026lt;(ostream\u0026amp; out,RainyInteger rainyInteger); public: RainyInteger(){ //初始化数据： this-\u0026gt;rainy_num=0; } //前置++操作 RainyInteger\u0026amp; operator++(){ rainy_num++; return *this; } //后自增操作：??? RainyInteger\u0026amp; operator++(int){ RainyInteger tmp= *this; rainy_num++; return tmp; } void speak(RainyInteger *r){ cout\u0026lt;\u0026lt;r-\u0026gt;rainy_num\u0026lt;\u0026lt;endl; } private: int rainy_num; }; 内联函数 inline #\rinline int max(int a,int b){ } 继承 #\r语法：class 子类 : 继承方式 父类\nclass Father{ }; class Child1: public Father; class Child2: private Father; class Child3: protected Father; 构造和析构顺序： #\r子类继承自父类之后，调用子的构造函数将会造成父类的构造函数的调用，析构函数则相反，因为清理先从最小的子类开始清理。\n菱形继承问题 #\r简而言之就是父类被多个子类继承，多个子类被某一个孙子类同时继承，导致得问题是使得当孙子类继承两个子类中含有相同变量或者字段时造成二义\n示意图：\n解决办法-\u0026gt;虚继承 关键字：virtural\n在基类的两个子类中继承基类时，使用 virtual 关键字。虚继承基类。使得基类的属性成员只有一份。\nclass Animal { public: int m_Age; }; class Sheep : virtual public Animal {}; class Tuo : virtual public Animal {}; class SheepTuo : public Sheep, public Tuo {}; 继承之后子类获得了什么？ #\r公共变量和方法肯定是获得了。\n同时：\n父类中私有成员也是被子类继承下去了，只是由编译器给隐藏后访问不到\n多态 #\r静态多态: 函数重载 和 运算符重载属于静态多态，复用函数名 动态多态: 派生类和虚函数实现运行时多态 区别：\n静态多态的函数地址早绑定 - 编译阶段确定函数地址 动态多态的函数地址晚绑定 - 运行阶段确定函数地址 class Animal { public: //Speak函数就是虚函数 //函数前面加上virtual关键字，变成虚函数，那么编译器在编译的时候就不能确定函数调用了。 virtual void speak() { cout \u0026lt;\u0026lt; \u0026#34;动物在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; class Cat :public Animal { public: void speak() { cout \u0026lt;\u0026lt; \u0026#34;小猫在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; class Dog :public Animal { public: void speak() { cout \u0026lt;\u0026lt; \u0026#34;小狗在说话\u0026#34; \u0026lt;\u0026lt; endl; } }; //我们希望传入什么对象，那么就调用什么对象的函数 //如果函数地址在编译阶段就能确定，那么静态联编 //如果函数地址在运行阶段才能确定，就是动态联编 void DoSpeak(Animal \u0026amp; animal) { animal.speak(); } // //多态满足条件： //1、有继承关系 //2、子类重写父类中的虚函数 //多态使用： //父类指针或引用指向子类对象 void test01() { Cat cat; DoSpeak(cat); Dog dog; DoSpeak(dog); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 虚函数和纯虚析构 #\r在多态中，通常父类中虚函数的实现是毫无意义的，主要都是调用子类重写的内容\n因此可以将虚函数改为纯虚函数\n纯虚函数语法：virtual 返回值类型 函数名 （参数列表）= 0 ;\n当类中有了纯虚函数，这个类也称为==抽象类==\n虚函数的前提： #\r-\n基类，派生类拥有原型相同的成员函数 virtual 关键字 虚析构函数 #\r-\n虚析构函数是为了解决基类指针指向派生类对象，并用基类的指针销毁派生类对象 纯虚函数 #\r多态使用时，如果子类中有属性开辟到堆区，那么父类指针在释放时无法调用到子类的析构代码\n解决方式：将父类中的析构函数改为虚析构或者纯虚析构\n虚析构和纯虚析构共性：\n可以解决父类指针释放子类对象 都需要有具体的函数实现 虚析构和纯虚析构区别：\n如果是纯虚析构，该类属于抽象类，无法实例化对象 虚析构语法：\nvirtual ~类名(){}\n纯虚析构语法：\nvirtual ~类名() = 0;\n类名::~类名(){}\n-\n纯虚函数没有函数体，其作用实在基类中为派生类保留一个函数接口，方便派生类根据需要对它实现，实现多态。 函数的可变长参数：\nflaot avg(int size,...){ } C++模板 #\r函数模板 #\r建立一个通用函数，其函数返回值类型和形参类型可以不具体制定，用一个虚拟的类型来代表。\ntemplate\u0026lt;typename T\u0026gt; 函数声明或定义 template — 声明创建模板\ntypename — 表面其后面的符号是一种数据类型，可以用 class 代替\nT — 通用的数据类型，名称可以替换，通常为大写字母\n看起来和 java 里面的泛型比较像\n注意事项：\n自动类型推导，必须推导出一致的数据类型 T,才可以使用 模板必须要确定出 T 的数据类型，才可以使用 //1、指定传入的类型 void printPerson1(Person\u0026lt;string, int\u0026gt; \u0026amp;p) { p.showPerson(); } void test01() { Person \u0026lt;string, int \u0026gt;p(\u0026#34;孙悟空\u0026#34;, 100); printPerson1(p); } 类模板成员类外实现：\n#include \u0026lt;string\u0026gt; //类模板中成员函数类外实现 template\u0026lt;class T1, class T2\u0026gt; class Person { public: //成员函数类内声明 Person(T1 name, T2 age); void showPerson(); public: T1 m_Name; T2 m_Age; }; //构造函数 类外实现 template\u0026lt;class T1, class T2\u0026gt; Person\u0026lt;T1, T2\u0026gt;::Person(T1 name, T2 age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } //成员函数 类外实现 template\u0026lt;class T1, class T2\u0026gt; void Person\u0026lt;T1, T2\u0026gt;::showPerson() { cout \u0026lt;\u0026lt; \u0026#34;姓名: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄:\u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_Age \u0026lt;\u0026lt; endl; } STL 基本认识 #\rSTL(Standard Template Library,标准模板库) STL 从广义上分为: 容器(container) 算法(algorithm) 迭代器(iterator) 容器和算法之间通过迭代器进行无缝连接。 STL 几乎所有的代码都采用了模板类或者模板函数 STL 大体分为六大组件，分别是:容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器\n容器：各种数据结构，如 vector、list、deque、set、map 等,用来存放数据。 算法：各种常用的算法，如 sort、find、copy、for_each 等 迭代器：扮演了容器与算法之间的胶合剂。 仿函数：行为类似函数，可作为算法的某种策略。 适配器：一种用来修饰容器或者仿函数或迭代器接口的东西。 空间配置器：负责空间的配置与管理。 容器：置物之所也\nSTL 容器就是将运用最广泛的一些数据结构实现出来\n常用的数据结构：数组, 链表,树, 栈, 队列, 集合, 映射表 等\n这些容器分为序列式容器和关联式容器两种:\n序列式容器:强调值的排序，序列式容器中的每个元素均有固定的位置。 关联式容器:二叉树结构，各元素之间没有严格的物理上的顺序关系\n算法：问题之解法也\n有限的步骤，解决逻辑或数学上的问题，这一门学科我们叫做算法(Algorithms)\n算法分为:质变算法和非质变算法。\n质变算法：是指运算过程中会更改区间内的元素的内容。例如拷贝，替换，删除等等\n非质变算法：是指运算过程中不会更改区间内的元素内容，例如查找、计数、遍历、寻找极值等等\n迭代器：容器和算法之间粘合剂\n提供一种方法，使之能够依序寻访某个容器所含的各个元素，而又无需暴露该容器的内部表示方式。\n每个容器都有自己专属的迭代器\n迭代器使用非常类似于指针，初学阶段我们可以先理解迭代器为指针\n常见的容器 #\r","date":"27 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/c++/","section":"编程语言s","summary":"C++实现数据结构和初步的认识 #\r鉴于未来数据结构和算法的实现我想通过 C++来实现，现在简要总结下 C++的常用方法和数据结构类型\n头文件和方法声明 #\r等同于 C 语言\n标准输入输出函数 #\rstd::cout \u0026lt;\u0026lt; \u0026#34;Hello, World!\u0026#34; \u0026lt;\u0026lt; std::endl; 引入 using namespace std;这可以避免函数要不断的添加前缀\nusing namespace std; ... int input; cout\u0026lt;\u0026lt;\u0026#34;Hello world\u0026#34;\u0026lt;\u0026lt;endl;//输出函数 cin\u0026gt;\u0026gt;input; printf(\u0026#34;%d\u0026#34;,input); .","title":"C++","type":"编程语言"},{"content":"\r你好我的朋友 #\r下一曲\r与你分享我的眼睛\rPer aspera ad astra · 寻此苦旅 终达星辰\r金圣皓\r我喜欢听花开的声音，更想自由地深情地呼吸\rAncientElement\r春江潮水连海平，海上明月共潮生\rfansea\r目标明确，只管去做\rPinpe的云端\r一个属于自己的云朵。\r小棉尾巴\r关心前端技术、个人成长、女性主义和内容创作\r宁子博客\r人生得意须尽欢\r丨浅笑安然丨\r生活不止眼前的苟且，还有诗和远方\r草方块\r还没有名字的折腾人\r本站博客仓库地址：\nToDreamr/todreamr.github.io\rHTML 0\r0\r1. 关于友情链接 #\rInternet 是一张大网，而友情链接是一根蛛丝，把本站和广大博客群落连接起来。通过友情链接，你可以发现更多个人网站。\n1.1 如何申请友链？ #\r要想让你的友链出现在此处，有以下两种方式：\n向我（ 484510171@qq.com或 amixrip@163.com）发送电子邮件\n在下方评论区留言\n相应地，如果你的网站也有友链区，请把本站放入。\n1.2 必要信息 #\r你的邮件或留言需包含以下字段：\nname\t网站名 link\t网站链接 avatar\t头像地址 description\t介绍 三语字段示例：\nname\t网站名\nWebsite name\nlink\t网站链接\navatar\t头像地址\ndescription\t介绍\nDescription 紹介\n为保证简洁优雅，请言简意赅地填写descrition字段。\n若有疑问，请留言或发邮箱。\n\u0026hellip;\n","date":"27 October 2023","externalUrl":null,"permalink":"/friend/","section":"","summary":"你好我的朋友 #\r下一曲\r与你分享我的眼睛\rPer aspera ad astra · 寻此苦旅 终达星辰\r金圣皓\r我喜欢听花开的声音，更想自由地深情地呼吸\rAncientElement\r春江潮水连海平，海上明月共潮生\rfansea\r目标明确，只管去做\rPinpe的云端\r一个属于自己的云朵。\r小棉尾巴\r关心前端技术、个人成长、女性主义和内容创作\r宁子博客\r人生得意须尽欢\r丨浅笑安然丨\r生活不止眼前的苟且，还有诗和远方\r草方块\r还没有名字的折腾人\r本站博客仓库地址：\nToDreamr/todreamr.github.io\rHTML 0\r0\r1.","title":"friend","type":"page"},{"content":"","date":"27 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/","section":"编程语言s","summary":"","title":"编程语言s","type":"编程语言"},{"content":"","date":"27 October 2023","externalUrl":null,"permalink":"/tags/%E6%9C%8B%E5%8F%8B%E4%BB%AC/","section":"Tags","summary":"","title":"朋友们","type":"tags"},{"content":"","date":"27 October 2023","externalUrl":null,"permalink":"/tags/%E8%AF%AD%E8%A8%80/","section":"Tags","summary":"","title":"语言","type":"tags"},{"content":"","date":"25 October 2023","externalUrl":null,"permalink":"/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/","section":"Tags","summary":"","title":"面试题","type":"tags"},{"content":"\r题目 #\r难点：合并\n解决方法：\n实体类：\npackage com.atguigu; import lombok.AllArgsConstructor; import lombok.Data; /** * com.atguigu.ItemDO * * @author 春江花朝秋月夜 * @since 2023/10/25 14:45 */ @Data @AllArgsConstructor public class ItemDO { int id;//10011 int type;//具体不确定 double score;//[0，1000] @Override public String toString() { return \u0026#34;ItemDO{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, type=\u0026#34; + type + \u0026#34;, score=\u0026#34; + score + \u0026#39;\\n\u0026#39;+ \u0026#39;}\u0026#39;; } } 方法：\npackage com.atguigu; import java.util.*; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.TimeUnit; import java.util.stream.Collectors; /** * com.atguigu.ItemRank * * @author 春江花朝秋月夜 * @since 2023/10/25 14:46 */ public class ItemRank { private static ExecutorService executorService= Executors.newFixedThreadPool(2); public static List\u0026lt;ItemDO\u0026gt; rerank(List\u0026lt;ItemDO\u0026gt; itemList) throws InterruptedException { List\u0026lt;Integer\u0026gt; type=new ArrayList\u0026lt;\u0026gt;(); for (ItemDO itemDO:itemList) { type.add(itemDO.type);//添加类型，这可以用在类型数目不确定时候的遍历方法 } //分组 Map\u0026lt;Integer, List\u0026lt;ItemDO\u0026gt;\u0026gt; group = itemList.stream().collect(Collectors.groupingBy(ItemDO::getType)); //排序 Runnable sort=()-\u0026gt;{ group.forEach((key, value) -\u0026gt; value.sort((o1, o2) -\u0026gt; (int) (o2.getScore()-o1.getScore()))); }; List\u0026lt;ItemDO\u0026gt; res=new ArrayList\u0026lt;\u0026gt;(); Runnable merge=()-\u0026gt;{ //合并排序依据： Map\u0026lt;Integer,Integer\u0026gt; typeSort=new HashMap\u0026lt;\u0026gt;();//按照原来的位置填进去 for (Integer integer:group.keySet()) { typeSort.put(integer,0); } typeSort.keySet().forEach(System.out::println); //合并结果 for (int i=0;i\u0026lt;type.size();i++) { Integer curType= type.get(i);//当前的类型 List\u0026lt;ItemDO\u0026gt; tmp=group.get(curType); Integer index = typeSort.get(curType); res.add(tmp.get(index)); typeSort.put(curType,index+1); } }; executorService.submit(sort); executorService.submit(merge); executorService.awaitTermination(3, TimeUnit.SECONDS); executorService.shutdown(); return res; } } ","date":"25 October 2023","externalUrl":null,"permalink":"/entire-note/%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%9F%90%E4%B8%AA%E7%BE%A4%E9%87%8C%E7%9A%84/","section":"Entire-notes","summary":"题目 #\r难点：合并\n解决方法：\n实体类：\npackage com.atguigu; import lombok.AllArgsConstructor; import lombok.Data; /** * com.atguigu.ItemDO * * @author 春江花朝秋月夜 * @since 2023/10/25 14:45 */ @Data @AllArgsConstructor public class ItemDO { int id;//10011 int type;//具体不确定 double score;//[0，1000] @Override public String toString() { return \u0026#34;ItemDO{\u0026#34; + \u0026#34;id=\u0026#34; + id + \u0026#34;, type=\u0026#34; + type + \u0026#34;, score=\u0026#34; + score + \u0026#39;\\n\u0026#39;+ \u0026#39;}\u0026#39;; } } 方法：","title":"面试题","type":"entire-note"},{"content":"CAFE BABE -\u0026gt;表示这是一个.class文件\n类加载机制 #\r类加载的条件：\n使用new关键字创建对象时 使用某个类的静态成员（包括方法和字段）的时候（当然，final类型的静态字段有可能在编译的时候被放到了当前类的常量池中，这种情况下是不会触发自动加载的） 使用反射对类信息进行获取的时候（之前的数据库驱动就是这样的） 加载一个类的子类时 加载接口的实现类，且接口带有default的方法默认实现时 字节码指令 #\r先返回结果再进行自增或者先自增再给出结果\nAsm字节码框架 #\r劝退，还是算了。。。\nSpring实现的CGLib就是基于这个实现的。\n类加载机制 #\r","date":"24 October 2023","externalUrl":null,"permalink":"/entire-note/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E7%B1%BB%E5%8A%A0%E8%BD%BD/","section":"Entire-notes","summary":"CAFE BABE -\u0026gt;表示这是一个.class文件\n类加载机制 #\r类加载的条件：\n使用new关键字创建对象时 使用某个类的静态成员（包括方法和字段）的时候（当然，final类型的静态字段有可能在编译的时候被放到了当前类的常量池中，这种情况下是不会触发自动加载的） 使用反射对类信息进行获取的时候（之前的数据库驱动就是这样的） 加载一个类的子类时 加载接口的实现类，且接口带有default的方法默认实现时 字节码指令 #\r先返回结果再进行自增或者先自增再给出结果\nAsm字节码框架 #\r劝退，还是算了。。。\nSpring实现的CGLib就是基于这个实现的。\n类加载机制 #\r","title":"类加载","type":"entire-note"},{"content":"","date":"24 October 2023","externalUrl":null,"permalink":"/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/","section":"Tags","summary":"","title":"虚拟机","type":"tags"},{"content":"\r引用类型 #\r强引用：new Object(); #\rJVM不会随意回收强引用对象\n相反，将会尝试回收软引用\n软引用： #\rSoftReference\u0026lt;Object\u0026gt; soft=new SoftReference(); 设置内存大小：-Xms -Xmx\nReferenceQueue\u0026lt;Object\u0026gt; queue = new ReferenceQueue\u0026lt;\u0026gt;(); SoftReference\u0026lt;Object\u0026gt; reference = new SoftReference\u0026lt;\u0026gt;(new Object(), queue); System.out.println(reference); try{ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); while (true) list.add(new String(\u0026#34;lbwnb\u0026#34;)); }catch (Throwable t){ System.out.println(\u0026#34;发生了内存溢出！\u0026#34;+t.getMessage()); System.out.println(\u0026#34;软引用对象：\u0026#34;+reference.get()); System.out.println(queue.poll()); } 弱引用： #\rReferenceQueue\u0026lt;Object\u0026gt; queue = new ReferenceQueue\u0026lt;\u0026gt;(); SoftReference\u0026lt;Object\u0026gt; reference = new SoftReference\u0026lt;\u0026gt;(new Object(), queue); WeakReference\u0026lt;Object\u0026gt; weakReference=new WeakReference\u0026lt;\u0026gt;(new Object(),queue); System.gc(); System.out.println(reference.get()); System.out.println(weakReference.get()); WeakHashMap #\r当引用变量被断开的时候，这个哈希将会被断开\n虚引用 PhantomReference #\r直接标识,虚引用相当于没有引用，随时都有可能会被回收。\n","date":"24 October 2023","externalUrl":null,"permalink":"/entire-note/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E5%85%83%E7%A9%BA%E9%97%B4/%E5%85%83%E7%A9%BA%E9%97%B4/","section":"Entire-notes","summary":"引用类型 #\r强引用：new Object(); #\rJVM不会随意回收强引用对象\n相反，将会尝试回收软引用\n软引用： #\rSoftReference\u0026lt;Object\u0026gt; soft=new SoftReference(); 设置内存大小：-Xms -Xmx\nReferenceQueue\u0026lt;Object\u0026gt; queue = new ReferenceQueue\u0026lt;\u0026gt;(); SoftReference\u0026lt;Object\u0026gt; reference = new SoftReference\u0026lt;\u0026gt;(new Object(), queue); System.out.println(reference); try{ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); while (true) list.","title":"元空间和引用方式","type":"entire-note"},{"content":"\r全部文章\rHelp\r30 April 2024\u0026middot;1 分钟\r帮助文档\r代码随想录算法合辑\r19 March 2024\u0026middot;1 分钟\r算法\r抽象数据类型ADT\r18 March 2024\u0026middot;2 分钟\r要求熟记\rMysql-Redis\r15 March 2024\u0026middot;8 分钟\r主从部分\rMac体验版\r14 March 2024\u0026middot;1 分钟\r笔记\r爬虫浅记\r13 March 2024\u0026middot;2 分钟\r笔记\rWaline评论系统\r11 March 2024\u0026middot;1 分钟\r笔记\r计算机科学基础\r9 March 2024\u0026middot;3 分钟\r要求熟记\r使用主从模式搭建一个Socket网络通信模型\r6 March 2024\u0026middot;1 分钟\rnio\r微服务基础知识\r5 March 2024\u0026middot;2 分钟\r微服务\r微信登录\r2 March 2024\u0026middot;4 分钟\rOauth2\r自用的Vscode个人觉得还算耐看的主题和字体以及编码习惯\r2 March 2024\u0026middot;1 分钟\r笔记\rSpring-Security\r23 February 2024\u0026middot;1 分钟\rspring\rDocker\r8 February 2024\u0026middot;1 分钟\r笔记\rMusic\r7 February 2024\u0026middot;1 分钟\r笔记\r本站Music搭建相关\r7 February 2024\u0026middot;1 分钟\r笔记\r音乐\r29 January 2024\rNetFlix和SpringCloudAlibaba\r26 January 2024\u0026middot;1 分钟\r微服务\r我的生日\r15 November 2023\u0026middot;1 分钟\r生活\r区间个位和\r14 November 2023\u0026middot;1 分钟\rleetcode\r数之和\r14 November 2023\u0026middot;1 分钟\rleetcode\rEureka\r11 November 2023\u0026middot;1 分钟\r微服务\r写点脚本\r11 November 2023\u0026middot;1 分钟\r随机\r没备份笔记的后果\r11 November 2023\u0026middot;1 分钟\r随记\rRabbitMq\r7 November 2023\u0026middot;2 分钟\r消息队列\rVue3 响应式Api开发笔记\r4 November 2023\u0026middot;2 分钟\rvue\r搭建图床\r3 November 2023\u0026middot;1 分钟\r杂记\rC++\r27 October 2023\u0026middot;6 分钟\r语言\rfriend\r27 October 2023\u0026middot;1 分钟\r朋友们\r面试题\r25 October 2023\u0026middot;1 分钟\r面试题\r类加载\r24 October 2023\u0026middot;1 分钟\r虚拟机\r元空间和引用方式\r24 October 2023\u0026middot;1 分钟\r虚拟机\rLatex语法\r19 October 2023\u0026middot;1 分钟\rlatex\rJvm\r12 October 2023\u0026middot;2 分钟\r虚拟机\r垃圾回收机制\r12 October 2023\u0026middot;1 分钟\r虚拟机\r状态机\r12 October 2023\u0026middot;1 分钟\r硬件语言\r学习计划\r10 October 2023\u0026middot;1 分钟\r规划\r并发进阶\r9 October 2023\u0026middot;4 分钟\r并发编程\rJava-Concurrent\r9 October 2023\u0026middot;3 分钟\r并发编程\r如何通过hugo搭建自己的博客\r3 October 2023\u0026middot;1 分钟\r杂记\r科学上网\r3 October 2023\u0026middot;1 分钟\r杂记\r对象间的关系\r3 October 2023\u0026middot;1 分钟\rJava SE\r关键字\r3 October 2023\u0026middot;5 分钟\rJava SE\r实例化Node\r3 October 2023\u0026middot;1 分钟\rJava SE\r数据结构篇\r3 October 2023\u0026middot;1 分钟\r算法\r应该没人来这里吧\r3 October 2023\u0026middot;1 分钟\rThreadLocal\r3 October 2023\u0026middot;2 分钟\rJava SE\rRedis\r3 October 2023\u0026middot;2 分钟\r缓存\rHello Friend\r3 October 2003\u0026middot;1 分钟\rpost\r1 January 0001\u0026middot;52 分钟\r1 January 0001\u0026middot;1 分钟\rDocker\r1 January 0001\u0026middot;7 分钟\rMysql\r1 January 0001\u0026middot;6 分钟\rNetty\r1 January 0001\u0026middot;17 分钟\rNIO\r1 January 0001\u0026middot;22 分钟\rRabbitMq\r1 January 0001\u0026middot;7 分钟\rSpringCloud 1\r1 January 0001\u0026middot;9 分钟\rSpringCloud 2\r1 January 0001\u0026middot;11 分钟\rSpringCloud 3\r1 January 0001\u0026middot;10 分钟\r创建型\r1 January 0001\u0026middot;4 分钟\r二分法\r1 January 0001\u0026middot;1 分钟\r代码随想录\r封面测试\r1 January 0001\r复杂度\r1 January 0001\u0026middot;1 分钟\r代码随想录\r哈希篇\r1 January 0001\u0026middot;2 分钟\r代码随想录\r结构型\r1 January 0001\u0026middot;5 分钟\r链表的基本操作\r1 January 0001\u0026middot;1 分钟\r代码随想录\r链表篇\r1 January 0001\u0026middot;3 分钟\r代码随想录\r螺旋矩阵\r1 January 0001\u0026middot;2 分钟\r代码随想录\r面向对象设计原则\r1 January 0001\u0026middot;4 分钟\r书影音\r行为型\r1 January 0001\u0026middot;7 分钟\r移除元素\r1 January 0001\u0026middot;1 分钟\r代码随想录\r有序数组的平方\r1 January 0001\u0026middot;1 分钟\r代码随想录\r长度最小的数组\r1 January 0001\u0026middot;2 分钟\r代码随想录\r","date":"21 October 2023","externalUrl":null,"permalink":"/all/","section":"","summary":"\r全部文章\rHelp\r30 April 2024\u0026middot;1 分钟\r帮助文档\r代码随想录算法合辑\r19 March 2024\u0026middot;1 分钟\r算法\r抽象数据类型ADT\r18 March 2024\u0026middot;2 分钟\r要求熟记\rMysql-Redis\r15 March 2024\u0026middot;8 分钟\r主从部分\rMac体验版\r14 March 2024\u0026middot;1 分钟\r笔记\r爬虫浅记\r13 March 2024\u0026middot;2 分钟\r笔记\rWaline评论系统\r11 March 2024\u0026middot;1 分钟\r笔记\r计算机科学基础\r9 March 2024\u0026middot;3 分钟\r要求熟记\r使用主从模式搭建一个Socket网络通信模型\r6 March 2024\u0026middot;1 分钟\rnio\r微服务基础知识\r5 March 2024\u0026middot;2 分钟\r微服务\r微信登录\r2 March 2024\u0026middot;4 分钟\rOauth2\r自用的Vscode个人觉得还算耐看的主题和字体以及编码习惯\r2 March 2024\u0026middot;1 分钟\r笔记\rSpring-Security\r23 February 2024\u0026middot;1 分钟\rspring\rDocker\r8 February 2024\u0026middot;1 分钟\r笔记\rMusic\r7 February 2024\u0026middot;1 分钟\r笔记\r本站Music搭建相关\r7 February 2024\u0026middot;1 分钟\r笔记\r音乐\r29 January 2024\rNetFlix和SpringCloudAlibaba\r26 January 2024\u0026middot;1 分钟\r微服务\r我的生日\r15 November 2023\u0026middot;1 分钟\r生活\r区间个位和\r14 November 2023\u0026middot;1 分钟\rleetcode\r数之和\r14 November 2023\u0026middot;1 分钟\rleetcode\rEureka\r11 November 2023\u0026middot;1 分钟\r微服务\r写点脚本\r11 November 2023\u0026middot;1 分钟\r随机\r没备份笔记的后果\r11 November 2023\u0026middot;1 分钟\r随记\rRabbitMq\r7 November 2023\u0026middot;2 分钟\r消息队列\rVue3 响应式Api开发笔记\r4 November 2023\u0026middot;2 分钟\rvue\r搭建图床\r3 November 2023\u0026middot;1 分钟\r杂记\rC++\r27 October 2023\u0026middot;6 分钟\r语言\rfriend\r27 October 2023\u0026middot;1 分钟\r朋友们\r面试题\r25 October 2023\u0026middot;1 分钟\r面试题\r类加载\r24 October 2023\u0026middot;1 分钟\r虚拟机\r元空间和引用方式\r24 October 2023\u0026middot;1 分钟\r虚拟机\rLatex语法\r19 October 2023\u0026middot;1 分钟\rlatex\rJvm\r12 October 2023\u0026middot;2 分钟\r虚拟机\r垃圾回收机制\r12 October 2023\u0026middot;1 分钟\r虚拟机\r状态机\r12 October 2023\u0026middot;1 分钟\r硬件语言\r学习计划\r10 October 2023\u0026middot;1 分钟\r规划\r并发进阶\r9 October 2023\u0026middot;4 分钟\r并发编程\rJava-Concurrent\r9 October 2023\u0026middot;3 分钟\r并发编程\r如何通过hugo搭建自己的博客\r3 October 2023\u0026middot;1 分钟\r杂记\r科学上网\r3 October 2023\u0026middot;1 分钟\r杂记\r对象间的关系\r3 October 2023\u0026middot;1 分钟\rJava SE\r关键字\r3 October 2023\u0026middot;5 分钟\rJava SE\r实例化Node\r3 October 2023\u0026middot;1 分钟\rJava SE\r数据结构篇\r3 October 2023\u0026middot;1 分钟\r算法\r应该没人来这里吧\r3 October 2023\u0026middot;1 分钟\rThreadLocal\r3 October 2023\u0026middot;2 分钟\rJava SE\rRedis\r3 October 2023\u0026middot;2 分钟\r缓存\rHello Friend\r3 October 2003\u0026middot;1 分钟\rpost\r1 January 0001\u0026middot;52 分钟\r1 January 0001\u0026middot;1 分钟\rDocker\r1 January 0001\u0026middot;7 分钟\rMysql\r1 January 0001\u0026middot;6 分钟\rNetty\r1 January 0001\u0026middot;17 分钟\rNIO\r1 January 0001\u0026middot;22 分钟\rRabbitMq\r1 January 0001\u0026middot;7 分钟\rSpringCloud 1\r1 January 0001\u0026middot;9 分钟\rSpringCloud 2\r1 January 0001\u0026middot;11 分钟\rSpringCloud 3\r1 January 0001\u0026middot;10 分钟\r创建型\r1 January 0001\u0026middot;4 分钟\r二分法\r1 January 0001\u0026middot;1 分钟\r代码随想录\r封面测试\r1 January 0001\r复杂度\r1 January 0001\u0026middot;1 分钟\r代码随想录\r哈希篇\r1 January 0001\u0026middot;2 分钟\r代码随想录\r结构型\r1 January 0001\u0026middot;5 分钟\r链表的基本操作\r1 January 0001\u0026middot;1 分钟\r代码随想录\r链表篇\r1 January 0001\u0026middot;3 分钟\r代码随想录\r螺旋矩阵\r1 January 0001\u0026middot;2 分钟\r代码随想录\r面向对象设计原则\r1 January 0001\u0026middot;4 分钟\r书影音\r行为型\r1 January 0001\u0026middot;7 分钟\r移除元素\r1 January 0001\u0026middot;1 分钟\r代码随想录\r有序数组的平方\r1 January 0001\u0026middot;1 分钟\r代码随想录\r长度最小的数组\r1 January 0001\u0026middot;2 分钟\r代码随想录\r","title":"全部","type":"page"},{"content":"","date":"19 October 2023","externalUrl":null,"permalink":"/tags/latex/","section":"Tags","summary":"","title":"latex","type":"tags"},{"content":"\r环境设置： #\r\\begin{center} \\end{center} 这样就是一个环境，所有的都是隔离的。\n头部文件 #\r\\documentclass{setting} \\usepackage[utf8]{inputenc} \\usepackage[T1]{fontenc} \\usepackage{graphicx} \\usepackage[]{setspace} 在头部设置文件排版样式，导入依赖包，基本在本地\n运行部分 #\r\\begin{document} 选择合适的编译器才可以编译，否则出错\n导入自定义式样 #\r更新命令：texhash 式样文件的后缀：.cls文件，在里面自定义命令和样式实现排版布局\n例如下面：\n\\newcommand{\\role}[2]{ {\\par \\textit{#1} ~ #2 \\par} \\vspace{0.5ex} } \\newcommand{\\biInfo}[2]{ {#1 \\quad #2} } \\newcommand{\\tripleInfo}[3]{ {#1 \\quad #2 \\quad #3} } ","date":"19 October 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/latex/","section":"笔记s","summary":"\r环境设置： #\r\\begin{center} \\end{center} 这样就是一个环境，所有的都是隔离的。\n头部文件 #\r\\documentclass{setting} \\usepackage[utf8]{inputenc} \\usepackage[T1]{fontenc} \\usepackage{graphicx} \\usepackage[]{setspace} 在头部设置文件排版样式，导入依赖包，基本在本地\n运行部分 #\r\\begin{document} 选择合适的编译器才可以编译，否则出错\n导入自定义式样 #\r更新命令：texhash 式样文件的后缀：.cls文件，在里面自定义命令和样式实现排版布局\n例如下面：\n\\newcommand{\\role}[2]{ {\\par \\textit{#1} ~ #2 \\par} \\vspace{0.5ex} } \\newcommand{\\biInfo}[2]{ {#1 \\quad #2} } \\newcommand{\\tripleInfo}[3]{ {#1 \\quad #2 \\quad #3} } ","title":"Latex语法","type":"笔记"},{"content":"\r概述 #\rJVM 是模拟物理机实现的将 javac 编译为.class 文件，jvm 支持平台无关性。 class 文件通过类加载器-》解释器-》硬件沟通\nJvm 基于 HotSpot 虚拟机架构同时也是基于栈实现的。与 C 语言不同，不同架构的操作系统编译输出的文件不同，jvm 编译后产生的 文件完全相同。\n由于执行一段程序需要不断地编译和反编译，将热点执行的代买柜内为热点代码再转换为机器码提高执行效率。同时 jdk1.2 之后支持使用 JNI 来 调用 C/C++代码提升代码执行效率\n指令 #\r基本数据结构：堆栈+队列\n常见的编译命令：\njavap -g :vars xxx.java\n反编译： javap -v .class 文件地址\n反编译后的代码栈顶元素作为操作数，当需要保存变量的时候，进入队列\n部分变量某些关键字无法保存将会保存到常量池里面。例如 bipush 只支持单字节数据\n环境部署 #\rLinux 下下载相关依赖\nsudo yum install build-essential libxrender-dev xorg-dev libasound2-dev libcups2-dev gawk zip libxtst-dev libxi-dev libxt-dev gobjc gcc 环境：\nmake\njdk 环境：open-jdk8\nLinux 下编译结果：\n编译 Hello World：\n手动编译 jdk8 部分 #\rJVM 内存管理 #\rC/C++开发中，我们经常通过使用申请内存的方式来创建对象或是存放某些数据，但是这样也带来了一些额外的问题，我们要在何时释放这些内存，怎么才能使得内存的使用最高效，\u0026gt; 因此，内存管 理是一个非常严肃的问题。\n#include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(){ //动态申请4个int大小的内存空间 int* memory = malloc(sizeof(int) * 4); //修改第一个int空间的值 memory[0] = 10; //修改第二个int空间的值 memory[1] = 2; //遍历内存区域中所有的值 for (int i = 0;i \u0026lt; 4;i++){ printf(\u0026#34;%d \u0026#34;, memory[i]); } //释放指针所指向的内存区域 free(memory); //最后将指针赋值为NULL memory = NULL; } 一旦出现内存问题，我们就无法像 C/C++那样对所管理的内存进行合理地处理，因为所有的内存操作都是由 JVM 在进行，只有了解了 JVM 的内存管理机制，我们才能够在出现内存相关问题时找到解决方案。\nJNI #\r调用本地方法，调用 C 语言，关键字 native,通过静态代码块调用 C/C++的实现部分\npublic static void main(String[] args) { System.out.println(sum(1,2)); } private static native int sum(int a, int b);//原生的方法不可以具有函数实现 内存区域划分\n内存区域划分为：方法区（线程共享），堆（线程共享），虚拟机栈，本地方法栈，程序计数器\n方法区和堆栈随 JVM 生消，虚拟机栈，本地方法栈，程序计数器不共享彼此\n程序计数器 ：作为内存地址，每个地址指向下一条即将指令执行，自动更新，在 jvm 字节码解释器工作时改变时改变值确定指令位置 public static void main(String[] args) { System.out.println(sum(1,2)); }\nprivate static native int sum(int a, int b);//原生的方法不可以具有函数实现\n虚拟机栈 （关键部分），内次当 java 虚拟机创建的时候即可同步一个栈帧（栈里面的元素），栈帧包含了当前方法的一些元素信息：（局部变量表，操作数栈，动态链接，方法出口）\n虚拟机栈（线程私有） #\r每个栈帧保存一个可以指向当前方法所在类 的常量池，目的是：当前方法 8 中如果需要调用其他方法的时候，能够从运行时常量池中找到对应的符号引用，然后将符号引用转换为直接引用， 然后就能直接调用对应方法，这就是动态链接\n在虚拟机栈里面执行的行为就是对方法不断压栈出栈的过程，只有当所有方法出栈之后才可以执行主函数栈\n堆（线程共享） #\r作为虚拟机中最大的一块内存空间，区域职责是作为存放对象和数组，垃圾回收器也作用于此\n方法区（线程共享）（重点） #\r所有程序共享区域，存储类信息，静态变量，动态编译缓存部分，分为两大部分：类信息表+运行时常量池\n编译生成的常量也可以加入常量池里面。\n面试题：String 的常量池，常量池优化\n//String a=\u0026#34;I am a student\u0026#34;; // String b=\u0026#34;I am a student\u0026#34;; // String a=new String(\u0026#34;I am a student\u0026#34;); // String b=new String(\u0026#34;I am a student\u0026#34;); String a=new String(\u0026#34;I am \u0026#34;)+new String(\u0026#34;a student\u0026#34;); String b=new String(\u0026#34;I am \u0026#34;)+new String(\u0026#34;a student\u0026#34;); System.out.println(a.intern()==b.intern()); System.out.println(a.equals(b)); new 方式 #\rpublic static void main(String[] args) { String str1 = new String(\u0026#34;abc\u0026#34;); String str2 = new String(\u0026#34;abc\u0026#34;); System.out.println(str1 == str2); System.out.println(str1.equals(str2)); } %使用==判断时，比较地址得到的结果false %而使用equals时因为比较的是值，所以得到true 直接方式 #\rpublic static void main(String[] args) { String str1 = \u0026#34;abc\u0026#34;; String str2 = \u0026#34;abc\u0026#34;; System.out.println(str1 == str2);//注意这里不是通过new的方式，所以为了性能JVM会通过常量池指向这一块 System.out.println(str1.equals(str2)); } %是因为我们直接使用双引号赋值 %会先在常量池中查找是否存在相同的字符串，若存在，则将引用直接指向该字符串； %若不存在，则在常量池中生成一个字符串，再将引用指向该字符串： intern 方法(native 方法。底层实现是 C++) #\rpublic static void main(String[] args) { //不能直接写\u0026#34;abc\u0026#34;，双引号的形式，写了就直接在常量池里面吧abc创好了 String str1 = new String(\u0026#34;ab\u0026#34;)+new String(\u0026#34;c\u0026#34;); String str2 = new String(\u0026#34;ab\u0026#34;)+new String(\u0026#34;c\u0026#34;); System.out.println(str1.intern() == str2.intern()); System.out.println(str1.equals(str2)); } （线程独有）程序计数器：保存当前程序的执行位置。 （线程独有）虚拟机栈：通过栈帧，多线程里面的 markword 就维护在这里，来维持方法调用顺序，帮助控制程序有序运行。 （线程独有）本地方法栈：同上，作用与本地方法。 堆：所有的对象和数组都在这里保存。 方法区：类信息、即时编译器的代码缓存、运行时常量池。 内存爆炸和爆栈 #\rint[]arr=new int[Integer.MAX_VALUE]; 下面来个重磅的哈哈，直接爆栈 4 个 G\nstatic class Test{ } public static void main(String[] args) { List\u0026lt;Test\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); while (true){ list.add(new Test()); //无限创建Test对象并丢进List中 } } 好家伙，我这里直接 new 了一亿个 Test 对象 虚拟机栈是有限制的，无线递归压栈将会导致虚拟机栈爆炸\n申请堆外内存 #\rField unsafeField= Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe= (Unsafe) unsafeField.get(null); long memory = unsafe.allocateMemory(4); unsafe.putInt(memory,123); System.out.println(unsafe.getAddress(memory)); 获取类中定义的属性 #\rClass.getField(properties name) //获取当前类的属性 Class.getSuperClass().getDeclaredField(properties name) //获取当前类的父类的信息 ","date":"12 October 2023","externalUrl":null,"permalink":"/entire-note/%E8%99%9A%E6%8B%9F%E6%9C%BA/jvm/","section":"Entire-notes","summary":"概述 #\rJVM 是模拟物理机实现的将 javac 编译为.class 文件，jvm 支持平台无关性。 class 文件通过类加载器-》解释器-》硬件沟通\nJvm 基于 HotSpot 虚拟机架构同时也是基于栈实现的。与 C 语言不同，不同架构的操作系统编译输出的文件不同，jvm 编译后产生的 文件完全相同。\n由于执行一段程序需要不断地编译和反编译，将热点执行的代买柜内为热点代码再转换为机器码提高执行效率。同时 jdk1.2 之后支持使用 JNI 来 调用 C/C++代码提升代码执行效率\n指令 #\r基本数据结构：堆栈+队列\n常见的编译命令：","title":"Jvm","type":"entire-note"},{"content":"\r垃圾回收机制 #\r引用计数法 #\r创建引用变量\n循环引用,当对象成为null就没办法了\n可达性分析算法：\n最终判定过程，此过程可以最后挽留对象\n重写finalize方法，最后可以救赎被gc的对象\n比如下面这个情况\n注意：\n同时，这个方法只能生效一次，躲得过初一躲不过十五\n分代收集机制: #\r方法区使用永久代实现\n垃圾收集也分为： Minor GC - 次要垃圾回收，主要进行新生代区域的垃圾收集。\n触发条件：新生代的Eden区容量已满时。\nMajor GC - 主要垃圾回收，主要进行老年代的垃圾收集。\nFull GC - 完全垃圾回收，对整个Java堆内存和方法区进行垃圾回收。\n触发条件1：每次晋升到老年代的对象平均大小大于老年代剩余空间\n触发条件2：Minor GC后存活的对象超过了老年代剩余空间\n触发条件3：永久代内存不足（JDK8之前）\n触发条件4：手动调用System.gc()方法\n在JDK8之前，使用 永久代保存类和元数据 （meta）信息，类加载时产生同时全程JVM不会主动进行清除，最终将会导致OOM异常；\nJava8 中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间 的本质和永久代类似，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用 本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 native memory, 字符串池和类的静态变量放入 java 堆中，这样可以加载多少类的元数据就不再由 MaxPermSize 控制, 而由系统的实际可用空间来控制\n打印GC日志\nVM选项: -XX:PrintGCDetails\nMinor GC流程\n标记复制算法： #\r标记清除算法 利用GC算法，标记回收对象清除，但是会造成内存空隙，内存利用率低\n标记复制算法：解决内存利用率低的问题\n标记整理算法：\n在一次GC之后仍然存在大量的老年代,效率较低，将会出现程序停顿\n垃圾收集器实现： #\rSerial收集器 #\r当前垃圾收集器实现 #\r并发垃圾收集器CMS #\r垃圾清理过程中不会打断其他线程\n","date":"12 October 2023","externalUrl":null,"permalink":"/entire-note/%E8%99%9A%E6%8B%9F%E6%9C%BA/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","section":"Entire-notes","summary":"垃圾回收机制 #\r引用计数法 #\r创建引用变量\n循环引用,当对象成为null就没办法了\n可达性分析算法：\n最终判定过程，此过程可以最后挽留对象\n重写finalize方法，最后可以救赎被gc的对象\n比如下面这个情况\n注意：\n同时，这个方法只能生效一次，躲得过初一躲不过十五\n分代收集机制: #\r方法区使用永久代实现\n垃圾收集也分为： Minor GC - 次要垃圾回收，主要进行新生代区域的垃圾收集。\n触发条件：新生代的Eden区容量已满时。\nMajor GC - 主要垃圾回收，主要进行老年代的垃圾收集。\nFull GC - 完全垃圾回收，对整个Java堆内存和方法区进行垃圾回收。","title":"垃圾回收机制","type":"entire-note"},{"content":"","date":"12 October 2023","externalUrl":null,"permalink":"/tags/%E7%A1%AC%E4%BB%B6%E8%AF%AD%E8%A8%80/","section":"Tags","summary":"","title":"硬件语言","type":"tags"},{"content":"\r有限状态机 #\r寄存器和组合时序逻辑电路构成硬件时序逻辑电路\n特点：只能在时钟沿发生跳变时才能完成状态转移，状态机可以在时钟跳变时完成复杂的任务。\n状态机的结构 #\r状态寄存器由一组寄存器构成,n个寄存器可存储2^n个状态\n输出取决于状态和输入时，这样的状态机称为Mealy状态机，只和当前状态有关的称为Moore状态机\n描述有限状态机的方法： always语句和case语句\n","date":"12 October 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/vhdl/","section":"笔记s","summary":"有限状态机 #\r寄存器和组合时序逻辑电路构成硬件时序逻辑电路\n特点：只能在时钟沿发生跳变时才能完成状态转移，状态机可以在时钟跳变时完成复杂的任务。\n状态机的结构 #\r状态寄存器由一组寄存器构成,n个寄存器可存储2^n个状态\n输出取决于状态和输入时，这样的状态机称为Mealy状态机，只和当前状态有关的称为Moore状态机\n描述有限状态机的方法： always语句和case语句","title":"状态机","type":"笔记"},{"content":"","date":"10 October 2023","externalUrl":null,"permalink":"/tags/%E8%A7%84%E5%88%92/","section":"Tags","summary":"","title":"规划","type":"tags"},{"content":"\r必须完成！ #\r1:主线学习内容，消息队列，操作系统，计算机网络（理论），分布式微服务，安全框架（Spring-Security)\n2:支线学习内容，RBAC权限控制，防XSS攻击，JVM虚拟机， ElasticSearch搜索引擎（ELK）。Zookeeper,Dubbo。容器技术Docker，K8s。\n3：深入了解（底层）：Redis底层数据结构与实现，Redis集群，哨兵模式，Redis协议，Mysql隔离级别，日志，锁，事务\n2024.2.23日，上述70%完成，接下来应该完成：\r2024.3.20日，需要学习2，3,学习算法，修改简历\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r紧要任务 代码随想录-算法-计算机知识复习\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r学期任务 大厂\r毕业\r完成以下任务\r简历投递\r算法\r学习分布式事务Seata\r学习Redis集群+Mysql索引\r学习计算机网络专业课\r学习TCP/UDP\r图集 二次元赛高\r此生无悔二次元\r2023.10.24规定任务：\n学习内容 计划日期 是否完成 延期 Redis黑马点评项目完结 这学期 ✔️ ❌ 消息队列 这学期 ✔️ ❌ SpringSecurity安全框架 这学期 ✔️ ❌ Redis底层 这学期 ❌ ❌ JUC 这学期 ✔️ ❌ JVM 这学期 ✔️ ❌ GateWay 这学期 ✔️ ❌ Nacos 这学期 ✔️ ❌ 微服务 这学期 ✔️ ❌ 数据结构-图，哈希 这学期 ❌ ❌ ","date":"10 October 2023","externalUrl":null,"permalink":"/tasks/","section":"","summary":"必须完成！ #\r1:主线学习内容，消息队列，操作系统，计算机网络（理论），分布式微服务，安全框架（Spring-Security)\n2:支线学习内容，RBAC权限控制，防XSS攻击，JVM虚拟机， ElasticSearch搜索引擎（ELK）。Zookeeper,Dubbo。容器技术Docker，K8s。\n3：深入了解（底层）：Redis底层数据结构与实现，Redis集群，哨兵模式，Redis协议，Mysql隔离级别，日志，锁，事务\n2024.2.23日，上述70%完成，接下来应该完成：\r2024.3.20日，需要学习2，3,学习算法，修改简历\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r紧要任务 代码随想录-算法-计算机知识复习\r\u003c?xml version=\"1.0\" standalone=\"no\"?\u003e\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\r学期任务 大厂\r毕业\r完成以下任务\r简历投递\r算法\r学习分布式事务Seata\r学习Redis集群+Mysql索引\r学习计算机网络专业课\r学习TCP/UDP\r图集 二次元赛高\r此生无悔二次元\r2023.","title":"学习计划","type":"page"},{"content":"","date":"9 October 2023","externalUrl":null,"permalink":"/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","section":"Tags","summary":"","title":"并发编程","type":"tags"},{"content":"\r线程池 #\rnew Thread缺点：频繁创建和销毁，浪费了线程资源，短时间创建大量线程和销毁 线程池是有限可重复使用的线程，用完需要归还\n//构造方法，含有七个参数 public ThreadPoolExecutor(int corePoolSize,//核心线程池大小 int maximumPoolSize,//最大线程池大小 long keepAliveTime,//线程最大空闲时间 TimeUnit unit,//最大空闲时间单位 BlockingQueue\u0026lt;Runnable\u0026gt; workQueue//线程等待队列，当超出最大容量时，任务进入等待队列) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(),//线程创建工厂，可自定义 defaultHandler//拒绝策略，实在不能加入新的任务时，拒绝任务); } 根据CPU类型分配线程池大小 #\rThreadPoolExecutor #\rpublic static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, //2个核心线程，最大线程数为4个 3, TimeUnit.SECONDS, //最大空闲时间为3秒钟 new ArrayBlockingQueue\u0026lt;\u0026gt;(2)); //这里使用容量为2的ArrayBlockingQueue队列 for (int i = 0; i \u0026lt; 6; i++) { //开始6个任务 int finalI = i; executor.execute(() -\u0026gt; { try { System.out.println(Thread.currentThread().getName()+\u0026#34; 开始执行！（\u0026#34;+ finalI); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName()+\u0026#34; 已结束！（\u0026#34;+finalI); } catch (InterruptedException e) { e.printStackTrace(); } }); } TimeUnit.SECONDS.sleep(1); //看看当前线程池中的线程数量 System.out.println(\u0026#34;线程池中线程数量：\u0026#34;+executor.getPoolSize()); TimeUnit.SECONDS.sleep(5); //等到超过空闲时间 System.out.println(\u0026#34;线程池中线程数量：\u0026#34;+executor.getPoolSize()); executor.shutdownNow(); //使用完线程池记得关闭，不然程序不会结束，它会取消所有等待中的任务以及试图中断正在执行的任务，关闭后，无法再提交任务，一律拒绝 //executor.shutdown(); 同样可以关闭，但是会执行完等待队列中的任务再关闭 } } ArrayBlockingQueue #\r作为有界的阻塞队列，具有响应的容量，可以自行设置，对比SynchronousQueue没有容量，选这个会出现爆栈的问题，原因 是线程池ThreadPoolExecutor发现容量超出时会poll线程，但SynchronousQueue没有容量poll无意义。 在线程池里面的等待队列需要具有容量。\n线程池的拒绝策略 #\r线程池超过最大的容量时，需要拒绝这个任务。\nAbortPolicy(default): 直接抛异常 CallerRunsPolicy: 直接让提交任务的线程运行这个任务，如果向主线程提交了任务就让主线程去执行这个任务，谁提交谁执行 DiscardOldestPolicy: 丢弃队列中最近的任务，替换为当前任务 DiscardPolicy: Do nothing 自定义拒绝策略和线程生产工厂 任务过程出现异常，线程池当中执行任务时发生异常，线程将会自动销毁\nExecutorService #\r可以使用Executors工具类来快速创建线程池：\nExecutorService executor = Executors.newFixedThreadPool(2); //直接创建一个固定容量的线程池 ExecutorService本质内部实现其实是ThreadPoolExecutor，所以创建的线程都不是核心线程\n//内部实现 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } 直接将最大线程和核心线程数量设定为一样的，并且等待时间为0，因为压根不需要，并且采用的是一个无界的LinkedBlockingQueue作为等待队列。\n//创建单个线程 public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } 这里并不是直接创建的一个ThreadPoolExecutor对象，而是套了一层FinalizableDelegatedExecutorService，目的是内部套了一层，外部不可见，不可修改，保证安全性\n由于executorService内部直接最大容量为Integer.\tMAX_VALUE,非常大，不安全\nnewCachedThreadPool #\r注意生成的线程池里面都不是核心线程，同时最大容量非常大，需要慎用\n执行带返回值的任务： #\rExecutorService执行任务有两种方法：submit和execute\n接受返回值的只有submit\npublic static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService=Executors.newSingleThreadExecutor(); Future\u0026lt;String\u0026gt; future= executorService.submit(()-\u0026gt;{ TimeUnit.SECONDS.sleep(3); return \u0026#34;你好世界\u0026#34;; }); System.out.println(future.cancel(true));//取消任务，这时候里面的字串将不会再返回出来 executorService.shutdown(); System.out.println(future.get()); } 定时任务ScheduledThreadPoolExecutor #\rScheduledThreadPoolExecutor executor=new ScheduledThreadPoolExecutor(1); // executor.schedule(()-\u0026gt; System.out.println(\u0026#34;开始定时任务\u0026#34;),3,TimeUnit.SECONDS); // ScheduledFuture\u0026lt;String\u0026gt; scheduledFuture=executor.schedule(()-\u0026gt; \u0026#34;开始定时任务\u0026#34;,3,TimeUnit.SECONDS); // System.out.println(scheduledFuture.isDone()); //固定频率进行定时计划： executor.scheduleAtFixedRate(()-\u0026gt; System.out.println(\u0026#34;hello!\u0026#34;),3,1,TimeUnit.SECONDS); // executor.shutdown(); 线程延迟线程池：ScheduledWithFixedDelay protected void finalize() { //在GC时，会执行finalize方法，此方法中会关闭掉线程池，释放资源 super.shutdown(); } 线程池实现原理 #\r//这个就是我们指定的阻塞队列 private final BlockingQueue\u0026lt;Runnable\u0026gt; workQueue; //再次提醒，这里没加锁！！该有什么意识不用我说了吧，所以说ctl才会使用原子类。 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); //如果任务为null，那执行个寂寞，所以说直接空指针 int c = ctl.get(); //获取ctl的值，一会要读取信息的 if (workerCountOf(c) \u0026lt; corePoolSize) { //判断工作线程数量是否小于核心线程数 if (addWorker(command, true)) //如果是，那不管三七二十一，直接加新的线程执行，然后返回即可 return; c = ctl.get(); //如果线程添加失败（有可能其他线程也在对线程池进行操作），那就更新一下c的值 } if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { //继续判断，如果当前线程池是运行状态，那就尝试向阻塞队列中添加一个新的等待任务 int recheck = ctl.get(); //再次获取ctl的值 if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) //这里是再次确认当前线程池是否关闭，如果添加等待任务后线程池关闭了，那就把刚刚加进去任务的又拿出来 reject(command); //然后直接拒绝当前任务的提交（会根据我们的拒绝策略决定如何进行拒绝操作） else if (workerCountOf(recheck) == 0) //如果这个时候线程池依然在运行状态，那么就检查一下当前工作线程数是否为0，如果是那就直接添加新线程执行 addWorker(null, false); //添加一个新的非核心线程，但是注意没添加任务 //其他情况就啥也不用做了 } else if (!addWorker(command, false)) //这种情况要么就是线程池没有运行，要么就是队列满了，按照我们之前的规则，核心线程数已满且队列已满，那么会直接添加新的非核心线程，但是如果已经添加到最大数量，这里肯定是会失败的 reject(command); //确实装不下了，只能拒绝 } addWorker实现 #\rprivate boolean addWorker(Runnable firstTask, boolean core) { //这里给最外层循环打了个标签，方便一会的跳转操作 retry: for (;;) { //无限循环，老套路了，注意这里全程没加锁 int c = ctl.get(); //获取ctl值 int rs = runStateOf(c); //解析当前的运行状态 // Check if queue empty only if necessary. if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; //判断线程池是否不是处于运行状态 ! (rs == SHUTDOWN \u0026amp;\u0026amp; //如果不是运行状态，判断线程是SHUTDOWN状态并、任务不为null、等待队列不为空，只要有其中一者不满足，直接返回false，添加失败 firstTask == null \u0026amp;\u0026amp; ! workQueue.isEmpty())) return false; for (;;) { //内层又一轮无限循环，这个循环是为了将线程计数增加，然后才可以真正地添加一个新的线程 int wc = workerCountOf(c); //解析当前的工作线程数量 if (wc \u0026gt;= CAPACITY || wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) //判断一下还装得下不，如果装得下，看看是核心线程还是非核心线程，如果是核心线程，不能大于核心线程数的限制，如果是非核心线程，不能大于最大线程数限制 return false; if (compareAndIncrementWorkerCount(c)) //CAS自增线程计数，如果增加成功，任务完成，直接跳出继续 break retry; //注意这里要直接跳出最外层循环，所以用到了标签（类似于goto语句） c = ctl.get(); // 如果CAS失败，更新一下c的值 if (runStateOf(c) != rs) //如果CAS失败的原因是因为线程池状态和一开始的不一样了，那么就重新从外层循环再来一次 continue retry; //注意这里要直接从最外层循环继续，所以用到了标签（类似于goto语句） // 如果是其他原因导致的CAS失败，那只可能是其他线程同时在自增，所以重新再来一次内层循环 } } //好了，线程计数自增也完了，接着就是添加新的工作线程了 boolean workerStarted = false; //工作线程是否已启动 boolean workerAdded = false; //工作线程是否已添加 Worker w = null; //暂时理解为工作线程，别急，我们之后会解读Worker类 try { w = new Worker(firstTask); //创建新的工作线程，传入我们提交的任务 final Thread t = w.thread; //拿到工作线程中封装的Thread对象 if (t != null) { //如果线程不为null，那就可以安排干活了 final ReentrantLock mainLock = this.mainLock; //又是ReentrantLock加锁环节，这里开始就是只有一个线程能进入了 mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); //获取当前线程的运行状态 if (rs \u0026lt; SHUTDOWN || (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) { //只有当前线程池是正在运行状态，或是SHUTDOWN状态且firstTask为空，那么就继续 if (t.isAlive()) // 检查一下线程是否正在运行状态 throw new IllegalThreadStateException(); //如果是那肯定是不能运行我们的任务的 workers.add(w); //直接将新创建的Work丢进 workers 集合中 int s = workers.size(); //看看当前workers的大小 if (s \u0026gt; largestPoolSize) //这里是记录线程池运行以来，历史上的最多线程数 largestPoolSize = s; workerAdded = true; //工作线程已添加 } } finally { mainLock.unlock(); //解锁 } if (workerAdded) { t.start(); //启动线程 workerStarted = true; //工作线程已启动 } } } finally { if (! workerStarted) //如果线程在上面的启动过程中失败了 addWorkerFailed(w); //将w移出workers并将计数器-1，最后如果线程池是终止状态，会尝试加速终止线程池 } return workerStarted; //返回是否成功 } 并发工具类 #\r计数器锁（CountDownLatch） #\r多任务同步神器。它允许一个或多个线程，等待其他线程完成工作,典型应用场景：多个线程分段相加最后统计所有线程的和\n要实现这个需求，那么有一个很麻烦的地方，我们不知道任务到底什么时候执行完毕，那么可否将最终统计延迟一定时间进行呢？但是最终统计无论延迟多久进行， 要么不能保证所有任务都完成，要么可能所有任务都完成了而这里还在等。\npublic static void main(String[] args) throws InterruptedException { CountDownLatch latch=new CountDownLatch(20); for (int i = 0; i \u0026lt; 20; i++) { int finalI=i; new Thread(()-\u0026gt;{ try { Thread.sleep((long) (2000 * new Random().nextDouble())); System.out.println(\u0026#34;任务\u0026#34;+finalI+\u0026#34;完成\u0026#34;); }catch (InterruptedException e){ e.printStackTrace(); } latch.countDown(); //每执行一次计数器都会-1 }).start(); } //开始等待所有的线程完成，当计数器为0时，恢复运行 latch.await(); //这个操作可以同时被多个线程执行，一起等待，这里只演示了一个 System.out.println(\u0026#34;所有子任务都完成！任务完成！！！\u0026#34;); } 例子： 用四个线程实现对1到10000完成累计加和\npublic static void main(String[] args) throws InterruptedException { long begin=System.currentTimeMillis(); CountDownLatch latch=new CountDownLatch(4); int res[]=new int[4]; for (int i = 0; i \u0026lt; 4; i++) { int finalI=i; new Thread(()-\u0026gt;{ int sum=0; int numbersPerThread = (int) Math.ceil((double) 100/ 4); int startNumber = finalI * numbersPerThread + 1; int endNumber = (finalI + 1) * numbersPerThread; for (int j =startNumber ; j \u0026lt;=endNumber; j++) { sum+=j; } System.out.println(sum); res[finalI]=sum; latch.countDown(); //每执行一次计数器都会-1 }).start(); } //开始等待所有的线程完成，当计数器为0时，恢复运行 latch.await(); //这个操作可以同时被多个线程执行，一起等待，这里只演示了一个 int result=0; for (Integer integer:res) { result+=integer; } long end=System.currentTimeMillis(); System.out.println(\u0026#34;所有子任务都完成！任务完成,结果是\u0026#34;+result+\u0026#34;花费时间：\u0026#34;+(end-begin)+\u0026#34;ms\u0026#34;); } 实现效果： 共享锁是线程共享的，同一时刻能有多个线程拥有共享锁。 如果一个线程刚获取了共享锁，那么在其之后等待的线程也很有可能能够获取到锁，所以得传播下去继续尝试唤醒后面的结点，不像独占锁，独占的压根不需要考虑这些。 如果一个线程刚释放了锁，不管是独占锁还是共享锁，都需要唤醒后续等待结点的线程。 实现原理：\n在工具构建的时候创建多个共享锁，调用countDown（）调用时就可以减去一把锁，当state减为0时即可获取共享锁，实现方式是通过 链表向后继节点一个个从等待状态唤醒\n循环屏障CyclicBarrier #\r循环屏障会不断阻挡线程，直到被阻挡的线程足够多时，才能一起冲破屏障，并且在 冲破屏障时，我们也可以做一些其他的任务。这和人多力量大的道理是差不多的，当人足够多时方能冲破阻碍， 到达美好的明天。当然，屏障由于是可循环的，所以它在被冲破后，会重新开始计数，继续阻挡后续的线程：\nCyclicBarrier barrier = new CyclicBarrier(5); //创建一个初始值为5的循环屏障 屏障最大容量：parties 特点：等待线程冲破阻碍的时候才可以 一起完成任务，完成任务之后继续等待，直到下一次达到最大值 。\n当await状态下的线程被中断，屏障将会被破坏，这一轮不能使用，除非重新开始\n信号量 Semaphore #\r限制信号容量，在一段任务中，要求 只能部分线程完成这段工作的时候完成\n线程之间进行数据交换 Exchanger #\r实现两个线程之间进行数据交换的通信，只有当两个线程完成交换之后才可以完成任务，否则线程阻塞。\nFork/Join框架 #\rForkJoinPool pool = new ForkJoinPool();\nfork指的是划分任务，任务约分越细 join指的是加入任务，任务开始执行 END #\r","date":"9 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/%E8%BF%9B%E9%98%B6/","section":"编程语言s","summary":"线程池 #\rnew Thread缺点：频繁创建和销毁，浪费了线程资源，短时间创建大量线程和销毁 线程池是有限可重复使用的线程，用完需要归还\n//构造方法，含有七个参数 public ThreadPoolExecutor(int corePoolSize,//核心线程池大小 int maximumPoolSize,//最大线程池大小 long keepAliveTime,//线程最大空闲时间 TimeUnit unit,//最大空闲时间单位 BlockingQueue\u0026lt;Runnable\u0026gt; workQueue//线程等待队列，当超出最大容量时，任务进入等待队列) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(),//线程创建工厂，可自定义 defaultHandler//拒绝策略，实在不能加入新的任务时，拒绝任务); } 根据CPU类型分配线程池大小 #\rThreadPoolExecutor #\rpublic static void main(String[] args) throws InterruptedException { ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 4, //2个核心线程，最大线程数为4个 3, TimeUnit.","title":"并发进阶","type":"编程语言"},{"content":"\rJava 并发编程 #\r轻量级锁： #\r检查当前对象的mark word是否有被其他线程占用，假如没有就会在当前栈帧里面建立一个 锁记录，复制并存储当前对象的mark word 信息。\n不像重量级锁需要向系统申请互斥量，\nCAS（无锁算法） #\r显然，当cas失败的时候，说明有线程进入了这个同步代码块，这个时候，虚拟机将会检查 当前对象的mark word是否指向当前对象的栈帧，是的话就说明当前已经获得锁，否则不是-》退化为重量级锁(不可逆) 解锁时，同样使用CAS算法操作，同时唤醒挂起的线程\n偏向锁 #\r当某个锁频繁的被同一个线程获取，对轻量级锁进行优化，所以偏向锁专门为单个线程服务，此时，无须再进行CAS操作，当其他线程 又开始抢锁，偏向锁可能退化为轻量级锁。注意当调用对象的hashCode（）方法，由于mark word 数据结构无法 保存hash值，偏向锁直接退化为轻量级锁。\n锁的退化不可逆\n锁消除和锁优化 #\r代码块中有可能不会总是出现请求锁和释放锁的问题，（比如循环中加锁），此时锁为了优化出现锁消除和锁优化\nJava内存模型（JMM） #\r主内存： 存放对象实例的部分 工作内存：虚拟机栈的部分，放入cpu的高速缓存里面。 自增操作不是由一个指令实现的！！！包括获取，修改和保存\nclass Test{ private static volatile int sum=0;//成员变量,这样的变量必须是当前的对象所拥有的 //加入了volatile关键字之后，线程之间可以感知彼此的值 @Test void LockTestAdd() throws InterruptedException { //没有加锁的时候，由于线程之间不能感知对方的值，最终结构可能不会是200 Thread th1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 100; i++) sum++; }); Thread th2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 100; i++) sum++; }); th1.start(); th2.start(); Thread.sleep(100); System.out.println(sum); } } 重排序 #\r由于JVM虚拟机和编译器的优化，指令可能出现重排序，在这种情况下可能出现不符合预期的情况\nvolatile关键字（无法保证原子性，但能保证可见性） #\rload和save操作，将主内存中的变量拷贝到本地，只对本地变量进行操作。\nvolatile实现原理就是改变成员变量时，save的工作区的变量无效。重新更新主内存中的变量值， volatile关键字会禁止指令重排序。\nclass VolatileTest{ private static volatile int sum=0;//成员变量,这样的变量必须是当前的对象所拥有的 //加入了volatile关键字之后，线程之间可以感知彼此的值,但还是无法保证原子性操作，不能达到预期效果 @Test void LockTestAdd() throws InterruptedException { //没有加锁的时候，由于线程之间不能感知对方的值，最终结构可能不会是200 Thread th1 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) sum++; }); Thread th2 = new Thread(() -\u0026gt; { for (int i = 0; i \u0026lt; 1000; i++) { sum++; } }); th1.start(); th2.start(); Thread.sleep(100); System.out.println(sum); } } JVM编译器下面的顺序执行：\nHappens Before 原则（之前的对之后的可见） #\r程序次序规则，监视器锁原则，volatile关键字原则（写操作在读操作之前），\nstart(线程启动规则) #\rA线程用start调用B线程，那么A在B之前（A happens before B）\njoin线程加入规则 #\rA线程join线程B，那么B在A之前（B happens before A）\n程和线程的区别 #\r程序软件 \u0026gt; 进程 \u0026gt; 线程\n锁的框：Lock #\r为了代替传统的synchronized,notify,wait,notifyAll关键字，Lock接口-\u0026gt;ReentrantLock可重入锁\n可重入锁（排他锁） #\r多次加锁，其他线程想要得到锁需要把多次的锁释放才可以获取这把锁\n当存在线程想要获取锁但是锁没有释放的时候，此时这些线程将会进入线程队列里面\n公平锁和非公平锁（AQS） #\r公平锁始终保持先到先得到锁，非公平锁则是在等待队列中所有等待线程同时尝试获取锁，获取不到则再次进入等待队列\nReentrantLock lock=new ReentrantLock(false);//公平锁不一定总是保持公平。队列同步器 Runnable runnable=()-\u0026gt;{ System.out.println(Thread.currentThread().getName() + \u0026#34;开始尝试获取锁资源\u0026#34;); lock.lock(); System.out.println(Thread.currentThread().getName() + \u0026#34;成功😺😺😺😺😺😺😺😺😺获取锁资源\u0026#34;); lock.unlock(); }; for (int i = 0; i \u0026lt; 10; i++) { new Thread(runnable,\u0026#34;T\u0026#34;+i).start(); } 读写锁： #\r除了可重入锁之外，还有一种类型的锁叫做读写锁，当然它并不是专门用作读写操作的锁， 它和可重入锁不同的地方在于，可重入锁是一种排他锁，当一个线程得到锁之后，另一个线程必须等待其释放锁，否则一律不允许获取到锁。而读写锁在同一时间，是可以让多个线程获取到锁的，它其实就是针对于读写场景而出现的。\n读写锁维护了一个读锁和一个写锁，这两个锁的机制是不同的。\n读锁：在没有任何线程占用写锁的情况下，同一时间可以有多个线程加读锁。\n写锁：在没有任何线程占用读锁的情况下，同一时间只能有一个线程加写锁。\n显然读锁是可以重复获取的但是写锁不能，当一个线程同时拥有写锁和读锁的时候，先申请读锁 然后释放写锁，此时其他的线程又可以获取读锁，只剩下读锁，此时称之为“锁降级”。 在仅仅持有读锁的时候去申请写锁，称为“锁升级”，这时候ReentryReadWriteLock类不支持。\n队列同步器AQS（AbstractQueuedSynchronizer） #\r继承关系：Lock-\u0026gt; Sync -\u0026gt; AbstractQueuedSynchronizer\n多线程并发环境下的ABA问题 #\r//ABA问题的版本号解决方法 AtomicReference\u0026lt;String\u0026gt; atomicReference=new AtomicReference\u0026lt;\u0026gt;(\u0026#34;A\u0026#34;); System.out.println(atomicReference.compareAndSet(\u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;)); String hello = \u0026#34;hello\u0026#34;; String world = \u0026#34;world\u0026#34;; Runnable r=()-\u0026gt;{ System.out.println(atomicReference.compareAndSet(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;)); }; for (int i = 0; i \u0026lt; 100; i++) { new Thread(r).start(); } 可以看到多个线程尝试去修改的时候出现了一个true\n解决办法：添加版本号，每次修改的时候对版本号（stamp）进行修正\n并发容器 #\r比如在对链表添加元素的时候，还没有完成对链表扩容之前，其他线程插队，非法插入元素，就会造成数组越界的报错。\nConcurrentHashMap:在jdk1.7之前的实现方法，比如在原子类里面实现LongAdder具有压力分散的思想，提高了性能，选择将数据一段一段的存储，这样就减少了等待，当线程访问锁的时候只占用锁的一小部分 jdk8之后，实现方法是通过cas算法配合锁机制实现的。由于HashMap利用了哈希表，容量越大，加锁的粒度就会越细。 //原子类的测试操作 //ABA问题的版本号解决方法 CopyOnWriteArrayList\u0026lt;Object\u0026gt; objects = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); //读取不加锁，写数据需要加锁，所以性能还行 //专用于多线程环境下的容器 LinkedList\u0026lt;Object\u0026gt; list = new LinkedList\u0026lt;\u0026gt;();//没有发生并发异常 ArrayList\u0026lt;Object\u0026gt; list1 = new ArrayList\u0026lt;\u0026gt;(); ConcurrentHashMap\u0026lt;Integer, String\u0026gt; map = new ConcurrentHashMap\u0026lt;\u0026gt;(); HashMap\u0026lt;Integer, String\u0026gt; hashMap = new HashMap\u0026lt;\u0026gt;(); Runnable r=()-\u0026gt;{ for (int j = 0; j \u0026lt; 100; j++) { int finalI=j; objects.add(\u0026#34;aaa\u0026#34;); map.put(finalI,\u0026#34;aaa\u0026#34;); hashMap.put(finalI,\u0026#34;aaa\u0026#34;); } }; for (int i = 0; i \u0026lt; 100; i++) { new Thread(r).start(); } TimeUnit.SECONDS.sleep(1); 阻塞队列（BlokingQueue） #\r生产者消费之模型：\n//测试阻塞队列实现生产者消费者模型 BlockingQueue\u0026lt;Object\u0026gt; queue=new ArrayBlockingQueue\u0026lt;\u0026gt;(1);//窗口只能放一个菜，阻塞队列的容量 Runnable supplier=()-\u0026gt;{ while (true){ try { String name = Thread.currentThread().getName(); System.err.println(time()+\u0026#34;生产者\u0026#34;+name+\u0026#34;正在准备餐品\u0026#34;); TimeUnit.SECONDS.sleep(3); System.err.println(time()+\u0026#34;生产者\u0026#34;+name+\u0026#34;已出餐\u0026#34;); queue.put(new Object()); }catch (InterruptedException e){ e.printStackTrace(); break; } } }; Runnable consumer=()-\u0026gt;{ while (true){ try { String name = Thread.currentThread().getName(); System.out.println(time()+\u0026#34;消费者\u0026#34;+name+\u0026#34;正在等待餐品\u0026#34;); queue.take(); System.out.println(time()+\u0026#34;消费者\u0026#34;+name+\u0026#34;已取餐\u0026#34;); TimeUnit.SECONDS.sleep(4); System.out.println(time()+\u0026#34;消费者\u0026#34;+name+\u0026#34;已吃完\u0026#34;); }catch (InterruptedException e){ e.printStackTrace(); break; } } }; for (int i = 0; i \u0026lt; 2; i++) { new Thread(supplier,\u0026#34;supplier\u0026#34;+i).start(); } for (int i = 0; i \u0026lt; 3; i++) { new Thread(consumer,\u0026#34;consumer\u0026#34;+i).start(); } } public static String time(){ SimpleDateFormat format = new SimpleDateFormat(\u0026#34;HH:mm:ss\u0026#34;); return \u0026#34;[\u0026#34;+format.format(new Date())+\u0026#34;]\u0026#34;; } 常见的阻塞队列：ArrayBlokingQueue(有界缓冲阻塞队列),SynchronousQueue(无缓冲阻塞队列),LinkedBlokingQueue(无界带缓冲阻塞队列)\npublic boolean offer(E e) { Objects.requireNonNull(e);//检查当前的队列是否为空 final ReentrantLock lock = this.lock;//对当前线程加锁 lock.lock(); try { if (count == items.length) return false; else { enqueue(e); return true; } } finally { lock.unlock(); } } public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await();//当当前线程读取到队列为空时，由于take操作时阻塞的，需要挂起当前线程，等待直到队列里面有值 return dequeue(); } finally { lock.unlock(); } } SynchronousQueue(没有任何容量，插入和取出是一一对应的) #\rSynchronousQueue\u0026lt;String\u0026gt; queue=new SynchronousQueue\u0026lt;\u0026gt;(); new Thread(()-\u0026gt;{ try { System.out.println(queue.take()); } catch (InterruptedException e) { throw new RuntimeException(e); } }).start(); queue.put(\u0026#34;sss\u0026#34;); 这是一个特殊的队列，内部维护了一个抽象类Transfer（put和take操作糅合在一起了）， 里面有一个方法：transfer（E e,bolean timed,long nanos）直接通过生产者和消费者模型来实现数据的传递。 当新的元素put进去线程将会阻塞。直到元素被take。同时这个类维护了公平锁和非公平锁两种方法。\n当当前队列里面有元素但是没有线程来取元素时候，就会开启自旋，当自旋一定次数之后还没有来取就会挂起\nPriorityBlockingQueue优先队列 #\r构造方法：PriorityQueue queue=new PriorityQueue(10,Integer::compare);\n传入容量和函数逻辑（优先逻辑）\nDelayQueue延时队列 #\r特殊地方：存储的元素必须是继承自Delayed接口的类，同时元素类必须实现Delayed接口。\n使用时可以实现延时出队，按照同时的时候按照优先级（自己实现）进行出队，这样就可以实现缓存了。\n底层实现：\npublic class DelayQueue\u0026lt;E extends Delayed\u0026gt; extends AbstractQueue\u0026lt;E\u0026gt; implements BlockingQueue\u0026lt;E\u0026gt; { private final transient ReentrantLock lock = new ReentrantLock(); private final PriorityQueue\u0026lt;E\u0026gt; q = new PriorityQueue\u0026lt;E\u0026gt;(); //通过内部维护的优先队列来实现元素的存储，而不是本身进行存储 } 主要常见的阻塞队列总结如下： #\rArrayBlokingQueue底层通过数组实现的阻塞队列，可以设置初始的容量，换句话容量是固定的 LinkedTransferQueue SynchronousQueue要求入队和出队必须同时进行，一一对应，原因是内部维护了一个抽象类tansfer，需要等到消费者和生产者同时到齐才可以完成交接工作，支持公平和非公平 PriorityBlokingQueue优先队列，元素的获取顺序按照优先级决定 DelayQueue能够实现延迟获取元素，同样支持优先级，要求加入的元素必须继承Delayed接口 数据字典 #\r常见的常用的数据，具有分级的特点，现在将比如省份县市地点的信息维护成一张表就可以是实现 据字典，通常具有id，parent_id这些字段，维护父级和子级的关系。\n关于ElementUi的数据字典的显示方法就是检查hasChildren字段的值进行渲染\n线程池 #\r引入原因：频繁创建和销毁线程对系统资源的浪费十分严重，为了合理分配和调用系统资源，产生了线程池的技术\n实现原理：将已创建的线程复用，利用池化技术，就像数据库连接池一样，我们也可以创建很多个线程，然后反复地使用这些线程，而不对它们进行销毁。\n由于线程池可以反复利用已有线程执行多线程操作，所以它一般是有容量限制的，当所有的线程都处于工作状态时，那么新的多线程请求会被阻塞，直到有一个线程空闲出来为止，实际上这里就会用到我们之前讲解的阻塞队列。\n","date":"9 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/%E5%B9%B6%E5%8F%91/","section":"编程语言s","summary":"Java 并发编程 #\r轻量级锁： #\r检查当前对象的mark word是否有被其他线程占用，假如没有就会在当前栈帧里面建立一个 锁记录，复制并存储当前对象的mark word 信息。\n不像重量级锁需要向系统申请互斥量，\nCAS（无锁算法） #\r显然，当cas失败的时候，说明有线程进入了这个同步代码块，这个时候，虚拟机将会检查 当前对象的mark word是否指向当前对象的栈帧，是的话就说明当前已经获得锁，否则不是-》退化为重量级锁(不可逆) 解锁时，同样使用CAS算法操作，同时唤醒挂起的线程\n偏向锁 #\r当某个锁频繁的被同一个线程获取，对轻量级锁进行优化，所以偏向锁专门为单个线程服务，此时，无须再进行CAS操作，当其他线程 又开始抢锁，偏向锁可能退化为轻量级锁。注意当调用对象的hashCode（）方法，由于mark word 数据结构无法 保存hash值，偏向锁直接退化为轻量级锁。\n锁的退化不可逆\n锁消除和锁优化 #\r代码块中有可能不会总是出现请求锁和释放锁的问题，（比如循环中加锁），此时锁为了优化出现锁消除和锁优化\nJava内存模型（JMM） #\r主内存： 存放对象实例的部分 工作内存：虚拟机栈的部分，放入cpu的高速缓存里面。 自增操作不是由一个指令实现的！！！包括获取，修改和保存","title":"Java-Concurrent","type":"编程语言"},{"content":"\r如何通过Hugo这个框架来搭建一款属于自己的博客呢？ #\r观前提醒：这篇笔记借鉴了下面两个作者：\n一是：\r小棉尾巴\n事件契机 #\r我其实原本就知道github的pages自动部署博客功能，当时大二不熟练，今天目睹专业大佬的博客，自然也就重新搞起来了。\n如下就是大佬的博客（这个主题本来尝试用，后续发现比较花哨就不采用了）\n本人搭建的博客：\n第一步下载HuGo框架： #\r以Windows为例：只需打开CMD执行下面这个命令\nwinget install Hugo.Hugo.Extended 等待下载完成重启Shell命令窗口即可，Hugo将会自动配置环境变量。\n检查是否安装成功：\nhugo version 第二部创建Hugo博客项目 #\r只需要在文件夹下面新建终端使用如下命令，hugo将会自动创建你的项目名称文件夹 ，同时弹出一个主题链接\nhugo new site +你的项目名称 现在你需要进入你的项目也就是命令： cd 你的项目名称\n同时将项目注册为git根\ngit init 例如： 点击\rhttps://themes.gohugo.io/.这个链接\n如下就是一些主题了：\n随意选取一个之后点击Download就会进入主题的github仓库，然后需要\n比如这个：\n执行install the theme 里面的命令\ngit submodule add git@github.com:MeiK2333/github-style.git themes/github-style 下载的主题插件将会进入themes目录里面:\n接着拷贝exampleSite目录下面的content,static,config.toml到自己的项目里面覆盖自己项目的目录。同时记得删除hugo.toml配置文件\n第三步，几个重要的命令 #\r第一个是：hugo server:类似于npm run serve/dev 将会部署项目，这时候自己访问\rhttp://127.0.0.1:1313/就可以查看自己的网站 第二个是：hugo new 文件路径+文件名称.md则是创建笔记，hugo将会自主创建文档 第三个是：hugo ,hugo将会编译markdown文件为html文件存储到public文件夹下面同时部署到网站上 最后一步 #\r将public注册为git根绑定github上你的仓库同时提交文件即可。\n感谢\n","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E5%BB%BA%E7%AB%99%E7%9B%B8%E5%85%B3/","section":"笔记s","summary":"如何通过Hugo这个框架来搭建一款属于自己的博客呢？ #\r观前提醒：这篇笔记借鉴了下面两个作者：\n一是：\r小棉尾巴\n事件契机 #\r我其实原本就知道github的pages自动部署博客功能，当时大二不熟练，今天目睹专业大佬的博客，自然也就重新搞起来了。\n如下就是大佬的博客（这个主题本来尝试用，后续发现比较花哨就不采用了）\n本人搭建的博客：\n第一步下载HuGo框架： #\r以Windows为例：只需打开CMD执行下面这个命令\nwinget install Hugo.Hugo.Extended 等待下载完成重启Shell命令窗口即可，Hugo将会自动配置环境变量。\n检查是否安装成功：\nhugo version 第二部创建Hugo博客项目 #\r只需要在文件夹下面新建终端使用如下命令，hugo将会自动创建你的项目名称文件夹 ，同时弹出一个主题链接\nhugo new site +你的项目名称 现在你需要进入你的项目也就是命令： cd 你的项目名称","title":"如何通过hugo搭建自己的博客","type":"笔记"},{"content":"\r先放一张跳墙成功的画面： #\r科学上网难吗？ #\r结论：很简单！！！\n首先是我在配置代理时候发现的几个好的站点：如下 #\r科学上网主要有两个代理方法，但实际内核应该是一样的：\n这里有关于两个不同的翻墙方法的说明链接 #\r第一个：\n第二个：\n参考链接：\rSSR配置说明 ssr链接方式\n如何翻墙啊，说了那么多。 #\r第一步：下载 #\r下载链接 蓝色款（不推荐，本文也不采用）：\rShadowsocksR\r然后点击zip下载即可。ss的好处是没被墙，可以直接到git上下载。\n红色款（强烈推荐！！！）：这里我直接放上zip，因为国内无法下载，我已经提前翻墙下载好咯。 #\r下好后： #\r先复制下面的链接，然后点击ShadowssocksR-dotnet4.0.exe！！！！ #\r首先准备好ssr链接。这个方法最简单。 #\rssr://Y20xLWhrLmh1dGFvbm9kZTIudG9wOjEyNDA1OmF1dGhfYWVzMTI4X3 NoYTE6Y2hhY2hhMjAtaWV0ZjpodHRwX3NpbXBsZTpTSFZVWVc5RGJHOTFaQS8_b 2Jmc3BhcmFtPU16WmhNV0V6TWpVd05TNXRhV055YjNOdlpuUXVZMjl0JnByb3RvcGFyYW0 9TXpJMU1EVTZTSEF6VlVVNE5YTmhWMjl2UjFOTlJnJnJlbWFya3M9NmFhWjVyaXZJQzBnU1VWUVRDQXRJ Rk5UTDFOVFVpQXRJREExJmdyb3VwPTVhU0g1NVNvVVZIdnZKb3pORFF6T1RVMk5qRXk 这里我们选择用SSR,影梭的粉红色飞机。\n出现飞机图标后，左键点击它！！！\n选择剪贴板导入SSR链接。\n代理规则设置为全局： #\r#\r选择PAC为绕过常见即可。 #\r接下来就可以愉快上网啦！ #\r可以看到左下角IP地址也是香港的 #\r最后，注意安全，上网愉快！ #\r","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/vpn-ssr/","section":"笔记s","summary":"先放一张跳墙成功的画面： #\r科学上网难吗？ #\r结论：很简单！！！\n首先是我在配置代理时候发现的几个好的站点：如下 #\r科学上网主要有两个代理方法，但实际内核应该是一样的：\n这里有关于两个不同的翻墙方法的说明链接 #\r第一个：\n第二个：\n参考链接：\rSSR配置说明 ssr链接方式\n如何翻墙啊，说了那么多。 #\r第一步：下载 #\r下载链接 蓝色款（不推荐，本文也不采用）：\rShadowsocksR\r然后点击zip下载即可。ss的好处是没被墙，可以直接到git上下载。\n红色款（强烈推荐！！！）：这里我直接放上zip，因为国内无法下载，我已经提前翻墙下载好咯。 #\r下好后： #\r先复制下面的链接，然后点击ShadowssocksR-dotnet4.0.exe！！！！ #\r首先准备好ssr链接。这个方法最简单。 #\rssr://Y20xLWhrLmh1dGFvbm9kZTIudG9wOjEyNDA1OmF1dGhfYWVzMTI4X3 NoYTE6Y2hhY2hhMjAtaWV0ZjpodHRwX3NpbXBsZTpTSFZVWVc5RGJHOTFaQS8_b 2Jmc3BhcmFtPU16WmhNV0V6TWpVd05TNXRhV055YjNOdlpuUXVZMjl0JnByb3RvcGFyYW0 9TXpJMU1EVTZTSEF6VlVVNE5YTmhWMjl2UjFOTlJnJnJlbWFya3M9NmFhWjVyaXZJQzBnU1VWUVRDQXRJ Rk5UTDFOVFVpQXRJREExJmdyb3VwPTVhU0g1NVNvVVZIdnZKb3pORFF6T1RVMk5qRXk 这里我们选择用SSR,影梭的粉红色飞机。","title":"科学上网","type":"笔记"},{"content":"","date":"3 October 2023","externalUrl":null,"permalink":"/tags/java-se/","section":"Tags","summary":"","title":"Java SE","type":"tags"},{"content":"1 综述 在Java中对象与对象的关系总体分为四类，分别是：依赖、关联、聚合和组合。\n（1）依赖(Dependency)关系是类与类之间的联接。依赖关系表示一个类依赖于另一个类的定义，一般而言，依赖关系在Java语言中体现为局域变量、方法的形参，或者对静态方法的调用。 （2）关联(Association）关系是类与类之间的联接，它使一个类知道另一个类的属性和方法。关联可以是双向的，也可以是单向的。在Java语言中，关联关系一般使用成员变量来实现 （3）聚合(Aggregation) 关系是关联关系的一种，是强的关联关系。聚合是整体和个体之间的关系 （4）组合(Composition) 关系是关联关系的一种，是比聚合关系强的关系。它要求普通的聚合关系中代表整体的对象负责代表部分对象的生命周期，组合关系是不能共享的\n依赖： #\r个类A使用到了另一个类B，而这种使用关系是具有偶然性的、临时性的、非常弱的，但是B类的变化会影响到A\n关联： #\r关联是一种“拥有”的关系。表现在代码上，就是一个类包含另一个类的实例，通常表现为被关联类以类属性的形式出现在关联类的类定义中，也可以表现为关联类引用了一个类型为被关联类的全局变量。关联可以使单向的，也可以使双向的。依赖和关联的区别在于依赖是使用，关联是拥有.\n聚合 #\r聚合是关联关系的一种，它是一种强关联关系（has-a）;聚合关系是整体和个体/部分之间的关系;关联关系的两个类处于同一个层次上,而聚合关系的两个类处于不同的层次上,一个是整体,一个是个体/部分;在聚合关系中,代表个体/部分的对象有可能会被多个代表整体的对象所共享;表现在代码层面上就是在构造器初始化时将两个类关联起来\n组合 #\r组合也是关联关系的一种（is-a）,但它是比聚合关系更强的关系.组合关系要求聚合关系中代表整体的对象要负责代表个体/部分的对象的整个生命周期;组合关系不能共享;在组合关系中,如果代表整体的对象被销毁或破坏,那么代表个体/部分的对象也一定会被销毁或破坏,而聚在合关系中,代表个体/部分的对象则有可能被多个代表整体的对象所共享,而不一定会随着某个代表整体的对象被销毁或破坏而被销毁或破坏;\n","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/javase/object/%E5%AF%B9%E8%B1%A1%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB/","section":"编程语言s","summary":"1 综述 在Java中对象与对象的关系总体分为四类，分别是：依赖、关联、聚合和组合。\n（1）依赖(Dependency)关系是类与类之间的联接。依赖关系表示一个类依赖于另一个类的定义，一般而言，依赖关系在Java语言中体现为局域变量、方法的形参，或者对静态方法的调用。 （2）关联(Association）关系是类与类之间的联接，它使一个类知道另一个类的属性和方法。关联可以是双向的，也可以是单向的。在Java语言中，关联关系一般使用成员变量来实现 （3）聚合(Aggregation) 关系是关联关系的一种，是强的关联关系。聚合是整体和个体之间的关系 （4）组合(Composition) 关系是关联关系的一种，是比聚合关系强的关系。它要求普通的聚合关系中代表整体的对象负责代表部分对象的生命周期，组合关系是不能共享的\n依赖： #\r个类A使用到了另一个类B，而这种使用关系是具有偶然性的、临时性的、非常弱的，但是B类的变化会影响到A\n关联： #\r关联是一种“拥有”的关系。表现在代码上，就是一个类包含另一个类的实例，通常表现为被关联类以类属性的形式出现在关联类的类定义中，也可以表现为关联类引用了一个类型为被关联类的全局变量。关联可以使单向的，也可以使双向的。依赖和关联的区别在于依赖是使用，关联是拥有.\n聚合 #\r聚合是关联关系的一种，它是一种强关联关系（has-a）;聚合关系是整体和个体/部分之间的关系;关联关系的两个类处于同一个层次上,而聚合关系的两个类处于不同的层次上,一个是整体,一个是个体/部分;在聚合关系中,代表个体/部分的对象有可能会被多个代表整体的对象所共享;表现在代码层面上就是在构造器初始化时将两个类关联起来\n组合 #\r组合也是关联关系的一种（is-a）,但它是比聚合关系更强的关系.组合关系要求聚合关系中代表整体的对象要负责代表个体/部分的对象的整个生命周期;组合关系不能共享;在组合关系中,如果代表整体的对象被销毁或破坏,那么代表个体/部分的对象也一定会被销毁或破坏,而聚在合关系中,代表个体/部分的对象则有可能被多个代表整体的对象所共享,而不一定会随着某个代表整体的对象被销毁或破坏而被销毁或破坏;","title":"对象间的关系","type":"编程语言"},{"content":"Java中常用的关键字有以下分类： 访问控制 private protected public\n类,方法和变量修饰符 abstract class extends final implements interface native new static strictfp synchronized transient volatile\n程序控制 break continue return do while if else for instanceof switch case default\n异常处理 try cathc throw throws\n包相关 import package\n基本类型 boolean byte char double float int long short null true false\n变量引用 super this void 保留字 goto const\n详细解释：\n访问控制 private 私有的 private 关键字是访问控制修饰符，可以应用于类、方法或字段（在类中声明的变量）。 只能在声明 private（内部）类、方法或字段的类中引用这些类、方法或字段。在类的外部或者对于子类而言，它们是不可见的。 所有类成员的默认访问范围都是 package 访问，也就是说，除非存在特定的访问控制修饰符，否则，可以从同一个包中的任何类访问类成员。\nprotected 受保护的 protected 关键字是可以应用于类、方法或字段（在类中声明的变量）的访问控制修饰符。可以在声明 protected 类、方法或字段的类、同一个包中的其他任何类以及任何子类（无论子类是在哪个包中声明的）中引用这些类、方法或字段。所有类成员的默认访问范围都是 package 访问，也就是说，除非存在特定的访问控制修饰符，否则，可以从同一个包中的任何类访问类成员。\npublic 公共的 public 关键字是可以应用于类、方法或字段（在类中声明的变量）的访问控制修饰符。 可能只会在其他任何类或包中引用 public 类、方法或字段。所有类成员的默认访问范围都是 package 访问，也就是说，除非存在特定的访问控制修饰符，否则，可以从同一个包中的任何类访问类成员。\n4）总结 自身\t同包子类\t不同包子类\t同包类\t其他类 public\t可访问\t可继承\t可继承\t可访问\t可访问 protected\t可访问\t可继承\t可继承\t可访问\t不可访问 private\t可访问\t不可继承\t不可继承\t不可访问\t不可访问 defaule(不写)\t可访问\t可继承\t不可继承\t可访问\t不可访问\n类、方法和变量修饰符 abstract 声明抽象 abstract关键字可以修改类或方法。abstract类可以扩展（增加子类），但不能直接实例化。abstract方法不在声明它的类中实现，但必须在某个子类中重写。采用 abstract方法的类本来就是抽象类，并且必须声明为abstract。\nclass类 class 关键字用来声明新的 Java 类，该类是相关变量和/或方法的集合。类是面向对象的程序设计方法的基本构造单位。类通常代表某种实际实体，如几何形状或人。类是对象的模板。每个对象都是类的一个实例。要使用类，通常使用 new 操作符将类的对象实例化，然后调用类的方法来访问类的功能。\nextends 继承、扩展 extends 关键字用在 class 或 interface 声中，用于指示所声明的类或接口是其名称后跟有 extends 关键字的类或接口的子类。子类继承父类的所有 public 和 protected 变量和方法。 子类可以重写父类的任何非 final 方法。一个类只能扩展一个其他类。\nfinal 最终、不可改变 final 关键字可以应用于类，以指示不能扩展该类（不能有子类）。final 关键字可以应用于方法，以指示在子类中不能重写此方法。一个类不能同时是 abstract 又是 final。abstract 意味着必须扩展类，final 意味着不能扩展类。一个方法不能同时是 abstract 又是 final。abstract 意味着必须重写方法，final 意味着不能重写方法。\nimplements实现 implements 关键字在 class 声明中使用，以指示所声明的类提供了在 implements 关键字后面的名称所指定的接口中所声明的所有方法的实现。类必须提供在接口中所声明的所有方法的实现。一个类可以实现多个接口。\ninterface 接口 interface 关键字用来声明新的 Java 接口，接口是方法的集合。\n接口是 Java 语言的一项强大功能。任何类都可声明它实现一个或多个接口，这意味着它实现了在这些接口中所定义的所有方法。\n实现了接口的任何类都必须提供在该接口中的所有方法的实现。一个类可以实现多个接口。\nnative 本地 native 关键字可以应用于方法，以指示该方法是用 Java 以外的语言实现的。\nnew 新,创建 new 关键字用于创建类的新实例。\nnew 关键字后面的参数必须是类名，并且类名的后面必须是一组构造方法参数（必须带括号）。\n参数集合必须与类的构造方法的签名匹配。\n= 左侧的变量的类型必须与要实例化的类或接口具有赋值兼容关系。\nstatic 静态 static 关键字可以应用于内部类（在另一个类中定义的类）、方法或字段（类的成员变量）。 通常，static 关键字意味着应用它的实体在声明该实体的类的任何特定实例外部可用。\nstatic（内部）类可以被其他类实例化和引用（即使它是顶级类）。\nstatic 字段（类的成员变量）在类的所有实例中只存在一次。\n可以从类的外部调用 static 方法，而不用首先实例化该类。这样的引用始终包括类名作为方法调用的限定符。\n模式：public final static varName = ; 通常用于声明可以在类的外部使用的类常量。在引用这样的类常量时需要用类名加以限定。\nstrictfp 严格,精准 strictfp的意思是FP-strict，也就是说精确浮点的意思。在Java虚拟机进行浮点运算时，如果没有指定strictfp关键字时，Java的编译器以及运行环境在对浮点运算的表达式是采取一种近似于我行我素的行为来完成这些操作，以致于得到的结果往往无法令人满意。而一旦使用了strictfp来声明一个类、接口或者方法时，那么所声明的范围内Java的编译器以及运行环境会完全依照浮点规范IEEE-754来执行。因此如果想让浮点运算更加精确，而且不会因为不同的硬件平台所执行的结果不一致的话，那就请用关键字strictfp。 可以将一个类、接口以及方法声明为strictfp，但是不允许对接口中的方法以及构造函数声明strictfp关键字\nsynchronized线程、同步 synchronized 关键字可以应用于方法或语句块，并为一次只应由一个线程执行的关键代码段提供保护。 synchronized 关键字可防止代码的关键代码段一次被多个线程执行。\n如果应用于静态方法，那么，当该方法一次由一个线程执行时，整个类将被锁定。\n如果应用于实例方法，那么，当该方法一次由一个线程访问时，该实例将被锁定。\n如果应用于对象或数组，当关联的代码块一次由一个线程执行时，对象或数组将被锁定。\ninstanceof 实例 instanceof 关键字用来确定对象所属的类。\ntransient 短暂 transient 关键字可以应用于类的成员变量，以便指出该成员变量不应在包含它的类实例已序列化时被序列化。\n当一个对象被串行化的时候，transient型变量的值不包括在串行化的表示中，然而非transient型的变量是被包括进去的。\nJava的serialization提供了一种持久化对象实例的机制。当持久化对象时，可能有一个特殊的对象数据成员，我们不想用serialization机制来保存它。为了在一个特定对象的一个域上关闭serialization，可以在这个域前加上关键字transient。 transient是Java语言的关键字，用来表示一个域不是该对象串行化的一部分。当一个对象被串行化的时候，transient型变量的值不包括在串行化的表示中，然而非transient型的变量是被包括进去的。\nvolatile 易失 volatile 关键字用于表示可以被多个线程异步修改的成员变量。 注意：volatile 关键字在许多 Java 虚拟机中都没有实现。 volatile 的目标用途是为了确保所有线程所看到的指定变量的值都是相同的。\nJava 语言中的 volatile 变量可以被看作是一种 “程度较轻的 synchronized”；与 synchronized 块相比，volatile 变量所需的编码较少，并且运行时开销也较少，但是它所能实现的功能也仅是 synchronized 的一部分。\n程序控制语句 break 跳出，中断 break 关键字用于提前退出 for、while 或 do 循环，或者在 switch 语句中用来结束 case 块。 break 总是退出最深层的 while、for、do 或 switch 语句。\ncontinue 继续 continue 关键字用来跳转到 for、while 或 do 循环的下一个迭代。 continue 总是跳到最深层 while、for 或 do 语句的下一个迭代。\nreturn 返回 return 关键字会导致方法返回到调用它的方法，从而传递与返回方法的返回类型匹配的值。 如果方法具有非 void 的返回类型，return 语句必须具有相同或兼容类型的参数。\ndo 运行 do 关键字用于指定一个在每次迭代结束时检查其条件的循环。 do 循环体至少执行一次。\n条件表达式后面必须有分号。\nwhile 循环 while 关键字用于指定一个只要条件为真就会重复的循环。\nif 如果 if 关键字指示有条件地执行代码块。条件的计算结果必须是布尔值。\nif 语句可以有可选的 else 子句，该子句包含条件为 false 时将执行的代码。\n包含 boolean 操作数的表达式只能包含 boolean 操作数。\nelse 否则 else 关键字总是在 if-else 语句中与 if 关键字结合使用。else 子句是可选的，如果 if 条件为 false，则执行该子句。\nfor 循环 for 关键字用于指定一个在每次迭代结束前检查其条件的循环。\nfor 语句的形式为 for(initialize; condition; increment)\n控件流进入 for 语句时，将执行一次 initialize 语句。\n每次执行循环体之前将计算 condition 的结果。如果 condition 为 true，则执行循环体。\n每次执行循环体之后，在计算下一个迭代的 condition 之前，将执行 increment 语句。\nswitch 观察 switch 语句用于基于某个表达式选择执行多个代码块中的某一个。 switch 条件的计算结果必须等于 byte、char、short 或 int。\n如果没有 break 语句，执行流将进入所有后面的 case 和/或 default 块。\ncase 返回观察里的结果 case 用来标记 switch 语句中的每个分支。 case 块没有隐式结束点。break 语句通常在每个 case 块末尾使用，用于退出 switch 语句。\n如果没有 break 语句，执行流将进入所有后面的 case 和/或 default 块。\ndefault 默认 default 关键字用来标记 switch 语句中的默认分支。 default 块没有隐式结束点。break 语句通常在每个 case 或 default 块的末尾使用，以便在完成块时退出 switch 语句。\n如果没有 default 语句，其参数与任何 case 块都不匹配的 switch 语句将不执行任何操作。\n错误处理 try 捕获异常 try 关键字用于包含可能引发异常的语句块。 每个 try 块都必须至少有一个 catch 或 finally 子句。\n如果某个特定异常类未被任何 catch 子句处理，该异常将沿着调用栈递归地传播到下一个封闭 try 块。如果任何封闭 try 块都未捕获到异常，Java 解释器将退出，并显示错误消息和堆栈跟踪信息。\ncatch 处理异常 catch 关键字用来在 try-catch 或 try-catch-finally 语句中定义异常处理块。 开始和结束标记 { 和 } 是 catch 子句语法的一部分，即使该子句只包含一个语句，也不能省略这两个标记。\n每个 try 块都必须至少有一个 catch 或 finally 子句。\n如果某个特定异常类未被任何 catch 子句处理，该异常将沿着调用栈递归地传播到下一个封闭 try 块。如果任何封闭 try 块都未捕获到异常，Java 解释器将退出，并显示错误消息和堆栈跟踪信息。\nthrow 抛出一个异常对象 throw 关键字用于引发异常。 throw 语句将 java.lang.Throwable 作为参数。Throwable 在调用栈中向上传播，直到被适当的 catch 块捕获。\nthrows 声明一个异常可能被抛出 throws 关键字可以应用于方法，以便指出方法引发了特定类型的异常。 throws 关键字将逗号分隔的 java.lang.Throwables 列表作为参数。\n引发非 RuntimeException 异常的任何方法还必须在方法声明中使用 throws 修饰符来声明它引发的异常。\n要在 try-catch 块中包含带 throws 子句的方法的调用，必须提供该方法的调用者。\nfinally异常处理补充 不管有无异常发生，finally块中的代码总会执行 包相关 import 引入 import 关键字使一个包中的一个或所有类在当前 Java 源文件中可见。可以不使用完全限定的类名来引用导入的类。 当多个包包含同名的类时，许多 Java 程序员只使用特定的 import 语句（没有“*”）来避免不确定性。\npackage 包 package 关键字指定在 Java 源文件中声明的类所驻留的 Java 包。 package 语句（如果出现）必须是 Java 源文件中的第一个非注释性文本。\n例:java.lang.Object。\n如果 Java 源文件不包含 package 语句，在该文件中定义的类将位于“默认包”中。请注意，不能从非默认包中的类引用默认包中的类。\n基本类型 boolean 布尔型 boolean 是 Java 原始类型。boolean 变量的值可以是 true 或 false。 boolean 变量只能以 true 或 false 作为值。boolean 不能与数字类型相互转换。\n包含 boolean 操作数的表达式只能包含 boolean 操作数。\nBoolean 类是 boolean 原始类型的包装对象类。\nbyte 字节型 byte 是 Java 原始类型。byte 可存储在 [-128, 127] 范围以内的整数值。 Byte 类是 byte 原始类型的包装对象类。它定义代表此类型的值的范围的 MIN_VALUE 和 MAX_VALUE 常量。\nJava 中的所有整数值都是 32 位的 int 值，除非值后面有 l 或 L（如 235L），这表示该值应解释为 long。\nchar 字符型 char 是 Java 原始类型。char 变量可以存储一个 Unicode 字符。 可以使用下列 char 常量：\\b - 空格, \\f - 换页, \\n - 换行, \\r - 回车, \\t - 水平制表符, ’ - 单引号, \u0026quot; - 双引号, \\ - 反斜杠, \\xxx - 采用 xxx 编码的 Latin-1 字符。\\x 和 \\xx 均为合法形式，但可能引起混淆。 \\uxxxx - 采用十六进制编码 xxxx 的 Unicode 字符。\nCharacter 类包含一些可用来处理 char 变量的 static 方法，这些方法包括 isDigit()、isLetter()、isWhitespace() 和 toUpperCase()。\nchar 值没有符号。\ndouble 双精度 double 是 Java 原始类型。double 变量可以存储双精度浮点值。 由于浮点数据类型是实际数值的近似值，因此，一般不要对浮点数值进行是否相等的比较。\nJava 浮点数值可代表无穷大和 NaN（非数值）。Double 包装对象类用来定义常量 MIN_VALUE、MAX_VALUE、NEGATIVE_INFINITY、POSITIVE_INFINITY 和 NaN。\nfloat 浮点 float 是 Java 原始类型。float 变量可以存储单精度浮点值。 使用此关键字时应遵循下列规则：\nJava 中的浮点文字始终默认为双精度。要指定单精度文字值，应在数值后加上 f 或 F，如 0.01f。\n由于浮点数据类型是实际数值的近似值，因此，一般不要对浮点数值进行是否相等的比较。\nJava 浮点数值可代表无穷大和 NaN（非数值）。Float 包装对象类用来定义常量 MIN_VALUE、MAX_VALUE、NEGATIVE_INFINITY、POSITIVE_INFINITY 和 NaN。\nint 整型 int 是 Java 原始类型。int 变量可以存储 32 位的整数值。 Integer 类是 int 原始类型的包装对象类。它定义代表此类型的值的范围的 MIN_VALUE 和 MAX_VALUE 常量。\nJava 中的所有整数值都是 32 位的 int 值，除非值后面有 l 或 L（如 235L），这表示该值应解释为 long。\nlong 长整型 long 是 Java 原始类型。long 变量可以存储 64 位的带符号整数。 Long 类是 long 原始类型的包装对象类。它定义代表此类型的值的范围的 MIN_VALUE 和 MAX_VALUE 常量。\nJava 中的所有整数值都是 32 位的 int 值，除非值后面有 l 或 L（如 235L），这表示该值应解释为 long。\nshort 短整型 short 是 Java 原始类型。short 变量可以存储 16 位带符号的整数。 Short 类是 short 原始类型的包装对象类。它定义代表此类型的值的范围的 MIN_VALUE 和 MAX_VALUE 常量。\nJava 中的所有整数值都是 32 位的 int 值，除非值后面有 l 或 L（如 235L），这表示该值应解释为 long。\nnull 空 null 是 Java 的保留字，表示无值。 将 null 赋给非原始变量相当于释放该变量先前所引用的对象。\n不能将 null 赋给原始类型（byte、short、int、long、char、float、double、boolean）变量。\ntrue 真 true 关键字表示 boolean 变量的两个合法值中的一个。\nfalse 假 false 关键字代表 boolean 变量的两个合法值之一。\n基本数据类型总结 关于Java数据类型，我也专门写过一篇总结性博客：Java数据类型\n变量引用 super 父类,超类 super 关键字用于引用使用该关键字的类的超类。 作为独立语句出现的 super 表示调用超类的构造方法。\nsuper.\u0026lt; methodName \u0026gt;() 表示调用超类的方法。只有在如下情况中才需要采用这种用法：要调用在该类中被重写的方法，以便指定应当调用在超类中的该方法。\nthis 本类 this 关键字用于引用当前实例。 当引用可能不明确时，可以使用 this 关键字来引用当前的实例。\nvoid 无返回值 void 关键字表示 null 类型。 void 可以用作方法的返回类型，以指示该方法不返回值。\n保留字 正确识别java语言的关键字（keyword）和保留字（reserved word）是十分重要的。Java的关键字对java的编译器有特殊的意义，他们用来表示一种数据类型，或者表示程序的结构等。保留字是为java预留的关键字，他们虽然现在没有作为关键字，但在以后的升级版本中有可能作为关键字。 识别java语言的关键字，不要和其他语言如c/c++的关键字混淆。 const和goto是java的保留字。 所有的关键字都是小写\ngoto 跳转 goto 保留关键字，但无任何作用。结构化程序设计完全不需要 goto 语句即可完成各种流程，而 goto 语句的使用往往会使程序的可读性降低，所以 Java 不允许 goto 跳转。\nconst 静态 const 保留字，是一个类型修饰符，使用const声明的对象不能更新。与final某些类似。\nnative 本地 Java不是完美的，Java的不足除了体现在运行速度上要比传统的C++慢许多之外，Java无法直接访问到操作系统底层（如系统硬件等)，为此Java使用native方法来扩展Java程序的功能。\n可以将native方法比作Java程序同Ｃ程序的接口，其实现步骤：\n１、在Java中声明native()方法，然后编译；\n２、用javah产生一个.h文件；\n３、写一个.cpp文件实现native导出方法，其中需要包含第二步产生的.h文件（注意其中又包含了JDK带的jni.h文件）；\n４、将第三步的.cpp文件编译成动态链接库文件；\n５、在Java中用System.loadLibrary()方法加载第四步产生的动态链接库文件，这个native()方法就可以在Java中被访问了。\n","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/javase/words/","section":"编程语言s","summary":"Java中常用的关键字有以下分类： 访问控制 private protected public\n类,方法和变量修饰符 abstract class extends final implements interface native new static strictfp synchronized transient volatile\n程序控制 break continue return do while if else for instanceof switch case default","title":"关键字","type":"编程语言"},{"content":"\r如何从 Java 中的 LinkedList 类外部声明 Node 类型？ #\r标签 java linked-list 如何声明 Node 类型的变量？ Node是LinkedList的内部类，在我正在编写的程序的main方法中，我想创建一个Node变量。但在下面代码片段的最后一行中，我收到错误消息“Nose 在 LinkedList 中具有私有(private)访问权限”。为什么我不能使用 Node 类型？\nimport java.util.LinkedList; public class MinSplit { public static long leastAmount; public static void main(String args[]) { LinkedList list = new LinkedList(); LinkedList.Node node = new LinkedList.Node(); 最佳答案 因为它被声明为私有(private)。它是 LinkedList 类的内部实现细节，您没有理由创建实例。显然，这是 Java 团队经过深思熟虑的设计决定，旨在保持 API 的整洁并避免由于人们破坏列表数据结构而导致的问题。 如果您想要实例化 Node 类以便可以对 LinkedList 执行某种操作，请再考虑一下。没有任何公共(public) API 以允许您将 Node 添加到 LinkedList 或使用它的方式公开 Node 类型任何其他方式。您可能需要从头开始实现您自己的链表类。 如果您希望将 Node 类用于其他目的，您应该声明一个新类或在第 3 方库中查找合适的类。\n从LinkedList的源码中可看出，Node是LinkedList（双向链表）的私有化内部类，外部无法访问，更不可能被实例化 #\r具体参考\n","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/javase/node/%E5%AE%9E%E4%BE%8B%E5%8C%96node/","section":"编程语言s","summary":"如何从 Java 中的 LinkedList 类外部声明 Node 类型？ #\r标签 java linked-list 如何声明 Node 类型的变量？ Node是LinkedList的内部类，在我正在编写的程序的main方法中，我想创建一个Node变量。但在下面代码片段的最后一行中，我收到错误消息“Nose 在 LinkedList 中具有私有(private)访问权限”。为什么我不能使用 Node 类型？\nimport java.util.LinkedList; public class MinSplit { public static long leastAmount; public static void main(String args[]) { LinkedList list = new LinkedList(); LinkedList.","title":"实例化Node","type":"编程语言"},{"content":"\r数组： #\r1 public class Demo1_Array { 2 public static void main(String[] args) { 3 String [] array=new String[5];//需要初始化长度 4 array[0]=\u0026#34;hello\u0026#34;; 5 array[1]=\u0026#34;world\u0026#34;; 6 array[4]=\u0026#34;Mufasa\u0026#34;; 7 // array[5]=\u0026#34;right or not\u0026#34;;//ArrayIndexOutOfBoundsException 8 for(String str:array){ 9 System.out.print(str+\u0026#34;、\u0026#34;);//hello、world、null、null、Mufasa、 10 } 11 } 12 } 1 public class Demo1_Array2 { 2 public static void main(String[] args) { 3 String [] array={\u0026#34;hello\u0026#34;,\u0026#34;world\u0026#34;,null,null,\u0026#34;Mufasa\u0026#34;};//实例化\u0026amp;赋值 4 array = (String[])resizeArray(array,10); 5 for(String str:array){ 6 System.out.print(str+\u0026#34;、\u0026#34;);//hello、world、null、null、Mufasa、 7 } 8 } 9 10 private static Object resizeArray(Object oldArray, int newSize) {//数组扩容！！！真麻烦，还利用反射机制来实现 11 int oldSize = java.lang.reflect.Array.getLength(oldArray);//获取旧数组长度,向上转型！！！ 12 // int oldSize =oldArray.length;//无法在此使用，因为array内容的是不定类型 13 Class elementType = oldArray.getClass().getComponentType();//获取对象类别 14 Object newArray = java.lang.reflect.Array.newInstance(elementType,newSize);//利用Java的反射机制实例化新数组 15 int preserveLength = Math.min(oldSize, newSize);//判断是否需要copy数据 16 if (preserveLength \u0026gt; 0) 17 System.arraycopy(oldArray, 0, newArray, 0, preserveLength); 18 return newArray;//oldArray切断索引成为垃圾由Runtime.getRuntime().gc();回收处理 19 } 20 } 具体参考资料 #\r","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/javase/datastruct/","section":"编程语言s","summary":"数组： #\r1 public class Demo1_Array { 2 public static void main(String[] args) { 3 String [] array=new String[5];//需要初始化长度 4 array[0]=\u0026#34;hello\u0026#34;; 5 array[1]=\u0026#34;world\u0026#34;; 6 array[4]=\u0026#34;Mufasa\u0026#34;; 7 // array[5]=\u0026#34;right or not\u0026#34;;//ArrayIndexOutOfBoundsException 8 for(String str:array){ 9 System.","title":"数据结构篇","type":"编程语言"},{"content":"\rHi ，你好！ #\r你好，我是春江花朝秋月夜，我是这个博客的作者。我这样做是为了记录之前学习的笔记 因为我基本很难记住我学过的东西\u0026hellip;. 我关心后端技术，也喜欢做一些前端效果，我偶尔写一些笔记和心得并且定期分享到\r哔哩哔哩和我的\r语雀频道 世界充满了很多不确定的东西，希望大家保持独立的思考。如果你好奇\r我目前在做的事情,也可以了解更多\r关于我的信息。\n这个博客网站在下面的支持下完成\n白天/夜晚 模式, 依赖于\rUI设计 非常感谢下面的几个网站支持我\rInter UI font,由\rRasmus Andersson制作 非常感谢这位提供的帮助\rPrismJS 以及我同专业的前辈：\rAncientElement 所以，希望你在这儿可以玩的开心！！！\n本人简历： #\r107706430_p0_hu46370d4ccd3481872546da16224d0daa_1972225_288x288_fill_box_center_3\n求职（长期有效）\r↘ 本人简历\r2024年3月09日\r· 12:01\n","date":"3 October 2023","externalUrl":null,"permalink":"/info/","section":"","summary":"Hi ，你好！ #\r你好，我是春江花朝秋月夜，我是这个博客的作者。我这样做是为了记录之前学习的笔记 因为我基本很难记住我学过的东西\u0026hellip;. 我关心后端技术，也喜欢做一些前端效果，我偶尔写一些笔记和心得并且定期分享到\r哔哩哔哩和我的\r语雀频道 世界充满了很多不确定的东西，希望大家保持独立的思考。如果你好奇\r我目前在做的事情,也可以了解更多\r关于我的信息。\n这个博客网站在下面的支持下完成\n白天/夜晚 模式, 依赖于\rUI设计 非常感谢下面的几个网站支持我\rInter UI font,由\rRasmus Andersson制作 非常感谢这位提供的帮助\rPrismJS 以及我同专业的前辈：\rAncientElement 所以，希望你在这儿可以玩的开心！！！\n本人简历： #\r107706430_p0_hu46370d4ccd3481872546da16224d0daa_1972225_288x288_fill_box_center_3","title":"应该没人来这里吧","type":"page"},{"content":"特点：线程隔离，相互是隔离的，不影响的,每个线程都自己玩自己的，只操作自己的单独的变量副本\n内部维护的是ThreadLocalMap，所以有key和value\n当key指向的值为null时，value不被清理，由于key是弱引用，此时就会造成内存泄露，所以必须要通过ThreadLocal里面的remove方法手动删除值，避免内存泄露。\nThreadLocalMap里面面由一个个由数组组成的key-value，组成了Entry 由ThreadLocal来设置值，删除值\n弱引用非常容易GC，很容易造成内存泄露，所以需要将key为null的entry清除\n引用关系：Thread-\u0026gt; ThreadLocal-\u0026gt;Entry（弱）-\u0026gt;key（弱）-\u0026gt;value(强)（不清除时容易发生内存泄露）\n//内部类，实=实现 static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) { return new ThreadLocalMap(parentMap); } static class ThreadLocalMap { static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int size = 0; private int threshold; // Default to 0 private void setThreshold(int len) { threshold = len * 2 / 3; } private static int nextIndex(int i, int len) { return ((i + 1 \u0026lt; len) ? i + 1 : 0); } private static int prevIndex(int i, int len) { return ((i - 1 \u0026gt;= 0) ? i - 1 : len - 1); } ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } private ThreadLocalMap(ThreadLocalMap parentMap) { Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (Entry e : parentTable) { if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) ThreadLocal\u0026lt;Object\u0026gt; key = (ThreadLocal\u0026lt;Object\u0026gt;) e.get(); if (key != null) { Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode \u0026amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; } } } } } ","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/javase/threadlocal/","section":"编程语言s","summary":"特点：线程隔离，相互是隔离的，不影响的,每个线程都自己玩自己的，只操作自己的单独的变量副本\n内部维护的是ThreadLocalMap，所以有key和value\n当key指向的值为null时，value不被清理，由于key是弱引用，此时就会造成内存泄露，所以必须要通过ThreadLocal里面的remove方法手动删除值，避免内存泄露。\nThreadLocalMap里面面由一个个由数组组成的key-value，组成了Entry 由ThreadLocal来设置值，删除值\n弱引用非常容易GC，很容易造成内存泄露，所以需要将key为null的entry清除\n引用关系：Thread-\u0026gt; ThreadLocal-\u0026gt;Entry（弱）-\u0026gt;key（弱）-\u0026gt;value(强)（不清除时容易发生内存泄露）\n//内部类，实=实现 static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) { return new ThreadLocalMap(parentMap); } static class ThreadLocalMap { static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal.","title":"ThreadLocal","type":"编程语言"},{"content":"\rRedis学习： #\r通用命令 #\r不要在主节点用：keys param 命令来查询，这查询速率很慢，单线程将会被阻塞 del param（可以是多个参数） :删除指定的key exists param(判断key是否存在) expire key time :设置有效期时间 ttl key :查看key的有效期\nString类型 #\r最简单的Redis数据类型，value：string,int,float；最大空间不超过512M set key value get key\nMset 批量 添加key-value\nMget批量获取\n数值类型：incr ：让变量自增加一\nincrby num：按照步长增加\nsetnx:不存在 key才可以添加这个key\n如何区分不同的key？ #\r利用层级结构来表明table，以后的大部分业务都是用层级结构来展现和布局的！\nHash类型 #\r哈希类型，也叫做散列，Hash的value是一个无须字典，类似于HashMap的结构。\n具有field这一个字段，这是不一样的。\nList类型 #\r类似于 LinkedList(也就是双向链表)\n有序 元素可重复 插入删除快 查询速度一般 Lpush key element：向左侧插入元素 返回列表长度，相应的向右边：Rpush key element\nLpop key:移除左侧第一个元素，没有则返回nil\nBlop/Brpop key times:阻塞队列的插入 ,加上阻塞时间\n如何用List来模拟栈？\n入口和出口一起。Lpush和Lpop\n模拟队列？\n入口和出口不在一起。Lpush和Rpop\n模拟阻塞队列？\n入口出口不在一边，取的时候用阻塞Brpop/Blpop\nSet类型 #\r类似于HashSet，可以看作是value为null的hashMap。\nSadd key member:添加一个或多个元素。\nSrem key member:删除元素\nSmembers：获取所有元素\nSinter key1 key2:求取交集\nSdiff：求差集\nSunion:求并集\nScard:求元素个数\nSismenber key member:是否是成员\nSortedSet #\rzrank key member:排名从0开始计算\nzcount key min max:统计区间数量\n#\rRedis实际开发时序列化的问题 #\rSession共享问题，基于Redis实现的Session数据数据共享 #\r多台Tomcat服务器，每一台都有不同的Session空间，将会存在共享问题,互相拷贝具有时间延迟和空间浪费的问题。\n解决方案：Redis数据共享\ncode作为key显然是不行的，将会覆盖，所有选用Phone作为key，使用Hash结构来存储， 内存占用也会比较少相对于String类型，使用随机token作为key来存储用户信息。 现在token作为登录凭证，返回token给客户端\n缓存：浏览器缓存-\u0026gt;应用层缓存（Redis，Nginx,Tomcat\u0026hellip;各种缓存）-\u0026gt;数据库缓存，根据索引来进行缓存，减少磁盘IO\n优点：降低后端负载，提高读写速率，降低响应时间 成本：数据一致性成本，当数据库发生改变时，缓存未跟新，就会出现不一致， 代码维护成本也会提高，为了高可用，运维成本也会提高\n缓存更新策略： #\r内存淘汰，超时剔除(低一致性)，主动更新（高一致性）\n主动更新：\n1调用者更新数据库时同时更新缓存；（可控性最高）\n2 缓存和数据库整合为一个服务；\n3 调用只操作，独立异步线程持久化到数据库,从而实现缓存和数据库一致\n删除缓存（无效操作太多）而不是更新缓存，单体项目需要将缓存和数据库放在一个事务，考虑线程安全 Cache Aside Pattern（解决线程安全问题） 缓存穿透： #\r请求客户端数据中，缓存里面和数据库里面数据都不存在，请求都打到数据库上面了\n解决办法：布隆过滤器（内存占用少），缓存空对象或者null（额外内存消耗，可能造成短期不一致） 主动添加 对ID的复杂度\n缓存雪崩 #\r很多key同时失效\n缓存击穿 #\r热点key突然失效，无效热点数据给数据库带来巨大压力\n1：使用互斥锁来写入缓存，但是互相等待时间比较长，性能较差\n2：逻辑过期TTL=-1\n选择一致性还是可用性\n全局唯一 ID生成器 UUID：没有满足特性 ，RedisId：数字类型，snowflake：算法，维护机器ID\n多线程下高并发超卖问题是怎么发生的 #\r当线程扣减时候，多线程查询库存，扣减库存之前，直接一个数据用两次，使得出现并发安全问题。\n锁的介绍： #\r悲观锁： #\r悲观锁\n例如synchronized 和lock，认为线程安全问题一定会发生，在操作数据之前一定要获得锁之后才执行\n乐观锁\n认为线程安全问题不一定会发生，多数情况不发生，不加锁， 在线程做数据更新时进行数据判断，看之前的判断数据是否发生修改，性能相较于乐观锁好\n那怎么判断之前的数据是否发生了修改呢？\n1：版本号法（最广泛） 给数据加上版本号，同时在修改时不仅要查询版本号同时还要修改版本号\n2：CAS方法，假如数据本身具有变化，那么数据本深就可以作为版本号\n3：分段锁，解决成功率较低的问题，实际秒杀还要对秒杀进行优化，不对数据库造成压力\n集群模式下的并发安全问题：\n当出现集群和负载均衡时，可能出现交叉执行，锁失效了，这就是分布式来解决这个问题\n锁监视器不是同一个\n出现了两套JVM，锁监视器具有不同的，这将会导致出现并发安全问题\n==》解决办法：分布式锁\n一人一单 #\r分布式锁 #\r实现原理：不同的JVM采用同一个JVM\n分布式锁特点：多进程可见同时时互斥的锁，高可用性，高并发（高性能），安全性，是否会产生死锁\n是否满足可重入性？（不是重点）\n分布式锁的实现\n实现方式：Mysql Redis Zookeeper\nmysql:利用mysql本身的互斥锁机制，redis:利用setnx这样的互斥命令，利用key的过期时间来解决安全问题。\nzookeeper 利用唯一节点和有序性来实现互斥锁。高可用性还是比较好的，安全性较好\n基于Redis实现分布式锁： #\r127.0.0.1:6379\u0026gt; help set SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET] summary: Set the string value of a key since: 1.0.0 group: string 127.0.0.1:6379\u0026gt; set lock thread EX 10 NX OK 127.0.0.1:6379\u0026gt; set lock thread EX 10 NX (nil) 127.0.0.1:6379\u0026gt; ttl lock (integer) -2 实现将会是非阻塞式的分布式锁\n极端情况线程出现并发安全问题。\n解决办法：释放锁的时候需要进行检查，看自己的锁标识是否和之前获取的一样。\n只要redis锁发生了超时释放就有可能发生并发问题。\n例如FullGc时，发生阻塞就会出现并发问题，所以释放锁和判断锁标识必须是原子性的，必须同时\n用Lua脚本来解决原子性问题 #\r利用看门狗解决锁超时释放的问题\nRedisson问题(呵呵，这是一个把分布式锁实现好的开源框架) #\rredisson 分布式锁原理： #\r可重入：利用hash结构来记录线程id和重入次数，类似于ReentryLock\n可重试：利用信号量实现等待和获取锁失败的重试机制\n超时续约：利用看门狗，在获取锁之后，每隔一段时间，就自动续约，锁满血复活。\n分布式锁的主从一致性问题。 #\r利用redisson的multi lock来实现\n利用Redis来优化秒杀 #\r使用Set类型，解决唯一性问题。lua脚本来解决锁释放和事务提交的原子性问题\n将下单信息添加到阻塞队列里面\nWindows相关命令： #\r查找并记录需要杀死的进程号码： netstat -ano\n查找端口：netstat -ano|findstr [Port]\n查找名称：tasklist |findstr [PID]\n杀死进程： taskkill -f -pid [PID]\n#\r消息队列【Message Queue】:【RabbitMq Kafka RedisQ】 #\r基于Redis实现的异步阻塞队列存在jvm内存溢出问题，基于此实现了消息队列。\n消息队列：存储和管理消息，称为消息代理（message broker）\n生产者:发送消息到消息队列\n消费者：从消息队列中获取消息并处理\n基于Redis-List结构来模拟消息队列 #\rBLpush+BRpop/BRpush+BLpop\n独立于JVM，不依赖于机器，具备数据持久化，满足消息的有序性。 无法避免消息丢失，只支持单消费者。\n基于PubSub的消息队列 #\r发布-订阅模式\n支持多生产和多消费：publish subscribe，psubscribe匹配使用正则表达式\n不支持消息持久化，无法避免消息丢失（当客户端宕机时，不接受消息，消息将会丢失），消息堆积有上限。\n基于Stream的消息队列。基于Redis-5.0实现 #\rXADD key [队列是否创建] [消息队列最大上限] [ID] [filed] [value] XREAD [count] [block sec] streams [key] [id] xgroup creat key groupName ID 消息可回溯，可阻塞读取，可被多个消费者读取，有漏读的风险 单词：pending:待定\n消费者组： #\r消息分流 消息标识（确保消息都会被消费） 消息确认（消息处于pending状态，存入list中，需要得到确认 ）\nxgroup create/destory/delconsumer key groupName ID [\u0026ldquo;mkstream\u0026rdquo;]\n基于stream来实现的消费者组， 读取消息都是从pending-list中读取消息，实现方法是通过id进行筛选\n消息读取之后必须进行确认，参数为消息id，确认之后消息id将会被消息队列移除\n消费者组的名称一般企业环境下都是写在yml文件里面\n三种消息队列List PubSub Stream 解决方案的区别 #\r发布达人探店 #\r对两张表去进行表的设计：\n利用Zsort来作为点赞和排行榜数据结构 相关命令：zadd member score ,zscore member，zrange key from to\n关注推送，Feed流，提供沉浸式体验 #\r常见的两种实现模式：\ntimeline：核心需要带上时间戳，不做内容筛选，信息全面，实现相对简单，但是信息噪音比较多\n实现方式：拉模式，推模式，推拉结合\n拉模式（读扩散）：缺点是延迟高\n推模式\n推拉结合： 收件箱使用redis来实现，查询redis查询收件箱数据时需要实现分页查询，list，soretedset，数据的角标会发生变换，按照传统的分页方案将会出现错误\n智能排序：针对用户使用习惯做一些算法，尽量接近用户使用习惯，但当用户习惯与算法不对称时，将会出现反作用\n","date":"3 October 2023","externalUrl":null,"permalink":"/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/java/%E7%BC%93%E5%AD%98/","section":"编程语言s","summary":"Redis学习： #\r通用命令 #\r不要在主节点用：keys param 命令来查询，这查询速率很慢，单线程将会被阻塞 del param（可以是多个参数） :删除指定的key exists param(判断key是否存在) expire key time :设置有效期时间 ttl key :查看key的有效期\nString类型 #\r最简单的Redis数据类型，value：string,int,float；最大空间不超过512M set key value get key\nMset 批量 添加key-value","title":"Redis","type":"编程语言"},{"content":"","date":"3 October 2023","externalUrl":null,"permalink":"/tags/%E7%BC%93%E5%AD%98/","section":"Tags","summary":"","title":"缓存","type":"tags"},{"content":" 我的名字是春江花朝秋月夜，我是这个博客的作者。我这样做是为了记录之前学习的笔记，这样很有成就感。 我们都知道在网络上开始做一些事情有多难，尤其是现在。但是，为了自己的头发没有白掉，加油吧，大家！\n— 春江花朝秋月夜 S01E01\n","date":"3 October 2003","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/post/","section":"笔记s","summary":"我的名字是春江花朝秋月夜，我是这个博客的作者。我这样做是为了记录之前学习的笔记，这样很有成就感。 我们都知道在网络上开始做一些事情有多难，尤其是现在。但是，为了自己的头发没有白掉，加油吧，大家！\n— 春江花朝秋月夜 S01E01","title":"Hello Friend","type":"笔记"},{"content":"","date":"3 October 2003","externalUrl":null,"permalink":"/tags/post/","section":"Tags","summary":"","title":"post","type":"tags"},{"content":"\rC++提高编程 #\r本阶段主要针对C++==泛型编程==和==STL==技术做详细讲解，探讨C++更深层的使用 1 模板 #\r1.1 模板的概念 #\r模板就是建立通用的模具，大大提高复用性\n模板的特点：\n模板不可以直接使用，它只是一个框架 模板的通用并不是万能的 1.2 函数模板 #\rC++另一种编程思想称为 ==泛型编程== ，主要利用的技术就是模板\nC++提供两种模板机制:函数模板和类模板\n1.2.1 函数模板语法 #\r函数模板作用：\n建立一个通用函数，其函数返回值类型和形参类型可以不具体制定，用一个虚拟的类型来代表。\n语法：\ntemplate\u0026lt;typename T\u0026gt; 函数声明或定义 解释：\ntemplate \u0026mdash; 声明创建模板\ntypename \u0026mdash; 表面其后面的符号是一种数据类型，可以用class代替\nT \u0026mdash; 通用的数据类型，名称可以替换，通常为大写字母\n示例：\n//交换整型函数 void swapInt(int\u0026amp; a, int\u0026amp; b) { int temp = a; a = b; b = temp; } //交换浮点型函数 void swapDouble(double\u0026amp; a, double\u0026amp; b) { double temp = a; a = b; b = temp; } //利用模板提供通用的交换函数 template\u0026lt;typename T\u0026gt; void mySwap(T\u0026amp; a, T\u0026amp; b) { T temp = a; a = b; b = temp; } void test01() { int a = 10; int b = 20; //swapInt(a, b); //利用模板实现交换 //1、自动类型推导 mySwap(a, b); //2、显示指定类型 mySwap\u0026lt;int\u0026gt;(a, b); cout \u0026lt;\u0026lt; \u0026#34;a = \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;b = \u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n函数模板利用关键字 template 使用函数模板有两种方式：自动类型推导、显示指定类型 模板的目的是为了提高复用性，将类型参数化 1.2.2 函数模板注意事项 #\r注意事项：\n自动类型推导，必须推导出一致的数据类型T,才可以使用\n模板必须要确定出T的数据类型，才可以使用\n示例：\n//利用模板提供通用的交换函数 template\u0026lt;class T\u0026gt; void mySwap(T\u0026amp; a, T\u0026amp; b) { T temp = a; a = b; b = temp; } // 1、自动类型推导，必须推导出一致的数据类型T,才可以使用 void test01() { int a = 10; int b = 20; char c = \u0026#39;c\u0026#39;; mySwap(a, b); // 正确，可以推导出一致的T //mySwap(a, c); // 错误，推导不出一致的T类型 } // 2、模板必须要确定出T的数据类型，才可以使用 template\u0026lt;class T\u0026gt; void func() { cout \u0026lt;\u0026lt; \u0026#34;func 调用\u0026#34; \u0026lt;\u0026lt; endl; } void test02() { //func(); //错误，模板不能独立使用，必须确定出T的类型 func\u0026lt;int\u0026gt;(); //利用显示指定类型的方式，给T一个类型，才可以使用该模板 } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n使用模板时必须确定出通用数据类型T，并且能够推导出一致的类型 1.2.3 函数模板案例 #\r案例描述：\n利用函数模板封装一个排序的函数，可以对不同数据类型数组进行排序 排序规则从大到小，排序算法为选择排序 分别利用char数组和int数组进行测试 示例：\n//交换的函数模板 template\u0026lt;typename T\u0026gt; void mySwap(T \u0026amp;a, T\u0026amp;b) { T temp = a; a = b; b = temp; } template\u0026lt;class T\u0026gt; // 也可以替换成typename //利用选择排序，进行对数组从大到小的排序 void mySort(T arr[], int len) { for (int i = 0; i \u0026lt; len; i++) { int max = i; //最大数的下标 for (int j = i + 1; j \u0026lt; len; j++) { if (arr[max] \u0026lt; arr[j]) { max = j; } } if (max != i) //如果最大数的下标不是i，交换两者 { mySwap(arr[max], arr[i]); } } } template\u0026lt;typename T\u0026gt; void printArray(T arr[], int len) { for (int i = 0; i \u0026lt; len; i++) { cout \u0026lt;\u0026lt; arr[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } void test01() { //测试char数组 char charArr[] = \u0026#34;bdcfeagh\u0026#34;; int num = sizeof(charArr) / sizeof(char); mySort(charArr, num); printArray(charArr, num); } void test02() { //测试int数组 int intArr[] = { 7, 5, 8, 1, 3, 9, 2, 4, 6 }; int num = sizeof(intArr) / sizeof(int); mySort(intArr, num); printArray(intArr, num); } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：模板可以提高代码复用，需要熟练掌握\n1.2.4 普通函数与函数模板的区别 #\r普通函数与函数模板区别：\n普通函数调用时可以发生自动类型转换（隐式类型转换） 函数模板调用时，如果利用自动类型推导，不会发生隐式类型转换 如果利用显示指定类型的方式，可以发生隐式类型转换 示例：\n//普通函数 int myAdd01(int a, int b) { return a + b; } //函数模板 template\u0026lt;class T\u0026gt; T myAdd02(T a, T b) { return a + b; } //使用函数模板时，如果用自动类型推导，不会发生自动类型转换,即隐式类型转换 void test01() { int a = 10; int b = 20; char c = \u0026#39;c\u0026#39;; cout \u0026lt;\u0026lt; myAdd01(a, c) \u0026lt;\u0026lt; endl; //正确，将char类型的\u0026#39;c\u0026#39;隐式转换为int类型 \u0026#39;c\u0026#39; 对应 ASCII码 99 //myAdd02(a, c); // 报错，使用自动类型推导时，不会发生隐式类型转换 myAdd02\u0026lt;int\u0026gt;(a, c); //正确，如果用显示指定类型，可以发生隐式类型转换 } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：建议使用显示指定类型的方式，调用函数模板，因为可以自己确定通用类型T\n1.2.5 普通函数与函数模板的调用规则 #\r调用规则如下：\n如果函数模板和普通函数都可以实现，优先调用普通函数 可以通过空模板参数列表来强制调用函数模板 函数模板也可以发生重载 如果函数模板可以产生更好的匹配,优先调用函数模板 示例：\n//普通函数与函数模板调用规则 void myPrint(int a, int b) { cout \u0026lt;\u0026lt; \u0026#34;调用的普通函数\u0026#34; \u0026lt;\u0026lt; endl; } template\u0026lt;typename T\u0026gt; void myPrint(T a, T b) { cout \u0026lt;\u0026lt; \u0026#34;调用的模板\u0026#34; \u0026lt;\u0026lt; endl; } template\u0026lt;typename T\u0026gt; void myPrint(T a, T b, T c) { cout \u0026lt;\u0026lt; \u0026#34;调用重载的模板\u0026#34; \u0026lt;\u0026lt; endl; } void test01() { //1、如果函数模板和普通函数都可以实现，优先调用普通函数 // 注意 如果告诉编译器 普通函数是有的，但只是声明没有实现，或者不在当前文件内实现，就会报错找不到 int a = 10; int b = 20; myPrint(a, b); //调用普通函数 //2、可以通过空模板参数列表来强制调用函数模板 myPrint\u0026lt;\u0026gt;(a, b); //调用函数模板 //3、函数模板也可以发生重载 int c = 30; myPrint(a, b, c); //调用重载的函数模板 //4、 如果函数模板可以产生更好的匹配,优先调用函数模板 char c1 = \u0026#39;a\u0026#39;; char c2 = \u0026#39;b\u0026#39;; myPrint(c1, c2); //调用函数模板 } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：既然提供了函数模板，最好就不要提供普通函数，否则容易出现二义性\n1.2.6 模板的局限性 #\r局限性：\n模板的通用性并不是万能的 例如：\ntemplate\u0026lt;class T\u0026gt; void f(T a, T b) { a = b; } 在上述代码中提供的赋值操作，如果传入的a和b是一个数组，就无法实现了\n再例如：\ntemplate\u0026lt;class T\u0026gt; void f(T a, T b) { if(a \u0026gt; b) { ... } } 在上述代码中，如果T的数据类型传入的是像Person这样的自定义数据类型，也无法正常运行\n因此C++为了解决这种问题，提供模板的重载，可以为这些特定的类型提供具体化的模板\n示例：\n#include\u0026lt;iostream\u0026gt; using namespace std; #include \u0026lt;string\u0026gt; class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } string m_Name; int m_Age; }; //普通函数模板 template\u0026lt;class T\u0026gt; bool myCompare(T\u0026amp; a, T\u0026amp; b) { if (a == b) { return true; } else { return false; } } //具体化，显示具体化的原型和定意思以template\u0026lt;\u0026gt;开头，并通过名称来指出类型 //具体化优先于常规模板 template\u0026lt;\u0026gt; bool myCompare(Person \u0026amp;p1, Person \u0026amp;p2) { if ( p1.m_Name == p2.m_Name \u0026amp;\u0026amp; p1.m_Age == p2.m_Age) { return true; } else { return false; } } void test01() { int a = 10; int b = 20; //内置数据类型可以直接使用通用的函数模板 bool ret = myCompare(a, b); if (ret) { cout \u0026lt;\u0026lt; \u0026#34;a == b \u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;a != b \u0026#34; \u0026lt;\u0026lt; endl; } } void test02() { Person p1(\u0026#34;Tom\u0026#34;, 10); Person p2(\u0026#34;Tom\u0026#34;, 10); //自定义数据类型，不会调用普通的函数模板 //可以创建具体化的Person数据类型的模板，用于特殊处理这个类型 bool ret = myCompare(p1, p2); if (ret) { cout \u0026lt;\u0026lt; \u0026#34;p1 == p2 \u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;p1 != p2 \u0026#34; \u0026lt;\u0026lt; endl; } } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n利用具体化的模板，可以解决自定义类型的通用化 学习模板并不是为了写模板，而是在STL能够运用系统提供的模板 1.3 类模板 #\r1.3.1 类模板语法 #\r类模板作用：\n建立一个通用类，类中的成员 数据类型可以不具体制定，用一个虚拟的类型来代表。 语法：\ntemplate\u0026lt;typename T\u0026gt; 类 解释：\ntemplate \u0026mdash; 声明创建模板\ntypename \u0026mdash; 表面其后面的符号是一种数据类型，可以用class代替\nT \u0026mdash; 通用的数据类型，名称可以替换，通常为大写字母\n示例：\n#include \u0026lt;string\u0026gt; //类模板 template\u0026lt;class NameType, class AgeType\u0026gt; class Person { public: Person(NameType name, AgeType age) { this-\u0026gt;mName = name; this-\u0026gt;mAge = age; } void showPerson() { cout \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;mName \u0026lt;\u0026lt; \u0026#34; age: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;mAge \u0026lt;\u0026lt; endl; } public: NameType mName; AgeType mAge; }; void test01() { // 指定NameType 为string类型，AgeType 为 int类型 Person\u0026lt;string, int\u0026gt;P1(\u0026#34;孙悟空\u0026#34;, 999); P1.showPerson(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：类模板和函数模板语法相似，在声明模板template后面加类，此类称为类模板\n1.3.2 类模板与函数模板区别 #\r类模板与函数模板区别主要有两点：\n类模板没有自动类型推导的使用方式 类模板在模板参数列表中可以有默认参数 示例：\n#include \u0026lt;string\u0026gt; //类模板 template\u0026lt;class NameType, class AgeType = int\u0026gt; class Person { public: Person(NameType name, AgeType age) { this-\u0026gt;mName = name; this-\u0026gt;mAge = age; } void showPerson() { cout \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;mName \u0026lt;\u0026lt; \u0026#34; age: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;mAge \u0026lt;\u0026lt; endl; } public: NameType mName; AgeType mAge; }; //1、类模板没有自动类型推导的使用方式 void test01() { // Person p(\u0026#34;孙悟空\u0026#34;, 1000); // 错误 类模板使用时候，不可以用自动类型推导 Person \u0026lt;string ,int\u0026gt;p(\u0026#34;孙悟空\u0026#34;, 1000); //必须使用显示指定类型的方式，使用类模板 p.showPerson(); } //2、类模板在模板参数列表中可以有默认参数 void test02() { Person \u0026lt;string\u0026gt; p(\u0026#34;猪八戒\u0026#34;, 999); //类模板中的模板参数列表 可以指定默认参数 p.showPerson(); } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n类模板使用只能用显示指定类型方式 类模板中的模板参数列表可以有默认参数 1.3.3 类模板中成员函数创建时机 #\r类模板中成员函数和普通类中成员函数创建时机是有区别的：\n普通类中的成员函数一开始就可以创建 类模板中的成员函数在调用时才创建 示例：\nclass Person1 { public: void showPerson1() { cout \u0026lt;\u0026lt; \u0026#34;Person1 show\u0026#34; \u0026lt;\u0026lt; endl; } }; class Person2 { public: void showPerson2() { cout \u0026lt;\u0026lt; \u0026#34;Person2 show\u0026#34; \u0026lt;\u0026lt; endl; } }; template\u0026lt;class T\u0026gt; class MyClass { public: T obj; //类模板中的成员函数，并不是一开始就创建的，而是在模板调用时再生成 void fun1() { obj.showPerson1(); } void fun2() { obj.showPerson2(); } }; void test01() { MyClass\u0026lt;Person1\u0026gt; m; m.fun1(); //m.fun2();//编译会出错，说明函数调用才会去创建成员函数 } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：类模板中的成员函数并不是一开始就创建的，在调用时才去创建\n1.3.4 类模板对象做函数参数 #\r学习目标：\n类模板实例化出的对象，向函数传参的方式 一共有三种传入方式：\n指定传入的类型 \u0026mdash; 直接显示对象的数据类型 参数模板化 \u0026mdash; 将对象中的参数变为模板进行传递 整个类模板化 \u0026mdash; 将这个对象类型 模板化进行传递 示例：\n#include \u0026lt;string\u0026gt; //类模板 template\u0026lt;class NameType, class AgeType = int\u0026gt; class Person { public: Person(NameType name, AgeType age) { this-\u0026gt;mName = name; this-\u0026gt;mAge = age; } void showPerson() { cout \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;mName \u0026lt;\u0026lt; \u0026#34; age: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;mAge \u0026lt;\u0026lt; endl; } public: NameType mName; AgeType mAge; }; //1、指定传入的类型 void printPerson1(Person\u0026lt;string, int\u0026gt; \u0026amp;p) { p.showPerson(); } void test01() { Person \u0026lt;string, int \u0026gt;p(\u0026#34;孙悟空\u0026#34;, 100); printPerson1(p); } //2、参数模板化 template \u0026lt;class T1, class T2\u0026gt; void printPerson2(Person\u0026lt;T1, T2\u0026gt;\u0026amp;p) { p.showPerson(); cout \u0026lt;\u0026lt; \u0026#34;T1的类型为： \u0026#34; \u0026lt;\u0026lt; typeid(T1).name() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;T2的类型为： \u0026#34; \u0026lt;\u0026lt; typeid(T2).name() \u0026lt;\u0026lt; endl; } void test02() { Person \u0026lt;string, int \u0026gt;p(\u0026#34;猪八戒\u0026#34;, 90); printPerson2(p); } //3、整个类模板化 template\u0026lt;class T\u0026gt; void printPerson3(T \u0026amp; p) { cout \u0026lt;\u0026lt; \u0026#34;T的类型为： \u0026#34; \u0026lt;\u0026lt; typeid(T).name() \u0026lt;\u0026lt; endl; p.showPerson(); } void test03() { Person \u0026lt;string, int \u0026gt;p(\u0026#34;唐僧\u0026#34;, 30); printPerson3(p); } int main() { test01(); test02(); test03(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n通过类模板创建的对象，可以有三种方式向函数中进行传参 使用比较广泛是第一种：指定传入的类型 1.3.5 类模板与继承 #\r当类模板碰到继承时，需要注意一下几点：\n当子类继承的父类是一个类模板时，子类在声明的时候，要指定出父类中T的类型 如果不指定，编译器无法给子类分配内存 如果想灵活指定出父类中T的类型，子类也需变为类模板 示例：\ntemplate\u0026lt;class T\u0026gt; class Base { T m; }; //class Son:public Base //错误，c++编译需要给子类分配内存，必须知道父类中T的类型才可以向下继承 class Son :public Base\u0026lt;int\u0026gt; //必须指定一个类型 { }; void test01() { Son c; } //类模板继承类模板 ,可以用T2指定父类中的T类型 template\u0026lt;class T1, class T2\u0026gt; class Son2 :public Base\u0026lt;T2\u0026gt; { public: Son2() { cout \u0026lt;\u0026lt; typeid(T1).name() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; typeid(T2).name() \u0026lt;\u0026lt; endl; } }; void test02() { Son2\u0026lt;int, char\u0026gt; child1; } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：如果父类是类模板，子类需要指定出父类中T的数据类型\n1.3.6 类模板成员函数类外实现 #\r学习目标：能够掌握类模板中的成员函数类外实现\n示例：\n#include \u0026lt;string\u0026gt; //类模板中成员函数类外实现 template\u0026lt;class T1, class T2\u0026gt; class Person { public: //成员函数类内声明 Person(T1 name, T2 age); void showPerson(); public: T1 m_Name; T2 m_Age; }; //构造函数 类外实现 template\u0026lt;class T1, class T2\u0026gt; Person\u0026lt;T1, T2\u0026gt;::Person(T1 name, T2 age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } //成员函数 类外实现 template\u0026lt;class T1, class T2\u0026gt; void Person\u0026lt;T1, T2\u0026gt;::showPerson() { cout \u0026lt;\u0026lt; \u0026#34;姓名: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄:\u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_Age \u0026lt;\u0026lt; endl; } void test01() { Person\u0026lt;string, int\u0026gt; p(\u0026#34;Tom\u0026#34;, 20); p.showPerson(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：类模板中成员函数类外实现时，需要加上模板参数列表\n1.3.7 类模板分文件编写 #\r学习目标：\n掌握类模板成员函数分文件编写产生的问题以及解决方式 问题：\n类模板中成员函数创建时机是在调用阶段，导致分文件编写时链接不到 解决：\n解决方式1：直接包含.cpp源文件 解决方式2：将声明和实现写到同一个文件中，并更改后缀名为.hpp，hpp是约定的名称，并不是强制 示例：\nperson.hpp中代码：\n#pragma once #include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026lt;string\u0026gt; template\u0026lt;class T1, class T2\u0026gt; class Person { public: Person(T1 name, T2 age); void showPerson(); public: T1 m_Name; T2 m_Age; }; //构造函数 类外实现 template\u0026lt;class T1, class T2\u0026gt; Person\u0026lt;T1, T2\u0026gt;::Person(T1 name, T2 age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } //成员函数 类外实现 template\u0026lt;class T1, class T2\u0026gt; void Person\u0026lt;T1, T2\u0026gt;::showPerson() { cout \u0026lt;\u0026lt; \u0026#34;姓名: \u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄:\u0026#34; \u0026lt;\u0026lt; this-\u0026gt;m_Age \u0026lt;\u0026lt; endl; } 类模板分文件编写.cpp中代码\n#include\u0026lt;iostream\u0026gt; using namespace std; //#include \u0026#34;person.h\u0026#34; #include \u0026#34;person.cpp\u0026#34; //解决方式1，包含cpp源文件 //解决方式2，将声明和实现写到一起，文件后缀名改为.hpp #include \u0026#34;person.hpp\u0026#34; void test01() { Person\u0026lt;string, int\u0026gt; p(\u0026#34;Tom\u0026#34;, 10); p.showPerson(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：主流的解决方式是第二种，将类模板成员函数写到一起，并将后缀名改为.hpp\n1.3.8 类模板与友元 #\r学习目标：\n掌握类模板配合友元函数的类内和类外实现 全局函数类内实现 - 直接在类内声明友元即可\n全局函数类外实现 - 需要提前让编译器知道全局函数的存在\n示例：\n#include \u0026lt;string\u0026gt; //2、全局函数配合友元 类外实现 - 先做函数模板声明，下方在做函数模板定义，在做友元 template\u0026lt;class T1, class T2\u0026gt; class Person; //如果声明了函数模板，可以将实现写到后面，否则需要将实现体写到类的前面让编译器提前看到 //template\u0026lt;class T1, class T2\u0026gt; void printPerson2(Person\u0026lt;T1, T2\u0026gt; \u0026amp; p); template\u0026lt;class T1, class T2\u0026gt; void printPerson2(Person\u0026lt;T1, T2\u0026gt; \u0026amp; p) { cout \u0026lt;\u0026lt; \u0026#34;类外实现 ---- 姓名： \u0026#34; \u0026lt;\u0026lt; p.m_Name \u0026lt;\u0026lt; \u0026#34; 年龄：\u0026#34; \u0026lt;\u0026lt; p.m_Age \u0026lt;\u0026lt; endl; } template\u0026lt;class T1, class T2\u0026gt; class Person { //1、全局函数配合友元 类内实现 friend void printPerson(Person\u0026lt;T1, T2\u0026gt; \u0026amp; p) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; p.m_Name \u0026lt;\u0026lt; \u0026#34; 年龄：\u0026#34; \u0026lt;\u0026lt; p.m_Age \u0026lt;\u0026lt; endl; } //全局函数配合友元 类外实现 friend void printPerson2\u0026lt;\u0026gt;(Person\u0026lt;T1, T2\u0026gt; \u0026amp; p); public: Person(T1 name, T2 age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } private: T1 m_Name; T2 m_Age; }; //1、全局函数在类内实现 void test01() { Person \u0026lt;string, int \u0026gt;p(\u0026#34;Tom\u0026#34;, 20); printPerson(p); } //2、全局函数在类外实现 void test02() { Person \u0026lt;string, int \u0026gt;p(\u0026#34;Jerry\u0026#34;, 30); printPerson2(p); } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：建议全局函数做类内实现，用法简单，而且编译器可以直接识别\n1.3.9 类模板案例 #\r案例描述: 实现一个通用的数组类，要求如下：\n可以对内置数据类型以及自定义数据类型的数据进行存储 将数组中的数据存储到堆区 构造函数中可以传入数组的容量 提供对应的拷贝构造函数以及operator=防止浅拷贝问题 提供尾插法和尾删法对数组中的数据进行增加和删除 可以通过下标的方式访问数组中的元素 可以获取数组中当前元素个数和数组的容量 示例：\nmyArray.hpp中代码\n#pragma once #include \u0026lt;iostream\u0026gt; using namespace std; template\u0026lt;class T\u0026gt; class MyArray { public: //构造函数 MyArray(int capacity) { this-\u0026gt;m_Capacity = capacity; this-\u0026gt;m_Size = 0; pAddress = new T[this-\u0026gt;m_Capacity]; } //拷贝构造 MyArray(const MyArray \u0026amp; arr) { this-\u0026gt;m_Capacity = arr.m_Capacity; this-\u0026gt;m_Size = arr.m_Size; this-\u0026gt;pAddress = new T[this-\u0026gt;m_Capacity]; for (int i = 0; i \u0026lt; this-\u0026gt;m_Size; i++) { //如果T为对象，而且还包含指针，必须需要重载 = 操作符，因为这个等号不是 构造 而是赋值， // 普通类型可以直接= 但是指针类型需要深拷贝 this-\u0026gt;pAddress[i] = arr.pAddress[i]; } } //重载= 操作符 防止浅拷贝问题 MyArray\u0026amp; operator=(const MyArray\u0026amp; myarray) { if (this-\u0026gt;pAddress != NULL) { delete[] this-\u0026gt;pAddress; this-\u0026gt;m_Capacity = 0; this-\u0026gt;m_Size = 0; } this-\u0026gt;m_Capacity = myarray.m_Capacity; this-\u0026gt;m_Size = myarray.m_Size; this-\u0026gt;pAddress = new T[this-\u0026gt;m_Capacity]; for (int i = 0; i \u0026lt; this-\u0026gt;m_Size; i++) { this-\u0026gt;pAddress[i] = myarray[i]; } return *this; } //重载[] 操作符 arr[0] T\u0026amp; operator [](int index) { return this-\u0026gt;pAddress[index]; //不考虑越界，用户自己去处理 } //尾插法 void Push_back(const T \u0026amp; val) { if (this-\u0026gt;m_Capacity == this-\u0026gt;m_Size) { return; } this-\u0026gt;pAddress[this-\u0026gt;m_Size] = val; this-\u0026gt;m_Size++; } //尾删法 void Pop_back() { if (this-\u0026gt;m_Size == 0) { return; } this-\u0026gt;m_Size--; } //获取数组容量 int getCapacity() { return this-\u0026gt;m_Capacity; } //获取数组大小 int\tgetSize() { return this-\u0026gt;m_Size; } //析构 ~MyArray() { if (this-\u0026gt;pAddress != NULL) { delete[] this-\u0026gt;pAddress; this-\u0026gt;pAddress = NULL; this-\u0026gt;m_Capacity = 0; this-\u0026gt;m_Size = 0; } } private: T * pAddress; //指向一个堆空间，这个空间存储真正的数据 int m_Capacity; //容量 int m_Size; // 大小 }; 类模板案例—数组类封装.cpp中\n#include \u0026#34;myArray.hpp\u0026#34; #include \u0026lt;string\u0026gt; void printIntArray(MyArray\u0026lt;int\u0026gt;\u0026amp; arr) { for (int i = 0; i \u0026lt; arr.getSize(); i++) { cout \u0026lt;\u0026lt; arr[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //测试内置数据类型 void test01() { MyArray\u0026lt;int\u0026gt; array1(10); for (int i = 0; i \u0026lt; 10; i++) { array1.Push_back(i); } cout \u0026lt;\u0026lt; \u0026#34;array1打印输出：\u0026#34; \u0026lt;\u0026lt; endl; printIntArray(array1); cout \u0026lt;\u0026lt; \u0026#34;array1的大小：\u0026#34; \u0026lt;\u0026lt; array1.getSize() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;array1的容量：\u0026#34; \u0026lt;\u0026lt; array1.getCapacity() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;--------------------------\u0026#34; \u0026lt;\u0026lt; endl; MyArray\u0026lt;int\u0026gt; array2(array1); array2.Pop_back(); cout \u0026lt;\u0026lt; \u0026#34;array2打印输出：\u0026#34; \u0026lt;\u0026lt; endl; printIntArray(array2); cout \u0026lt;\u0026lt; \u0026#34;array2的大小：\u0026#34; \u0026lt;\u0026lt; array2.getSize() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;array2的容量：\u0026#34; \u0026lt;\u0026lt; array2.getCapacity() \u0026lt;\u0026lt; endl; } //测试自定义数据类型 class Person { public: Person() {} Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } public: string m_Name; int m_Age; }; void printPersonArray(MyArray\u0026lt;Person\u0026gt;\u0026amp; personArr) { for (int i = 0; i \u0026lt; personArr.getSize(); i++) { cout \u0026lt;\u0026lt; \u0026#34;姓名：\u0026#34; \u0026lt;\u0026lt; personArr[i].m_Name \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; personArr[i].m_Age \u0026lt;\u0026lt; endl; } } void test02() { //创建数组 MyArray\u0026lt;Person\u0026gt; pArray(10); Person p1(\u0026#34;孙悟空\u0026#34;, 30); Person p2(\u0026#34;韩信\u0026#34;, 20); Person p3(\u0026#34;妲己\u0026#34;, 18); Person p4(\u0026#34;王昭君\u0026#34;, 15); Person p5(\u0026#34;赵云\u0026#34;, 24); //插入数据 pArray.Push_back(p1); pArray.Push_back(p2); pArray.Push_back(p3); pArray.Push_back(p4); pArray.Push_back(p5); printPersonArray(pArray); cout \u0026lt;\u0026lt; \u0026#34;pArray的大小：\u0026#34; \u0026lt;\u0026lt; pArray.getSize() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;pArray的容量：\u0026#34; \u0026lt;\u0026lt; pArray.getCapacity() \u0026lt;\u0026lt; endl; } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n能够利用所学知识点实现通用的数组\n2 STL初识 #\r2.1 STL的诞生 #\r长久以来，软件界一直希望建立一种可重复利用的东西\nC++的面向对象和泛型编程思想，目的就是复用性的提升\n大多情况下，数据结构和算法都未能有一套标准,导致被迫从事大量重复工作\n为了建立数据结构和算法的一套标准,诞生了STL\n​\n2.2 STL基本概念 #\rSTL(Standard Template Library,标准模板库) STL 从广义上分为: 容器(container) 算法(algorithm) 迭代器(iterator) 容器和算法之间通过迭代器进行无缝连接。 STL 几乎所有的代码都采用了模板类或者模板函数 2.3 STL六大组件 #\rSTL大体分为六大组件，分别是:容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器\n容器：各种数据结构，如vector、list、deque、set、map等,用来存放数据。 算法：各种常用的算法，如sort、find、copy、for_each等 迭代器：扮演了容器与算法之间的胶合剂。 仿函数：行为类似函数，可作为算法的某种策略。 适配器：一种用来修饰容器或者仿函数或迭代器接口的东西。 空间配置器：负责空间的配置与管理。 2.4 STL中容器、算法、迭代器 #\r**容器：**置物之所也\nSTL容器就是将运用最广泛的一些数据结构实现出来\n常用的数据结构：数组, 链表,树, 栈, 队列, 集合, 映射表 等\n这些容器分为序列式容器和关联式容器两种:\n​\t序列式容器:强调值的排序，序列式容器中的每个元素均有固定的位置。 关联式容器:二叉树结构，各元素之间没有严格的物理上的顺序关系\n**算法：**问题之解法也\n有限的步骤，解决逻辑或数学上的问题，这一门学科我们叫做算法(Algorithms)\n算法分为:质变算法和非质变算法。\n质变算法：是指运算过程中会更改区间内的元素的内容。例如拷贝，替换，删除等等\n非质变算法：是指运算过程中不会更改区间内的元素内容，例如查找、计数、遍历、寻找极值等等\n**迭代器：**容器和算法之间粘合剂\n提供一种方法，使之能够依序寻访某个容器所含的各个元素，而又无需暴露该容器的内部表示方式。\n每个容器都有自己专属的迭代器\n迭代器使用非常类似于指针，初学阶段我们可以先理解迭代器为指针\n迭代器种类：\n种类 功能 支持运算 输入迭代器 对数据的只读访问 只读，支持++、==、！= 输出迭代器 对数据的只写访问 只写，支持++ 前向迭代器 读写操作，并能向前推进迭代器 读写，支持++、==、！= 双向迭代器 读写操作，并能向前和向后操作 读写，支持++、\u0026ndash;， 随机访问迭代器 读写操作，可以以跳跃的方式访问任意数据，功能最强的迭代器 读写，支持++、\u0026ndash;、[n]、-n、\u0026lt;、\u0026lt;=、\u0026gt;、\u0026gt;= 常用的容器中迭代器种类为双向迭代器，和随机访问迭代器\n2.5 容器算法迭代器初识 #\r了解STL中容器、算法、迭代器概念之后，我们利用代码感受STL的魅力\nSTL中最常用的容器为Vector，可以理解为数组，下面我们将学习如何向这个容器中插入数据、并遍历这个容器\n2.5.1 vector存放内置数据类型 #\r容器： vector\n算法： for_each\n迭代器： vector\u0026lt;int\u0026gt;::iterator\n示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; void MyPrint(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; endl; } void test01() { //创建vector容器对象，并且通过模板参数指定容器中存放的数据的类型 vector\u0026lt;int\u0026gt; v; //向容器中放数据 v.push_back(10); v.push_back(20); v.push_back(30); v.push_back(40); //每一个容器都有自己的迭代器，迭代器是用来遍历容器中的元素 //v.begin()返回迭代器，这个迭代器指向容器中第一个数据 //v.end()返回迭代器，这个迭代器指向容器元素的最后一个元素的下一个位置 //vector\u0026lt;int\u0026gt;::iterator 拿到vector\u0026lt;int\u0026gt;这种容器的迭代器类型 vector\u0026lt;int\u0026gt;::iterator pBegin = v.begin(); vector\u0026lt;int\u0026gt;::iterator pEnd = v.end(); //第一种遍历方式： while (pBegin != pEnd) { cout \u0026lt;\u0026lt; *pBegin \u0026lt;\u0026lt; endl; pBegin++; } //第二种遍历方式： for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; //第三种遍历方式： //使用STL提供标准遍历算法 头文件 algorithm for_each(v.begin(), v.end(), MyPrint); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 2.5.2 Vector存放自定义数据类型 #\r学习目标：vector中存放自定义数据类型，并打印输出\n示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; //自定义数据类型 class Person { public: Person(string name, int age) { mName = name; mAge = age; } public: string mName; int mAge; }; //存放对象 void test01() { vector\u0026lt;Person\u0026gt; v; //创建数据 Person p1(\u0026#34;aaa\u0026#34;, 10); Person p2(\u0026#34;bbb\u0026#34;, 20); Person p3(\u0026#34;ccc\u0026#34;, 30); Person p4(\u0026#34;ddd\u0026#34;, 40); Person p5(\u0026#34;eee\u0026#34;, 50); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); v.push_back(p5); for (vector\u0026lt;Person\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;Name:\u0026#34; \u0026lt;\u0026lt; (*it).mName \u0026lt;\u0026lt; \u0026#34; Age:\u0026#34; \u0026lt;\u0026lt; (*it).mAge \u0026lt;\u0026lt; endl; } } //放对象指针 void test02() { vector\u0026lt;Person*\u0026gt; v; //创建数据 Person p1(\u0026#34;aaa\u0026#34;, 10); Person p2(\u0026#34;bbb\u0026#34;, 20); Person p3(\u0026#34;ccc\u0026#34;, 30); Person p4(\u0026#34;ddd\u0026#34;, 40); Person p5(\u0026#34;eee\u0026#34;, 50); v.push_back(\u0026amp;p1); v.push_back(\u0026amp;p2); v.push_back(\u0026amp;p3); v.push_back(\u0026amp;p4); v.push_back(\u0026amp;p5); for (vector\u0026lt;Person*\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { Person * p = (*it); cout \u0026lt;\u0026lt; \u0026#34;Name:\u0026#34; \u0026lt;\u0026lt; p-\u0026gt;mName \u0026lt;\u0026lt; \u0026#34; Age:\u0026#34; \u0026lt;\u0026lt; (*it)-\u0026gt;mAge \u0026lt;\u0026lt; endl; } } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 2.5.3 Vector容器嵌套容器 #\r学习目标：容器中嵌套容器，我们将所有数据进行遍历输出\n示例：\n#include \u0026lt;vector\u0026gt; //容器嵌套容器 void test01() { vector\u0026lt; vector\u0026lt;int\u0026gt; \u0026gt; v; vector\u0026lt;int\u0026gt; v1; vector\u0026lt;int\u0026gt; v2; vector\u0026lt;int\u0026gt; v3; vector\u0026lt;int\u0026gt; v4; for (int i = 0; i \u0026lt; 4; i++) { v1.push_back(i + 1); v2.push_back(i + 2); v3.push_back(i + 3); v4.push_back(i + 4); } //将容器元素插入到vector v中 v.push_back(v1); v.push_back(v2); v.push_back(v3); v.push_back(v4); for (vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { for (vector\u0026lt;int\u0026gt;::iterator vit = (*it).begin(); vit != (*it).end(); vit++) { cout \u0026lt;\u0026lt; *vit \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 3 STL- 常用容器 #\r3.1 string容器 #\r3.1.1 string基本概念 #\r本质：\nstring是C++风格的字符串，而string本质上是一个类 string和char * 区别：\nchar * 是一个指针 string是一个类，类内部封装了char*，管理这个字符串，是一个char*型的容器。 特点：\nstring 类内部封装了很多成员方法\n例如：查找find，拷贝copy，删除delete 替换replace，插入insert\nstring管理char*所分配的内存，不用担心复制越界和取值越界等，由类内部进行负责\n3.1.2 string构造函数 #\r构造函数原型：\nstring(); //创建一个空的字符串 例如: string str; string(const char* s);\t//使用字符串s初始化 string(const string\u0026amp; str); //使用一个string对象初始化另一个string对象 string(int n, char c); //使用n个字符c初始化 示例：\n#include \u0026lt;string\u0026gt; //string构造 void test01() { string s1; //创建空字符串，调用无参构造函数 cout \u0026lt;\u0026lt; \u0026#34;str1 = \u0026#34; \u0026lt;\u0026lt; s1 \u0026lt;\u0026lt; endl; const char* str = \u0026#34;hello world\u0026#34;; string s2(str); //把c_string转换成了string cout \u0026lt;\u0026lt; \u0026#34;str2 = \u0026#34; \u0026lt;\u0026lt; s2 \u0026lt;\u0026lt; endl; string s3(s2); //调用拷贝构造函数 cout \u0026lt;\u0026lt; \u0026#34;str3 = \u0026#34; \u0026lt;\u0026lt; s3 \u0026lt;\u0026lt; endl; string s4(10, \u0026#39;a\u0026#39;); cout \u0026lt;\u0026lt; \u0026#34;str3 = \u0026#34; \u0026lt;\u0026lt; s3 \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：string的多种构造方式没有可比性，灵活使用即可\n3.1.3 string赋值操作 #\r功能描述：\n给string字符串进行赋值 赋值的函数原型：\nstring\u0026amp; operator=(const char* s); //char*类型字符串 赋值给当前的字符串 string\u0026amp; operator=(const string \u0026amp;s); //把字符串s赋给当前的字符串 string\u0026amp; operator=(char c); //字符赋值给当前的字符串 string\u0026amp; assign(const char *s); //把字符串s赋给当前的字符串 string\u0026amp; assign(const char *s, int n); //把字符串s的前n个字符赋给当前的字符串 string\u0026amp; assign(const string \u0026amp;s); //把字符串s赋给当前字符串 string\u0026amp; assign(int n, char c); //用n个字符c赋给当前字符串 示例：\n//赋值 void test01() { string str1; str1 = \u0026#34;hello world\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;str1 = \u0026#34; \u0026lt;\u0026lt; str1 \u0026lt;\u0026lt; endl; string str2; str2 = str1; cout \u0026lt;\u0026lt; \u0026#34;str2 = \u0026#34; \u0026lt;\u0026lt; str2 \u0026lt;\u0026lt; endl; string str3; str3 = \u0026#39;a\u0026#39;; cout \u0026lt;\u0026lt; \u0026#34;str3 = \u0026#34; \u0026lt;\u0026lt; str3 \u0026lt;\u0026lt; endl; string str4; str4.assign(\u0026#34;hello c++\u0026#34;); cout \u0026lt;\u0026lt; \u0026#34;str4 = \u0026#34; \u0026lt;\u0026lt; str4 \u0026lt;\u0026lt; endl; string str5; str5.assign(\u0026#34;hello c++\u0026#34;,5); cout \u0026lt;\u0026lt; \u0026#34;str5 = \u0026#34; \u0026lt;\u0026lt; str5 \u0026lt;\u0026lt; endl; string str6; str6.assign(str5); cout \u0026lt;\u0026lt; \u0026#34;str6 = \u0026#34; \u0026lt;\u0026lt; str6 \u0026lt;\u0026lt; endl; string str7; str7.assign(5, \u0026#39;x\u0026#39;); cout \u0026lt;\u0026lt; \u0026#34;str7 = \u0026#34; \u0026lt;\u0026lt; str7 \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n​\tstring的赋值方式很多，operator= 这种方式是比较实用的\n3.1.4 string字符串拼接 #\r功能描述：\n实现在字符串末尾拼接字符串 函数原型：\nstring\u0026amp; operator+=(const char* str); //重载+=操作符 string\u0026amp; operator+=(const char c); //重载+=操作符 string\u0026amp; operator+=(const string\u0026amp; str); //重载+=操作符 string\u0026amp; append(const char *s); //把字符串s连接到当前字符串结尾 string\u0026amp; append(const char *s, int n); //把字符串s的前n个字符连接到当前字符串结尾 string\u0026amp; append(const string \u0026amp;s); //同operator+=(const string\u0026amp; str) string\u0026amp; append(const string \u0026amp;s, int pos, int n);//字符串s中从pos开始的n个字符连接到字符串结尾 示例：\n//字符串拼接 void test01() { string str1 = \u0026#34;我\u0026#34;; str1 += \u0026#34;爱玩游戏\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;str1 = \u0026#34; \u0026lt;\u0026lt; str1 \u0026lt;\u0026lt; endl; str1 += \u0026#39;:\u0026#39;; cout \u0026lt;\u0026lt; \u0026#34;str1 = \u0026#34; \u0026lt;\u0026lt; str1 \u0026lt;\u0026lt; endl; string str2 = \u0026#34;LOL DNF\u0026#34;; str1 += str2; cout \u0026lt;\u0026lt; \u0026#34;str1 = \u0026#34; \u0026lt;\u0026lt; str1 \u0026lt;\u0026lt; endl; string str3 = \u0026#34;I\u0026#34;; str3.append(\u0026#34; love \u0026#34;); str3.append(\u0026#34;game abcde\u0026#34;, 4); //str3.append(str2); str3.append(str2, 4, 3); // 从下标4位置开始 ，截取3个字符，拼接到字符串末尾 cout \u0026lt;\u0026lt; \u0026#34;str3 = \u0026#34; \u0026lt;\u0026lt; str3 \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：字符串拼接的重载版本很多，初学阶段记住几种即可\n3.1.5 string查找和替换 #\r功能描述：\n查找：查找指定字符串是否存在 替换：在指定的位置替换字符串 函数原型：\nint find(const string\u0026amp; str, int pos = 0) const; //查找str第一次出现位置,从pos开始查找 int find(const char* s, int pos = 0) const; //查找s第一次出现位置,从pos开始查找 int find(const char* s, int pos, int n) const; //从pos位置查找s的前n个字符第一次位置 int find(const char c, int pos = 0) const; //查找字符c第一次出现位置 int rfind(const string\u0026amp; str, int pos = npos) const; //查找str最后一次位置,从pos开始查找 int rfind(const char* s, int pos = npos) const; //查找s最后一次出现位置,从pos开始查找 int rfind(const char* s, int pos, int n) const; //从pos查找s的前n个字符最后一次位置 int rfind(const char c, int pos = 0) const; //查找字符c最后一次出现位置 string\u0026amp; replace(int pos, int n, const string\u0026amp; str); //替换从pos开始n个字符为字符串str string\u0026amp; replace(int pos, int n,const char* s); //替换从pos开始的n个字符为字符串s 示例：\n//查找和替换 void test01() { //查找 string str1 = \u0026#34;abcdefgde\u0026#34;; int pos = str1.find(\u0026#34;de\u0026#34;); if (pos == -1) { cout \u0026lt;\u0026lt; \u0026#34;未找到\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;pos = \u0026#34; \u0026lt;\u0026lt; pos \u0026lt;\u0026lt; endl; } pos = str1.rfind(\u0026#34;de\u0026#34;); cout \u0026lt;\u0026lt; \u0026#34;pos = \u0026#34; \u0026lt;\u0026lt; pos \u0026lt;\u0026lt; endl; } void test02() { //替换 string str1 = \u0026#34;abcdefgde\u0026#34;; str1.replace(1, 3, \u0026#34;1111\u0026#34;); cout \u0026lt;\u0026lt; \u0026#34;str1 = \u0026#34; \u0026lt;\u0026lt; str1 \u0026lt;\u0026lt; endl; } int main() { //test01(); //test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\nfind查找是从左往后，rfind从右往左 find找到字符串后返回查找的第一个字符位置，找不到返回-1 replace在替换时，要指定从哪个位置起，多少个字符，替换成什么样的字符串 3.1.6 string字符串比较 #\r功能描述：\n字符串之间的比较 比较方式：\n字符串比较是按字符的ASCII码进行对比 = 返回 0\n\u0026gt; 返回 1\n\u0026lt; 返回 -1\n函数原型：\nint compare(const string \u0026amp;s) const; //与字符串s比较 int compare(const char *s) const; //与字符串s比较 示例：\n//字符串比较 void test01() { string s1 = \u0026#34;hello\u0026#34;; string s2 = \u0026#34;aello\u0026#34;; int ret = s1.compare(s2); if (ret == 0) { cout \u0026lt;\u0026lt; \u0026#34;s1 等于 s2\u0026#34; \u0026lt;\u0026lt; endl; } else if (ret \u0026gt; 0) { cout \u0026lt;\u0026lt; \u0026#34;s1 大于 s2\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;s1 小于 s2\u0026#34; \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：字符串对比主要是用于比较两个字符串是否相等，判断谁大谁小的意义并不是很大\n3.1.7 string字符存取 #\rstring中单个字符存取方式有两种\nchar\u0026amp; operator[](int n); //通过[]方式取字符 char\u0026amp; at(int n); //通过at方法获取字符 示例：\nvoid test01() { string str = \u0026#34;hello world\u0026#34;; for (int i = 0; i \u0026lt; str.size(); i++) { cout \u0026lt;\u0026lt; str[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; str.size(); i++) { cout \u0026lt;\u0026lt; str.at(i) \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; //字符修改 str[0] = \u0026#39;x\u0026#39;; str.at(1) = \u0026#39;x\u0026#39;; cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：string字符串中单个字符存取有两种方式，利用 [ ] 或 at\n3.1.8 string插入和删除 #\r功能描述：\n对string字符串进行插入和删除字符操作 函数原型：\nstring\u0026amp; insert(int pos, const char* s); //插入字符串 string\u0026amp; insert(int pos, const string\u0026amp; str); //插入字符串 string\u0026amp; insert(int pos, int n, char c); //在指定位置插入n个字符c string\u0026amp; erase(int pos, int n = npos); //删除从Pos开始的n个字符 示例：\n//字符串插入和删除 void test01() { string str = \u0026#34;hello\u0026#34;; str.insert(1, \u0026#34;111\u0026#34;); cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; str.erase(1, 3); //从1号位置开始3个字符 cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**插入和删除的起始下标都是从0开始\n3.1.9 string子串 #\r功能描述：\n从字符串中获取想要的子串 函数原型：\nstring substr(int pos = 0, int n = npos) const; //返回由pos开始的n个字符组成的字符串 示例：\n//子串 void test01() { string str = \u0026#34;abcdefg\u0026#34;; string subStr = str.substr(1, 3); cout \u0026lt;\u0026lt; \u0026#34;subStr = \u0026#34; \u0026lt;\u0026lt; subStr \u0026lt;\u0026lt; endl; string email = \u0026#34;hello@sina.com\u0026#34;; int pos = email.find(\u0026#34;@\u0026#34;); string username = email.substr(0, pos); cout \u0026lt;\u0026lt; \u0026#34;username: \u0026#34; \u0026lt;\u0026lt; username \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**灵活的运用求子串功能，可以在实际开发中获取有效的信息\n3.2 vector容器 #\r3.2.1 vector基本概念 #\r功能：\nvector数据结构和数组非常相似，也称为单端数组 vector与普通数组区别：\n不同之处在于数组是静态空间，而vector可以动态扩展 动态扩展：\n并不是在原空间之后续接新空间，而是找更大的内存空间，然后将原数据拷贝新空间，释放原空间 vector容器的迭代器是支持随机访问的迭代器 3.2.2 vector构造函数 #\r功能描述：\n创建vector容器 函数原型：\nvector\u0026lt;T\u0026gt; v; //采用模板实现类实现，默认构造函数 vector(v.begin(), v.end()); //将v[begin(), end())区间中的元素拷贝给本身。 vector(n, elem); //构造函数将n个elem拷贝给本身。 vector(const vector \u0026amp;vec); //拷贝构造函数。 示例：\n#include \u0026lt;vector\u0026gt; void printVector(vector\u0026lt;int\u0026gt;\u0026amp; v) { for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } void test01() { vector\u0026lt;int\u0026gt; v1; //无参构造 for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); } printVector(v1); vector\u0026lt;int\u0026gt; v2(v1.begin(), v1.end()); printVector(v2); vector\u0026lt;int\u0026gt; v3(10, 100); printVector(v3); vector\u0026lt;int\u0026gt; v4(v3); printVector(v4); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**vector的多种构造方式没有可比性，灵活使用即可\n3.2.3 vector赋值操作 #\r功能描述：\n给vector容器进行赋值 函数原型：\nvector\u0026amp; operator=(const vector \u0026amp;vec);//重载等号操作符\nassign(beg, end); //将[beg, end)区间中的数据拷贝赋值给本身。\nassign(n, elem); //将n个elem拷贝赋值给本身。\n示例：\n#include \u0026lt;vector\u0026gt; void printVector(vector\u0026lt;int\u0026gt;\u0026amp; v) { for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //赋值操作 void test01() { vector\u0026lt;int\u0026gt; v1; //无参构造 for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); } printVector(v1); vector\u0026lt;int\u0026gt;v2; v2 = v1; printVector(v2); vector\u0026lt;int\u0026gt;v3; v3.assign(v1.begin(), v1.end()); printVector(v3); vector\u0026lt;int\u0026gt;v4; v4.assign(10, 100); printVector(v4); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结： vector赋值方式比较简单，使用operator=，或者assign都可以\n3.2.4 vector容量和大小 #\r功能描述：\n对vector容器的容量和大小操作 函数原型：\nempty(); //判断容器是否为空\ncapacity(); //容器的容量\nsize(); //返回容器中元素的个数\nresize(int num); //重新指定容器的长度为num，若容器变长，则以默认值填充新位置。\n​\t//如果容器变短，则末尾超出容器长度的元素被删除。\nresize(int num, elem); //重新指定容器的长度为num，若容器变长，则以elem值填充新位置。\n​\t//如果容器变短，则末尾超出容器长度的元素被删除\n示例：\n#include \u0026lt;vector\u0026gt; void printVector(vector\u0026lt;int\u0026gt;\u0026amp; v) { for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } void test01() { vector\u0026lt;int\u0026gt; v1; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); } printVector(v1); if (v1.empty()) { cout \u0026lt;\u0026lt; \u0026#34;v1为空\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;v1不为空\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v1的容量 = \u0026#34; \u0026lt;\u0026lt; v1.capacity() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v1的大小 = \u0026#34; \u0026lt;\u0026lt; v1.size() \u0026lt;\u0026lt; endl; } //resize 重新指定大小 ，若指定的更大，默认用0填充新位置，可以利用重载版本替换默认填充 v1.resize(15,10); printVector(v1); //resize 重新指定大小 ，若指定的更小，超出部分元素被删除 v1.resize(5); printVector(v1); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n判断是否为空 \u0026mdash; empty 返回元素个数 \u0026mdash; size 返回容器容量 \u0026mdash; capacity 重新指定大小 \u0026mdash; resize 3.2.5 vector插入和删除 #\r功能描述：\n对vector容器进行插入、删除操作 函数原型：\npush_back(ele); //尾部插入元素ele pop_back(); //删除最后一个元素 insert(const_iterator pos, ele); //迭代器指向位置pos插入元素ele insert(const_iterator pos, int count,ele);//迭代器指向位置pos插入count个元素ele erase(const_iterator pos); //删除迭代器指向的元素 erase(const_iterator start, const_iterator end);//删除迭代器从start到end之间的元素 clear(); //删除容器中所有元素 示例：\n#include \u0026lt;vector\u0026gt; void printVector(vector\u0026lt;int\u0026gt;\u0026amp; v) { for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //插入和删除 void test01() { vector\u0026lt;int\u0026gt; v1; //尾插 v1.push_back(10); v1.push_back(20); v1.push_back(30); v1.push_back(40); v1.push_back(50); printVector(v1); //尾删 v1.pop_back(); printVector(v1); //插入 v1.insert(v1.begin(), 100); printVector(v1); v1.insert(v1.begin(), 2, 1000); printVector(v1); //删除 v1.erase(v1.begin()); printVector(v1); //清空 v1.erase(v1.begin(), v1.end()); v1.clear(); printVector(v1); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n尾插 \u0026mdash; push_back 尾删 \u0026mdash; pop_back 插入 \u0026mdash; insert (位置迭代器) 删除 \u0026mdash; erase （位置迭代器） 清空 \u0026mdash; clear 3.2.6 vector数据存取 #\r功能描述：\n对vector中的数据的存取操作 函数原型：\nat(int idx); //返回索引idx所指的数据 operator[]; //返回索引idx所指的数据 front(); //返回容器中第一个数据元素 back(); //返回容器中最后一个数据元素 示例：\n#include \u0026lt;vector\u0026gt; void test01() { vector\u0026lt;int\u0026gt;v1; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); } for (int i = 0; i \u0026lt; v1.size(); i++) { cout \u0026lt;\u0026lt; v1[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; v1.size(); i++) { cout \u0026lt;\u0026lt; v1.at(i) \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v1的第一个元素为： \u0026#34; \u0026lt;\u0026lt; v1.front() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v1的最后一个元素为： \u0026#34; \u0026lt;\u0026lt; v1.back() \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n除了用迭代器获取vector容器中元素， 和at也可以 front返回容器第一个元素 back返回容器最后一个元素 3.2.7 vector互换容器 #\r功能描述：\n实现两个容器内元素进行互换 函数原型：\nswap(vec); // 将vec与本身的元素互换 示例：\n#include \u0026lt;vector\u0026gt; void printVector(vector\u0026lt;int\u0026gt;\u0026amp; v) { for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } void test01() { vector\u0026lt;int\u0026gt;v1; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); } printVector(v1); vector\u0026lt;int\u0026gt;v2; for (int i = 10; i \u0026gt; 0; i--) { v2.push_back(i); } printVector(v2); //互换容器 cout \u0026lt;\u0026lt; \u0026#34;互换后\u0026#34; \u0026lt;\u0026lt; endl; v1.swap(v2); printVector(v1); printVector(v2); } void test02() { vector\u0026lt;int\u0026gt; v; for (int i = 0; i \u0026lt; 100000; i++) { v.push_back(i); } cout \u0026lt;\u0026lt; \u0026#34;v的容量为：\u0026#34; \u0026lt;\u0026lt; v.capacity() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v的大小为：\u0026#34; \u0026lt;\u0026lt; v.size() \u0026lt;\u0026lt; endl; v.resize(3); cout \u0026lt;\u0026lt; \u0026#34;v的容量为：\u0026#34; \u0026lt;\u0026lt; v.capacity() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v的大小为：\u0026#34; \u0026lt;\u0026lt; v.size() \u0026lt;\u0026lt; endl; //收缩内存 vector\u0026lt;int\u0026gt;(v).swap(v); //匿名对象 cout \u0026lt;\u0026lt; \u0026#34;v的容量为：\u0026#34; \u0026lt;\u0026lt; v.capacity() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v的大小为：\u0026#34; \u0026lt;\u0026lt; v.size() \u0026lt;\u0026lt; endl; } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：swap可以使两个容器互换，可以达到实用的收缩内存效果\n3.2.8 vector预留空间 #\r功能描述：\n减少vector在动态扩展容量时的扩展次数 函数原型：\nreserve(int len);//容器预留len个元素长度，预留位置不初始化，元素不可访问。\n​\n示例：\n#include \u0026lt;vector\u0026gt; void test01() { vector\u0026lt;int\u0026gt; v; //预留空间 v.reserve(100000); int num = 0; int* p = NULL; for (int i = 0; i \u0026lt; 100000; i++) { v.push_back(i); if (p != \u0026amp;v[0]) { p = \u0026amp;v[0]; num++; } } cout \u0026lt;\u0026lt; \u0026#34;num:\u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：如果数据量较大，可以一开始利用reserve预留空间\n3.3 deque容器 #\r3.3.1 deque容器基本概念 #\r功能：\n双端数组，可以对头端进行插入删除操作 deque与vector区别：\nvector对于头部的插入删除效率低，数据量越大，效率越低 deque相对而言，对头部的插入删除速度回比vector快 vector访问元素时的速度会比deque快,这和两者内部实现有关 deque内部工作原理:\ndeque内部有个中控器，维护每段缓冲区中的内容，缓冲区中存放真实数据\n中控器维护的是每个缓冲区的地址，使得使用deque时像一片连续的内存空间\ndeque容器的迭代器也是支持随机访问的 3.3.2 deque构造函数 #\r功能描述：\ndeque容器构造 函数原型：\ndeque\u0026lt;T\u0026gt; deqT; //默认构造形式 deque(beg, end); //构造函数将[beg, end)区间中的元素拷贝给本身。 deque(n, elem); //构造函数将n个elem拷贝给本身。 deque(const deque \u0026amp;deq); //拷贝构造函数 示例：\n#include \u0026lt;deque\u0026gt; void printDeque(const deque\u0026lt;int\u0026gt;\u0026amp; d) { for (deque\u0026lt;int\u0026gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //deque构造 void test01() { deque\u0026lt;int\u0026gt; d1; //无参构造函数 for (int i = 0; i \u0026lt; 10; i++) { d1.push_back(i); } printDeque(d1); deque\u0026lt;int\u0026gt; d2(d1.begin(),d1.end()); printDeque(d2); deque\u0026lt;int\u0026gt;d3(10,100); printDeque(d3); deque\u0026lt;int\u0026gt;d4 = d3; printDeque(d4); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**deque容器和vector容器的构造方式几乎一致，灵活使用即可\n3.3.3 deque赋值操作 #\r功能描述：\n给deque容器进行赋值 函数原型：\ndeque\u0026amp; operator=(const deque \u0026amp;deq); //重载等号操作符\nassign(beg, end); //将[beg, end)区间中的数据拷贝赋值给本身。\nassign(n, elem); //将n个elem拷贝赋值给本身。\n示例：\n#include \u0026lt;deque\u0026gt; void printDeque(const deque\u0026lt;int\u0026gt;\u0026amp; d) { for (deque\u0026lt;int\u0026gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //赋值操作 void test01() { deque\u0026lt;int\u0026gt; d1; for (int i = 0; i \u0026lt; 10; i++) { d1.push_back(i); } printDeque(d1); deque\u0026lt;int\u0026gt;d2; d2 = d1; printDeque(d2); deque\u0026lt;int\u0026gt;d3; d3.assign(d1.begin(), d1.end()); printDeque(d3); deque\u0026lt;int\u0026gt;d4; d4.assign(10, 100); printDeque(d4); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：deque赋值操作也与vector相同，需熟练掌握\n3.3.4 deque大小操作 #\r功能描述：\n对deque容器的大小进行操作 函数原型：\ndeque.empty(); //判断容器是否为空\ndeque.size(); //返回容器中元素的个数\ndeque.resize(num); //重新指定容器的长度为num,若容器变长，则以默认值填充新位置。\n​\t//如果容器变短，则末尾超出容器长度的元素被删除。\ndeque.resize(num, elem); //重新指定容器的长度为num,若容器变长，则以elem值填充新位置。\n​ //如果容器变短，则末尾超出容器长度的元素被删除。\n​\n示例：\n#include \u0026lt;deque\u0026gt; void printDeque(const deque\u0026lt;int\u0026gt;\u0026amp; d) { for (deque\u0026lt;int\u0026gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //大小操作 void test01() { deque\u0026lt;int\u0026gt; d1; for (int i = 0; i \u0026lt; 10; i++) { d1.push_back(i); } printDeque(d1); //判断容器是否为空 if (d1.empty()) { cout \u0026lt;\u0026lt; \u0026#34;d1为空!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;d1不为空!\u0026#34; \u0026lt;\u0026lt; endl; //统计大小 cout \u0026lt;\u0026lt; \u0026#34;d1的大小为：\u0026#34; \u0026lt;\u0026lt; d1.size() \u0026lt;\u0026lt; endl; } //重新指定大小 d1.resize(15, 1); printDeque(d1); d1.resize(5); printDeque(d1); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\ndeque没有容量的概念 判断是否为空 \u0026mdash; empty 返回元素个数 \u0026mdash; size 重新指定个数 \u0026mdash; resize 3.3.5 deque 插入和删除 #\r功能描述：\n向deque容器中插入和删除数据 函数原型：\n两端插入操作：\npush_back(elem); //在容器尾部添加一个数据 push_front(elem); //在容器头部插入一个数据 pop_back(); //删除容器最后一个数据 pop_front(); //删除容器第一个数据 指定位置操作：\ninsert(pos,elem); //在pos位置插入一个elem元素的拷贝，返回新数据的位置。\ninsert(pos,n,elem); //在pos位置插入n个elem数据，无返回值。\ninsert(pos,beg,end); //在pos位置插入[beg,end)区间的数据，无返回值。\nclear(); //清空容器的所有数据\nerase(beg,end); //删除[beg,end)区间的数据，返回下一个数据的位置。\nerase(pos); //删除pos位置的数据，返回下一个数据的位置。\n​\n​\n示例：\n#include \u0026lt;deque\u0026gt; void printDeque(const deque\u0026lt;int\u0026gt;\u0026amp; d) { for (deque\u0026lt;int\u0026gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //两端操作 void test01() { deque\u0026lt;int\u0026gt; d; //尾插 d.push_back(10); d.push_back(20); //头插 d.push_front(100); d.push_front(200); printDeque(d); //尾删 d.pop_back(); //头删 d.pop_front(); printDeque(d); } //插入 void test02() { deque\u0026lt;int\u0026gt; d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); printDeque(d); d.insert(d.begin(), 1000); printDeque(d); d.insert(d.begin(), 2,10000); printDeque(d); deque\u0026lt;int\u0026gt;d2; d2.push_back(1); d2.push_back(2); d2.push_back(3); d.insert(d.begin(), d2.begin(), d2.end()); printDeque(d); } //删除 void test03() { deque\u0026lt;int\u0026gt; d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); printDeque(d); d.erase(d.begin()); printDeque(d); d.erase(d.begin(), d.end()); d.clear(); printDeque(d); } int main() { //test01(); //test02(); test03(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n插入和删除提供的位置是迭代器！ 尾插 \u0026mdash; push_back 尾删 \u0026mdash; pop_back 头插 \u0026mdash; push_front 头删 \u0026mdash; pop_front 3.3.6 deque 数据存取 #\r功能描述：\n对deque 中的数据的存取操作 函数原型：\nat(int idx); //返回索引idx所指的数据 operator[]; //返回索引idx所指的数据 front(); //返回容器中第一个数据元素 back(); //返回容器中最后一个数据元素 示例：\n#include \u0026lt;deque\u0026gt; void printDeque(const deque\u0026lt;int\u0026gt;\u0026amp; d) { for (deque\u0026lt;int\u0026gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //数据存取 void test01() { deque\u0026lt;int\u0026gt; d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); for (int i = 0; i \u0026lt; d.size(); i++) { cout \u0026lt;\u0026lt; d[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; d.size(); i++) { cout \u0026lt;\u0026lt; d.at(i) \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;front:\u0026#34; \u0026lt;\u0026lt; d.front() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;back:\u0026#34; \u0026lt;\u0026lt; d.back() \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n除了用迭代器获取deque容器中元素， 和at也可以 front返回容器第一个元素 back返回容器最后一个元素 3.3.7 deque 排序 #\r功能描述：\n利用算法实现对deque容器进行排序 算法：\nsort(iterator beg, iterator end) //对beg和end区间内元素进行排序 示例：\n#include \u0026lt;deque\u0026gt; #include \u0026lt;algorithm\u0026gt; void printDeque(const deque\u0026lt;int\u0026gt;\u0026amp; d) { for (deque\u0026lt;int\u0026gt;::const_iterator it = d.begin(); it != d.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } void test01() { deque\u0026lt;int\u0026gt; d; d.push_back(10); d.push_back(20); d.push_front(100); d.push_front(200); printDeque(d); sort(d.begin(), d.end()); printDeque(d); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：sort算法非常实用，使用时包含头文件 algorithm即可\n3.4 案例-评委打分 #\r3.4.1 案例描述 #\r有5名选手：选手ABCDE，10个评委分别对每一名选手打分，去除最高分，去除评委中最低分，取平均分。\n3.4.2 实现步骤 #\r创建五名选手，放到vector中 遍历vector容器，取出来每一个选手，执行for循环，可以把10个评分打分存到deque容器中 sort算法对deque容器中分数排序，去除最高和最低分 deque容器遍历一遍，累加总分 获取平均分 示例代码：\n//选手类 class Person { public: Person(string name, int score) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Score = score; } string m_Name; //姓名 int m_Score; //平均分 }; void createPerson(vector\u0026lt;Person\u0026gt;\u0026amp;v) { string nameSeed = \u0026#34;ABCDE\u0026#34;; for (int i = 0; i \u0026lt; 5; i++) { string name = \u0026#34;选手\u0026#34;; name += nameSeed[i]; int score = 0; Person p(name, score); //将创建的person对象 放入到容器中 v.push_back(p); } } //打分 void setScore(vector\u0026lt;Person\u0026gt;\u0026amp;v) { for (vector\u0026lt;Person\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { //将评委的分数 放入到deque容器中 deque\u0026lt;int\u0026gt;d; for (int i = 0; i \u0026lt; 10; i++) { int score = rand() % 41 + 60; // 60 ~ 100 d.push_back(score); } //cout \u0026lt;\u0026lt; \u0026#34;选手： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 打分： \u0026#34; \u0026lt;\u0026lt; endl; //for (deque\u0026lt;int\u0026gt;::iterator dit = d.begin(); dit != d.end(); dit++) //{ //\tcout \u0026lt;\u0026lt; *dit \u0026lt;\u0026lt; \u0026#34; \u0026#34;; //} //cout \u0026lt;\u0026lt; endl; //排序 sort(d.begin(), d.end()); //去除最高和最低分 d.pop_back(); d.pop_front(); //取平均分 int sum = 0; for (deque\u0026lt;int\u0026gt;::iterator dit = d.begin(); dit != d.end(); dit++) { sum += *dit; //累加每个评委的分数 } int avg = sum / d.size(); //将平均分 赋值给选手身上 it-\u0026gt;m_Score = avg; } } void showScore(vector\u0026lt;Person\u0026gt;\u0026amp;v) { for (vector\u0026lt;Person\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 平均分： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Score \u0026lt;\u0026lt; endl; } } int main() { //随机数种子 srand((unsigned int)time(NULL)); //1、创建5名选手 vector\u0026lt;Person\u0026gt;v; //存放选手容器 createPerson(v); //测试 //for (vector\u0026lt;Person\u0026gt;::iterator it = v.begin(); it != v.end(); it++) //{ //\tcout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; (*it).m_Name \u0026lt;\u0026lt; \u0026#34; 分数： \u0026#34; \u0026lt;\u0026lt; (*it).m_Score \u0026lt;\u0026lt; endl; //} //2、给5名选手打分 setScore(v); //3、显示最后得分 showScore(v); system(\u0026#34;pause\u0026#34;); return 0; } 总结： 选取不同的容器操作数据，可以提升代码的效率\n3.5 stack容器 #\r3.5.1 stack 基本概念 #\r概念：stack是一种先进后出(First In Last Out,FILO)的数据结构，它只有一个出口\n栈中只有顶端的元素才可以被外界使用，因此栈不允许有遍历行为\n栈中进入数据称为 \u0026mdash; 入栈 push\n栈中弹出数据称为 \u0026mdash; 出栈 pop\n生活中的栈：\n3.5.2 stack 常用接口 #\r功能描述：栈容器常用的对外接口\n构造函数：\nstack\u0026lt;T\u0026gt; stk; //stack采用模板类实现， stack对象的默认构造形式 stack(const stack \u0026amp;stk); //拷贝构造函数 赋值操作：\nstack\u0026amp; operator=(const stack \u0026amp;stk); //重载等号操作符 数据存取：\npush(elem); //向栈顶添加元素 pop(); //从栈顶移除第一个元素 top(); //返回栈顶元素 大小操作：\nempty(); //判断堆栈是否为空 size(); //返回栈的大小 示例：\n#include \u0026lt;stack\u0026gt; //栈容器常用接口 void test01() { //创建栈容器 栈容器必须符合先进后出 stack\u0026lt;int\u0026gt; s; //向栈中添加元素，叫做 压栈 入栈 s.push(10); s.push(20); s.push(30); while (!s.empty()) { //输出栈顶元素 cout \u0026lt;\u0026lt; \u0026#34;栈顶元素为： \u0026#34; \u0026lt;\u0026lt; s.top() \u0026lt;\u0026lt; endl; //弹出栈顶元素 s.pop(); } cout \u0026lt;\u0026lt; \u0026#34;栈的大小为：\u0026#34; \u0026lt;\u0026lt; s.size() \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n入栈 \u0026mdash; push 出栈 \u0026mdash; pop 返回栈顶 \u0026mdash; top 判断栈是否为空 \u0026mdash; empty 返回栈大小 \u0026mdash; size 3.6 queue 容器 #\r3.6.1 queue 基本概念 #\r概念：Queue是一种先进先出(First In First Out,FIFO)的数据结构，它有两个出口\n队列容器允许从一端新增元素，从另一端移除元素\n队列中只有队头和队尾才可以被外界使用，因此队列不允许有遍历行为\n队列中进数据称为 \u0026mdash; 入队 push\n队列中出数据称为 \u0026mdash; 出队 pop\n生活中的队列：\n3.6.2 queue 常用接口 #\r功能描述：栈容器常用的对外接口\n构造函数：\nqueue\u0026lt;T\u0026gt; que; //queue采用模板类实现，queue对象的默认构造形式 queue(const queue \u0026amp;que); //拷贝构造函数 赋值操作：\nqueue\u0026amp; operator=(const queue \u0026amp;que); //重载等号操作符 数据存取：\npush(elem); //往队尾添加元素 pop(); //从队头移除第一个元素 back(); //返回最后一个元素 front(); //返回第一个元素 大小操作：\nempty(); //判断堆栈是否为空 size(); //返回栈的大小 示例：\n#include \u0026lt;queue\u0026gt; #include \u0026lt;string\u0026gt; class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } string m_Name; int m_Age; }; void test01() { //创建队列 queue\u0026lt;Person\u0026gt; q; //准备数据 Person p1(\u0026#34;唐僧\u0026#34;, 30); Person p2(\u0026#34;孙悟空\u0026#34;, 1000); Person p3(\u0026#34;猪八戒\u0026#34;, 900); Person p4(\u0026#34;沙僧\u0026#34;, 800); //向队列中添加元素 入队操作 q.push(p1); q.push(p2); q.push(p3); q.push(p4); //队列不提供迭代器，更不支持随机访问\twhile (!q.empty()) { //输出队头元素 cout \u0026lt;\u0026lt; \u0026#34;队头元素-- 姓名： \u0026#34; \u0026lt;\u0026lt; q.front().m_Name \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34;\u0026lt;\u0026lt; q.front().m_Age \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;队尾元素-- 姓名： \u0026#34; \u0026lt;\u0026lt; q.back().m_Name \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; q.back().m_Age \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; endl; //弹出队头元素 q.pop(); } cout \u0026lt;\u0026lt; \u0026#34;队列大小为：\u0026#34; \u0026lt;\u0026lt; q.size() \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n入队 \u0026mdash; push 出队 \u0026mdash; pop 返回队头元素 \u0026mdash; front 返回队尾元素 \u0026mdash; back 判断队是否为空 \u0026mdash; empty 返回队列大小 \u0026mdash; size 3.7 list容器 #\r3.7.1 list基本概念 #\r**功能：**将数据进行链式存储\n链表（list）是一种物理存储单元上非连续的存储结构，数据元素的逻辑顺序是通过链表中的指针链接实现的\n链表的组成：链表由一系列结点组成\n结点的组成：一个是存储数据元素的数据域，另一个是存储下一个结点地址的指针域\nSTL中的链表是一个双向循环链表\n由于链表的存储方式并不是连续的内存空间，因此链表list中的迭代器只支持前移和后移，属于双向迭代器\nlist的优点：\n采用动态存储分配，不会造成内存浪费和溢出 链表执行插入和删除操作十分方便，修改指针即可，不需要移动大量元素 list的缺点：\n链表灵活，但是空间(指针域) 和 时间（遍历）额外耗费较大 List有一个重要的性质，插入操作和删除操作都不会造成原有list迭代器的失效，这在vector是不成立的。\n总结：STL中List和vector是两个最常被使用的容器，各有优缺点\n3.7.2 list构造函数 #\r功能描述：\n创建list容器 函数原型：\nlist\u0026lt;T\u0026gt; lst; //list采用采用模板类实现,对象的默认构造形式： list(beg,end); //构造函数将[beg, end)区间中的元素拷贝给本身。 list(n,elem); //构造函数将n个elem拷贝给本身。 list(const list \u0026amp;lst); //拷贝构造函数。 示例：\n#include \u0026lt;list\u0026gt; void printList(const list\u0026lt;int\u0026gt;\u0026amp; L) { for (list\u0026lt;int\u0026gt;::const_iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } void test01() { list\u0026lt;int\u0026gt;L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); printList(L1); list\u0026lt;int\u0026gt;L2(L1.begin(),L1.end()); printList(L2); list\u0026lt;int\u0026gt;L3(L2); printList(L3); list\u0026lt;int\u0026gt;L4(10, 1000); printList(L4); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：list构造方式同其他几个STL常用容器，熟练掌握即可\n3.7.3 list 赋值和交换 #\r功能描述：\n给list容器进行赋值，以及交换list容器 函数原型：\nassign(beg, end); //将[beg, end)区间中的数据拷贝赋值给本身。 assign(n, elem); //将n个elem拷贝赋值给本身。 list\u0026amp; operator=(const list \u0026amp;lst); //重载等号操作符 swap(lst); //将lst与本身的元素互换。 示例：\n#include \u0026lt;list\u0026gt; void printList(const list\u0026lt;int\u0026gt;\u0026amp; L) { for (list\u0026lt;int\u0026gt;::const_iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //赋值和交换 void test01() { list\u0026lt;int\u0026gt;L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); printList(L1); //赋值 list\u0026lt;int\u0026gt;L2; L2 = L1; printList(L2); list\u0026lt;int\u0026gt;L3; L3.assign(L2.begin(), L2.end()); printList(L3); list\u0026lt;int\u0026gt;L4; L4.assign(10, 100); printList(L4); } //交换 void test02() { list\u0026lt;int\u0026gt;L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); list\u0026lt;int\u0026gt;L2; L2.assign(10, 100); cout \u0026lt;\u0026lt; \u0026#34;交换前： \u0026#34; \u0026lt;\u0026lt; endl; printList(L1); printList(L2); cout \u0026lt;\u0026lt; endl; L1.swap(L2); cout \u0026lt;\u0026lt; \u0026#34;交换后： \u0026#34; \u0026lt;\u0026lt; endl; printList(L1); printList(L2); } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：list赋值和交换操作能够灵活运用即可\n3.7.4 list 大小操作 #\r功能描述：\n对list容器的大小进行操作 函数原型：\nsize(); //返回容器中元素的个数\nempty(); //判断容器是否为空\nresize(num); //重新指定容器的长度为num，若容器变长，则以默认值填充新位置。\n​\t//如果容器变短，则末尾超出容器长度的元素被删除。\nresize(num, elem); //重新指定容器的长度为num，若容器变长，则以elem值填充新位置。\n​\t//如果容器变短，则末尾超出容器长度的元素被删除。\r示例：\n#include \u0026lt;list\u0026gt; void printList(const list\u0026lt;int\u0026gt;\u0026amp; L) { for (list\u0026lt;int\u0026gt;::const_iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //大小操作 void test01() { list\u0026lt;int\u0026gt;L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); if (L1.empty()) { cout \u0026lt;\u0026lt; \u0026#34;L1为空\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;L1不为空\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;L1的大小为： \u0026#34; \u0026lt;\u0026lt; L1.size() \u0026lt;\u0026lt; endl; } //重新指定大小 L1.resize(10); printList(L1); L1.resize(2); printList(L1); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n判断是否为空 \u0026mdash; empty 返回元素个数 \u0026mdash; size 重新指定个数 \u0026mdash; resize 3.7.5 list 插入和删除 #\r功能描述：\n对list容器进行数据的插入和删除 函数原型：\npush_back(elem);//在容器尾部加入一个元素 pop_back();//删除容器中最后一个元素 push_front(elem);//在容器开头插入一个元素 pop_front();//从容器开头移除第一个元素 insert(pos,elem);//在pos位置插elem元素的拷贝，返回新数据的位置。 insert(pos,n,elem);//在pos位置插入n个elem数据，无返回值。 insert(pos,beg,end);//在pos位置插入[beg,end)区间的数据，无返回值。 clear();//移除容器的所有数据 erase(beg,end);//删除[beg,end)区间的数据，返回下一个数据的位置。 erase(pos);//删除pos位置的数据，返回下一个数据的位置。 remove(elem);//删除容器中所有与elem值匹配的元素。 示例：\n#include \u0026lt;list\u0026gt; void printList(const list\u0026lt;int\u0026gt;\u0026amp; L) { for (list\u0026lt;int\u0026gt;::const_iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //插入和删除 void test01() { list\u0026lt;int\u0026gt; L; //尾插 L.push_back(10); L.push_back(20); L.push_back(30); //头插 L.push_front(100); L.push_front(200); L.push_front(300); printList(L); //尾删 L.pop_back(); printList(L); //头删 L.pop_front(); printList(L); //插入 list\u0026lt;int\u0026gt;::iterator it = L.begin(); L.insert(++it, 1000); printList(L); //删除 it = L.begin(); L.erase(++it); printList(L); //移除 L.push_back(10000); L.push_back(10000); L.push_back(10000); printList(L); L.remove(10000); printList(L); //清空 L.clear(); printList(L); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n尾插 \u0026mdash; push_back 尾删 \u0026mdash; pop_back 头插 \u0026mdash; push_front 头删 \u0026mdash; pop_front 插入 \u0026mdash; insert 删除 \u0026mdash; erase 移除 \u0026mdash; remove 清空 \u0026mdash; clear 3.7.6 list 数据存取 #\r功能描述：\n对list容器中数据进行存取 函数原型：\nfront(); //返回第一个元素。 back(); //返回最后一个元素。 示例：\n#include \u0026lt;list\u0026gt; //数据存取 void test01() { list\u0026lt;int\u0026gt;L1; L1.push_back(10); L1.push_back(20); L1.push_back(30); L1.push_back(40); //cout \u0026lt;\u0026lt; L1.at(0) \u0026lt;\u0026lt; endl;//错误 不支持at访问数据 //cout \u0026lt;\u0026lt; L1[0] \u0026lt;\u0026lt; endl; //错误 不支持[]方式访问数据 cout \u0026lt;\u0026lt; \u0026#34;第一个元素为： \u0026#34; \u0026lt;\u0026lt; L1.front() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;最后一个元素为： \u0026#34; \u0026lt;\u0026lt; L1.back() \u0026lt;\u0026lt; endl; //list容器的迭代器是双向迭代器，不支持随机访问 list\u0026lt;int\u0026gt;::iterator it = L1.begin(); //it = it + 1;//错误，不可以跳跃访问，即使是+1 } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\nlist容器中不可以通过[]或者at方式访问数据 返回第一个元素 \u0026mdash; front 返回最后一个元素 \u0026mdash; back 3.7.7 list 反转和排序 #\r功能描述：\n将容器中的元素反转，以及将容器中的数据进行排序 函数原型：\nreverse(); //反转链表 sort(); //链表排序 示例：\nvoid printList(const list\u0026lt;int\u0026gt;\u0026amp; L) { for (list\u0026lt;int\u0026gt;::const_iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } bool myCompare(int val1 , int val2) { return val1 \u0026gt; val2; } //反转和排序 void test01() { list\u0026lt;int\u0026gt; L; L.push_back(90); L.push_back(30); L.push_back(20); L.push_back(70); printList(L); //反转容器的元素 L.reverse(); printList(L); //排序 L.sort(); //默认的排序规则 从小到大 printList(L); L.sort(myCompare); //指定规则，从大到小 printList(L); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n反转 \u0026mdash; reverse 排序 \u0026mdash; sort （成员函数） 3.7.8 排序案例 #\r案例描述：将Person自定义数据类型进行排序，Person中属性有姓名、年龄、身高\n排序规则：按照年龄进行升序，如果年龄相同按照身高进行降序\n示例：\n#include \u0026lt;list\u0026gt; #include \u0026lt;string\u0026gt; class Person { public: Person(string name, int age , int height) { m_Name = name; m_Age = age; m_Height = height; } public: string m_Name; //姓名 int m_Age; //年龄 int m_Height; //身高 }; bool ComparePerson(Person\u0026amp; p1, Person\u0026amp; p2) { if (p1.m_Age == p2.m_Age) { return p1.m_Height \u0026gt; p2.m_Height; } else { return p1.m_Age \u0026lt; p2.m_Age; } } void test01() { list\u0026lt;Person\u0026gt; L; Person p1(\u0026#34;刘备\u0026#34;, 35 , 175); Person p2(\u0026#34;曹操\u0026#34;, 45 , 180); Person p3(\u0026#34;孙权\u0026#34;, 40 , 170); Person p4(\u0026#34;赵云\u0026#34;, 25 , 190); Person p5(\u0026#34;张飞\u0026#34;, 35 , 160); Person p6(\u0026#34;关羽\u0026#34;, 35 , 200); L.push_back(p1); L.push_back(p2); L.push_back(p3); L.push_back(p4); L.push_back(p5); L.push_back(p6); for (list\u0026lt;Person\u0026gt;::iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Age \u0026lt;\u0026lt; \u0026#34; 身高： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Height \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; \u0026#34;---------------------------------\u0026#34; \u0026lt;\u0026lt; endl; L.sort(ComparePerson); //排序 for (list\u0026lt;Person\u0026gt;::iterator it = L.begin(); it != L.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Age \u0026lt;\u0026lt; \u0026#34; 身高： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Height \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n对于自定义数据类型，必须要指定排序规则，否则编译器不知道如何进行排序\n高级排序只是在排序规则上再进行一次逻辑规则制定，并不复杂\n3.8 set/ multiset 容器 #\r3.8.1 set基本概念 #\r简介：\n所有元素都会在插入时自动被排序 本质：\nset/multiset属于关联式容器，底层结构是用二叉树实现。 set和multiset区别：\nset不允许容器中有重复的元素 multiset允许容器中有重复的元素 3.8.2 set构造和赋值 #\r功能描述：创建set容器以及赋值\n构造：\nset\u0026lt;T\u0026gt; st; //默认构造函数： set(const set \u0026amp;st); //拷贝构造函数 赋值：\nset\u0026amp; operator=(const set \u0026amp;st); //重载等号操作符 示例：\n#include \u0026lt;set\u0026gt; void printSet(set\u0026lt;int\u0026gt; \u0026amp; s) { for (set\u0026lt;int\u0026gt;::iterator it = s.begin(); it != s.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //构造和赋值 void test01() { set\u0026lt;int\u0026gt; s1; s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); printSet(s1); //拷贝构造 set\u0026lt;int\u0026gt;s2(s1); printSet(s2); //赋值 set\u0026lt;int\u0026gt;s3; s3 = s2; printSet(s3); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\nset容器插入数据时用insert set容器插入数据的数据会自动排序 3.8.3 set大小和交换 #\r功能描述：\n统计set容器大小以及交换set容器 函数原型：\nsize(); //返回容器中元素的数目 empty(); //判断容器是否为空 swap(st); //交换两个集合容器 示例：\n#include \u0026lt;set\u0026gt; void printSet(set\u0026lt;int\u0026gt; \u0026amp; s) { for (set\u0026lt;int\u0026gt;::iterator it = s.begin(); it != s.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //大小 void test01() { set\u0026lt;int\u0026gt; s1; s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); if (s1.empty()) { cout \u0026lt;\u0026lt; \u0026#34;s1为空\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;s1不为空\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;s1的大小为： \u0026#34; \u0026lt;\u0026lt; s1.size() \u0026lt;\u0026lt; endl; } } //交换 void test02() { set\u0026lt;int\u0026gt; s1; s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); set\u0026lt;int\u0026gt; s2; s2.insert(100); s2.insert(300); s2.insert(200); s2.insert(400); cout \u0026lt;\u0026lt; \u0026#34;交换前\u0026#34; \u0026lt;\u0026lt; endl; printSet(s1); printSet(s2); cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;交换后\u0026#34; \u0026lt;\u0026lt; endl; s1.swap(s2); printSet(s1); printSet(s2); } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n统计大小 \u0026mdash; size 判断是否为空 \u0026mdash; empty 交换容器 \u0026mdash; swap 3.8.4 set插入和删除 #\r功能描述：\nset容器进行插入数据和删除数据 函数原型：\ninsert(elem); //在容器中插入元素。 clear(); //清除所有元素 erase(pos); //删除pos迭代器所指的元素，返回下一个元素的迭代器。 erase(beg, end); //删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。 erase(elem); //删除容器中值为elem的元素。 示例：\n#include \u0026lt;set\u0026gt; void printSet(set\u0026lt;int\u0026gt; \u0026amp; s) { for (set\u0026lt;int\u0026gt;::iterator it = s.begin(); it != s.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } //插入和删除 void test01() { set\u0026lt;int\u0026gt; s1; //插入 s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); printSet(s1); //删除 s1.erase(s1.begin()); printSet(s1); s1.erase(30); printSet(s1); //清空 //s1.erase(s1.begin(), s1.end()); s1.clear(); printSet(s1); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n插入 \u0026mdash; insert 删除 \u0026mdash; erase 清空 \u0026mdash; clear 3.8.5 set查找和统计 #\r功能描述：\n对set容器进行查找数据以及统计数据 函数原型：\nfind(key); //查找key是否存在,若存在，返回该键的元素的迭代器；若不存在，返回set.end(); count(key); //统计key的元素个数 示例：\n#include \u0026lt;set\u0026gt; //查找和统计 void test01() { set\u0026lt;int\u0026gt; s1; //插入 s1.insert(10); s1.insert(30); s1.insert(20); s1.insert(40); //查找 set\u0026lt;int\u0026gt;::iterator pos = s1.find(30); if (pos != s1.end()) { cout \u0026lt;\u0026lt; \u0026#34;找到了元素 ： \u0026#34; \u0026lt;\u0026lt; *pos \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;未找到元素\u0026#34; \u0026lt;\u0026lt; endl; } //统计 int num = s1.count(30); cout \u0026lt;\u0026lt; \u0026#34;num = \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n查找 \u0026mdash; find （返回的是迭代器） 统计 \u0026mdash; count （对于set，结果为0或者1） 3.8.6 set和multiset区别 #\r学习目标：\n掌握set和multiset的区别 区别：\nset不可以插入重复数据，而multiset可以 set插入数据的同时会返回插入结果，表示插入是否成功 multiset不会检测数据，因此可以插入重复数据 示例：\n#include \u0026lt;set\u0026gt; //set和multiset区别 void test01() { set\u0026lt;int\u0026gt; s; pair\u0026lt;set\u0026lt;int\u0026gt;::iterator, bool\u0026gt; ret = s.insert(10); if (ret.second) { cout \u0026lt;\u0026lt; \u0026#34;第一次插入成功!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;第一次插入失败!\u0026#34; \u0026lt;\u0026lt; endl; } ret = s.insert(10); if (ret.second) { cout \u0026lt;\u0026lt; \u0026#34;第二次插入成功!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;第二次插入失败!\u0026#34; \u0026lt;\u0026lt; endl; } //multiset multiset\u0026lt;int\u0026gt; ms; ms.insert(10); ms.insert(10); for (multiset\u0026lt;int\u0026gt;::iterator it = ms.begin(); it != ms.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n如果不允许插入重复数据可以利用set 如果需要插入重复数据利用multiset 3.8.7 pair对组创建 #\r功能描述：\n成对出现的数据，利用对组可以返回两个数据 两种创建方式：\npair\u0026lt;type, type\u0026gt; p ( value1, value2 ); pair\u0026lt;type, type\u0026gt; p = make_pair( value1, value2 ); 示例：\n#include \u0026lt;string\u0026gt; //对组创建 void test01() { pair\u0026lt;string, int\u0026gt; p(string(\u0026#34;Tom\u0026#34;), 20); cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; p.first \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; p.second \u0026lt;\u0026lt; endl; pair\u0026lt;string, int\u0026gt; p2 = make_pair(\u0026#34;Jerry\u0026#34;, 10); cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; p2.first \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; p2.second \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n两种方式都可以创建对组，记住一种即可\n3.8.8 set容器排序 #\r学习目标：\nset容器默认排序规则为从小到大，掌握如何改变排序规则 主要技术点：\n利用仿函数，可以改变排序规则 示例一 set存放内置数据类型\n#include \u0026lt;set\u0026gt; class MyCompare { public: bool operator()(int v1, int v2) { return v1 \u0026gt; v2; } }; void test01() { set\u0026lt;int\u0026gt; s1; s1.insert(10); s1.insert(40); s1.insert(20); s1.insert(30); s1.insert(50); //默认从小到大 for (set\u0026lt;int\u0026gt;::iterator it = s1.begin(); it != s1.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; //指定排序规则 set\u0026lt;int,MyCompare\u0026gt; s2; s2.insert(10); s2.insert(40); s2.insert(20); s2.insert(30); s2.insert(50); for (set\u0026lt;int, MyCompare\u0026gt;::iterator it = s2.begin(); it != s2.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：利用仿函数可以指定set容器的排序规则\n示例二 set存放自定义数据类型\n#include \u0026lt;set\u0026gt; #include \u0026lt;string\u0026gt; class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } string m_Name; int m_Age; }; class comparePerson { public: bool operator()(const Person\u0026amp; p1, const Person \u0026amp;p2) { //按照年龄进行排序 降序 return p1.m_Age \u0026gt; p2.m_Age; } }; void test01() { set\u0026lt;Person, comparePerson\u0026gt; s; Person p1(\u0026#34;刘备\u0026#34;, 23); Person p2(\u0026#34;关羽\u0026#34;, 27); Person p3(\u0026#34;张飞\u0026#34;, 25); Person p4(\u0026#34;赵云\u0026#34;, 21); s.insert(p1); s.insert(p2); s.insert(p3); s.insert(p4); for (set\u0026lt;Person, comparePerson\u0026gt;::iterator it = s.begin(); it != s.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Age \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n对于自定义数据类型，set必须指定排序规则才可以插入数据\n3.9 map/ multimap容器 #\r3.9.1 map基本概念 #\r简介：\nmap中所有元素都是pair pair中第一个元素为key（键值），起到索引作用，第二个元素为value（实值） 所有元素都会根据元素的键值自动排序 本质：\nmap/multimap属于关联式容器，底层结构是用二叉树实现。 优点：\n可以根据key值快速找到value值 map和multimap区别：\nmap不允许容器中有重复key值元素 multimap允许容器中有重复key值元素 3.9.2 map构造和赋值 #\r功能描述：\n对map容器进行构造和赋值操作 函数原型：\n构造：\nmap\u0026lt;T1, T2\u0026gt; mp; //map默认构造函数: map(const map \u0026amp;mp); //拷贝构造函数 赋值：\nmap\u0026amp; operator=(const map \u0026amp;mp); //重载等号操作符 示例：\n#include \u0026lt;map\u0026gt; void printMap(map\u0026lt;int,int\u0026gt;\u0026amp;m) { for (map\u0026lt;int, int\u0026gt;::iterator it = m.begin(); it != m.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;key = \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;first \u0026lt;\u0026lt; \u0026#34; value = \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;second \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; } void test01() { map\u0026lt;int,int\u0026gt;m; //默认构造 m.insert(pair\u0026lt;int, int\u0026gt;(1, 10)); m.insert(pair\u0026lt;int, int\u0026gt;(2, 20)); m.insert(pair\u0026lt;int, int\u0026gt;(3, 30)); printMap(m); map\u0026lt;int, int\u0026gt;m2(m); //拷贝构造 printMap(m2); map\u0026lt;int, int\u0026gt;m3; m3 = m2; //赋值 printMap(m3); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：map中所有元素都是成对出现，插入数据时候要使用对组\n3.9.3 map大小和交换 #\r功能描述：\n统计map容器大小以及交换map容器 函数原型：\nsize(); //返回容器中元素的数目 empty(); //判断容器是否为空 swap(st); //交换两个集合容器 示例：\n#include \u0026lt;map\u0026gt; void printMap(map\u0026lt;int,int\u0026gt;\u0026amp;m) { for (map\u0026lt;int, int\u0026gt;::iterator it = m.begin(); it != m.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;key = \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;first \u0026lt;\u0026lt; \u0026#34; value = \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;second \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; } void test01() { map\u0026lt;int, int\u0026gt;m; m.insert(pair\u0026lt;int, int\u0026gt;(1, 10)); m.insert(pair\u0026lt;int, int\u0026gt;(2, 20)); m.insert(pair\u0026lt;int, int\u0026gt;(3, 30)); if (m.empty()) { cout \u0026lt;\u0026lt; \u0026#34;m为空\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;m不为空\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;m的大小为： \u0026#34; \u0026lt;\u0026lt; m.size() \u0026lt;\u0026lt; endl; } } //交换 void test02() { map\u0026lt;int, int\u0026gt;m; m.insert(pair\u0026lt;int, int\u0026gt;(1, 10)); m.insert(pair\u0026lt;int, int\u0026gt;(2, 20)); m.insert(pair\u0026lt;int, int\u0026gt;(3, 30)); map\u0026lt;int, int\u0026gt;m2; m2.insert(pair\u0026lt;int, int\u0026gt;(4, 100)); m2.insert(pair\u0026lt;int, int\u0026gt;(5, 200)); m2.insert(pair\u0026lt;int, int\u0026gt;(6, 300)); cout \u0026lt;\u0026lt; \u0026#34;交换前\u0026#34; \u0026lt;\u0026lt; endl; printMap(m); printMap(m2); cout \u0026lt;\u0026lt; \u0026#34;交换后\u0026#34; \u0026lt;\u0026lt; endl; m.swap(m2); printMap(m); printMap(m2); } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n统计大小 \u0026mdash; size 判断是否为空 \u0026mdash; empty 交换容器 \u0026mdash; swap 3.9.4 map插入和删除 #\r功能描述：\nmap容器进行插入数据和删除数据 函数原型：\ninsert(elem); //在容器中插入元素。 clear(); //清除所有元素 erase(pos); //删除pos迭代器所指的元素，返回下一个元素的迭代器。 erase(beg, end); //删除区间[beg,end)的所有元素 ，返回下一个元素的迭代器。 erase(key); //删除容器中值为key的元素。 示例：\n#include \u0026lt;map\u0026gt; void printMap(map\u0026lt;int,int\u0026gt;\u0026amp;m) { for (map\u0026lt;int, int\u0026gt;::iterator it = m.begin(); it != m.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;key = \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;first \u0026lt;\u0026lt; \u0026#34; value = \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;second \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; } void test01() { //插入 map\u0026lt;int, int\u0026gt; m; //第一种插入方式 m.insert(pair\u0026lt;int, int\u0026gt;(1, 10)); //第二种插入方式 m.insert(make_pair(2, 20)); //第三种插入方式 m.insert(map\u0026lt;int, int\u0026gt;::value_type(3, 30)); //第四种插入方式 m[4] = 40; printMap(m); //删除 m.erase(m.begin()); printMap(m); m.erase(3); printMap(m); //清空 m.erase(m.begin(),m.end()); m.clear(); printMap(m); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\nmap插入方式很多，记住其一即可 插入 \u0026mdash; insert 删除 \u0026mdash; erase 清空 \u0026mdash; clear 3.9.5 map查找和统计 #\r功能描述：\n对map容器进行查找数据以及统计数据 函数原型：\nfind(key); //查找key是否存在,若存在，返回该键的元素的迭代器；若不存在，返回set.end(); count(key); //统计key的元素个数 示例：\n#include \u0026lt;map\u0026gt; //查找和统计 void test01() { map\u0026lt;int, int\u0026gt;m; m.insert(pair\u0026lt;int, int\u0026gt;(1, 10)); m.insert(pair\u0026lt;int, int\u0026gt;(2, 20)); m.insert(pair\u0026lt;int, int\u0026gt;(3, 30)); //查找 map\u0026lt;int, int\u0026gt;::iterator pos = m.find(3); if (pos != m.end()) { cout \u0026lt;\u0026lt; \u0026#34;找到了元素 key = \u0026#34; \u0026lt;\u0026lt; (*pos).first \u0026lt;\u0026lt; \u0026#34; value = \u0026#34; \u0026lt;\u0026lt; (*pos).second \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;未找到元素\u0026#34; \u0026lt;\u0026lt; endl; } //统计 int num = m.count(3); cout \u0026lt;\u0026lt; \u0026#34;num = \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n查找 \u0026mdash; find （返回的是迭代器） 统计 \u0026mdash; count （对于map，结果为0或者1） 3.9.6 map容器排序 #\r学习目标：\nmap容器默认排序规则为 按照key值进行 从小到大排序，掌握如何改变排序规则 主要技术点:\n利用仿函数，可以改变排序规则 示例：\n#include \u0026lt;map\u0026gt; class MyCompare { public: bool operator()(int v1, int v2) { return v1 \u0026gt; v2; } }; void test01() { //默认从小到大排序 //利用仿函数实现从大到小排序 map\u0026lt;int, int, MyCompare\u0026gt; m; m.insert(make_pair(1, 10)); m.insert(make_pair(2, 20)); m.insert(make_pair(3, 30)); m.insert(make_pair(4, 40)); m.insert(make_pair(5, 50)); for (map\u0026lt;int, int, MyCompare\u0026gt;::iterator it = m.begin(); it != m.end(); it++) { cout \u0026lt;\u0026lt; \u0026#34;key:\u0026#34; \u0026lt;\u0026lt; it-\u0026gt;first \u0026lt;\u0026lt; \u0026#34; value:\u0026#34; \u0026lt;\u0026lt; it-\u0026gt;second \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n利用仿函数可以指定map容器的排序规则 对于自定义数据类型，map必须要指定排序规则,同set容器 3.10 案例-员工分组 #\r3.10.1 案例描述 #\r公司今天招聘了10个员工（ABCDEFGHIJ），10名员工进入公司之后，需要指派员工在那个部门工作 员工信息有: 姓名 工资组成；部门分为：策划、美术、研发 随机给10名员工分配部门和工资 通过multimap进行信息的插入 key(部门编号) value(员工) 分部门显示员工信息 3.10.2 实现步骤 #\r创建10名员工，放到vector中 遍历vector容器，取出每个员工，进行随机分组 分组后，将员工部门编号作为key，具体员工作为value，放入到multimap容器中 分部门显示员工信息 案例代码：\n#include\u0026lt;iostream\u0026gt; using namespace std; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;ctime\u0026gt; /* - 公司今天招聘了10个员工（ABCDEFGHIJ），10名员工进入公司之后，需要指派员工在那个部门工作 - 员工信息有: 姓名 工资组成；部门分为：策划、美术、研发 - 随机给10名员工分配部门和工资 - 通过multimap进行信息的插入 key(部门编号) value(员工) - 分部门显示员工信息 */ #define CEHUA 0 #define MEISHU 1 #define YANFA 2 class Worker { public: string m_Name; int m_Salary; }; void createWorker(vector\u0026lt;Worker\u0026gt;\u0026amp;v) { string nameSeed = \u0026#34;ABCDEFGHIJ\u0026#34;; for (int i = 0; i \u0026lt; 10; i++) { Worker worker; worker.m_Name = \u0026#34;员工\u0026#34;; worker.m_Name += nameSeed[i]; worker.m_Salary = rand() % 10000 + 10000; // 10000 ~ 19999 //将员工放入到容器中 v.push_back(worker); } } //员工分组 void setGroup(vector\u0026lt;Worker\u0026gt;\u0026amp;v,multimap\u0026lt;int,Worker\u0026gt;\u0026amp;m) { for (vector\u0026lt;Worker\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { //产生随机部门编号 int deptId = rand() % 3; // 0 1 2 //将员工插入到分组中 //key部门编号，value具体员工 m.insert(make_pair(deptId, *it)); } } void showWorkerByGourp(multimap\u0026lt;int,Worker\u0026gt;\u0026amp;m) { // 0 A B C 1 D E 2 F G ... cout \u0026lt;\u0026lt; \u0026#34;策划部门：\u0026#34; \u0026lt;\u0026lt; endl; multimap\u0026lt;int,Worker\u0026gt;::iterator pos = m.find(CEHUA); int count = m.count(CEHUA); // 统计具体人数 int index = 0; for (; pos != m.end() \u0026amp;\u0026amp; index \u0026lt; count; pos++ , index++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; pos-\u0026gt;second.m_Name \u0026lt;\u0026lt; \u0026#34; 工资： \u0026#34; \u0026lt;\u0026lt; pos-\u0026gt;second.m_Salary \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; \u0026#34;----------------------\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;美术部门： \u0026#34; \u0026lt;\u0026lt; endl; pos = m.find(MEISHU); count = m.count(MEISHU); // 统计具体人数 index = 0; for (; pos != m.end() \u0026amp;\u0026amp; index \u0026lt; count; pos++, index++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; pos-\u0026gt;second.m_Name \u0026lt;\u0026lt; \u0026#34; 工资： \u0026#34; \u0026lt;\u0026lt; pos-\u0026gt;second.m_Salary \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; \u0026#34;----------------------\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;研发部门： \u0026#34; \u0026lt;\u0026lt; endl; pos = m.find(YANFA); count = m.count(YANFA); // 统计具体人数 index = 0; for (; pos != m.end() \u0026amp;\u0026amp; index \u0026lt; count; pos++, index++) { cout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; pos-\u0026gt;second.m_Name \u0026lt;\u0026lt; \u0026#34; 工资： \u0026#34; \u0026lt;\u0026lt; pos-\u0026gt;second.m_Salary \u0026lt;\u0026lt; endl; } } int main() { srand((unsigned int)time(NULL)); //1、创建员工 vector\u0026lt;Worker\u0026gt;vWorker; createWorker(vWorker); //2、员工分组 multimap\u0026lt;int, Worker\u0026gt;mWorker; setGroup(vWorker, mWorker); //3、分组显示员工 showWorkerByGourp(mWorker); ////测试 //for (vector\u0026lt;Worker\u0026gt;::iterator it = vWorker.begin(); it != vWorker.end(); it++) //{ //\tcout \u0026lt;\u0026lt; \u0026#34;姓名： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 工资： \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Salary \u0026lt;\u0026lt; endl; //} system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n当数据以键值对形式存在，可以考虑用map 或 multimap 4 STL- 函数对象 #\r4.1 函数对象 #\r4.1.1 函数对象概念 #\r概念：\n重载函数调用操作符的类，其对象常称为函数对象 函数对象使用重载的()时，行为类似函数调用，也叫仿函数 本质：\n函数对象(仿函数)是一个类，不是一个函数\n4.1.2 函数对象使用 #\r特点：\n函数对象在使用时，可以像普通函数那样调用, 可以有参数，可以有返回值 函数对象超出普通函数的概念，函数对象可以有自己的状态 函数对象可以作为参数传递 示例:\n#include \u0026lt;string\u0026gt; //1、函数对象在使用时，可以像普通函数那样调用, 可以有参数，可以有返回值 class MyAdd { public : int operator()(int v1,int v2) { return v1 + v2; } }; void test01() { MyAdd myAdd; cout \u0026lt;\u0026lt; myAdd(10, 10) \u0026lt;\u0026lt; endl; } //2、函数对象可以有自己的状态 class MyPrint { public: MyPrint() { count = 0; } void operator()(string test) { cout \u0026lt;\u0026lt; test \u0026lt;\u0026lt; endl; count++; //统计使用次数 } int count; //内部自己的状态 }; void test02() { MyPrint myPrint; myPrint(\u0026#34;hello world\u0026#34;); myPrint(\u0026#34;hello world\u0026#34;); myPrint(\u0026#34;hello world\u0026#34;); cout \u0026lt;\u0026lt; \u0026#34;myPrint调用次数为： \u0026#34; \u0026lt;\u0026lt; myPrint.count \u0026lt;\u0026lt; endl; } //3、函数对象可以作为参数传递 void doPrint(MyPrint \u0026amp;mp , string test) { mp(test); } void test03() { MyPrint myPrint; doPrint(myPrint, \u0026#34;Hello C++\u0026#34;); } int main() { //test01(); //test02(); test03(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n仿函数写法非常灵活，可以作为参数进行传递。 4.2 谓词 #\r4.2.1 谓词概念 #\r概念：\n返回bool类型的仿函数称为谓词 如果operator()接受一个参数，那么叫做一元谓词 如果operator()接受两个参数，那么叫做二元谓词 4.2.2 一元谓词 #\r示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; //1.一元谓词 struct GreaterFive{ bool operator()(int val) { return val \u0026gt; 5; } }; void test01() { vector\u0026lt;int\u0026gt; v; for (int i = 0; i \u0026lt; 10; i++) { v.push_back(i); } vector\u0026lt;int\u0026gt;::iterator it = find_if(v.begin(), v.end(), GreaterFive()); if (it == v.end()) { cout \u0026lt;\u0026lt; \u0026#34;没找到!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;找到:\u0026#34; \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：参数只有一个的谓词，称为一元谓词\n4.2.3 二元谓词 #\r示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; //二元谓词 class MyCompare { public: bool operator()(int num1, int num2) { return num1 \u0026gt; num2; } }; void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(10); v.push_back(40); v.push_back(20); v.push_back(30); v.push_back(50); //默认从小到大 sort(v.begin(), v.end()); for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;----------------------------\u0026#34; \u0026lt;\u0026lt; endl; //使用函数对象改变算法策略，排序从大到小 sort(v.begin(), v.end(), MyCompare()); for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：参数只有两个的谓词，称为二元谓词\n4.3 内建函数对象 #\r4.3.1 内建函数对象意义 #\r概念：\nSTL内建了一些函数对象 分类:\n算术仿函数\n关系仿函数\n逻辑仿函数\n用法：\n这些仿函数所产生的对象，用法和一般函数完全相同 使用内建函数对象，需要引入头文件 #include\u0026lt;functional\u0026gt; 4.3.2 算术仿函数 #\r功能描述：\n实现四则运算 其中negate是一元运算，其他都是二元运算 仿函数原型：\ntemplate\u0026lt;class T\u0026gt; T plus\u0026lt;T\u0026gt; //加法仿函数 template\u0026lt;class T\u0026gt; T minus\u0026lt;T\u0026gt; //减法仿函数 template\u0026lt;class T\u0026gt; T multiplies\u0026lt;T\u0026gt; //乘法仿函数 template\u0026lt;class T\u0026gt; T divides\u0026lt;T\u0026gt; //除法仿函数 template\u0026lt;class T\u0026gt; T modulus\u0026lt;T\u0026gt; //取模仿函数 template\u0026lt;class T\u0026gt; T negate\u0026lt;T\u0026gt; //取反仿函数 示例：\n#include \u0026lt;functional\u0026gt; //negate void test01() { negate\u0026lt;int\u0026gt; n; cout \u0026lt;\u0026lt; n(50) \u0026lt;\u0026lt; endl; } //plus void test02() { plus\u0026lt;int\u0026gt; p; cout \u0026lt;\u0026lt; p(10, 20) \u0026lt;\u0026lt; endl; } int main() { test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：使用内建函数对象时，需要引入头文件 #include \u0026lt;functional\u0026gt;\n4.3.3 关系仿函数 #\r功能描述：\n实现关系对比 仿函数原型：\ntemplate\u0026lt;class T\u0026gt; bool equal_to\u0026lt;T\u0026gt; //等于 template\u0026lt;class T\u0026gt; bool not_equal_to\u0026lt;T\u0026gt; //不等于 template\u0026lt;class T\u0026gt; bool greater\u0026lt;T\u0026gt; //大于 template\u0026lt;class T\u0026gt; bool greater_equal\u0026lt;T\u0026gt; //大于等于 template\u0026lt;class T\u0026gt; bool less\u0026lt;T\u0026gt; //小于 template\u0026lt;class T\u0026gt; bool less_equal\u0026lt;T\u0026gt; //小于等于 示例：\n#include \u0026lt;functional\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; class MyCompare { public: bool operator()(int v1,int v2) { return v1 \u0026gt; v2; } }; void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(10); v.push_back(30); v.push_back(50); v.push_back(40); v.push_back(20); for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; //自己实现仿函数 //sort(v.begin(), v.end(), MyCompare()); //STL内建仿函数 大于仿函数 sort(v.begin(), v.end(), greater\u0026lt;int\u0026gt;()); for (vector\u0026lt;int\u0026gt;::iterator it = v.begin(); it != v.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：关系仿函数中最常用的就是greater\u0026lt;\u0026gt;大于\n4.3.4 逻辑仿函数 #\r功能描述：\n实现逻辑运算 函数原型：\ntemplate\u0026lt;class T\u0026gt; bool logical_and\u0026lt;T\u0026gt; //逻辑与 template\u0026lt;class T\u0026gt; bool logical_or\u0026lt;T\u0026gt; //逻辑或 template\u0026lt;class T\u0026gt; bool logical_not\u0026lt;T\u0026gt; //逻辑非 示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;algorithm\u0026gt; void test01() { vector\u0026lt;bool\u0026gt; v; v.push_back(true); v.push_back(false); v.push_back(true); v.push_back(false); for (vector\u0026lt;bool\u0026gt;::iterator it = v.begin();it!= v.end();it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; //逻辑非 将v容器搬运到v2中，并执行逻辑非运算 vector\u0026lt;bool\u0026gt; v2; v2.resize(v.size()); transform(v.begin(), v.end(), v2.begin(), logical_not\u0026lt;bool\u0026gt;()); for (vector\u0026lt;bool\u0026gt;::iterator it = v2.begin(); it != v2.end(); it++) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：逻辑仿函数实际应用较少，了解即可\n5 STL- 常用算法 #\r概述:\n算法主要是由头文件\u0026lt;algorithm\u0026gt; \u0026lt;functional\u0026gt; \u0026lt;numeric\u0026gt;组成。\n\u0026lt;algorithm\u0026gt;是所有STL头文件中最大的一个，范围涉及到比较、 交换、查找、遍历操作、复制、修改等等\n\u0026lt;numeric\u0026gt;体积很小，只包括几个在序列上面进行简单数学运算的模板函数\n\u0026lt;functional\u0026gt;定义了一些模板类,用以声明函数对象。\n5.1 常用遍历算法 #\r学习目标：\n掌握常用的遍历算法 算法简介：\nfor_each //遍历容器 transform //搬运容器到另一个容器中 5.1.1 for_each #\r功能描述：\n实现遍历容器 函数原型：\nfor_each(iterator beg, iterator end, _func); // 遍历算法 遍历容器元素\n// beg 开始迭代器\n// end 结束迭代器\n// _func 函数或者函数对象\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; //普通函数 void print01(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } //函数对象 class print02 { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; //for_each算法基本用法 void test01() { vector\u0026lt;int\u0026gt; v; for (int i = 0; i \u0026lt; 10; i++) { v.push_back(i); } //遍历算法 for_each(v.begin(), v.end(), print01); cout \u0026lt;\u0026lt; endl; for_each(v.begin(), v.end(), print02()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**for_each在实际开发中是最常用遍历算法，需要熟练掌握\n5.1.2 transform #\r功能描述：\n搬运容器到另一个容器中 函数原型：\ntransform(iterator beg1, iterator end1, iterator beg2, _func); //beg1 源容器开始迭代器\n//end1 源容器结束迭代器\n//beg2 目标容器开始迭代器\n//_func 函数或者函数对象\n示例：\n#include\u0026lt;vector\u0026gt; #include\u0026lt;algorithm\u0026gt; //常用遍历算法 搬运 transform class TransForm { public: int operator()(int val) { return val; } }; class MyPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt;v; for (int i = 0; i \u0026lt; 10; i++) { v.push_back(i); } vector\u0026lt;int\u0026gt;vTarget; //目标容器 vTarget.resize(v.size()); // 目标容器需要提前开辟空间 transform(v.begin(), v.end(), vTarget.begin(), TransForm()); for_each(vTarget.begin(), vTarget.end(), MyPrint()); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结： 搬运的目标容器必须要提前开辟空间，否则无法正常搬运\n5.2 常用查找算法 #\r学习目标：\n掌握常用的查找算法 算法简介：\nfind //查找元素 find_if //按条件查找元素 adjacent_find //查找相邻重复元素 binary_search //二分查找法 count //统计元素个数 count_if //按条件统计元素个数 5.2.1 find #\r功能描述：\n查找指定元素，找到返回指定元素的迭代器，找不到返回结束迭代器end() 函数原型：\nfind(iterator beg, iterator end, value); // 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置\n// beg 开始迭代器\n// end 结束迭代器\n// value 查找的元素\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; void test01() { vector\u0026lt;int\u0026gt; v; for (int i = 0; i \u0026lt; 10; i++) { v.push_back(i + 1); } //查找容器中是否有 5 这个元素 vector\u0026lt;int\u0026gt;::iterator it = find(v.begin(), v.end(), 5); if (it == v.end()) { cout \u0026lt;\u0026lt; \u0026#34;没有找到!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;找到:\u0026#34; \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } } class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } //重载== bool operator==(const Person\u0026amp; p) { if (this-\u0026gt;m_Name == p.m_Name \u0026amp;\u0026amp; this-\u0026gt;m_Age == p.m_Age) { return true; } return false; } public: string m_Name; int m_Age; }; void test02() { vector\u0026lt;Person\u0026gt; v; //创建数据 Person p1(\u0026#34;aaa\u0026#34;, 10); Person p2(\u0026#34;bbb\u0026#34;, 20); Person p3(\u0026#34;ccc\u0026#34;, 30); Person p4(\u0026#34;ddd\u0026#34;, 40); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); vector\u0026lt;Person\u0026gt;::iterator it = find(v.begin(), v.end(), p2); if (it == v.end()) { cout \u0026lt;\u0026lt; \u0026#34;没有找到!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;找到姓名:\u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄: \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Age \u0026lt;\u0026lt; endl; } } 总结： 利用find可以在容器中找指定的元素，返回值是迭代器\n5.2.2 find_if #\r功能描述：\n按条件查找元素 函数原型：\nfind_if(iterator beg, iterator end, _Pred); // 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置\n// beg 开始迭代器\n// end 结束迭代器\n// _Pred 函数或者谓词（返回bool类型的仿函数）\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; //内置数据类型 class GreaterFive { public: bool operator()(int val) { return val \u0026gt; 5; } }; void test01() { vector\u0026lt;int\u0026gt; v; for (int i = 0; i \u0026lt; 10; i++) { v.push_back(i + 1); } vector\u0026lt;int\u0026gt;::iterator it = find_if(v.begin(), v.end(), GreaterFive()); if (it == v.end()) { cout \u0026lt;\u0026lt; \u0026#34;没有找到!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;找到大于5的数字:\u0026#34; \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } } //自定义数据类型 class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } public: string m_Name; int m_Age; }; class Greater20 { public: bool operator()(Person \u0026amp;p) { return p.m_Age \u0026gt; 20; } }; void test02() { vector\u0026lt;Person\u0026gt; v; //创建数据 Person p1(\u0026#34;aaa\u0026#34;, 10); Person p2(\u0026#34;bbb\u0026#34;, 20); Person p3(\u0026#34;ccc\u0026#34;, 30); Person p4(\u0026#34;ddd\u0026#34;, 40); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); vector\u0026lt;Person\u0026gt;::iterator it = find_if(v.begin(), v.end(), Greater20()); if (it == v.end()) { cout \u0026lt;\u0026lt; \u0026#34;没有找到!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;找到姓名:\u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Name \u0026lt;\u0026lt; \u0026#34; 年龄: \u0026#34; \u0026lt;\u0026lt; it-\u0026gt;m_Age \u0026lt;\u0026lt; endl; } } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：find_if按条件查找使查找更加灵活，提供的仿函数可以改变不同的策略\n5.2.3 adjacent_find #\r功能描述：\n查找相邻重复元素 函数原型：\nadjacent_find(iterator beg, iterator end); // 查找相邻重复元素,返回相邻元素的第一个位置的迭代器\n// beg 开始迭代器\n// end 结束迭代器\n​\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(1); v.push_back(2); v.push_back(5); v.push_back(2); v.push_back(4); v.push_back(4); v.push_back(3); //查找相邻重复元素 vector\u0026lt;int\u0026gt;::iterator it = adjacent_find(v.begin(), v.end()); if (it == v.end()) { cout \u0026lt;\u0026lt; \u0026#34;找不到!\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;找到相邻重复元素为:\u0026#34; \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; } } 总结：面试题中如果出现查找相邻重复元素，记得用STL中的adjacent_find算法\n5.2.4 binary_search #\r功能描述：\n查找指定元素是否存在 函数原型：\nbool binary_search(iterator beg, iterator end, value); // 查找指定的元素，查到 返回true 否则false\n// 注意: 在无序序列中不可用\n// beg 开始迭代器\n// end 结束迭代器\n// value 查找的元素\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; void test01() { vector\u0026lt;int\u0026gt;v; for (int i = 0; i \u0026lt; 10; i++) { v.push_back(i); } //二分查找 bool ret = binary_search(v.begin(), v.end(),2); if (ret) { cout \u0026lt;\u0026lt; \u0026#34;找到了\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;未找到\u0026#34; \u0026lt;\u0026lt; endl; } } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**二分查找法查找效率很高，值得注意的是查找的容器中元素必须的有序序列\n5.2.5 count #\r功能描述：\n统计元素个数 函数原型：\ncount(iterator beg, iterator end, value); // 统计元素出现次数\n// beg 开始迭代器\n// end 结束迭代器\n// value 统计的元素\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; //内置数据类型 void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(1); v.push_back(2); v.push_back(4); v.push_back(5); v.push_back(3); v.push_back(4); v.push_back(4); int num = count(v.begin(), v.end(), 4); cout \u0026lt;\u0026lt; \u0026#34;4的个数为： \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } //自定义数据类型 class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } bool operator==(const Person \u0026amp; p) { if (this-\u0026gt;m_Age == p.m_Age) { return true; } else { return false; } } string m_Name; int m_Age; }; void test02() { vector\u0026lt;Person\u0026gt; v; Person p1(\u0026#34;刘备\u0026#34;, 35); Person p2(\u0026#34;关羽\u0026#34;, 35); Person p3(\u0026#34;张飞\u0026#34;, 35); Person p4(\u0026#34;赵云\u0026#34;, 30); Person p5(\u0026#34;曹操\u0026#34;, 25); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); v.push_back(p5); Person p(\u0026#34;诸葛亮\u0026#34;,35); int num = count(v.begin(), v.end(), p); cout \u0026lt;\u0026lt; \u0026#34;num = \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } 总结： 统计自定义数据类型时候，需要配合重载 operator==\n5.2.6 count_if #\r功能描述：\n按条件统计元素个数 函数原型：\ncount_if(iterator beg, iterator end, _Pred); // 按条件统计元素出现次数\n// beg 开始迭代器\n// end 结束迭代器\n// _Pred 谓词\n​\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class Greater4 { public: bool operator()(int val) { return val \u0026gt;= 4; } }; //内置数据类型 void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(1); v.push_back(2); v.push_back(4); v.push_back(5); v.push_back(3); v.push_back(4); v.push_back(4); int num = count_if(v.begin(), v.end(), Greater4()); cout \u0026lt;\u0026lt; \u0026#34;大于4的个数为： \u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } //自定义数据类型 class Person { public: Person(string name, int age) { this-\u0026gt;m_Name = name; this-\u0026gt;m_Age = age; } string m_Name; int m_Age; }; class AgeLess35 { public: bool operator()(const Person \u0026amp;p) { return p.m_Age \u0026lt; 35; } }; void test02() { vector\u0026lt;Person\u0026gt; v; Person p1(\u0026#34;刘备\u0026#34;, 35); Person p2(\u0026#34;关羽\u0026#34;, 35); Person p3(\u0026#34;张飞\u0026#34;, 35); Person p4(\u0026#34;赵云\u0026#34;, 30); Person p5(\u0026#34;曹操\u0026#34;, 25); v.push_back(p1); v.push_back(p2); v.push_back(p3); v.push_back(p4); v.push_back(p5); int num = count_if(v.begin(), v.end(), AgeLess35()); cout \u0026lt;\u0026lt; \u0026#34;小于35岁的个数：\u0026#34; \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; } int main() { //test01(); test02(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**按值统计用count，按条件统计用count_if\n5.3 常用排序算法 #\r学习目标：\n掌握常用的排序算法 算法简介：\nsort //对容器内元素进行排序 random_shuffle //洗牌 指定范围内的元素随机调整次序 merge // 容器元素合并，并存储到另一容器中 reverse // 反转指定范围的元素 5.3.1 sort #\r功能描述：\n对容器内元素进行排序 函数原型：\nsort(iterator beg, iterator end, _Pred); // 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置\n// beg 开始迭代器\n// end 结束迭代器\n// _Pred 谓词\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; void myPrint(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(10); v.push_back(30); v.push_back(50); v.push_back(20); v.push_back(40); //sort默认从小到大排序 sort(v.begin(), v.end()); for_each(v.begin(), v.end(), myPrint); cout \u0026lt;\u0026lt; endl; //从大到小排序 sort(v.begin(), v.end(), greater\u0026lt;int\u0026gt;()); for_each(v.begin(), v.end(), myPrint); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**sort属于开发中最常用的算法之一，需熟练掌握\n5.3.2 random_shuffle #\r功能描述：\n洗牌 指定范围内的元素随机调整次序 函数原型：\nrandom_shuffle(iterator beg, iterator end); // 指定范围内的元素随机调整次序\n// beg 开始迭代器\n// end 结束迭代器\n​\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;ctime\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { srand((unsigned int)time(NULL)); vector\u0026lt;int\u0026gt; v; for(int i = 0 ; i \u0026lt; 10;i++) { v.push_back(i); } for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; //打乱顺序 random_shuffle(v.begin(), v.end()); for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**random_shuffle洗牌算法比较实用，使用时记得加随机数种子\n5.3.3 merge #\r功能描述：\n两个容器元素合并，并存储到另一容器中 函数原型：\nmerge(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); // 容器元素合并，并存储到另一容器中\n// 注意: 两个容器必须是有序的\n// beg1 容器1开始迭代器 // end1 容器1结束迭代器 // beg2 容器2开始迭代器 // end2 容器2结束迭代器 // dest 目标容器开始迭代器\n​\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v1; vector\u0026lt;int\u0026gt; v2; for (int i = 0; i \u0026lt; 10 ; i++) { v1.push_back(i); v2.push_back(i + 1); } vector\u0026lt;int\u0026gt; vtarget; //目标容器需要提前开辟空间 vtarget.resize(v1.size() + v2.size()); //合并 需要两个有序序列 merge(v1.begin(), v1.end(), v2.begin(), v2.end(), vtarget.begin()); for_each(vtarget.begin(), vtarget.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**merge合并的两个容器必须的有序序列\n5.3.4 reverse #\r功能描述：\n将容器内元素进行反转 函数原型：\nreverse(iterator beg, iterator end); // 反转指定范围的元素\n// beg 开始迭代器\n// end 结束迭代器\n​\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(10); v.push_back(30); v.push_back(50); v.push_back(20); v.push_back(40); cout \u0026lt;\u0026lt; \u0026#34;反转前： \u0026#34; \u0026lt;\u0026lt; endl; for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;反转后： \u0026#34; \u0026lt;\u0026lt; endl; reverse(v.begin(), v.end()); for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**reverse反转区间内元素，面试题可能涉及到\n5.4 常用拷贝和替换算法 #\r学习目标：\n掌握常用的拷贝和替换算法 算法简介：\ncopy // 容器内指定范围的元素拷贝到另一容器中 replace // 将容器内指定范围的旧元素修改为新元素 replace_if // 容器内指定范围满足条件的元素替换为新元素 swap // 互换两个容器的元素 5.4.1 copy #\r功能描述：\n容器内指定范围的元素拷贝到另一容器中 函数原型：\ncopy(iterator beg, iterator end, iterator dest); // 按值查找元素，找到返回指定位置迭代器，找不到返回结束迭代器位置\n// beg 开始迭代器\n// end 结束迭代器\n// dest 目标起始迭代器\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v1; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i + 1); } vector\u0026lt;int\u0026gt; v2; v2.resize(v1.size()); copy(v1.begin(), v1.end(), v2.begin()); for_each(v2.begin(), v2.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**利用copy算法在拷贝时，目标容器记得提前开辟空间\n5.4.2 replace #\r功能描述：\n将容器内指定范围的旧元素修改为新元素 函数原型：\nreplace(iterator beg, iterator end, oldvalue, newvalue); // 将区间内旧元素 替换成 新元素\n// beg 开始迭代器\n// end 结束迭代器\n// oldvalue 旧元素\n// newvalue 新元素\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(20); v.push_back(30); v.push_back(20); v.push_back(40); v.push_back(50); v.push_back(10); v.push_back(20); cout \u0026lt;\u0026lt; \u0026#34;替换前：\u0026#34; \u0026lt;\u0026lt; endl; for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; //将容器中的20 替换成 2000 cout \u0026lt;\u0026lt; \u0026#34;替换后：\u0026#34; \u0026lt;\u0026lt; endl; replace(v.begin(), v.end(), 20,2000); for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**replace会替换区间内满足条件的元素\n5.4.3 replace_if #\r功能描述:\n将区间内满足条件的元素，替换成指定元素 函数原型：\nreplace_if(iterator beg, iterator end, _pred, newvalue); // 按条件替换元素，满足条件的替换成指定元素\n// beg 开始迭代器\n// end 结束迭代器\n// _pred 谓词\n// newvalue 替换的新元素\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; class ReplaceGreater30 { public: bool operator()(int val) { return val \u0026gt;= 30; } }; void test01() { vector\u0026lt;int\u0026gt; v; v.push_back(20); v.push_back(30); v.push_back(20); v.push_back(40); v.push_back(50); v.push_back(10); v.push_back(20); cout \u0026lt;\u0026lt; \u0026#34;替换前：\u0026#34; \u0026lt;\u0026lt; endl; for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; //将容器中大于等于的30 替换成 3000 cout \u0026lt;\u0026lt; \u0026#34;替换后：\u0026#34; \u0026lt;\u0026lt; endl; replace_if(v.begin(), v.end(), ReplaceGreater30(), 3000); for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**replace_if按条件查找，可以利用仿函数灵活筛选满足的条件\n5.4.4 swap #\r功能描述：\n互换两个容器的元素 函数原型：\nswap(container c1, container c2); // 互换两个容器的元素\n// c1容器1\n// c2容器2\n​\n示例：\n#include \u0026lt;algorithm\u0026gt; #include \u0026lt;vector\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v1; vector\u0026lt;int\u0026gt; v2; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); v2.push_back(i+100); } cout \u0026lt;\u0026lt; \u0026#34;交换前： \u0026#34; \u0026lt;\u0026lt; endl; for_each(v1.begin(), v1.end(), myPrint()); cout \u0026lt;\u0026lt; endl; for_each(v2.begin(), v2.end(), myPrint()); cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;交换后： \u0026#34; \u0026lt;\u0026lt; endl; swap(v1, v2); for_each(v1.begin(), v1.end(), myPrint()); cout \u0026lt;\u0026lt; endl; for_each(v2.begin(), v2.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**swap交换容器时，注意交换的容器要同种类型\n5.5 常用算术生成算法 #\r学习目标：\n掌握常用的算术生成算法 注意：\n算术生成算法属于小型算法，使用时包含的头文件为 #include \u0026lt;numeric\u0026gt; 算法简介：\naccumulate // 计算容器元素累计总和\nfill // 向容器中添加元素\n​\n5.5.1 accumulate #\r功能描述：\n计算区间内 容器元素累计总和 函数原型：\naccumulate(iterator beg, iterator end, value); // 计算容器元素累计总和\n// beg 开始迭代器\n// end 结束迭代器\n// value 起始值\n示例：\n#include \u0026lt;numeric\u0026gt; #include \u0026lt;vector\u0026gt; void test01() { vector\u0026lt;int\u0026gt; v; for (int i = 0; i \u0026lt;= 100; i++) { v.push_back(i); } int total = accumulate(v.begin(), v.end(), 0); cout \u0026lt;\u0026lt; \u0026#34;total = \u0026#34; \u0026lt;\u0026lt; total \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**accumulate使用时头文件注意是 numeric，这个算法很实用\n5.5.2 fill #\r功能描述：\n向容器中填充指定的元素 函数原型：\nfill(iterator beg, iterator end, value); // 向容器中填充元素\n// beg 开始迭代器\n// end 结束迭代器\n// value 填充的值\n示例：\n#include \u0026lt;numeric\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v; v.resize(10); //填充 fill(v.begin(), v.end(), 100); for_each(v.begin(), v.end(), myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } **总结：**利用fill可以将容器区间内元素填充为 指定的值\n5.6 常用集合算法 #\r学习目标：\n掌握常用的集合算法 算法简介：\nset_intersection // 求两个容器的交集\nset_union // 求两个容器的并集\nset_difference // 求两个容器的差集\n​\n5.6.1 set_intersection #\r功能描述：\n求两个容器的交集 函数原型：\nset_intersection(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); // 求两个集合的交集\n// 注意:两个集合必须是有序序列\n// beg1 容器1开始迭代器 // end1 容器1结束迭代器 // beg2 容器2开始迭代器 // end2 容器2结束迭代器 // dest 目标容器开始迭代器\n示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v1; vector\u0026lt;int\u0026gt; v2; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); v2.push_back(i+5); } vector\u0026lt;int\u0026gt; vTarget; //取两个里面较小的值给目标容器开辟空间 vTarget.resize(min(v1.size(), v2.size())); //返回目标容器的最后一个元素的迭代器地址 vector\u0026lt;int\u0026gt;::iterator itEnd = set_intersection(v1.begin(), v1.end(), v2.begin(), v2.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n求交集的两个集合必须的有序序列 目标容器开辟空间需要从两个容器中取小值 set_intersection返回值既是交集中最后一个元素的位置 5.6.2 set_union #\r功能描述：\n求两个集合的并集 函数原型：\nset_union(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); // 求两个集合的并集\n// 注意:两个集合必须是有序序列\n// beg1 容器1开始迭代器 // end1 容器1结束迭代器 // beg2 容器2开始迭代器 // end2 容器2结束迭代器 // dest 目标容器开始迭代器\n​\n示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v1; vector\u0026lt;int\u0026gt; v2; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); v2.push_back(i+5); } vector\u0026lt;int\u0026gt; vTarget; //取两个容器的和给目标容器开辟空间 vTarget.resize(v1.size() + v2.size()); //返回目标容器的最后一个元素的迭代器地址 vector\u0026lt;int\u0026gt;::iterator itEnd = set_union(v1.begin(), v1.end(), v2.begin(), v2.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n求并集的两个集合必须的有序序列 目标容器开辟空间需要两个容器相加 set_union返回值既是并集中最后一个元素的位置 5.6.3 set_difference #\r功能描述：\n求两个集合的差集 函数原型：\nset_difference(iterator beg1, iterator end1, iterator beg2, iterator end2, iterator dest); // 求两个集合的差集\n// 注意:两个集合必须是有序序列\n// beg1 容器1开始迭代器 // end1 容器1结束迭代器 // beg2 容器2开始迭代器 // end2 容器2结束迭代器 // dest 目标容器开始迭代器\n​\n示例：\n#include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; class myPrint { public: void operator()(int val) { cout \u0026lt;\u0026lt; val \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } }; void test01() { vector\u0026lt;int\u0026gt; v1; vector\u0026lt;int\u0026gt; v2; for (int i = 0; i \u0026lt; 10; i++) { v1.push_back(i); v2.push_back(i+5); } vector\u0026lt;int\u0026gt; vTarget; //取两个里面较大的值给目标容器开辟空间 vTarget.resize( max(v1.size() , v2.size())); //返回目标容器的最后一个元素的迭代器地址 cout \u0026lt;\u0026lt; \u0026#34;v1与v2的差集为： \u0026#34; \u0026lt;\u0026lt; endl; vector\u0026lt;int\u0026gt;::iterator itEnd = set_difference(v1.begin(), v1.end(), v2.begin(), v2.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;v2与v1的差集为： \u0026#34; \u0026lt;\u0026lt; endl; itEnd = set_difference(v2.begin(), v2.end(), v1.begin(), v1.end(), vTarget.begin()); for_each(vTarget.begin(), itEnd, myPrint()); cout \u0026lt;\u0026lt; endl; } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } 总结：\n求差集的两个集合必须的有序序列 目标容器开辟空间需要从两个容器取较大值 set_difference返回值既是差集中最后一个元素的位置 ","date":"1 January 0001","externalUrl":null,"permalink":"/doc/cpp/","section":"Docs","summary":"C++提高编程 #\r本阶段主要针对C++==泛型编程==和==STL==技术做详细讲解，探讨C++更深层的使用 1 模板 #\r1.1 模板的概念 #\r模板就是建立通用的模具，大大提高复用性\n模板的特点：\n模板不可以直接使用，它只是一个框架 模板的通用并不是万能的 1.2 函数模板 #\rC++另一种编程思想称为 ==泛型编程== ，主要利用的技术就是模板\nC++提供两种模板机制:函数模板和类模板\n1.2.1 函数模板语法 #\r函数模板作用：\n建立一个通用函数，其函数返回值类型和形参类型可以不具体制定，用一个虚拟的类型来代表。\n语法：\ntemplate\u0026lt;typename T\u0026gt; 函数声明或定义 解释：","title":"","type":"doc"},{"content":"\r发誓： #\r本人将会参加校招和研究生考试中，为之努力！谦虚向学而不是三天打鱼两天晒网\n","date":"1 January 0001","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/%E5%BF%83%E8%B7%AF%E5%8E%86%E7%A8%8B/","section":"笔记s","summary":"发誓： #\r本人将会参加校招和研究生考试中，为之努力！谦虚向学而不是三天打鱼两天晒网","title":"","type":"笔记"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/cloud/","section":"Series","summary":"","title":"cloud","type":"series"},{"content":"\rDocker容器技术 #\rDocker是一门平台级别的技术，涉及的范围很广，所以，在开始之前，请确保你完成：Java SpringBoot 篇（推荐完成SpringCloud篇再来）视频教程及之前全部路线，否则学习会非常吃力，另外推荐额外掌握：《计算机网络》、《操作系统》相关知识。学一样东西不能完全靠记忆来完成，而是需要结合自己所学的基础知识加以理解，一般来说，单凭记忆能够掌握的东西往往是最廉价的。\n**Docker官网：**\rhttps://www.docker.com\n**课前准备：**配置2C2G以上Linux服务器一台，云服务器、虚拟机均可。\n容器技术入门 #\r随着时代的发展，Docker也逐渐走上了历史舞台，曾经我们想要安装一套环境，需要花费一下午甚至一整天来配置和安装各个部分（比如运行我们自己的SpringBoot应用程序，可能需要安装数据库、安装Redis、安装MQ等，各种各样的环境光是安装就要花费很多时间，真的是搞得心态爆炸），而有了Docker之后，我们的程序和环境部署就变得非常简单了，我们只需要将这些环境一起打包成一个镜像。而到服务器上部署时，可以直接下载镜像实现一键部署，是不是很方便？\n包括我们在学习SpringCloud需要配置的各种组件，可能在自己电脑的环境中运行会遇到各种各样的问题（可能由于电脑上各种环境没配置，导致无法运行），而现在只需要下载镜像就能直接运行，所有的环境全部在镜像中配置完成，开箱即用。\n真的有这么神奇吗？我们来试试看。\n环境安装和部署 #\r首先我们还是先将Docker环境搭建好（建议和我同一个环境，不然出了问题只能自己想办法了），这里我们使用：\nUbuntu 22.04 操作系统 Docker分为免费的CE（Community Edition）社区版本和EE（Enterprise Edition）企业级付费版本，所以我们这里选择docker-ce进行安装。官方安装文档：https://docs.docker.com/engine/install/ubuntu/\n首先安装一些工具：\nsudo apt-get install ca-certificates curl gnupg lsb-release 不过在Ubuntu22.04已经默认安装好了。接着安装官方的GPG key：\nsudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg 最后将Docker的库添加到apt资源列表中：\necho \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 接着我们更新一次apt：\nsudo apt update 最后安装Docker CE版本：\nsudo apt install docker-ce 等待安装完成就可以了：\n可以看到安装成功后版本是20.10.17，当然可能你们安装的时候就是更新的版本了。最后我们将当前用户添加到docker用户组中，不然每次使用docker命令都需要sudo执行，很麻烦：\nsudo usermod -aG docker \u0026lt;用户名\u0026gt; 配置好后，我们先退出SSH终端，然后重新连接就可以生效了。\n这样我们Docker 的学习环境就配置好了，现在我们就尝试通过Docker来部署一个Nginx服务器试试看，使用很简单，只需要一个命令就可以了（当然现在看不懂没关系，我们后面会细嗦）：\nsudo docker run -d -p 80:80 nginx 首选它会从镜像仓库中下载对应的镜像，国内访问速度还行，不需要单独配置镜像源。接着下载完成后，就会在后台运行了，我们可以使用浏览器访问试试看：\n可以看到，Nginx服务器已经成功部署了，但是实际上我们并没有在Ubuntu中安装Nginx，而是通过Docker运行的镜像来进行服务器搭建的，是不是感觉玩法挺新奇的。除了Nginx这种简单的应用之外，我们还可以通过Docker来部署复杂应用，之后我们都会一一进行讲解的。\n从虚拟机到容器 #\r前面我们成功安装了Docker学习环境，以及浅尝了一下Docker为我们带来的应用快速部署。在正式进入学习之前，我们就先从Docker的发展开始说起。\n在Docker出现之前，虚拟化技术可以说是占据了主导地位。首先我们来谈谈为什么会出现虚拟化技术，我们知道在企业中服务器可以说是必不可少的一种硬件设施了，服务器也是电脑，但是不像我们的家用电脑，服务器的配置是非常高的，我们家用电脑的CPU可能最高配也就20核了，内存很少有超过128G的电脑，64G内存的家用电脑可以算奢侈了。而服务器不一样，服务器级别的CPU动辄12核，甚至服务器还能同时安装多块CPU，能直接堆到好几十核：\n我们家用级CPU一般是AMD的锐龙系列和Intel的酷睿系列（比如i3 i5 i7 i9），而服务器CPU一般是Intel的志强（Xeno）系列，这种CPU的特点就是核心数非常多：\n并且服务器CPU相比家用CPU的功耗也会更大，因此服务器CPU的发热量非常高，如果你有幸去过机房，你会听见散热风扇猛烈转动的声音（但是服务器CPU的频率没有家用级CPU高，一般大型游戏要求的是高频率而不是核心数，而且功耗也比较大，所以并不适合做家用电脑，所以以后在网上买台式机，看到什么“i9级”CPU千万别买，是这些黑心商家把国外服务器上淘汰下来的服务器CPU（洋垃圾）装成电脑卖给你，所以会很便宜，同时核心数又能媲美i9，所以还是一分钱一分货实在）\n服务器无论是CPU资源还是内存资源都远超家用电脑，而我们编写的Java后端项目，最后都会运行在这些服务器上，不过有一个问题，服务器既然有这么丰富的硬件资源，就跑咱们这一个小Java后端，是不是有点核弹炸蚊子的感觉了？可能顶多就用了服务器5%的硬件资源，服务器这么牛就运行个这也太浪费了吧。\n所以，为了解决这种资源利用率只有5%-15%的情况，咱们能不能想个办法，把这一台服务器分成多个小服务器使用，每个小服务器只分配一部分的资源，比如分一个小服务器出去，只给2个CPU核心和4G内存。但是由于设计上的问题，我们的电脑只能同时运行一个操作系统，那么怎么办呢？此时虚拟化技术就开始兴起了。\n虚拟化使用软件来模拟硬件并创建虚拟计算机系统。这样一来，企业便可以在单台服务器上运行多个虚拟系统，也就是运行多个操作系统和应用，而这可以实现规模经济以及提高效益。比如我们电脑上经常使用的VMware就是一种民用级虚拟化软件：\n我们可以使用VMware来创建虚拟机，这些虚拟机实际上都是基于我们当前系统上的VMware软件来运行的，当然VMware也有服务器专用的虚拟化软件，有了虚拟化之后，我们的服务器就像这样：\n相当于通过虚拟机模拟了很多来电脑出来，这样我们就可以在划分出来的多台虚拟机上分别安装系统和部署我们的应用程序了，并且我们可以自由分配硬件资源，合理地使用。一般在企业中，不同的应用程序可能会被分别部署到各个服务器上，隔离开来，此时使用虚拟机就非常适合。\n实际上我们在什么腾讯云、阿里云租的云服务器，都是经过虚拟化技术划分出来的虚拟机而已。\n那么，既然虚拟机都这么方便了，容器又是怎么杀出一条血路的呢？我们先来看看什么是容器。\n容器和虚拟机比较类似，都可以为应用提供封装和隔离，都是软件，但是容器中的应用运行是寄托于宿主操作系统的，实际上依然是在直接使用操作系统的资源，当然应用程序之间环境依然是隔离的，而虚拟机则是完全模拟一台真正的电脑出来，直接就是两台不同的电脑。\n因此容器相比虚拟机就简单多了，并且启动速度也会快很多，开销小了不少。\n不过容器火的根本原因还是它的集装箱思想，我们知道，如果我们要写一个比如论坛、电商这类的Java项目，那么数据库、消息队列、缓存这类中间件是必不可少的，因此我们如果想要将一个服务部署到服务器，那么实际上还要提前准备好各种各样的环境，先安装好MySQL、Redis、RabbitMQ等应用，配置好了环境，再将我们的Java应用程序启动，整个流程下来，光是配置环境就要浪费大量的时间，如果是大型的分布式项目，可能要部署很多台机器，那岂不是我们得一个一个来？项目上个线就要花几天时间，显然是很荒唐的。\n而容器可以打包整个环境，比较MySQL、Redis等以及我们的Java应用程序，可以被一起打包为一个镜像，当我们需要部署服务时，只需要像我们之前那样，直接下载镜像运行即可，不需要再进行额外的配置了，整个镜像中环境是已经配置好的状态，开箱即用。\n而我们要重点介绍的就是Docker了，可以看到它的图标就是一只鲸鱼，鲸鱼的上面是很多个集装箱，每个集装箱就是我们的整个环境+应用程序，Docker可以将任何应用及其依赖打包为一个轻量级，可移植，自包含的容器，容器可以运行在几乎所有的操作系统上。\n容器工作机制简述 #\r我们先来看看Docker的整体架构：\n实际上分为三个部分：\nDocker 客户端：也就是我们之前使用的docker命令，都是在客户端上执行的，操作会发送到服务端上处理。 Docker 服务端：服务端就是启动容器的主体了，一般是作为服务在后台运行，支持远程连接。 Registry：是存放Docker镜像的仓库，跟Maven一样，也可以分公有和私有仓库，镜像可以从仓库下载到本地存放。 当我们需要在服务器上部署一个已经打包好的应用和环境，我们只需要下载打包好的镜像就可以了，我们前面执行了：\nsudo docker run -d -p 80:80 nginx 实际上这个命令输入之后：\nDocker客户端将操作发送给服务端，告诉服务端我们要运行nginx这个镜像。 Docker服务端先看看本地有没有这个镜像，发现没有。 接着只能从公共仓库Docker Hub去查找下载镜像了。 下载完成，镜像成功保存到本地。 Docker服务端加载Nginx镜像，启动容器开始正常运行（注意容器和其他容器之间，和外部之间，都是隔离的，互不影响） 所以，整个流程中，Docker就像是一搜运输船，镜像就像是集装箱，通过运输船将世界各地的货物送往我们的港口，货物到达港口后，Docker并不关心集装箱里面的是什么，只需要创建容器开箱即用就可以了。相比我们传统的手动安装配置环境，不知道方便了几个层次。\n不过容器依然是寄托于宿主主机的运行的，所以一般在生产环境下，都是通过虚拟化先创建多台主机，然后再到各个虚拟机中部署Docker，这样的话，运维效率就大大提升了。\n从下一章开始，我们就正式地来学习一下Docker的各种操作。\n容器与镜像 #\r要启动容器最关键的就是镜像，我们来看看镜像相关的介绍。\n初识容器镜像 #\r首先我们来了解一下镜像的相关操作，比如现在我们希望把某个镜像从仓库下载到本地，这里使用官方的hello-world镜像：\ndocker pull hello-world 只需要输入pull命令，就可以直接下载到指定的镜像了：\n可以看到对上面一行有一句Using default tag，实际上一个镜像的名称是由两部分组成的，一个是repository，还有一个是tag，一般情况下约定repository就是镜像名称，tag作为版本，默认为latest，表示最新版本。所以指定版本运行的话：\ndocker pull 名称:版本 之后为了教学方便，我们就直接使用默认的tag，不去指定版本了。\n镜像下载之后会存放在本地，要启动这个镜像的容器，实际上就像我们之前那样，输入run命令就可以了：\ndocker run hello-world 当然如果仅仅是只想创建而不想马上运行的话，可以使用create命令：\ndocker create hello-world 可以看到成功启动了：\n启动之后，会使用当前镜像自动创建一个容器，我们可以输入ps命令来查看当前容器的容器列表：\ndocker ps -a 注意后面要加一个-a表示查看所有容器（其他选项可以使用-h查看），如果不加的话，只会显示当前正在运行的容器，而HelloWorld是一次性的不是Nginx那样的常驻程序，所以容器启动打印了上面的内容之后，容器就停止运行了：\n可以看到容器列表中有我们刚刚创建的hello-world以及我们之前创建的nginx（注意同一个镜像可以创建多个容器），每个容器都有一个随机生成的容器ID写在最前面，后面是容器的创建时间以及当前的运行状态，最后一列是容器的名称，在创建容器时，名称可以由我们指定也可以自动生成，这里就是自动生成的。\n我们可以手动指定名称启动，在使用run命令时，添加--name参数即可：\ndocker run --name=lbwnb hello-world 我们可以手动开启处于停止状态的容器：\ndocker start \u0026lt;容器名称/容器ID\u0026gt; 注意启动的对象我们要填写容器的ID或是容器的名称才可以，容器ID比较长，可以不写全只写一半，但是你要保证你输入的不完全容器ID是唯一的。\n如果想要停止容器直接输入stop命令就可以了：\ndocker stop \u0026lt;容器名称/容器ID\u0026gt; 或是重启：\ndocker restart \u0026lt;容器名称/容器ID\u0026gt; 如果我们不需要使用容器了，那么可以将容器删除，但是注意只有容器处于非运行状态时才可以删除：\ndocker rm \u0026lt;容器名称/容器ID\u0026gt; 当然如果我们希望容器在停止后自动删除，我们可以在运行时添加--rm参数：\ndocker run --rm 镜像名称 删除后，容器将不复存在，当没有任何关于nginx的容器之后，我们可以删除nginx的本地镜像：\n我们可以使用images命令来检查一下当前本地有那些镜像：\ndocker images 至此，我们已经了解了Docker的简单使用，在后面的学习中，我们还会继续认识更多的玩法。\n镜像结构介绍 #\r前面我们了解了Docker的相关基本操作，实际上容器的基石就是镜像，有了镜像才能创建对应的容器实例，那么我们就先从镜像的基本结构开始说起，我们来看看镜像到底是个什么样的存在。\n我们在打包项目时，实际上往往需要一个基本的操作系统环境，这样我们才可以在这个操作系统上安装各种依赖软件，比如数据库、缓存等，像这种基本的系统镜像，我们称为base镜像，我们的项目之后都会基于base镜像进行打包，当然也可以不需要base镜像，仅仅是基于当前操作系统去执行简单的命令，比如我们之前使用的hello-world就是。\n一般base镜像就是各个Linux操作系统的发行版，比如我们正在使用的Ubuntu，还有CentOS、Kali等等。这里我们就下载一下CentOS的base镜像：\ndocker pull centos 可以看到，CentOS的base镜像就已经下载完成，不像我们使用完整系统一样，base镜像的CentOS省去了内核，所以大小只有272M，这里需要解释一下base镜像的机制：\nLinux操作体系由内核空间和用户空间组成，其中内核空间就是整个Linux系统的核心，Linux启动后首先会加bootfs文件系统，加载完成后会自动卸载掉，之后会加载用户空间的文件系统，这一层是我们自己可以进行操作的部分：\nbootfs包含了BootLoader和Linux内核，用户是不能对这层作任何修改的，在内核启动之后，bootfs会自动卸载。 rootfs则包含了系统上的常见的目录结构，包括/dev、 /proc、 /bin等等以及一些基本的文件和命令，也就是我们进入系统之后能够操作的整个文件系统，包括我们在Ubuntu下使用的apt和CentOS下使用的yum，都是用户空间上的。 base镜像底层会直接使用宿主主机的内核，也就是说你的Ubuntu内核版本是多少，那么base镜像中的CentOS内核版本就是多少，而rootfs则可以在不同的容器中运行多种不同的版本。所以，base镜像实际上只有CentOS的rootfs，因此只有300M大小左右，当然，CentOS里面包含多种基础的软件，还是比较臃肿的，而某些操作系统的base镜像甚至都不到10M。\n使用uname命令可以查看当前内核版本：\n因此，Docker能够同时模拟多种Linux操作系统环境，就不足为奇了，我们可以尝试启动一下刚刚下载的base镜像：\ndocker run -it centos 注意这里需要添加-it参数进行启动，其中-i表示在容器上打开一个标准的输入接口，-t表示分配一个伪tty设备，可以支持终端登录，一般这两个是一起使用，否则base容器启动后就自动停止了。\n可以看到使用ls命令能够查看所有根目录下的文件，不过很多命令都没有，连clear都没有，我们来看看内核版本：\n可以看到内核版本是一样的（这也是缺点所在，如果软件对内核版本有要求的话，那么此时使用Docker就直接寄了），我们输入exit就可以退出容器终端了，可以看到退出后容器也停止了：\n当然我们也可以再次启动，注意启动的时候要加上-i才能进入到容器进行交互，否则会在后台运行：\n基于base镜像，我们就可以在这基础上安装各种各样的软件的了，几乎所有的镜像都是通过在base镜像的基础上安装和配置需要的软件构建出来的：\n每安装一个软件，就在base镜像上一层层叠加上去，采用的是一种分层的结构，这样多个容器都可以将这些不同的层次自由拼装，比如现在好几个容器都需要使用CentOS的base镜像，而上面运行的软件不同，此时分层结构就很爽了，我们只需要在本地保存一份base镜像，就可以给多个不同的容器拼装使用，是不是感觉很灵活？\n我们看到除了这些软件之外，最上层还有一个可写容器层，这个是干嘛的呢，为什么要放在最上面？\n我们知道，所有的镜像会叠起来组成一个统一的文件系统，如果不同层中存在相同位置的文件，那么上层的会覆盖掉下层的文件，最终我们看到的是一个叠加之后的文件系统。当我们需要修改容器中的文件时，实际上并不会对镜像进行直接修改，而是在最顶上的容器层（最上面一般称为容器层，下面都是镜像层）进行修改，不会影响到下面的镜像，否则镜像就很难实现多个容器共享了。所以各个操作如下：\n文件读取：要读取一个文件，Docker会最上层往下依次寻找，找到后则打开文件。 文件创建和修改：创建新文件会直接添加到容器层中，修改文件会从上往下依次寻找各个镜像中的文件，如果找到，则将其复制到容器层，再进行修改。 删除文件：删除文件也会从上往下依次寻找各个镜像中的文件，一旦找到，并不会直接删除镜像中的文件，而是在容器层标记这个删除操作。 也就是说，我们对整个容器内的文件进行的操作，几乎都是在最上面的容器层进行的，我们是无法干涉到下面所有的镜像层文件的，这样就很好地保护了镜像的完整性，才能实现多个容器共享使用。\n构建镜像 #\r前面我们已经了解了Docker镜像的结构，实际上所有常用的应用程序都有对应的镜像，我们只需要下载这些镜像然后就可以使用了，而不需要自己去手动安装，顶多需要进行一些特别的配置。当然要是遇到某些冷门的应用，可能没有提供镜像，这时就要我们手动去安装，接着我们就来看看如何构建我们自己的Docker镜像。构建镜像有两种方式，一种是使用commit命令来完成，还有一种是使用Dockerfile来完成，我们先来看第一种。\n这里我们就做一个简单的例子，比如我们现在想要在Ubuntu的base镜像中安装Java环境，并将其打包为新的镜像（这个新的镜像就是一个包含Java环境的Ubuntu系统镜像）\n咱们先启动Ubuntu镜像，然后使用yum命令（跟apt比较类似）来安装Java环境，首先是run命令：\ndocker pull ubuntu 接着启动：\n直接使用apt命令来安装Java环境，在这之前先更新一下，因为是最小安装所以本地没有任何软件包：\n接着输入：\napt install openjdk-8-jdk 等待安装完成：\n这样，我们就完成了对Java环境的安装了，接着我们就可以退出这个镜像然后将其构建为新的镜像：\n使用commit命令可以将容器保存为新的镜像：\ndocker commit 容器名称/ID 新的镜像名称 可以看到安装了软件之后的镜像大小比我们原有的大小大得多，这样我们就可以通过这个镜像来直接启动一个带Java环境的Ubuntu操作系统容器了。不过这种方式虽然自定义度很高，但是Docker官方并不推荐，这样的话使用者并不知道镜像是如何构建出来的，是否里面带了后门都不知道，并且这样去构建效率太低了，如果要同时构建多种操作系统的镜像岂不是要一个一个去敲？我们作为普通用户实际上采用Dokcerfile的方式会更好一些。\n我们来看看如何使用Dockerfile的形式创建一个带Java环境的Ubuntu系统镜像。首先直接新建一个名为Dockerfile的文件：\ntouch Dockerfile 接着我们来进行编辑，Dockerfile内部需要我们编写多种指令来告诉Docker我们的镜像的相关信息：\nFROM \u0026lt;基础镜像\u0026gt; 首先我们需要使用FROM指令来选择当前镜像的基础镜像（必须以这个指令开始），这里我们直接使用ubuntu作为基础镜像即可，当然如果不需要任何基础镜像的话，直接使用scratch表示从零开始构建，这里就不演示了。\n基础镜像设定完成之后，我们就需要在容器中运行命令来安装Java环境了，这里需要使用RUN指令：\nRUN apt update RUN apt install -y openjdk-8-jdk 每条指令执行之后，都会生成一个新的镜像层。\nOK，现在我们的Dockerfile就编写完成了，只需要完成一次构建即可：\ndocker build -t \u0026lt;镜像名称\u0026gt; \u0026lt;构建目录\u0026gt; 执行后，Docker会在构建目录中寻找Dockerfile文件，然后开始依次执行Dockerfile中的指令：\n构建过程的每一步都非常清晰地列出来了，一共三条指令对应三步依次进行，我们稍微等待一段时间进行安装，安装过程中所以的日志信息会直接打印到控制台（注意Docker镜像构建有缓存机制，就算你现在中途退出了，然后重新进行构建，也会直接将之前已经构建好的每一层镜像，直接拿来用，除非修改了Dockerfile文件重新构建，只要某一层发生变化其上层的构建缓存都会失效，当然包括pull时也会有类似的机制）\n最后成功安装，会出现在本地：\n可以看到安装出来的大小跟我们之前的是一样的，因为做的事情是一模一样的。我们可以使用history命令来查看构建历史：\n可以看到最上面两层是我们通过使用apt命令生成的内容，就直接作为当前镜像中的两层镜像，每层镜像都有一个自己的ID，不同的镜像大小也不一样。而我们手动通过commit命令来生成的镜像没有这个记录：\n如果遇到镜像ID为missing的一般是从Docker Hub中下载的镜像会有这个问题，但是问题不大。用我们自己构建的镜像来创建容器就可以直接体验带Java环境的容器了：\n有关Dockerfile的其他命令，我们还会在后续的学习中逐步认识。\n发布镜像到远程仓库 #\r前面我们学习了如何构建一个Docker镜像，我们可以将自己的镜像发布到Docker Hub中，就像Git远程仓库一样，我们可以将自己的镜像上传到这里：https://hub.docker.com/repositories，没有账号的先去进行注册。\n点击右上角的创建仓库，然后填写信息：\n创建完成后，我们就有了一个公共的镜像仓库，我们可以将本地的镜像上传了，上传之前我们需要将镜像名称修改得规范一点，这里使用tag命令来重新打标签：\ndocker tag ubuntu-java-file:latest 用户名/仓库名称:版本 这里我们将版本改成1.0版本吧，不用默认的latest了。\n修改完成后，会创建一个新的本地镜像，名称就是我们自己定义的了。接着我们需在本地登录一下：\n登录成功后我们就可以上传了：\ndocker push nagocoler/ubuntu-java:1.0 哈哈，500M的东西传上去，还是有点压力的，如果实在太慢各位可以重新做一个简单点的镜像。上传完成后，打开仓库，可以看到已经有一个1.0版本了：\n注意公共仓库是可以被搜索和下载的，所以我们这里把本地的镜像全部删掉，去下载我们刚刚上传好的镜像。这里我们先搜索一下，搜索使用search命令即可：\ndocker search nagocoler/ubuntu-java 我们可以使用pull命令将其下载下来：\ndocker pull nagocoler/ubuntu-java:1.0 上传之后的镜像是被压缩过的，所以下载的内容就比较少一些。运行试试看：\n当然各位也可以让自己的同学或是在其他机器上尝试下载自己的镜像，看看是不是都可以正常运行。\nDocker Hub也可以自行搭建私服，但是这里就不多做介绍了，至此，有关容器和镜像的一些基本操作就讲解得差不多了。\n实战：使用IDEA构建SpringBoot程序镜像 #\r这里我们创建一个新的SpringBoot项目，现在我们希望能够使用Docker快速地将我们的SpringBoot项目部署到安装了Docker的服务器上，我们就可以将其打包为一个Docker镜像。\n先创建好一个项目让它跑起来，可以正常运行就没问题了，接着我们需要将其打包为Docker镜像，这里创建一个新的Dockerfile：\nFROM ubuntu RUN apt update \u0026amp;\u0026amp; apt install -y openjdk-8-jdk 首先还是基于ubuntu构建一个带Java环境的系统镜像，接着我们先将其连接到我们的Docker服务器进行构建，由于IDEA自带了Docker插件，所以我们直接点击左上角的运行按钮，选择第二项 “为Dockerfile构建镜像”：\n这里需要配置Docker的服务器，也就是我们在Ubuntu服务器安装的Docker，这里我们填写服务器相关信息，我们首选需要去修改一下Docker的一些配置，开启远程客户端访问：\nsudo vim /etc/systemd/system/multi-user.target.wants/docker.service 打开后，添加高亮部分：\n修改完成后，重启Docker服务，如果是云服务器，记得开启2375 TCP连接端口：\nsudo systemctl daemon-reload sudo systemctl restart docker.service 现在接着在IDEA中进行配置：\n在引擎API URL处填写我们Docker服务器的IP地址：\ntcp://IP:2375 显示连接成功后，表示配置正确，点击保存即可，接着就开始在我们的Docker服务器上进行构建了：\n最后成功构建：\n可以看到，Docker服务器上已经有了我们刚刚构建好的镜像：\n不过名称没有指定，这里我们重新配置一下：\n重新进行构建，就是我们自定义的名称了：\n我们来创建一个容器试试看：\n好了，现在基本环境搭建好了，我们接着就需要将我们的SpringBoot项目打包然后再容器启动时运行了，打开Maven执行打包命令：\n接着我们需要编辑Dockerfile，将我们构建好的jar包放进去：\nCOPY target/DockerTest-0.0.1-SNAPSHOT.jar app.jar 这里需要使用COPY命令来将文件拷贝到镜像中，第一个参数是我们要拷贝的本地文件，第二个参数是存放在Docker镜像中的文件位置，由于还没有学习存储管理，这里我们直接输入app.jar直接保存在默认路径即可。\n接着我们就需要指定在启动时运行我们的Java程序，这里使用CMD命令来完成：\nFROM ubuntu RUN apt update \u0026amp;\u0026amp; apt install -y openjdk-8-jdk COPY target/DockerTest-0.0.1-SNAPSHOT.jar app.jar CMD java -jar app.jar # EXPOSE 8080 CMD命令可以设定容器启动后执行的命令，EXPOSE可以指定容器需要暴露的端口，但是现在我们还没有学习网络相关的知识，所以暂时不使用，这里指定为我们启动Java项目的命令。配置完成后，重新构建：\n可以看到历史中已经出现新的步骤了：\n接着启动我们的镜像，我们可以直接在IDEA中进行操作，不用再去敲命令了，有点累：\n启动后可以在右侧看到容器启动的日志信息：\n但是我们发现启动之后并不能直接访问，这是为什么呢？这是因为容器内部的网络和外部网络是隔离的，我们如果想要访问容器内的服务器，需要将对应端口绑定到宿主机上，让宿主主机也开启这个端口，这样才能连接到容器内：\ndocker run -p 8080:8080 -d springboot-test:1.0 这里-p表示端口绑定，将Docker容器内的端口绑定到宿主机的端口上，这样就可以通过宿主的8080端口访问到容器的8080端口了（有关容器网络管理我们还会在后面进行详细介绍），-d参数表示后台运行，当然直接在IDEA中配置也是可以的：\n配置好后，点击重新创建容器：\n重新运行后，我们就可以成功访问到容器中运行的SpringBoot项目了：\n当然，为了以后方便使用，我们可以直接将其推送到Docker Hub中，这里我们还是创建一个新的公开仓库：\n这次我们就使用IDEA来演示直接进行镜像的上传，直接点击：\n接着我们需要配置一下我们的Docker Hub相关信息：\nOK，远程镜像仓库配置完成，直接推送即可，等待推送完成。\n可以看到远程仓库中已经出现了我们的镜像，然后IDEA中也可以同步看到：\n这样，我们就完成了使用IDEA将SpringBoot项目打包为Docker镜像。\n容器网络管理 #\r**注意：**本小节学习需要掌握部分《计算机网络》课程中的知识。\n前面我们学习了容器和镜像的一些基本操作，了解了如何通过镜像创建容器、然后自己构建容器，以及远程仓库推送等，这一部分我们接着来讨论容器的网络管理。\n容器网络类型 #\rDocker在安装后，会在我们的主机上创建三个网络，使用network ls命令来查看：\ndocker network ls 可以看到默认情况下有bridge、host、none这三种网络类型（其实有点像虚拟机的网络配置，也是分桥接、共享网络之类的），我们先来依次介绍一下，在开始之前我们先构建一个镜像，默认的ubuntu镜像由于啥软件都没有，所以我们把一会网络要用到的先提前装好：\ndocker run -it ubuntu apt update apt install net-tools iputils-ping curl 这样就安装好了，我们直接退出然后将其构建为新的镜像：\ndocker commit lucid_sammet ubuntu-net OK，一会我们就可以使用了。\n**none网络：**这个网络除了有一个本地环回网络之外，就没有其他的网络了，我们可以在创建容器时指定这个网络。\n这里使用--network参数来指定网络：\ndocker run -it --network=none ubuntu-net 进入之后，我们可以直接查看一下当前的网络：\nifconfig 可以看到只有一个本地环回lo网络设备：\n所以这个容器是无法连接到互联网的：\n“真”单机运行，可以说是绝对的安全，没人能访问进去，存点密码这些还是不错的。\n**bridge网络：**容器默认使用的网络类型，这是桥接网络，也是应用最广泛的网络类型：\n实际上我们在宿主主机上查看网络信息，会发现有一个名为docker0的网络设备：\n这个网络设备是Docker安装时自动创建的虚拟设备，它有什么用呢？我们可以来看一下默认创建的容器内部的情况：\ndocker run -it ubuntu-net 可以看到容器的网络接口地址为172.17.0.2，实际上这是Docker创建的虚拟网络，就像容器单独插了一根虚拟的网线，连接到Docker创建的虚拟网络上，而docker0网络实际上作为一个桥接的角色，一头是自己的虚拟子网，另一头是宿主主机的网络。\n网络拓扑类似于下面这样：\n通过添加这样的网桥，我们就可以对容器的网络进行管理和控制，我们可以使用network inspect命令来查看docker0网桥的配置信息：\ndocker network inspect bridge 这里的配置的子网是172.17.0.0，子网掩码是255.255.0.0，网关是172.17.0.1，也就是docker0这个虚拟网络设备，所以我们上面创建的容器就是这个子网内分配的地址172.17.0.2了。\n之后我们还会讲解如何管理和控制容器网络。\n**host网络：**当容器连接到此网络后，会共享宿主主机的网络，网络配置也是完全一样的：\ndocker run -it --network=host ubuntu-net 可以看到网络列表和宿主主机的列表是一样的，不知道各位有没有注意到，连hostname都是和外面一模一样的：\n只要宿主主机能连接到互联网，容器内部也是可以直接使用的：\n这样的话，直接使用宿主的网络，传输性能基本没有什么折损，而且我们可以直接开放端口等，不需要进行任何的桥接：\napt install -y systemctl nginx systemctl start nginx 安装Nginx之后直接就可以访问了，不需要开放什么端口：\n相比桥接网络就方便得多了。\n我们可以根据实际情况，来合理地选择这三种网络使用。\n用户自定义网络 #\r除了前面我们介绍的三种网络之外，我们也可以自定义自己的网络，让容器连接到这个网络。\nDocker默认提供三种网络驱动：bridge、overlay、macvlan，不同的驱动对应着不同的网络设备驱动，实现的功能也不一样，比如bridge类型的，其实就和我们前面介绍的桥接网络是一样的。\n我们可以使用network create来试试看：\ndocker network create --driver bridge test 这里我们创建了一个桥接网络，名称为test：\n可以看到新增了一个网络设备，这个就是一会负责我们容器网络的网关了，和之前的docker0是一样的：\ndocker network inspect test 这里我们创建一个新的容器，使用此网络：\ndocker run -it --network=test ubuntu-net 成功得到分配的IP地址，是在这个网络内的，注意不同的网络之间是隔离的，我们可以再创建一个容器试试看：\n可以看到不同的网络是相互隔离的，无法进行通信，当然我们也为此容器连接到另一个容器所属的网络下：\ndocker network connect test 容器ID/名称 这样就连接了一个新的网络：\n可以看到容器中新增了一个网络设备连接到我们自己定义的网络中，现在这两个容器在同一个网络下，就可以相互ping了： 这里就不介绍另外两种类型的网络了，他们是用于多主机通信的，目前我们只学习单机使用。\n容器间网络 #\r我们首先来看看容器和容器之间的网络通信，实际上我们之前已经演示过ping的情况了，现在我们创建两个ubuntu容器：\ndocker run -it ubuntu-net 先获取其中一个容器的网络信息：\n我们可以直接在另一个容器中ping这个容器：\n可以看到能够直接ping通，因为这两个容器都是使用的bridge网络，在同一个子网中，所以可以互相访问。\n我们可以直接通过容器的IP地址在容器间进行通信，只要保证两个容器处于同一个网络下即可，虽然这样比较方便，但是大部分情况下，容器部署之后的IP地址是自动分配的（当然也可以使用--ip来手动指定，但是还是不方便），我们无法提前得知IP地址，那么有没有一直方法能够更灵活一些呢？\n我们可以借助Docker提供的DNS服务器，它就像是一个真的DNS服务器一样，能够对域名进行解析，使用很简单，我们只需要在容器启动时给个名字就行了，我们可以直接访问这个名称，最后会被解析为对应容器的IP地址，但是注意只会在我们用户自定义的网络下生效，默认的网络是不行的：\ndocker run -it --name=test01 --network=test ubuntu-net docker run -it --name=test02 --network=test ubuntu-net 接着直接ping对方的名字就可以了：\n可以看到名称会自动解析为对应的IP地址，这样的话就不用担心IP不确定的问题了。\n当然我们也可以让两个容器同时共享同一个网络，注意这里的共享是直接共享同一个网络设备，两个容器共同使用一个IP地址，只需要在创建时指定：\ndocker run -it --name=test01 --network=container:test02 ubuntu-net 这里将网络指定为一个容器的网络，这样两个容器使用的就是同一个网络了：\n可以看到两个容器的IP地址和网卡的Mac地址是完全一样的，它们的网络现在是共享状态，此时在容器中访问，localhost，既是自己也是别人。\n我们可以在容器1中，安装Nginx，然后再容器2中访问：\napt install -y systemctl nginx systemctl start nginx 成功访问到另一个容器中的Nginx服务器。\n容器外部网络 #\r前面我们介绍了容器之间的网络通信，我们接着来看容器与外部网络的通信。\n首先我们来看容器是如何访问到互联网的，在默认的三种的网络下，只有共享模式和桥接模式可以连接到外网，共享模式实际上就是直接使用宿主主机的网络设备连接到互联网，这里我们主要来看一下桥接模式。\n通过前面的学习，我们了解到桥接模式实际上就是创建一个单独的虚拟网络，让容器在这个虚拟网络中，然后通过桥接器来与外界相连，那么数据包是如何从容器内部的网络到达宿主主机再发送到互联网的呢？实际上整个过程中最关键的就是依靠NAT（Network Address Translation）将地址进行转换，再利用宿主主机的IP地址发送数据包出去。\n这里我们就来补充一下《计算机网络》课程中学习的NAT：\n实际上NAT在我们生活中也是经常见到的，比如我们要访问互联网上的某个资源，要和服务器进行通信，那么就需要将数据包发送出去，同时服务器也要将数据包发送回来，我们可以知道服务器的IP地址，也可以直接去连接，因为服务器的IP地址是暴露在互联网上的，但是我们的局域网就不一样了，它仅仅局限在我们的家里，比如我们连接了家里的路由器，可以得到一个IP地址，但是你会发现，这个IP公网是无法直接访问到我们的，因为这个IP地址仅仅是一个局域网的IP地址，俗称内网IP，既然公网无法访问到我们，那服务器是如何将数据包发送给我们的呢？\n实际上这里就借助了NAT在帮助我们与互联网上的服务器进行通信，通过NAT，可以实现将局域网的IP地址，映射为对应的公网IP地址，而NAT设备一端连接外网，另一端连接内网的所有设备，当我们想要与外网进行通信时，就可以将数据包发送给NAT设备，由它来将数据包的源地址映射为它在外网上的地址，这样服务器就能够发现它了，能够直接与它建立通信。当服务器发送数据回来时，也是直接交给NAT设备，然后再根据地址映射，转发给对应的内网设备（当然由于公网IP地址有限，所以一般采用IP+端口结合使用的形式ANPT）\n所以你打开百度直接搜IP，会发现这个IP地址并不是你本地的，而是NAT设备的公网地址：\n实际上我们家里的路由器一般都带有NAT功能，默认开启NAT模式，包括我们的小区也是有一个NAT设备在进行转换的，这样你的电脑才能在互联网的世界中遨游。当然NAT也可以保护内网的设备不会直接暴露在公网，这样也会更加的安全，只有当我们主动发起连接时，别人才能知道我们。\n当然，我们的Docker也是这样的，实际上内网的数据包想要发送到互联网上去，那么就需要经过这样的一套流程：\n这样，Docker容器使用的内网就可以和外网进行通信了。\n但是这样有一个问题，单纯依靠NAT的话，只有我们主动与外界联系时，外界才能知道我们，但是现在我们的容器中可能会部署一些服务，需要外界来主动连接我们，此时该怎么办呢？\n我们可以直接在容器时配置端口映射，还记得我们在第一节课部署Nginx服务器吗？\ndocker run -d -p 80:80 nginx 这里的-p参数实际上是进行端口映射配置，端口映射可以将容器需要对外提供服务的端口映射到宿主主机的端口上，这样，当外部访问到宿主主机的对应端口时，就会直接转发给容器内映射的端口了。规则为宿主端口:容器端口，这里配置的是将容器的80端口映射到宿主主机的80端口上。\n一旦监听到宿主主机的80端口收到了数据包，那么会直接转发给对应的容器。所以配置了端口映射之后，我们才可以从外部正常访问到容器内的服务：\n我们也可以直接输入docker ps查看端口映射情况：\n至此，有关容器的网络部分，就到此为止，当然这仅仅是单机下的容器网络操作，在以后的课程中，我们还会进一步学习多主机下的网络配置。\n容器存储管理 #\r前面我们介绍了容器的网络管理，我们现在已经了解了如何配置容器的网络，以及相关的一些原理。还有一个比较重要的部分就是容器的存储，在这一小节我们将深入了解容器的存储管理。\n容器持久化存储 #\r我们知道，容器在创建之后，实际上我们在容器中创建和修改的文件，实际上是被容器的分层机制保存在最顶层的容器层进行操作的，为了保护下面每一层的镜像不被修改，所以才有了这样的CopyOnWrite特性。但是这样也会导致容器在销毁时数据的丢失，当我们销毁容器重新创建一个新的容器时，所有的数据全部丢失，直接回到梦开始的地方。\n在某些情况下，我们可能希望对容器内的某些文件进行持久化存储，而不是一次性的，这里就要用到数据卷（Data Volume）了。\n在开始之前我们先准备一下实验要用到的镜像：\ndocker run -it ubuntu apt update \u0026amp;\u0026amp; apt install -y vim 然后打包为我们一会要使用的镜像：\ndocker commit 我们可以让容器将文件保存到宿主主机上，这样就算容器销毁，文件也会在宿主主机上保留，下次创建容器时，依然可以从宿主主机上读取到对应的文件。如何做到呢？只需要在容器启动时指定即可：\nmkdir test 我们现在用户目录下创建一个新的test目录，然后在里面随便创建一个文件，再写点内容：\nvim test/hello.txt 接着我们就可以将宿主主机上的目录或文件挂载到容器的某个目录上：\ndocker run -it -v ~/test:/root/test ubuntu-volume 这里用到了一个新的参数-v，用于指定文件挂载，这里是将我们刚刚创建好的test目录挂在到容器的/root/test路径上。\n这样我们就可以直接在容器中访问宿主主机上的文件了，当然如果我们对挂载目录中的文件进行编辑，那么相当于编辑的是宿主主机的数据：\nvim /root/test/test.txt 在宿主主机的对应目录下，可以直接访问到我们刚刚创建好的文件。\n接着我们来将容器销毁，看看当容器不复存在时，挂载的数据时候还能保留：\n可以看到，即使我们销毁了容器，在宿主主机上的文件依然存在，并不会受到影响，这样的话，当我们下次创建新的镜像时，依然可以使用这些保存在外面的文件。\n比如我们现在想要部署一个Nginx服务器来代理我们的前端，就可以直接将前端页面保存到宿主主机上，然后通过挂载的形式让容器中的Nginx访问，这样就算之后Nginx镜像有升级，需要重新创建，也不会影响到我们的前端页面。这里我们来测试一下，我们先将前端模板上传到服务器：\nscp Downloads/moban5676.zip 192.168.10.10:~/ 然后在服务器上解压一下：\nunzip moban5676.zip 接着我们就可以启动容器了：\ndocker run -it -v ~/moban5676:/usr/share/nginx/html/ -p 80:80 -d nginx 这里我们将解压出来的目录，挂载到容器中Nginx的默认站点目录/usr/share/nginx/html/（由于挂在后位于顶层，会替代镜像层原有的文件），这样Nginx就直接代理了我们存放在宿主主机上的前端页面，当然别忘了把端口映射到宿主主机上，这里我们使用的镜像是官方的nginx镜像。\n现在我们进入容器将Nginx服务启动：\nsystemctl start nginx 然后通过浏览器访问看看是否代理成功：\n可以看到我们的前端页面直接被代理了，当然如果我们要编写自定义的配置，也是使用同样的方法操作即可。\n注意如果我们在使用-v参数时不指定宿主主机上的目录进行挂载的话，那么就由Docker来自动创建一个目录，并且会将容器中对应路径下的内容拷贝到这个自动创建的目录中，最后挂在到容器中，这种就是由Docker管理的数据卷了（docker managed volume）我们来试试看：\ndocker run -it -v /root/abc ubuntu-volume 注意这里我们仅仅指定了挂载路径，没有指定宿主主机的对应目录，继续创建：\n创建后可以看到root目录下有一个新的abc目录，那么它具体是在宿主主机的哪个位置呢？这里我们依然可以使用inspect命令：\ndocker inspect bold_banzai 可以看到Sorce指向的是/var/lib中的某个目录，我们可以进入这个目录来创建一个新的文件，进入之前记得提升一下权限，权限低了还进不去：\n我们来创一个新的文本文档：\n实际上和我们之前是一样的，也是可以在容器中看到的，当然删除容器之后，数据依然是保留的。当我们不需要使用数据卷时，可以进行删除：\n当然有时候为了方便，可能并不需要直接挂载一个目录上去，仅仅是从宿主主机传递一些文件到容器中，这里我们可以使用cp命令来完成：\n这个命令支持从宿主主机复制文件到容器，或是从容器复制文件到宿主主机，使用方式类似于Linux自带的cp命令。\n容器数据共享 #\r前面我们通过挂载的形式，将宿主主机上的文件直接挂载到容器中，这样容器就可以直接访问到宿主主机上的文件了，并且在容器删除时也不会清理宿主主机上的文件。\n我们接着来看看如何实现容器与容器之间的数据共享，实际上按照我们之前的思路，我们可以在宿主主机创建一个公共的目录，让这些需要实现共享的容器，都挂载这个公共目录：\ndocker run -it -v ~/test:/root/test ubuntu-volume 由于挂载的是宿主主机上的同一块区域，所以内容可以直接在两个容器中都能访问。当然我们也可以将另一个容器挂载的目录，直接在启动容器时指定使用此容器挂载的目录：\ndocker run -it -v ~/test:/root/test --name=data_test ubuntu-volume docker run -it --volumes-from data_test ubuntu-volume 这里使用--volumes-from指定另一个容器（这种用于给其他容器提供数据卷的容器，我们一般称为数据卷容器）\n可以看到，数据卷容器中挂载的内容，在当前容器中也是存在的，当然就算此时数据卷容器被删除，那么也不会影响到这边，因为这边相当于是继承了数据卷容器提供的数据卷，所以本质上还是让两个容器挂载了同样的目录实现数据共享。\n虽然通过上面的方式，可以在容器之间实现数据传递，但是这样并不方便，可能某些时候我们仅仅是希望容器之间共享，而不希望有宿主主机这个角色直接参与到共享之中，此时我们就需要寻找一种更好的办法了。其实我们可以将数据完全放入到容器中，通过构建一个容器，来直接将容器中打包好的数据分享给其他容器，当然本质上依然是一个Docker管理的数据卷，虽然还是没有完全脱离主机，但是移植性就高得多了。\n我们来编写一个Dockerfile：\nFROM ubuntu ADD moban5676.tar.gz /usr/share/nginx/html/ VOLUME /usr/share/nginx/html/ 这里我们使用了一个新的指令ADD，它跟COPY命令类似，也可以复制文件到容器中，但是它可以自动对压缩文件进行解压，这里只需要将压缩好的文件填入即可，后面的VOLUME指令就像我们使用-v参数一样，会创建一个挂载点在容器中：\ncd test tar -zcvf moban5676.tar.gz * mv moban5676.tar.gz .. cd .. 接着我们直接构建：\ndocker build -t data . 现在我们运行一个容器看看：\n可以看到所有的文件都自动解压出来了（除了中文文件名称乱码了之外，不过无关紧要）我们退出容器，可以看到数据卷列表中新增了我们这个容器需要使用的：\n这个位置实际上就是数据存放在当前主机上的位置了，不过是由Docker进行管理而不是我们自定义的。现在我们就可以创建一个新的容器直接继承了：\ndocker run -p 80:80 --volumes-from=data_test -d nginx 访问一下Nginx服务器，可以看到成功代理：\n这样我们就实现了将数据放在容器中进行共享，我们不需要刻意去指定宿主主机的挂载点，而是Docker自行管理，这样就算迁移主机依然可以快速部署。\n容器资源管理 #\r前面我们已经完成Docker的几个主要模块的学习，最后我们来看看如何对容器的资源进行管理。\n容器控制操作 #\r在开始之前，我们还是要先补充一些我们前面没有提到的其他容器命令。\n首先我们的SpringBoot项目在运行是，怎么查看输出的日志信息呢？\ndocker logs test 这里使用log命令来打印容器中的日志信息：\n当然也可以添加-f参数来持续打印日志信息。\n现在我们的容器已经启动了，但是我们想要进入到容器监控容器的情况怎么办呢？我们可以是attach命令来附加到容器启动命令的终端上：\ndocker attach 容器ID/名称 注意现在就切换为了容器内的终端，如果想要退出的话，需要先按Ctrl+P然后再按Ctrl+Q来退出终端，不能直接使用Ctrl+C来终止，这样会直接终止掉Docker中运行的Java程序的。\n退出后，容器依然是处于运行状态的。\n我们也可以使用exec命令在容器中启动一个新的终端或是在容器中执行命令：\ndocker exec -it test bash -it和run命令的操作是一样的，这里执行后，会创建一个新的终端（当然原本的程序还是在正常运行）我们会在一个新的终端中进行交互：\n当然也可以仅仅在容器中执行一条命令：\n执行后会在容器中打开一个新的终端执行命令，并输出结果。\n前面我们还学习了容器的停止操作，通过输入stop命令来停止容器，但是此操作并不会立即停止，而是会等待容器处理善后，那么怎么样才能强制终止容器呢？我们可以直接使用kill命令，相当于给进程发送SIGKILL信号，强制结束。\ndocker kill test 相比stop命令，kill就没那么温柔了。\n有时候可能只是希望容器暂时停止运行，而不是直接终止运行，我们希望在未来的某个时间点，恢复容器的运行，此时就可以使用pause命令来暂停容器：\ndocker pause test 暂停容器后，程序暂时停止运行，无法响应浏览器发送的请求：\n此时处于爱的魔力转圈圈状态，我们可以将其恢复运行，使用unpause命令：\ndocker unpause test 恢复运行后，瞬间就响应成功了。\n物理资源管理 #\r对于一个容器，在某些情况下我们可能并不希望它占据所有的系统资源来运行，我们只希望分配一部分资源给容器，比如只分配给容器2G内存，最大只允许使用2G，不允许再占用更多的内存，此时我们就需要对容器的资源进行限制。\ndocker run -m 内存限制 --memory-swap=内存和交换分区总共的内存限制 镜像名称 其中-m参数是对容器的物理内存的使用限制，而--memory-swap是对内存和交换分区总和的限制，它们默认都是-1，也就是说没有任何的限制（如果在一开始仅指定-m参数，那么交换内存的限制与其保持一致，内存+交换等于-m的两倍大小）默认情况下跟宿主主机一样，都是2G内存，现在我们可以将容器的内存限制到100M试试看，其中物理内存50M，交换内存50M，尝试启动一下SpringBoot程序：\ndocker run -it -m 50M --memory-swap=100M nagocoler/springboot-test:1.0 可以看到，上来就因为内存不足无法启动了：\n当然除了对内存的限制之外，我们也可以对CPU资源进行限额，默认情况下所有的容器都可以平等地使用CPU资源，我们可以调整不同的容器的CPU权重（默认为1024），来按需分配资源，这里需要使用到-c选项，也可以输入全名--cpu-share：\ndocker run -c 1024 ubuntu docker run -c 512 ubuntu 这里容器的CPU权重比例为16比8，也就是2比1（注意多个容器时才会生效），那么当CPU资源紧张时，会按照此权重来分配资源，当然如果CPU资源并不紧张的情况下，依然是有机会使用到全部的CPU资源的。\n这里我们使用一个压力测试工具来进行验证：\ndocker run -c 1024 --name=cpu1024 -it ubuntu docker run -c 512 --name=cpu512 -it ubuntu 接着我们分别进入容器安装stress压力测试工具：\napt update \u0026amp;\u0026amp; apt install -y stress 接着我们分别在两个容器中都启动压力测试工具，产生4个进程不断计算随机数的平方根：\nstress -c 4 接着我们进入top来看看CPU状态（看完之后记得赶紧去kill掉容器，不然CPU拉满很卡的）：\n可以看到权重高的容器中，分配到了更多的CPU资源，而权重低的容器中，只分配到一半的CPU资源。\n当然我们也可以直接限制容器使用的CPU数量：\ndocker run -it --cpuset-cpus=1 ubuntu --cpuset-cpus选项可以直接限制在指定的CPU上运行，比如现在我们的宿主机是2核的CPU，那么就可以分0和1这两个CPU给Docker使用，限制后，只会使用CPU 1的资源了：\n可以看到，4个进程只各自使用了25%的CPU，加在一起就是100%，也就是只能占满一个CPU的使用率。如果要分配多个CPU，则使用逗号隔开：\ndocker run -it --cpuset-cpus=0,1 ubuntu 这样就会使用这两个CPU了：\n当然也可以直接使用--cpus来限制使用的CPU资源数：\ndocker run -it --cpus=1 ubuntu 限制为1后，只能使用一个CPU提供的资源，所以这里加载一起只有一个CPU的资源了。当然还有更精细的--cpu-period 和--cpu-quota，这里就不做介绍了。\n最后我们来看一下对磁盘IO读写性能的限制，我们首先使用dd命令来测试磁盘读写速度：\ndd if=/dev/zero of=/tmp/1G bs=4k count=256000 oflag=direct 可以不用等待跑完，中途Ctrl+C结束就行：\n可以看到当前的读写速度为86.4 MB/s，我们可以通过--device-read/write-bps和--device-read/write-iops参数对其进行限制。\n这里要先说一下区别：\nbps：每秒读写的数据量。 iops：每秒IO的次数。 为了直观，这里我们直接使用BPS作为限制条件：\ndocker run -it --device-write-bps=/dev/sda:10MB ubuntu 因为容器的文件系统是在/dev/sda上的，所以这我们就/dev/sda:10MB来限制对/dev/sda的写入速度只有10MB/s，我们来测试一下看看：\n可以看到现在的速度就只有10MB左右了。\n容器监控 #\r最后我们来看看如何对容器的运行状态进行实时监控，我们现在希望能够对容器的资源占用情况进行监控，该怎么办呢？\n我们可以使用stats命令来进行监控：\ndocker stats 可以实时对容器的各项状态进行监控，包括内存使用、CPU占用、网络I/O、磁盘I/O等信息，当然如果我们限制内存的使用的话：\ndocker run -d -m 200M nagocoler/springboot-test:1.0 可以很清楚地看到限制情况：\n除了使用stats命令来实时监控情况之外，还可以使用top命令来查看容器中的进程：\ndocker top 容器ID/名称 当然也可以携带一些参数，具体的参数与Linux中ps命令参数一致，这里就不多做介绍了。\n但是这样的监控是不是太原始了一点？有没有那种网页面板可以进行实时监控和管理的呢？有的。\n我们需要单独部署一个Docker网页管理面板应用，一般比较常见的有：Portainer，我们这里可以直接通过Docker镜像的方式去部署这个应用程序，搜索一下，发现最新版维护的地址为：https://hub.docker.com/r/portainer/portainer-ce\nCE为免费的社区版本，当然也有BE商业版本，这里我们就直接安装社区版就行了，官方Linux安装教程：https://docs.portainer.io/start/install/server/docker/linux，包含一些安装前需要的准备。\n首先我们需要创建一个数据卷供Portainer使用：\ndocker volume create portainer_data 接着通过官方命令安装启动：\ndocker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest 注意这里需要开放两个端口，一个是8000端口，还有一个是9443端口。\nOK，开启成功，我们可以直接登录后台面板：https://IP:9443/，这里需要HTTPS访问，浏览器可能会提示不安全，无视就行：\n进入后就需要我们进行注册了，这里我们只需输入两次密码即可，默认用户名就是admin，填写完成后，我们就可以开始使用了：\n点击Get Started即可进入到管理页面，我们可以看到目前有一个本地的Docker服务器正在运行：\n我们可以点击进入，进行详细地管理，不过唯一缺点就是没中文，挺难受的，也可以使用非官方的汉化版本：https://hub.docker.com/r/6053537/portainer-ce。\n单机容器编排 #\r最后我们来讲解一下Docker-Compose，它能够对我们的容器进行编排。比如现在我们要在一台主机上部署很多种类型的服务，包括数据库、消息队列、SpringBoot应用程序若干，或是想要搭建一个MySQL集群，这时我们就需要创建多个容器来完成来，但是我们希望能够实现一键部署，这时该怎么办呢？我们就要用到容器编排了，让多个容器按照我们自己的编排进行部署。\n**官方文档：**\rhttps://docs.docker.com/get-started/08_using_compose/，视频教程肯定不可能把所有的配置全部介绍完，所以如果各位小伙伴想要了解更多的配置，有更多需求的话，可以直接查阅官方文档。\n快速开始 #\r在Linux环境下我们需要先安装一下插件：\nsudo apt install docker-compose-plugin 接着输入docker compose version来验证一下是否安装成功。\n这里我们就以部署SpringBoot项目为例，我们继续使用之前打包好的SpringBoot项目，现在我们希望部署这个SpringBoot项目的同时，部署一个MySQL服务器，一个Redis服务器，这时我们SpringBoot项目要运行的整个完整环境，先获取到对应的镜像：\ndocker pull mysql/mysql-server docker pull redis 接着，我们需要在自己的本地安装一下DockerCompose，下载地址：https://github.com/docker/compose/releases，下载自己电脑对应的版本，然后在IDEA中配置：\n下载完成后，将Docker Compose可执行文件路径修改为你存放刚刚下载的可执行文件的路径，Windows直接设置路径就行，MacOS下载之后需要进行下面的操作：\nmv 下载的文件名称 docker-compose sudo chmod 777 docker-compose sudo mv docker-compose /usr/local/bin 配置完成后就可以正常使用了，否则会无法运行，接着我们就可以开始在IDEA中编写docker-compose.yml文件了。\n这里点击右上角的“与服务工具窗口同步”按钮，这样一会就可以在下面查看情况了。\n我们现在就从头开始配置这个文件，现在我们要创建三个服务，一个是MySQL服务器，一个是Redis服务器，还有一个是SpringBoot服务器，需要三个容器来分别运行，首先我们先写上这三个服务：\nversion: \u0026#34;3.9\u0026#34; #首先是版本号，别乱写，这个是和Docker版本有对应的 services: #services里面就是我们所有需要进行编排的服务了 spring: #服务名称，随便起 container_name: app_springboot #一会要创建的容器名称 mysql: container_name: app_mysql redis: container_name: app_redis 这样我们就配置好了一会要创建的三个服务和对应的容器名称，接着我们需要指定一下这些容器对应的镜像了，首先是我们的SpringBoot应用程序，可能我们后续还会对应用程序进行更新和修改，所以这里我们部署需要先由Dockerfile构建出镜像后，再进行部署：\nspring: container_name: app_springboot build: . #build表示使用构建的镜像，.表示使用当前目录下的Dockerfile进行构建 我们这里修改一下Dockerfile，将基础镜像修改为已经打包好JDK环境的镜像：\nFROM adoptopenjdk/openjdk8 COPY target/DockerTest-0.0.1-SNAPSHOT.jar app.jar CMD java -jar app.jar 接着是另外两个服务，另外两个服务需要使用对应的镜像来启动容器：\nmysql: container_name: app_mysql image: mysql/mysql-server:latest #image表示使用对应的镜像，这里会自动从仓库下载，然后启动容器 redis: container_name: app_redis image: redis:latest 还没有结束，我们还需要将SpringBoot项目的端口进行映射，最后一个简单的docker-compose配置文件就编写完成了：\nversion: \u0026#34;3.9\u0026#34; #首先是版本号，别乱写，这个是和Docker版本有对应的 services: #services里面就是我们所有需要进行编排的服务了 spring: #服务名称，随便起 container_name: app_springboot #一会要创建的容器名称 build: . ports: - \u0026#34;8080:8080\u0026#34; mysql: container_name: app_mysql image: mysql/mysql-server:latest redis: container_name: app_redis image: redis:latest 现在我们就可以直接一键部署了，我们点击下方部署按钮：\n看到 Running 4/4 就表示已经部署成功了，我们现在到服务器这边来看看情况：\n可以看到，这里确实是按照我们的配置，创建了3个容器，并且都是处于运行中，可以正常访问：\n如果想要结束的话，我们只需要点击停止就行了：\n当然如果我们不再需要这套环境的话，可以直接点击下方的按钮，将整套编排给down掉，这样的话相对应的容器也会被清理的：\n注意在使用docker-compose部署时，会自动创建一个新的自定义网络，并且所有的容器都是连接到这个自定义的网络里面：\n这个网络默认也是使用bridge作为驱动：\n这样，我们就完成了一个简单的配置，去部署我们的整套环境。\n部署完整项目 #\r前面我们学习了使用docker-compose进行简单部署，但是仅仅只是简单启动了服务，我们现在来将这些服务给连起来。首先是SpringBoot项目，我们先引入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着配置一下数据源，等等，我们怎么知道数据库的默认密码是多少呢？所以我们先配置一下MySQL服务：\nmysql: container_name: app_mysql image: mysql/mysql-server:latest environment: #这里我们通过环境变量配置MySQL的root账号和密码 MYSQL_ROOT_HOST: \u0026#39;%\u0026#39; #登陆的主机，这里直接配置为\u0026#39;%\u0026#39; MYSQL_ROOT_PASSWORD: \u0026#39;123456.root\u0026#39; #MySQL root账号的密码，别设定得太简单了 MYSQL_DATABASE: \u0026#39;study\u0026#39; #在启动时自动创建的数据库 TZ: \u0026#39;Asia/Shanghai\u0026#39; #时区 ports: - \u0026#34;3306:3306\u0026#34; #把端口暴露出来，当然也可以不暴露，因为默认所有容器使用的是同一个网络 有关MySQL的详细配置请查阅：https://registry.hub.docker.com/_/mysql\n接着我们将数据源配置完成：\nspring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://app_mysql:3306/study #地址直接输入容器名称，会自动进行解析，前面已经讲过了 username: root password: 123456.root 然后我们来写点测试的代码吧，这里我们使用JPA进行交互：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; @Data @AllArgsConstructor @NoArgsConstructor @Entity @Table(name = \u0026#34;db_account\u0026#34;) public class Account { @Column(name = \u0026#34;id\u0026#34;) @Id long id; @Column(name = \u0026#34;name\u0026#34;) String name; @Column(name = \u0026#34;password\u0026#34;) String password; } @Repository public interface AccountRepository extends JpaRepository\u0026lt;Account, Long\u0026gt; { } @RestController public class MainController { @Resource AccountRepository repository; @RequestMapping(\u0026#34;/\u0026#34;) public String hello(){ return \u0026#34;Hello World!\u0026#34;; } @GetMapping(\u0026#34;/get\u0026#34;) public Account get(@RequestParam(\u0026#34;id\u0026#34;) long id){ return repository.findById(id).orElse(null); } @PostMapping(\u0026#34;/post\u0026#34;) public Account get(@RequestParam(\u0026#34;id\u0026#34;) long id, @RequestParam(\u0026#34;name\u0026#34;) String name, @RequestParam(\u0026#34;password\u0026#34;) String password){ return repository.save(new Account(id, name, password)); } } 接着我们来修改一下配置文件：\nspring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://app_mysql:3306/study username: root password: 123456.root jpa: database: mysql show-sql: true hibernate: ddl-auto: update #这里自动执行DDL创建表，全程自动化，尽可能做到开箱即用 现在代码编写完成后，我们可以将项目打包了，注意执行我们下面的打包命令，不要进行测试，因为连不上数据库：\nmvn package -DskipTests 重新生成jar包后，我们修改一下docker-compose配置，因为MySQL的启动速度比较慢，我们要一点时间等待其启动完成，如果连接不上数据库导致SpringBoot项目启动失败，我们就重启：\nspring: #服务名称，随便起 container_name: app_springboot #一会要创建的容器名称 build: . ports: - \u0026#34;8080:8080\u0026#34; depends_on: #这里设置一下依赖，需要等待mysql启动后才运行，但是没啥用，这个并不是等到启动完成后，而是进程建立就停止等待 - mysql restart: always #这里配置容器停止后自动重启 然后我们将之前自动构建的镜像删除，等待重新构建：\n现在我们重新部署docker-compos吧：\n当三个服务全部为蓝色时，就表示已经正常运行了，现在我们来测试一下吧：\n接着我们来试试看向数据库传入数据：\n可以看到响应成功，接着我们来请求一下：\n这样，我们的项目和MySQL基本就是自动部署了。\n接着我们来配置一下Redis：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着配置连接信息：\nspring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://app_mysql:3306/study username: root password: 123456.root jpa: database: mysql show-sql: true hibernate: ddl-auto: update redis: host: app_redis //再加两个Redis操作进来 @Resource StringRedisTemplate template; @GetMapping(\u0026#34;/take\u0026#34;) public String take(@RequestParam(\u0026#34;key\u0026#34;) String key){ return template.opsForValue().get(key); } @PostMapping(\u0026#34;/put\u0026#34;) public String put(@RequestParam(\u0026#34;key\u0026#34;) String key, @RequestParam(\u0026#34;value\u0026#34;) String value){ template.opsForValue().set(key, value); return \u0026#34;操作成功！\u0026#34;; } 最后我们来配置一下docker-compose的配置文件：\nredis: container_name: app_redis image: redis:latest ports: - \u0026#34;6379:6379\u0026#34; OK，按照之前的方式，我们重新再部署一下，然后测试：\n这样我们就完成整套环境+应用程序的配置了，我们在部署整个项目时，只需要使用docker-compose配置文件进行启动即可，这样就大大方便了我们的操作，实现开箱即用。甚至我们还可以专门使用一个平台来同时对多个主机进行一次性配置，大规模快速部署，而这些就留到以后的课程中再说吧。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/docker/","section":"Docs","summary":"Docker容器技术 #\rDocker是一门平台级别的技术，涉及的范围很广，所以，在开始之前，请确保你完成：Java SpringBoot 篇（推荐完成SpringCloud篇再来）视频教程及之前全部路线，否则学习会非常吃力，另外推荐额外掌握：《计算机网络》、《操作系统》相关知识。学一样东西不能完全靠记忆来完成，而是需要结合自己所学的基础知识加以理解，一般来说，单凭记忆能够掌握的东西往往是最廉价的。\n**Docker官网：**\rhttps://www.docker.com\n**课前准备：**配置2C2G以上Linux服务器一台，云服务器、虚拟机均可。\n容器技术入门 #\r随着时代的发展，Docker也逐渐走上了历史舞台，曾经我们想要安装一套环境，需要花费一下午甚至一整天来配置和安装各个部分（比如运行我们自己的SpringBoot应用程序，可能需要安装数据库、安装Redis、安装MQ等，各种各样的环境光是安装就要花费很多时间，真的是搞得心态爆炸），而有了Docker之后，我们的程序和环境部署就变得非常简单了，我们只需要将这些环境一起打包成一个镜像。而到服务器上部署时，可以直接下载镜像实现一键部署，是不是很方便？\n包括我们在学习SpringCloud需要配置的各种组件，可能在自己电脑的环境中运行会遇到各种各样的问题（可能由于电脑上各种环境没配置，导致无法运行），而现在只需要下载镜像就能直接运行，所有的环境全部在镜像中配置完成，开箱即用。\n真的有这么神奇吗？我们来试试看。\n环境安装和部署 #\r首先我们还是先将Docker环境搭建好（建议和我同一个环境，不然出了问题只能自己想办法了），这里我们使用：\nUbuntu 22.04 操作系统 Docker分为免费的CE（Community Edition）社区版本和EE（Enterprise Edition）企业级付费版本，所以我们这里选择docker-ce进行安装。官方安装文档：https://docs.docker.com/engine/install/ubuntu/\n首先安装一些工具：\nsudo apt-get install ca-certificates curl gnupg lsb-release 不过在Ubuntu22.","title":"Docker","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/doc/","section":"Docs","summary":"","title":"Docs","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/mq/","section":"Series","summary":"","title":"mq","type":"series"},{"content":"\rMySQL高级 #\r在JavaWeb阶段，我们初步认识了MySQL数据库，包括一些基本操作，比如创建数据库、表、触发器，以及最基本的增删改查、事务等操作。而在此阶段，我们将继续深入学习MySQL，了解它的更多高级玩法，也相当于进行复习。\n函数 #\r其实函数我们在之前已经接触到一部分了，在JavaWeb阶段，我们了解了聚集函数，聚集函数一般用作统计，包括：\ncount([distinct]*) 统计所有的行数（distinct表示去重再统计，下同） count([distinct]列名) 统计某列的值总和 sum([distinct]列名) 求一列的和（注意必须是数字类型的） avg([distinct]列名) 求一列的平均值（注意必须是数字类型） max([distinct]列名) 求一列的最大值 min([distinct]列名) 求一列的最小值 比如我们需要计算某个表一共有多少行：\nSELECT COUNT(*) FROM student 通过使用COUNT聚集函数，就可以快速统计并得到结果，比如我们想计算某一列上所有数字的和：\nSELECT SUM(sid) FROM student 通过SUM聚集函数，就可以快速计算每一列的和，实际上这些函数都是由系统提供的函数，我们可以直接使用。\n本版块我们会详细介绍各类系统函数以及如何编写自定义函数。\n系统函数 #\r系统为我们提供的函数也是非常实用的，我们将会分为几个类型进行讲解。\n字符串函数 #\r处理字符串是一个比较重要的内容，我们可以使用字符串函数来帮助我们快速处理字符串，其中常用比如用于字符串分割的函数有：\nsubstring(字符串, 起始位置, 结束位置) 同Java中String类的substring一致，但是注意下标是从1开始，下同 left(字符串, 长度) 从最左边向右截取字符串 right(字符串, 长度) 从最右边向左截取字符串 比如我们只想获取所有学生姓名的第二个字，那么可以像这样写：\nSELECT SUBSTRING(name, 2, 2) FROM student 比如我们想获取所有学生姓名的第一个字，可以像这样写：\nSELECT LEFT(name, 1) FROM student 我们还可以利用字符串函数来快速将所有的字母转换为大写字母或是快速转换为小写字母：\nupper(字符串) 字符串中的所有字母转换为大写字母 lower(字符串) 字符串中的所有字母转换为小写字母 比如我们希望将一个字符串所有字符专为大写：\nSELECT UPPER(\u0026#39;abcdefg\u0026#39;) 我们也可以像Java中那样直接对字符串中的内容进行替换：\nreplace(字符串, 原文, 替换文) 同Java中String的replace效果 比如现在我们希望将查询到的所有同学的名称中的小全部替换大：\nSELECT REPLACE(`name`, \u0026#39;小\u0026#39;, \u0026#39;大\u0026#39;) FROM student 字符串也支持进行拼接，系统提供了字符串的拼接函数：\nconcat(字符串1, 字符串2) 连接两个字符串 比如我们希望将查询到的所有同学的名称最后都添加一个子字：\nSELECT concat(name, \u0026#39;子\u0026#39;) FROM student 最后就是计算字符串的长度：\nlength(字符串) 获取字符串长度（注意如果使用的是UTF-8编码格式，那么一个汉字占3字节，数字和字母占一个字节） 比如我们要获取所有人名字的长度：\nSELECT LENGTH(`name`) FROM student 日期函数 #\rMySQL提供的日期函数也非常实用，我们可以快速对日期进行操作，比如我们想要快速将日期添加N天，就可以使用：\ndate_add(日期, interval 增量 单位) 比如我们希望让2022-1-1向后5天：\nSELECT DATE_ADD(\u0026#39;2022-1-1\u0026#39;,INTERVAL 5 day) 同理，向前1年：\nSELECT DATE_ADD(\u0026#39;2022-1-1\u0026#39;,INTERVAL -1 year) 单位有：year（年）、month（月）、day（日）、hour（小时）、minute（分钟）、second（秒）\n我们还可以快速计算日期的间隔天数：\ndatediff(日期1, 日期2) 比如我们想计算2022年的2月有多少天：\nSELECT DATEDIFF(\u0026#39;2022-3-1\u0026#39;,\u0026#39;2022-2-1\u0026#39;) 如果我们想快速获取当前时间的话，可以使用这些：\ncurdate() 当前的日期 curtime() 当前的时间 now() 当前的日期+时间 此函数之前我们在编写实战项目的时候已经使用过了，这里就不演示了。我们也可以单独获取时间中的某个值：\nday(日期) 获取日期是几号 month(日期) 获取日期是几月 year(日期) 获取日期是哪一年 比如我们想获取今天是几号：\nSELECT DAY(NOW()) 数学函数 #\r数学函数比较常规，基本与Java的Math工具类一致，这里列出即可，各位可以自行尝试：\nabs(x) 求x的绝对值 ceiling(x) x向上取整 floor(x) x向下取整 round(x, 精度) x取四舍五入，遵循小数点精度 exp(x) e的x次方 rand() 0-1之间的随机数 log(x) x的对数 pi() π power(x, n) x的n次方 sqrt(x) x的平方根 sin(x) cos(x) tan(x) 三角函数（貌似没有arctan这类反函数？） 类型转换函数 #\rMySQL的类型转换也分为隐式类型转换和显示类型转换，首先我们来看看隐式类型转换：\nSELECT 1+\u0026#39;2\u0026#39; 虽然这句中既包含了数字和字符，但是字符串会被进行隐式转换（注意这里并不是按照字符的ASCII码转换，而是写的多少表示多少）所以最后得到的就是1+2的结果为3\nSELECT CONCAT(1, \u0026#39;2\u0026#39;) 这里因为需要传入字符串类型的数据，但是我们给的是1这个数字，因此这里也会发生隐式类型转换，1会被直接转换为字符串的'1\u0026rsquo;，所以这里得到的结果是'12'\n在某些情况下，我们可能需要使用强制类型转换来将得到的数据转换成我们需要的数据类型，这时就需要用到类型转换函数了，MySQL提供了：\ncast(数据 as 数据类型) 数据类型有以下几种：\nBINARY[(N)] ：二进制字符串，转换后长度小于N个字节 CHAR[(N)] ：字符串，转换后长度小于N个字符 DATE ：日期 DATETIME ：日期时间 DECIMAL[(M[,N])] ：浮点数，M为数字总位数(包括整数部分和小数部分)，N为小数点后的位数 SIGNED [INTEGER] ：有符号整数 TIME ：时间 UNSIGNED [INTEGER] ：无符号整数 比如我们现在需要将一个浮点数转换为一个整数：\nSELECT CAST(pi() AS SIGNED) 我们还可以将字符串转换为数字，会自动进行扫描，值得注意的是一旦遇到非数字的字符，会停止扫描：\nSELECT CAST(\u0026#39;123abc456\u0026#39; as SIGNED) 除了cast以外还有convert函数，功能比较相似，这里就不做讲解了。\n流程控制函数 #\rMySQL还为我们提供了很多的逻辑判断函数，比如：\nif(条件表达式, 结果1, 结果2) 与Java中的三目运算符一致 a \u0026gt; b ? \u0026ldquo;AAA\u0026rdquo; : \u0026ldquo;BBB\u0026rdquo; ifnull(值1, 值2) 如果值1为NULL则返回值2，否则返回值1 nullif(值1, 值2) 如果值1与值2相等，那么返回NULL isnull(值) 判断值是否为NULL 比如现在我们想判断：\nSELECT IF(1 \u0026lt; 0,\u0026#39;lbwnb\u0026#39;,\u0026#39;yyds\u0026#39;) 通过判断函数，我们就可以很方便地进行一些条件判断操作。\n除了IF条件判断，我们还可以使用类似Switch一样的语句完成多分支结构：\nSELECT CASE 2 WHEN 1 THEN 10 ELSE 5 END; 我们也可以将自定义的判断条件放入When之后，它类似于else-if：\nSELECT CASE WHEN 3\u0026gt;5 THEN 10 WHEN 0\u0026lt;1 THEN 11 ELSE 5 END; 还有一个类似于Java中的Thread.sleep的函数，以秒为单位：\nSELECT sleep(10); 有关MySQL8.0新增的窗口函数这里暂时不做介绍。\n自定义函数 #\r除了使用系统为我们提供的函数以外，我们也可以自定义函数，并使用我们自定义的函数进行数据处理，唯一比较麻烦的就是函数定义后不能修改，只能删了重新写。\n基本语法 #\rMySQL的函数与Java中的方法类似，也可以添加参数和返回值，可以通过CREATE FUNCTION创建函数：\nCREATE FUNCTION test() RETURNS INT BEGIN RETURN 666; END 定义函数的格式为：\ncreate function 函数名称([参数列表]) returns 返回值类型 begin 和 end 之间写函数的其他逻辑，begin和end就相当于Java中的花括号{ ... } return后紧跟返回的结果 添加参数也很简单，我们只需要在函数名称括号中添加即可，注意类型需要写在参数名称后面：\nCREATE FUNCTION test(i INT) RETURNS INT BEGIN RETURN i * i; END 我们可以在BEGIN和RETURN之间编写一些其他的逻辑，比如我们想要定义一个局部变量，并为其赋值：\nBEGIN DECLARE a INT; SET a = 10; RETURN i * i * a; END 定义局部变量的格式为：\ndeclare 变量名称 变量类型 [, \u0026hellip;] declare 变量名称 变量类型 default 默认值 为变量赋值的格式为：\nset 变量名称 = 值 我们还可以在函数内部使用select语句，它可以直接从表中读取数据，并可以结合into关键字将查询结果赋值给变量：\nBEGIN DECLARE a INT; -- select into from 语句 SELECT COUNT(*) INTO a FROM student; RETURN a; END 流程控制 #\r接着我们来看一下如何使用流程控制语句，其中最关键的就是IF判断语句：\nBEGIN DECLARE a INT DEFAULT 10; IF a \u0026gt; 10 THEN RETURN 1; ELSE RETURN 2; END IF; END IF分支语句的格式为：\nif 判断条件 then \u0026hellip; else if 判断条件 then \u0026hellip;. else \u0026hellip; end if; 我们可以结合exists关键字来判断是否为NULL：\nBEGIN DECLARE a INT DEFAULT 0; -- IF EXISTS(SELECT * FROM student WHERE sid = 100) THEN IF NOT EXISTS(SELECT * FROM student WHERE sid = 100) THEN SET a = 10; END IF; RETURN a; END 我们也可以在函数中使用switch语句：\nBEGIN DECLARE a INT DEFAULT 10; CASE a WHEN 10 THEN RETURN 2; ELSE RETURN 1; END CASE; END SWITCH分支语句的格式为：\ncase 变量 when 具体值或是布尔表达式 then \u0026hellip; when * then \u0026hellip; else \u0026hellip; end case; 与Java不同的是，它支持使用布尔表达式：\nBEGIN DECLARE a INT DEFAULT 10; CASE WHEN 1 \u0026lt; 5 THEN SET a = 5; ELSE SET a = 10; END CASE; RETURN a; END 我们以类似于elseif的形式进行判断，其实和上面直接使用是一样的。\n我们接着来看循环语句，MySQL提供了三种循环语句，其中第一种是WHILE语句：\nBEGIN DECLARE a INT DEFAULT 10; WHILE a \u0026lt; 11 DO SET a = a + 1; END WHILE; RETURN a; END 格式为：\nwhile 循环条件 do \u0026hellip; end while; 我们接着来看第二种循环语句，LOOP循环：\nBEGIN DECLARE a INT DEFAULT 10; lp1: LOOP SET a = a - 1; IF a = 0 THEN LEAVE lp1; END IF; END LOOP lp1; RETURN a; END 相比while语句，我们可以使用LEAVE精准控制结束哪个循环，有点类似于goto语句：\nBEGIN DECLARE a INT DEFAULT 0; lp1: LOOP lp2: LOOP SET a = a + 1; IF a \u0026gt; 5 THEN LEAVE lp1; END IF; END LOOP lp2; END LOOP lp1; RETURN a; END 类似于Java中的goto写法（在JavaSE阶段已经讲解过）：\npublic static void main(String[] args) { int a = 0; lp1: while (true){ lp2: while (true){ a++; if(a \u0026gt; 5) break lp1; } } System.out.println(a); } 它的语法格式如下：\n循环名称 loop \u0026hellip;(可以插入leave语句结束) end loop 循环名称; 接着我们来看最后一种循环语句，repeat语句：\nBEGIN DECLARE a INT DEFAULT 0; REPEAT SET a = a + 1; UNTIL a \u0026gt; 0 END REPEAT; RETURN a; END 它类似于Java中的do-while循环语句，它会先去执行里面的内容，再进行判断，格式为：\nrepeat \u0026hellip; until 结束循环条件 end repeat; 全局变量 #\r某些情况下，我们可以直接在一次会话中直接定义变量并使用，这时它并不是位于函数内的，这就是全局变量，它无需预先定义，直接使用即可：\nset @x = 10; 我们可以将全局变量作为参数传递给函数：\nselect test(@x); 除了我们自己定义的全部变量以外，系统默认也有很多的变量，因此我们自己定义的变量称为用户变量，系统默认变量称为系统变量。查看系统变量的命令为：\nshow GLOBAL VARIABLES 存储过程 #\r存储过程是一个包括多条SQL语句的集合，专用于特定表的特定操作，比如我们之前实战项目中的创建用户，那么我们就需要一次性为两张表添加数据，但是如果不使用Java，而是每次都去使用SQL命令来完成，就需要手动敲两次命令，非常麻烦，因此我们可以提前将这些操作定义好，预留出需要填写数据的位置，下次输入参数直接调用即可。\n这里很容易与函数搞混淆，存储过程也是执行多条SQL语句，但是它们的出发点不一样，函数是专用于进行数据处理，并将结果返回给调用者，它更多情况下是一条SQL语句的参与者，无法直接运行，并且不涉及某个特定表：\nselect count(*) from student; 而存储过程是多条SQL语句的执行者，这是它们的本质区别。\n定义存储过程与定义函数极为相似，它也可以包含参数，函数中使用的语句这里也能使用，但是它没有返回值：\nCREATE PROCEDURE lbwnb(`name` VARCHAR(20), pwd VARCHAR(255)) BEGIN INSERT INTO users(username, `password`) VALUES(`name`, pwd); END 我们可以在存储过程中编写多条SQL语句，但是注意，MySQL的存储过程不具有原子性，当出现错误时，并不会回滚之前的操作，因此需要我们自己来编写事务保证原子性。\n接着我们来看看如何执行存储过程：\nCALL lbwnb(\u0026#39;111\u0026#39;, \u0026#39;2222\u0026#39;) 通过使用call来执行一个存储过程，如果存储过程有参数，那么还需要填写参数。\n比如现在我们想要实现查询用户表，如果包含用户test那么就删除用户，如果不包含，就添加用户：\nCREATE PROCEDURE `lbwnb`() BEGIN IF NOT EXISTS(SELECT * FROM users WHERE username = \u0026#39;test\u0026#39;) THEN INSERT INTO users(username, `password`) VALUES(\u0026#39;test\u0026#39;, \u0026#39;123456\u0026#39;); ELSE DELETE FROM users WHERE username = \u0026#39;test\u0026#39;; END IF; END 这里其实只需要一个简单的IF判断即可实现。\n那么如果我们希望遍历一个SELECT语句查询的结果呢？我们可以使用游标来完成：\nBEGIN DECLARE id INT; DECLARE `name` VARCHAR(10); DECLARE sex VARCHAR(5); DECLARE cur CURSOR FOR SELECT * FROM student; OPEN cur; WHILE TRUE DO FETCH cur INTO id, `name`, sex; SELECT id, `name`, sex; END WHILE; CLOSE cur; END 游标的使用分为4个步骤：\nDECLARE 游标名称 CURSOR FOR 查询结果 - 定义游标 OPEN cur - 开启游标 FETCH 游标名称 INTO 存储结果的变量 - 从顶部开始，每执行一次，向下移动，如果已经在最底部，则触发异常 CLOSE cur - 关闭游标 我们这里利用了一个while循环来多次通过游标获取查询结果，但是最后是因为出现异常才退出的，这样会导致之后的代码就无法继续正常运行了。\n我们接着来看如何处理异常：\nBEGIN DECLARE id INT; DECLARE `name` VARCHAR(10); DECLARE sex VARCHAR(5); DECLARE score INT; DECLARE a INT DEFAULT 0; DECLARE cur CURSOR FOR SELECT * FROM student; -- 必须在游标定义之后编写 DECLARE CONTINUE HANDLER FOR 1329 SET a = 1; OPEN cur; WHILE a = 0 DO FETCH cur INTO id, `name`, sex, score; SELECT id, `name`, sex, score; END WHILE; CLOSE cur; SELECT 1; END 我们可以声明一个异常处理器（句柄），格式如下：\ndeclear (continue/exit) handler for 异常名称(ID) 做点什么 我们还可以限定存储过程的参数传递，比如我们只希望用户给我们一个参数用于接收数据，而不是值传递，我们可以将其设定为OUT类型：\nCREATE PROCEDURE `lbwnb`(OUT a INT) BEGIN SELECT a; SET a = 100; END 所有的参数默认为IN类型，也就是只能作为传入参数，无法为其赋值，而这里讲参数设定为OUT类型，那么参数无法将值传入，而只能被赋值。\n如果我们既希望参数可以传入也可以被重新赋值，我们可以将其修改为INOUT类型。\n存储引擎 #\r存储引擎就像我们电脑中的CPU，它是整个MySQL最核心的部分，数据库中的数据如何存储，数据库能够支持哪些功能，我们的增删改查请求如何执行，都是由存储引擎来决定的。\n我们可以大致了解一下以下三种存储引擎：\nMyISAM： MySQL5.5之前的默认存储引擎，在插入和查询的情况下性能很高，但是它不支持事务，只能添加表级锁。 InnoDB： MySQL5.5之后的默认存储引擎，它支持ACID事务、行级锁、外键，但是性能比不过MyISAM，更加消耗资源。 Memory： 数据都存放在内存中，数据库重启或发生崩溃，表中的数据都将消失。 我们可以使用下面的命令来查看MySQL支持的存储引擎：\nshow engines; 在创建表时，我们也可以为表指定其存储引擎。\n我们还可以在配置文件中修改默认的存储引擎，在Windows 11系统下，MySQL的配置文件默认放在C:\\ProgramData\\MySQL\\MySQL Server 5.7中，注意ProgramData是个隐藏文件夹。\n索引 #\r注意： 本小节会涉及数据结构与算法相关知识。\n索引就好像我们书的目录，每本书都有一个目录用于我们快速定位我们想要的内容在哪一页，索引也是，通过建立索引，我们就可以根据索引来快速找到想要的一条记录，大大提高查询效率。\n本版块我们会详细介绍索引的几种类型，以及索引的底层存储原理。\n单列索引 #\r单列索引只针对于某一列数据创建索引，单列索引有以下几种类型：\nNORMAL： 普通的索引类型，完完全全相当于一本书的目录。 UNIQUE： 唯一索引，我们之前已经用过了，一旦建立唯一索引，那么整个列中将不允许出现重复数据。每个表的主键列，都有一个特殊的唯一索引，叫做Primary Key，它不仅仅要求不允许出现重复，还要求不能为NULL，它还可以自动递增。每张表可以有多个唯一索引，但是只能有一个Primary索引。 SPATIAL： 空间索引，空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON，不是很常用，这里不做介绍。 FULLTEXT： 全文索引（MySQL 5.6 之后InnoDB才支持），它是模糊匹配的一种更好的解决方案，它的效率要比使用like %更高，并且它还支持多种匹配方式，灵活性也更加强大。只有字段的数据类型为 char、varchar、text 及其系列才可以建全文索引。 我们来看看如何使用全文索引，首先创建一张用于测试全文索引的表：\nCREATE TABLE articles ( id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY, title VARCHAR(200), body TEXT, FULLTEXT (body)); INSERT INTO articles VALUES (NULL,\u0026#39;MySQL Tutorial\u0026#39;, \u0026#39;DBMS stands for DataBase ...\u0026#39;), (NULL,\u0026#39;How To Use MySQL Efficiently\u0026#39;, \u0026#39;After you went through a ...\u0026#39;), (NULL,\u0026#39;Optimising MySQL\u0026#39;,\u0026#39;In this tutorial we will show ...\u0026#39;), (NULL,\u0026#39;1001 MySQL Tricks\u0026#39;,\u0026#39;1. Never run mysqld as root. 2. ...\u0026#39;), (NULL,\u0026#39;MySQL vs. YourSQL\u0026#39;, \u0026#39;In the following database comparison ...\u0026#39;), (NULL,\u0026#39;MySQL Security\u0026#39;, \u0026#39;When configured properly, MySQL ...\u0026#39;); 最后我们使用全文索引进行模糊匹配：\nSELECT * FROM articles WHERE MATCH (body) AGAINST (\u0026#39;database\u0026#39;); 注意全文索引如何定义字段的，match中就必须是哪些字段，against中定义需要模糊匹配的字符串，我们用作查找的字符串实际上是被分词之后的结果，如果进行模糊匹配的不是一个词语，那么会查找失败，但是它的效率远高于以下这种写法：\nSELECT * FROM articles WHERE body like \u0026#39;%database%\u0026#39;; 组合索引 #\r组合索引实际上就是将多行捆绑在一起，作为一个索引，它同样支持以上几种索引类型，我们可以在Navicat中进行演示。\n注意组合索引在进行匹配时，遵循最左原则。\n我们可以使用explain语句（它可以用于分析select语句的执行计划，也就是MySQL到底是如何在执行某条select语句的）来分析查询语句到底有没有通过索引进行匹配。\nexplain select * from student where name = \u0026#39;小王\u0026#39;; 得到的结果如下：\nselect_type：查询类型，上面的就是简单查询（SIMPLE） table：查询的表 type：MySQL决定如何查找对应的记录，效率从高到低：system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; all possible_keys：执行查询时可能会用到的索引 key：实际使用的索引 key_len：Mysql在索引里使用的字节数，字段的最大可能长度 rows：扫描的行数 extra：附加说明 索引底层原理 #\r在了解完了索引的类型之后，我们接着来看看索引是如何实现的。\n既然我们要通过索引来快速查找内容，那么如何设计索引就是我们的重点内容，因为索引是存储在硬盘上的，跟我们之前使用的HashMap之类的不同，它们都是在内存中的，但是硬盘的读取速度远小于内存的速度，每一次IO操作都会耗费大量的时间，我们也不可能把整个磁盘上的索引全部导入内存，因此我们需要考虑尽可能多的减少IO次数，索引的实现可以依靠两种数据结构，一种是我们在JavaSE阶段已经学习过的Hash表，还有一种就是B-Tree。\n我们首先来看看哈希表，实际上就是计算Hash值来快速定位：\n通过对Key进行散列值计算，我们可以直接得到对应数据的存放位置，它的查询效率能够达到O(1)，但是它也存在一定的缺陷：\nHash索引仅仅能满足“=”，“in”查询条件，不能使用范围查询。 Hash碰撞问题。 不能用部分索引键来搜索，因为组合索引在计算哈希值的时候是一起计算的。 那么，既然要解决这些问题，我们还有一种方案就是使用类似于二叉树那样的数据结构来存储索引，但是这样相比使用Hash索引，会牺牲一定的读取速度。\n但是这里并没有使用二叉树，而是使用了BTree，它是专门为磁盘数据读取设计的一种度为n的查找树：\n树中每个结点最多含有m个孩子（m \u0026gt;= 2）\n除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子。\n若根结点不是叶子结点，则至少有2个孩子。\n所有叶子结点都出现在同一层。\n每个非终端结点中包含有n个键值信息： (P1，K1，P2，K2，P3，\u0026hellip;\u0026hellip;，Kn，Pn+1)。其中：\nKi (i=1\u0026hellip;n)为键值，且键值按顺序升序排序K(i-1)\u0026lt; Ki。 Pi为指向子树根的结点，且指针P(i)指向的子树中所有结点的键值均小于Ki，但都大于K(i-1)。 键值的个数n必须满足： [ceil(m / 2)-1] \u0026lt;= n \u0026lt;= m-1。 比如现在我们要对键值为10的记录进行查找，过程如下：\n读取根节点数据（目前进行了一次IO操作） 根据根节点数据进行判断得到10\u0026lt;17，因为P1指向的子树中所有值都是小于17的，所以这时我们将P1指向的节点读取（目前进行了两次IO操作） 再次进行判断，得到8\u0026lt;10\u0026lt;12，因为P2指向的子树中所有的值都是小于12大于8的，所以这时读取P2指向的节点（目前进行了三次IO操作） 成功找到。 我们接着来看，虽然BTree能够很好地利用二叉查找树的思想大幅度减少查找次数，但是它的查找效率还是很低，因此它的优化版本B+Tree诞生了，它拥有更稳定的查询效率和更低的IO读取次数：\n我们可以发现，它和BTree有一定的区别：\n有n棵子树的结点中含有n个键值，BTree只有n-1个。 所有的键值信息只在叶子节点中包含，非叶子节点仅仅保存子节点的最小（或最大）值，和指向叶子节点的指针，这样相比BTree每一个节点在硬盘中存放了更少的内容（没有键值信息了） 所有叶子节点都有一个根据大小顺序指向下一个叶子节点的指针Q，本质上数据就是一个链表。 这样，读取IO的时间相比BTree就减少了很多，并且查询任何键值信息都需要完整地走到叶子节点，保证了查询的IO读取次数一致。因此MySQL默认选择B+Tree作为索引的存储数据结构。\n这是MyISAM存储引擎下的B+Tree实现：\n这是InnoDB存储引擎下的B+Tree实现：\nInnoDB与MyISAM实现的不同之处：\n数据本身就是索引的一部分（所以这里建议主键使用自增） 非主键索引的数据实际上存储的是对应记录的主键值（因此InnoDB必须有主键，若没有也会自动查找替代） 锁机制 #\r在JavaSE的学习中，我们在多线程板块首次用到了锁机制，当我们对某个方法或是某个代码块加锁后，除非锁的持有者释放当前的锁，否则其他线程无法进入此方法或是代码块，我们可以利用锁机制来保证多线程之间的安全性。\n在MySQL中，就很容易出现多线程同时操作表中数据的情况，如果要避免潜在的并发问题，那么我们可以使用之前讲解的事务隔离级别来处理，而事务隔离中利用了锁机制。\n读未提交(Read Uncommitted)：能够读取到其他事务中未提交的内容，存在脏读问题。 读已提交(Read Committed RC)：只能读取其他事务已经提交的内容，存在不可重复读问题。 可重复读(Repeated Read RR)：在读取某行后不允许其他事务操作此行，直到事务结束，但是依然存在幻读问题。 串行读(Serializable)：一个事务的开始必须等待另一个事务的完成。 我们可以切换隔离级别分别演示一下：\nset session transaction isolation level read uncommitted; 在RR级别下，MySQL在一定程度上解决了幻读问题：\n在快照读（不加锁）读情况下，mysql通过mvcc来避免幻读。 在当前读（加锁）读情况下，mysql通过next-key来避免幻读。 MVCC，全称 Multi-Version Concurrency Control ，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n读锁和写锁 #\r从对数据的操作类型上来说，锁分为读锁和写锁：\n读锁： 也叫共享锁，当一个事务添加了读锁后，其他的事务也可以添加读锁或是读取数据，但是不能进行写操作，只能等到所有的读锁全部释放。 写锁： 也叫排他锁，当一个事务添加了写锁后，其他事务不能读不能写也不能添加任何锁，只能等待当前事务释放锁。 全局锁、表锁和行锁 #\r从锁的作用范围上划分，分为全局锁、表锁和行锁：\n全局锁： 锁作用于全局，整个数据库的所有操作全部受到锁限制。 表锁： 锁作用于整个表，所有对表的操作都会收到锁限制。 行锁： 锁作用于表中的某一行，只会通过锁限制对某一行的操作（仅InnoDB支持） 全局锁 #\r我们首先来看全局锁，它作用于整个数据库，我们可以使用以下命令来开启读全局锁：\nflush tables with read lock; 开启后，整个数据库被上读锁，我们只能去读取数据，但是不允许进行写操作（包括更新、插入、删除等）一旦执行写操作，会被阻塞，直到锁被释放，我们可以使用以下命令来解锁：\nunlock tables; 除了手动释放锁之外，当我们的会话结束后，锁也会被自动释放。\n表锁 #\r表锁作用于某一张表，也是MyISAM和InnoDB存储引擎支持的方式，我们可以使用以下命令来为表添加锁：\nlock table 表名称 read/write; 在我们为表添加写锁后，我们发现其他地方是无法访问此表的，一律都被阻塞。\n行锁 #\r表锁的作用范围太广了，如果我们仅仅只是对某一行进行操作，那么大可不必对整个表进行加锁，因此InnoDB支持了行锁，我们可以使用以下命令来对某一行进行加锁：\n-- 添加读锁（共享锁） select * from ... lock in share mode; -- 添加写锁（排他锁） select * from ... for update; 使用InnoDB的情况下，在执行更新、删除、插入操作时，数据库也会自动为所涉及的行添加写锁（排他锁），直到事务提交时，才会释放锁，执行普通的查询操作时，不会添加任何锁。使用MyISAM的情况下，在执行更新、删除、插入操作时，数据库会对涉及的表添加写锁，在执行查询操作时，数据库会对涉及的表添加读锁。\n提问： 当我们不使用id进行选择，行锁会发生什么变化？（行锁升级）\n记录锁、间隙锁和临键锁 #\r我们知道InnoDB支持使用行锁，但是行锁比较复杂，它可以继续分为多个类型。\n记录锁 #\r（Record Locks）记录锁, 仅仅锁住索引记录的一行，在单条索引记录上加锁。Record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么innodb会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。所以说当一条sql没有走任何索引时，那么将会在每一条聚合索引后面加写锁，这个类似于表锁，但原理上和表锁应该是完全不同的。\n间隙锁 #\r（Gap Locks）仅仅锁住一个索引区间（开区间，不包括双端端点）。在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。比如在 1、2中，间隙锁的可能值有 (-∞, 1)，(1, 2)，(2, +∞)，间隙锁可用于防止幻读，保证索引间的不会被插入数据。\n临键锁 #\r（Next-Key Locks）Record lock + Gap lock，左开右闭区间。默认情况下，InnoDB正是使用Next-key Locks来锁定记录（如select … for update语句）它还会根据场景进行灵活变换：\n场景 转换 使用唯一索引进行精确匹配，但表中不存在记录 自动转换为 Gap Locks 使用唯一索引进行精确匹配，且表中存在记录 自动转换为 Record Locks 使用非唯一索引进行精确匹配 不转换 使用唯一索引进行范围匹配 不转换，但是只锁上界，不锁下界 https://zhuanlan.zhihu.com/p/48269420\n———————————————— 版权声明：本文为柏码知识库版权所有，禁止一切未经授权的转载、发布、出售等行为，违者将被追究法律责任。 原文链接：https://www.itbaima.cn/document/vkpmw9wbej21nei6\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/mysql/","section":"Docs","summary":"MySQL高级 #\r在JavaWeb阶段，我们初步认识了MySQL数据库，包括一些基本操作，比如创建数据库、表、触发器，以及最基本的增删改查、事务等操作。而在此阶段，我们将继续深入学习MySQL，了解它的更多高级玩法，也相当于进行复习。\n函数 #\r其实函数我们在之前已经接触到一部分了，在JavaWeb阶段，我们了解了聚集函数，聚集函数一般用作统计，包括：\ncount([distinct]*) 统计所有的行数（distinct表示去重再统计，下同） count([distinct]列名) 统计某列的值总和 sum([distinct]列名) 求一列的和（注意必须是数字类型的） avg([distinct]列名) 求一列的平均值（注意必须是数字类型） max([distinct]列名) 求一列的最大值 min([distinct]列名) 求一列的最小值 比如我们需要计算某个表一共有多少行：\nSELECT COUNT(*) FROM student 通过使用COUNT聚集函数，就可以快速统计并得到结果，比如我们想计算某一列上所有数字的和：\nSELECT SUM(sid) FROM student 通过SUM聚集函数，就可以快速计算每一列的和，实际上这些函数都是由系统提供的函数，我们可以直接使用。","title":"Mysql","type":"doc"},{"content":"\rNetty框架 #\r前面我们学习了Java为我们提供的NIO框架，提供使用NIO提供的三大组件，我们就可以编写更加高性能的客户端/服务端网络程序了，甚至还可以自行规定一种通信协议进行通信。\nNIO框架存在的问题 #\r但是之前我们在使用NIO框架的时候，还是发现了一些问题，我们先来盘点一下。\n客户端关闭导致服务端空轮询 #\r可能在之前的实验中，你发现了这样一个问题：\n当我们的客户端主动与服务端断开连接时，会导致READ事件一直被触发，也就是说selector.select()会直接通过，并且是可读的状态，但是我们发现实际上读到是数据是一个空的（上面的图中在空轮询两次后抛出异常了，也有可能是无限的循环下去）所以这里我们得稍微处理一下：\n} else if(key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); //这里我们需要判断一下，如果read操作得到的结果是-1，那么说明服务端已经断开连接了 if(channel.read(buffer) \u0026lt; 0) { System.out.println(\u0026#34;客户端已经断开连接了：\u0026#34;+channel.getRemoteAddress()); channel.close(); //直接关闭此通道 continue; //继续进行选择 } buffer.flip(); System.out.println(\u0026#34;接收到客户端数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); channel.write(ByteBuffer.wrap(\u0026#34;已收到！\u0026#34;.getBytes())); } 这样，我们就可以在客户端主动断开时关闭连接了：\n当然，除了这种情况可能会导致空轮询之外，实际上还有一种可能，这种情况是NIO框架本身的BUG：\nwhile (true) { int count = selector.select(); //由于底层epoll机制的问题，导致select方法可能会一直返回0，造成无限循环的情况。 System.out.println(\u0026#34;监听到 \u0026#34;+count+\u0026#34; 个事件\u0026#34;); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); 详细请看JDK官方BUG反馈：\nJDK-6670302 : (se) NIO selector wakes up with 0 selected keys infinitely JDK-6403933 : (se) Selector doesn\u0026rsquo;t block on Selector.select(timeout) (lnx) 本质原因也是因为客户端的主动断开导致：\nThis is an issue with poll (and epoll) on Linux. If a file descriptor for a connected socket is polled with a request event mask of 0, and if the connection is abruptly terminated (RST) then the poll wakes up with the POLLHUP (and maybe POLLERR) bit set in the returned event set. The implication of this behaviour is that Selector will wakeup and as the interest set for the SocketChannel is 0 it means there aren\u0026rsquo;t any selected events and the select method returns 0.\n这个问题本质是与操作系统有关的，所以JDK一直都认为是操作系统的问题，不应该由自己来处理，所以这个问题在当时的好几个JDK版本都是存在的，这是一个很严重的空转问题，无限制地进行空转操作会导致CPU资源被疯狂消耗。\n不过，这个问题，却被Netty框架巧妙解决了，我们后面再说。\n粘包/拆包问题 #\r除了上面的问题之外，我们接着来看下一个问题。\n我们在计算机网络这门课程中学习过，操作系统通过TCP协议发送数据的时候，也会先将数据存放在缓冲区中，而至于什么时候真正地发出这些数据，是由TCP协议来决定的，这是我们无法控制的事情。\n也就是说，比如现在我们要发送两个数据包（P1/P2），理想情况下，这两个包应该是依次到达服务端，并由服务端正确读取两次数据出来，但是由于上面的机制，可能会出现下面的情况：\n可能P1和P2被合在一起发送给了服务端（粘包现象） 可能P1和P2的前半部分合在一起发送给了服务端（拆包现象） 可能P1的前半部分就被单独作为一个部分发给了服务端，后面的和P2一起发给服务端（也是拆包现象） 当然，对于这种问题，也有一些比较常见的解决方案：\n消息定长，发送方和接收方规定固定大小的消息长度，例如每个数据包大小固定为200字节，如果不够，空位补空格，只有接收了200个字节之后，作为一个完整的数据包进行处理。 在每个包的末尾使用固定的分隔符，比如每个数据包末尾都是\\r\\n，这样就一定需要读取到这样的分隔符才能将前面所有的数据作为一个完整的数据包进行处理。 将消息分为头部和本体，在头部中保存有当前整个数据包的长度，只有在读到足够长度之后才算是读到了一个完整的数据包。 这里我们就来演示一下第一种解决方案：\npublic static void main(String[] args) { try (ServerSocketChannel serverChannel = ServerSocketChannel.open(); Selector selector = Selector.open()){ serverChannel.bind(new InetSocketAddress(8080)); serverChannel.configureBlocking(false); serverChannel.register(selector, SelectionKey.OP_ACCEPT); //一个数据包要求必须塞满30个字节 ByteBuffer buffer = ByteBuffer.allocate(30); while (true) { int count = selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { ... if(buffer.remaining() == 0) { buffer.flip(); System.out.println(\u0026#34;接收到客户端数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); buffer.clear(); } channel.write(ByteBuffer.wrap((\u0026#34;已收到 \u0026#34;+size+\u0026#34; 字节的数据！\u0026#34;).getBytes())); } ... 现在，当我们的客户端发送消息时，如果没有达到30个字节，那么会暂时存储起来，等有30个之后再一次性得到，当然如果数据量超过了30，那么最多也只会读取30个字节，其他的放在下一批：\n这样就可以在一定程度上解决粘包/拆包问题了。\n总的通过消息定长\n走进Netty框架 #\r前面我们盘点了一下NIO存在的一些问题，而在Netty框架中，这些问题都被巧妙的解决了。\nNetty是由JBOSS提供的一个开源的java网络编程框架，主要是对java的nio包进行了再次封装。Netty比java原生的nio包提供了更加强大、稳定的功能和易于使用的api。 netty的作者是Trustin Lee，这是一个韩国人，他还开发了另外一个著名的网络编程框架，mina。二者在很多方面都十分相似，它们的线程模型也是基本一致 。不过netty社区的活跃程度要mina高得多。\nNetty实际上应用场景非常多，比如我们的Minecraft游戏服务器：\nJava版本的Minecraft服务器就是使用Netty框架作为网络通信的基础，正是得益于Netty框架的高性能，我们才能愉快地和其他的小伙伴一起在服务器里面炸服。\n学习了Netty框架后，说不定你也可以摸索到部分Minecraft插件/模组开发的底层细节（太折磨了，UP主高中搞了大半年这玩意）\n当然除了游戏服务器之外，我们微服务之间的远程调用也可以使用Netty来完成，比如Dubbo的RPC框架，包括最新的SpringWebFlux框架，也抛弃了内嵌Tomcat而使用Netty作为通信框架。既然Netty这么强大，那么现在我们就开始Netty的学习吧！\n导包先：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.netty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.76.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; ByteBuf介绍 #\rNetty并没有使用NIO中提供的ByteBuffer来进行数据装载，而是自行定义了一个ByteBuf类。\n那么这个类相比NIO中的ByteBuffer有什么不同之处呢？\n写操作完成后无需进行flip()翻转。 具有比ByteBuffer更快的响应速度。 动态扩容。 首先我们来看看它的内部结构：\npublic abstract class AbstractByteBuf extends ByteBuf { ... int readerIndex; //index被分为了读和写，是两个指针在同时工作 int writerIndex; private int markedReaderIndex; //mark操作也分两种 private int markedWriterIndex; private int maxCapacity; //最大容量，没错，这玩意能动态扩容 可以看到，读操作和写操作分别由两个指针在进行维护，每写入一次，writerIndex向后移动一位，每读取一次，也是readerIndex向后移动一位，当然readerIndex不能大于writerIndex，这样就不会像NIO中的ByteBuffer那样还需要进行翻转了。\n其中readerIndex和writerIndex之间的部分就是是可读的内容，而writerIndex之后到capacity都是可写的部分。\n我们来实际使用一下看看：\npublic static void main(String[] args) { //创建一个初始容量为10的ByteBuf缓冲区，这里的Unpooled是用于快速生成ByteBuf的工具类 //至于为啥叫Unpooled是池化的意思，ByteBuf有池化和非池化两种，区别在于对内存的复用，我们之后再讨论 ByteBuf buf = Unpooled.buffer(10); System.out.println(\u0026#34;初始状态：\u0026#34;+Arrays.toString(buf.array())); buf.writeInt(-888888888); //写入一个Int数据 System.out.println(\u0026#34;写入Int后：\u0026#34;+Arrays.toString(buf.array())); buf.readShort(); //无需翻转，直接读取一个short数据出来 System.out.println(\u0026#34;读取Short后：\u0026#34;+Arrays.toString(buf.array())); buf.discardReadBytes(); //丢弃操作，会将当前的可读部分内容丢到最前面，并且读写指针向前移动丢弃的距离 System.out.println(\u0026#34;丢弃之后：\u0026#34;+Arrays.toString(buf.array())); buf.clear(); //清空操作，清空之后读写指针都归零 System.out.println(\u0026#34;清空之后：\u0026#34;+Arrays.toString(buf.array())); } 通过结合断点调试，我们可以观察读写指针的移动情况，更加清楚的认识一下ByteBuf的底层操作。\n我们再来看看划分操作是不是和之前一样的：\npublic static void main(String[] args) { //我们也可以将一个byte[]直接包装进缓冲区（和NIO是一样的）不过写指针的值一开始就跑到最后去了，但是这玩意是不是只读的 ByteBuf buf = Unpooled.wrappedBuffer(\u0026#34;abcdefg\u0026#34;.getBytes()); //除了包装，也可以复制数据，copiedBuffer()会完完整整将数据拷贝到一个新的缓冲区中 buf.readByte(); //读取一个字节 ByteBuf slice = buf.slice(); //现在读指针位于1，然后进行划分 System.out.println(slice.arrayOffset()); //得到划分出来的ByteBuf的偏移地址 System.out.println(Arrays.toString(slice.array())); } 可以看到，划分也是根据当前读取的位置来进行的。\n我们继续来看看它的另一个特性，动态扩容，比如我们申请一个容量为10的缓冲区：\npublic static void main(String[] args) { ByteBuf buf = Unpooled.buffer(10); //容量只有10字节 System.out.println(buf.capacity()); //直接写一个字符串 buf.writeCharSequence(\u0026#34;卢本伟牛逼！\u0026#34;, StandardCharsets.UTF_8); //很明显这么多字已经超过10字节了 System.out.println(buf.capacity()); } 通过结果我们发现，在写入一个超出当前容量的数据时，会进行动态扩容，扩容会从64开始，之后每次触发扩容都会x2，当然如果我们不希望它扩容，可以指定最大容量：\npublic static void main(String[] args) { //在生成时指定maxCapacity也为10 ByteBuf buf = Unpooled.buffer(10, 10); System.out.println(buf.capacity()); buf.writeCharSequence(\u0026#34;卢本伟牛逼！\u0026#34;, StandardCharsets.UTF_8); System.out.println(buf.capacity()); } 可以看到现在无法再动态扩容了：\n我们接着来看一下缓冲区的三种实现模式：堆缓冲区模式、直接缓冲区模式、复合缓冲区模式。\n堆缓冲区（数组实现）和直接缓冲区（堆外内存实现）不用多说，前面我们在NIO中已经了解过了，我们要创建一个直接缓冲区也很简单，直接调用：\npublic static void main(String[] args) { ByteBuf buf = Unpooled.directBuffer(10); System.out.println(Arrays.toString(buf.array())); } 同样的不能直接拿到数组，因为底层压根不是数组实现的：\n我们来看看复合模式，复合模式可以任意地拼凑组合其他缓冲区，比如我们可以：\n这样，如果我们想要对两个缓冲区组合的内容进行操作，我们就不用再单独创建一个新的缓冲区了，而是直接将其进行拼接操作，相当于是作为多个缓冲区组合的视图。\n//创建一个复合缓冲区 CompositeByteBuf buf = Unpooled.compositeBuffer(); buf.addComponent(Unpooled.copiedBuffer(\u0026#34;abc\u0026#34;.getBytes())); buf.addComponent(Unpooled.copiedBuffer(\u0026#34;def\u0026#34;.getBytes())); for (int i = 0; i \u0026lt; buf.capacity(); i++) { System.out.println((char) buf.getByte(i)); } 可以看到我们也可以正常操作组合后的缓冲区。\n最后我们来看看，池化缓冲区和非池化缓冲区的区别。\n我们研究一下Unpooled工具类中具体是如何创建buffer的：\npublic final class Unpooled { private static final ByteBufAllocator ALLOC; //实际上内部是有一个ByteBufAllocator对象的 public static final ByteOrder BIG_ENDIAN; public static final ByteOrder LITTLE_ENDIAN; public static final ByteBuf EMPTY_BUFFER; public static ByteBuf buffer() { return ALLOC.heapBuffer(); //缓冲区的创建操作实际上是依靠ByteBufAllocator来进行的 } ... static { //ALLOC在静态代码块中进行指定，实际上真正的实现类是UnpooledByteBufAllocator ALLOC = UnpooledByteBufAllocator.DEFAULT; BIG_ENDIAN = ByteOrder.BIG_ENDIAN; LITTLE_ENDIAN = ByteOrder.LITTLE_ENDIAN; EMPTY_BUFFER = ALLOC.buffer(0, 0); //空缓冲区容量和最大容量都是0 assert EMPTY_BUFFER instanceof EmptyByteBuf : \u0026#34;EMPTY_BUFFER must be an EmptyByteBuf.\u0026#34;; } } 那么我们来看看，这个ByteBufAllocator又是个啥，顾名思义，其实就是负责分配缓冲区的。\n它有两个具体实现类：UnpooledByteBufAllocator和PooledByteBufAllocator，一个是非池化缓冲区生成器，还有一个是池化缓冲区生成器，那么池化和非池化有啥区别呢？\n实际上池化缓冲区利用了池化思想，将缓冲区通过设置内存池来进行内存块复用，这样就不用频繁地进行内存的申请，尤其是在使用堆外内存的时候，避免多次重复通过底层malloc()函数系统调用申请内存造成的性能损失。Netty的内存管理机制主要是借鉴Jemalloc内存分配策略，感兴趣的小伙伴可以深入了解一下。\n所以，由于是复用内存空间，我们来看个例子：\npublic static void main(String[] args) { ByteBufAllocator allocator = PooledByteBufAllocator.DEFAULT; ByteBuf buf = allocator.directBuffer(10); //申请一个容量为10的直接缓冲区 buf.writeChar(\u0026#39;T\u0026#39;); //随便操作操作 System.out.println(buf.readChar()); buf.release(); //释放此缓冲区 ByteBuf buf2 = allocator.directBuffer(10); //重新再申请一个同样大小的直接缓冲区 System.out.println(buf2 == buf); } 可以看到，在我们使用完一个缓冲区之后，我们将其进行资源释放，当我们再次申请一个同样大小的缓冲区时，会直接得到之前已经申请好的缓冲区，所以，PooledByteBufAllocator实际上是将ByteBuf实例放入池中在进行复用。\n池化技术，避免底层重复的malloc操作浪费性能\n零拷贝简介 #\r**注意：**此小节作为选学内容，需要掌握操作系统和计算机组成原理才能学习。\n零拷贝是一种I/O操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间，首先第一个问题，什么是内核空间，什么又是用户空间呢？\n其实早期操作系统是不区分内核空间和用户空间的，但是应用程序能访问任意内存空间，程序很容易不稳定，常常把系统搞崩溃，比如清除操作系统的内存数据。实际上让应用程序随便访问内存真的太危险了，于是就按照CPU 指令的重要程度对指令进行了分级，指令分为四个级别：Ring0 ~ Ring3，Linux 下只使用了 Ring0 和 Ring3 两个运行级别，进程运行在 Ring3 级别时运行在用户态，指令只访问用户空间，而运行在 Ring0 级别时被称为运行在内核态，可以访问任意内存空间。\n比如我们Java中创建一个新的线程，实际上最终是要交给操作系统来为我们进行分配的，而需要操作系统帮助我们完成任务则需要进行系统调用，是内核在进行处理，不是我们自己的程序在处理，这时就相当于我们的程序处于了内核态，而当操作系统底层分配完成，最后到我们Java代码中返回得到线程对象时，又继续由我们的程序进行操作，所以从内核态转换回了用户态。\n而我们的文件操作也是这样，我们实际上也是需要让操作系统帮助我们从磁盘上读取文件数据或是向网络发送数据，比如使用传统IO的情况下，我们要从磁盘上读取文件然后发送到网络上，就会经历以下流程：\n可以看到整个过程中是经历了2次CPU拷贝+2次DMA拷贝，一共四次拷贝，虽然逻辑比较清晰，但是数据老是这样来回进行复制，是不是太浪费时间了点？所以我们就需要寻找一种更好的方式，来实现零拷贝。\n实现零拷贝我们这里演示三种方案：\n使用虚拟内存\n现在的操作系统基本都是支持虚拟内存的，我们可以让内核空间和用户空间的虚拟地址指向同一个物理地址，这样就相当于是直接共用了这一块区域，也就谈不上拷贝操作了：\n使用mmap/write内存映射\n实际上这种方式就是将内核空间中的缓存直接映射到用户空间缓存，比如我们之前在学习NIO中使用的MappedByteBuffer，就是直接作为映射存在，当我们需要将数据发送到Socket缓冲区时，直接在内核空间中进行操作就行了：\n不过这样还是会出现用户态和内核态的切换，我们得再优化优化。\n使用sendfile方式\n在Linux2.1开始，引入了sendfile方式来简化操作，我们可以直接告诉内核要把哪个文件数据拷贝拷贝到Socket上，直接在内核空间中一步到位：\n比如我们之前在NIO中使用的transferTo()方法，就是利用了这种机制来实现零拷贝的。\nNetty工作模型 #\r前面我们了解了Netty为我们提供的更高级的缓冲区类，我们接着来看看Netty是如何工作的，上一章我们介绍了Reactor模式，而Netty正是以主从Reactor多线程模型为基础，构建出了一套高效的工作模型。\n大致工作模型图如下：\n可以看到，和我们之前介绍的主从Reactor多线程模型非常类似：\n所有的客户端需要连接到主Reactor完成Accept操作后，其他的操作由从Reactor去完成，这里也是差不多的思想，但是它进行了一些改进，我们来看一下它的设计：\nNetty 抽象出两组线程池BossGroup和WorkerGroup，BossGroup专门负责接受客户端的连接, WorkerGroup专门负读写，就像我们前面说的主从Reactor一样。 无论是BossGroup还是WorkerGroup，都是使用EventLoop（事件循环，很多系统都采用了事件循环机制，比如前端框架Node.js，事件循环顾名思义，就是一个循环，不断地进行事件通知）来进行事件监听的，整个Netty也是使用事件驱动来运作的，比如当客户端已经准备好读写、连接建立时，都会进行事件通知，说白了就像我们之前写NIO多路复用那样，只不过这里换成EventLoop了而已，它已经帮助我们封装好了一些常用操作，而且我们可以自己添加一些额外的任务，如果有多个EventLoop，会存放在EventLoopGroup中，EventLoopGroup就是BossGroup和WorkerGroup的具体实现。 在BossGroup之后，会正常将SocketChannel绑定到WorkerGroup中的其中一个EventLoop上，进行后续的读写操作监听。 前面我们大致了解了一下Netty的工作模型，接着我们来尝试创建一个Netty服务器：\npublic static void main(String[] args) { //这里我们使用NioEventLoopGroup实现类即可，创建BossGroup和WorkerGroup //当然还有EpollEventLoopGroup，但是仅支持Linux，这是Netty基于Linux底层Epoll单独编写的一套本地实现，没有使用NIO那套 EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(); //创建服务端启动引导类 ServerBootstrap bootstrap = new ServerBootstrap(); //可链式，就很棒 bootstrap .group(bossGroup, workerGroup) //指定事件循环组 .channel(NioServerSocketChannel.class) //指定为NIO的ServerSocketChannel .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { //注意，这里的SocketChannel不是我们NIO里面的，是Netty的 @Override protected void initChannel(SocketChannel channel) { //获取流水线，当我们需要处理客户端的数据时，实际上是像流水线一样在处理，这个流水线上可以有很多Handler channel.pipeline().addLast(new ChannelInboundHandlerAdapter(){ //添加一个Handler，这里使用ChannelInboundHandlerAdapter @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { //ctx是上下文，msg是收到的消息，默认以ByteBuf形式（也可以是其他形式，后面再说） ByteBuf buf = (ByteBuf) msg; //类型转换一下 System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); //通过上下文可以直接发送数据回去，注意要writeAndFlush才能让客户端立即收到 ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes())); } }); } }); //最后绑定端口，启动 bootstrap.bind(8080); } 可以看到上面写了很多东西，但是你一定会懵逼，这些新来的东西，都是什么跟什么啊，怎么一个也没看明白？没关系，我们可以暂时先将代码写在这里，具体的各个部分，还请听后面细细道来。\n我们接着编写一个客户端，客户端可以直接使用我们之前的：\npublic static void main(String[] args) { //创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel = SocketChannel.open(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 8080)); Scanner scanner = new Scanner(System.in)){ System.out.println(\u0026#34;已连接到服务端！\u0026#34;); while (true) { //咱给它套个无限循环，这样就能一直发消息了 System.out.println(\u0026#34;请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); if(text.isEmpty()) continue; //直接向通道中写入数据，真舒服 channel.write(ByteBuffer.wrap(text.getBytes())); System.out.println(\u0026#34;已发送！\u0026#34;); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); //直接从通道中读取数据 buffer.flip(); System.out.println(\u0026#34;收到服务器返回：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); } } catch (IOException e) { throw new RuntimeException(e); } } 通过通道正常收发数据即可，这样我们就成功搭建好了一个Netty服务器。\nChannel详解 #\r在学习NIO时，我们就已经接触到Channel了，我们可以通过通道来进行数据的传输，并且通道支持双向传输。\n而在Netty中，也有对应的Channel类型：\n接口的静态变量通常不会再运行时被使用，不会产生歧义问题\npublic interface Channel extends AttributeMap, ChannelOutboundInvoker, Comparable\u0026lt;Channel\u0026gt; { ChannelId id(); //通道ID EventLoop eventLoop(); //获取此通道所属的EventLoop，因为一个Channel在它的生命周期内只能注册到一个EventLoop中 Channel parent(); //Channel是具有层级关系的，这里是返回父Channel ChannelConfig config(); boolean isOpen(); //通道当前的相关状态 boolean isRegistered(); boolean isActive(); ChannelMetadata metadata(); //通道相关信息 SocketAddress localAddress(); SocketAddress remoteAddress(); ChannelFuture closeFuture(); //关闭通道，但是会用到ChannelFuture，后面说 boolean isWritable(); long bytesBeforeUnwritable(); long bytesBeforeWritable(); Unsafe unsafe(); ChannelPipeline pipeline(); //流水线，之后也会说 ByteBufAllocator alloc(); //可以直接从Channel拿到ByteBufAllocator的实例，来分配ByteBuf Channel read(); Channel flush(); //刷新，基操 } 可以看到，Netty中的Channel相比NIO功能就多得多了。Netty中的Channel主要特点如下：\n所有的IO操作都是异步的，并不是在当前线程同步运行，方法调用之后就直接返回了，那怎么获取操作的结果呢？还记得我们在前面JUC篇教程中学习的Future吗，没错，这里的ChannelFuture也是干这事的。 多线程通过Future来获取线程执行的结果\n我们可以来看一下Channel接口的父接口ChannelOutboundInvoker接口，这里面定义了大量的I/O操作：\npublic interface ChannelOutboundInvoker { //通道出站调用（包含大量的网络出站操作，比如写） ChannelFuture bind(SocketAddress var1); //Socket绑定、连接、断开、关闭等操作 ChannelFuture connect(SocketAddress var1); ChannelFuture connect(SocketAddress var1, SocketAddress var2); ChannelFuture disconnect(); ChannelFuture close(); ChannelFuture deregister(); ChannelFuture bind(SocketAddress var1, ChannelPromise var2); //下面这一系列还有附带ChannelPromise的，ChannelPromise我们后面再说，其实就是ChannelFuture的增强版 ChannelFuture connect(SocketAddress var1, ChannelPromise var2); ChannelFuture connect(SocketAddress var1, SocketAddress var2, ChannelPromise var3); ChannelFuture disconnect(ChannelPromise var1); ChannelFuture close(ChannelPromise var1); ChannelFuture deregister(ChannelPromise var1); ChannelOutboundInvoker read(); ChannelFuture write(Object var1); //可以看到这些常见的写操作，都是返回的ChannelFuture，而不是直接给结果 ChannelFuture write(Object var1, ChannelPromise var2); ChannelOutboundInvoker flush(); ChannelFuture writeAndFlush(Object var1, ChannelPromise var2); ChannelFuture writeAndFlush(Object var1); ChannelPromise newPromise(); //其他的暂时不提 ChannelProgressivePromise newProgressivePromise(); ChannelFuture newSucceededFuture(); ChannelFuture newFailedFuture(Throwable var1); ChannelPromise voidPromise(); } 当然它还实现了AttributeMap接口，其实有点类似于Session那种感觉，我们可以添加一些属性之类的：\npublic interface AttributeMap { \u0026lt;T\u0026gt; Attribute\u0026lt;T\u0026gt; attr(AttributeKey\u0026lt;T\u0026gt; var1); \u0026lt;T\u0026gt; boolean hasAttr(AttributeKey\u0026lt;T\u0026gt; var1); } 我们了解了Netty底层的Channel之后，我们接着来看ChannelHandler，既然现在有了通道，那么怎么进行操作呢？我们可以将需要处理的事情放在ChannelHandler中，ChannelHandler充当了所有入站和出站数据的应用程序逻辑的容器，实际上就是我们之前Reactor模式中的Handler，全靠它来处理读写操作。\n不过这里不仅仅是一个简单的ChannelHandler在进行处理，而是一整套流水线，我们之后会介绍ChannelPipeline。\n比如我们上面就是使用了ChannelInboundHandlerAdapter抽象类，它是ChannelInboundHandler接口的实现，用于处理入站数据，可以看到我们实际上就是通过重写对应的方法来进行处理，这些方法会在合适的时间被调用：\nchannel.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { //ctx是上下文，msg是收到的消息，以ByteBuf形式 ByteBuf buf = (ByteBuf) msg; //类型转换一下 System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); //通过上下文可以直接发送数据回去，注意要writeAndFlush才能让客户端立即收到 ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes())); } }); 我们先从顶层接口开始看起：\npublic interface ChannelHandler { //当ChannelHandler被添加到流水线中时调用 void handlerAdded(ChannelHandlerContext var1) throws Exception; //当ChannelHandler从流水线中移除时调用 void handlerRemoved(ChannelHandlerContext var1) throws Exception; /** @deprecated 已过时那咱就不管了 */ @Deprecated void exceptionCaught(ChannelHandlerContext var1, Throwable var2) throws Exception; @Inherited @Documented @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) public @interface Sharable { } } 顶层接口的定义比较简单，就只有一些流水线相关的回调方法，我们接着来看下一级：\n//ChannelInboundHandler用于处理入站相关事件 public interface ChannelInboundHandler extends ChannelHandler { //当Channel已经注册到自己的EventLoop上时调用，前面我们说了，一个Channel只会注册到一个EventLoop上，注册到EventLoop后，这样才会在发生对应事件时被通知。 void channelRegistered(ChannelHandlerContext var1) throws Exception; //从EventLoop上取消注册时 void channelUnregistered(ChannelHandlerContext var1) throws Exception; //当Channel已经处于活跃状态时被调用，此时Channel已经连接/绑定，并且已经就绪 void channelActive(ChannelHandlerContext var1) throws Exception; //跟上面相反，不再活跃了，并且不在连接它的远程节点 void channelInactive(ChannelHandlerContext var1) throws Exception; //当从Channel读取数据时被调用，可以看到数据被自动包装成了一个Object（默认是ByteBuf） void channelRead(ChannelHandlerContext var1, Object var2) throws Exception; //上一个读取操作完成后调用 void channelReadComplete(ChannelHandlerContext var1) throws Exception; //暂时不介绍 void userEventTriggered(ChannelHandlerContext var1, Object var2) throws Exception; //当Channel的可写状态发生改变时被调用 void channelWritabilityChanged(ChannelHandlerContext var1) throws Exception; //出现异常时被调用 void exceptionCaught(ChannelHandlerContext var1, Throwable var2) throws Exception; } 而我们上面用到的ChannelInboundHandlerAdapter实际上就是对这些方法实现的抽象类，相比直接用接口，我们可以只重写我们需要的方法，没有重写的方法会默认向流水线下一个ChannelHandler发送。\n我们来测试一下吧：\npublic class TestChannelHandler extends ChannelInboundHandlerAdapter { public void channelRegistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelRegistered\u0026#34;); } public void channelUnregistered(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelUnregistered\u0026#34;); } public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelActive\u0026#34;); } public void channelInactive(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelInactive\u0026#34;); } public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); //这次我们就直接使用ctx.alloc()来生成缓冲区 ByteBuf back = ctx.alloc().buffer(); back.writeCharSequence(\u0026#34;已收到！\u0026#34;, StandardCharsets.UTF_8); ctx.writeAndFlush(back); System.out.println(\u0026#34;channelRead\u0026#34;); } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelReadComplete\u0026#34;); } public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { System.out.println(\u0026#34;userEventTriggered\u0026#34;); } public void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelWritabilityChanged\u0026#34;); } public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\u0026#34;exceptionCaught\u0026#34;+cause); } } public static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) //ChannelInitializer是一个特殊的ChannelHandler，它本身不处理任何出站/入站事件，它的目的仅仅是完成Channel的初始化 .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel channel) { //将我们自定义的ChannelHandler添加到流水线 channel.pipeline().addLast(new TestChannelHandler()); } }); bootstrap.bind(8080); } 现在我们启动服务器，让客户端来连接并发送一下数据试试看：\n可以看到ChannelInboundHandler的整个生命周期，首先是Channel注册成功，然后才会变成可用状态，接着就差不多可以等待客户端来数据了，当客户端主动断开连接时，会再次触发一次channelReadComplete，然后不可用，最后取消注册。\n我们来测试一下出现异常的情况呢？\npublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ByteBuf back = ctx.alloc().buffer(); back.writeCharSequence(\u0026#34;已收到！\u0026#34;, StandardCharsets.UTF_8); ctx.writeAndFlush(back); System.out.println(\u0026#34;channelRead\u0026#34;); throw new RuntimeException(\u0026#34;我是自定义异常1\u0026#34;); //弄点异常上去 } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(\u0026#34;channelReadComplete\u0026#34;); throw new RuntimeException(\u0026#34;我是自定义异常2\u0026#34;); //弄点异常上去 } ... public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\u0026#34;exceptionCaught\u0026#34;+cause); } 可以看到发生异常时，会接着调用exceptionCaught方法：\n与ChannelInboundHandler对应的还有ChannelOutboundHandler用于处理出站相关的操作，这里就不进行演示了。\n我们接着来看看ChannelPipeline，每一个Channel都对应一个ChannelPipeline（在Channel初始化时就被创建了）\n它就像是一条流水线一样，整条流水线上可能会有很多个Handler（包括入站和出站），整条流水线上的两端还有两个默认的处理器（用于一些预置操作和后续操作，比如释放资源等），我们只需要关心如何安排这些自定义的Handler即可，比如我们现在希望创建两个入站ChannelHandler，一个用于接收请求并处理，还有一个用于处理当前接收请求过程中出现的异常：\n.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { //注意，这里的SocketChannel不是我们NIO里面的，是Netty的 @Override protected void initChannel(SocketChannel channel) { channel.pipeline() //直接获取pipeline，然后添加两个Handler，注意顺序 .addLast(new ChannelInboundHandlerAdapter(){ //第一个用于处理消息接收 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ds throw new RuntimeException(\u0026#34;我是异常\u0026#34;); } }) .addLast(new ChannelInboundHandlerAdapter(){ //第二个用于处理异常 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { System.out.println(\u0026#34;我是异常处理：\u0026#34;+cause); } }); } }); 那么它是如何运作的呢？实际上如果我们不在ChannelInboundHandlerAdapter中重写对应的方法，它会默认传播到流水线的下一个ChannelInboundHandlerAdapter进行处理，比如：\npublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.fireExceptionCaught(cause); //通过ChannelHandlerContext来向下传递，ChannelHandlerContext是在Handler添加进Pipeline中时就被自动创建的 } 比如我们现在需要将一个消息在两个Handler中进行处理：\n@Override protected void initChannel(SocketChannel channel) { channel.pipeline() //直接获取pipeline，然后添加两个Handler .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;1接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); //通过ChannelHandlerContext } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;2接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); } }); } 我们接着来看看出站相关操作，我们可以使用ChannelOutboundHandlerAdapter来完成：\n@Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelOutboundHandlerAdapter(){ //注意出栈站操作应该在入站操作的前面，当我们使用ChannelHandlerContext的write方法时，是从流水线的当前位置倒着往前找下一个ChannelOutboundHandlerAdapter，而我们之前使用的ChannelInboundHandlerAdapter是从前往后找下一个，如果我们使用的是Channel的write方法，那么会从整个流水线的最后开始倒着往前找ChannelOutboundHandlerAdapter，一定要注意顺序。 @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { //当执行write操作时，会 System.out.println(msg); //write的是啥，这里就是是啥 //我们将其转换为ByteBuf，这样才能发送回客户端 ctx.writeAndFlush(Unpooled.wrappedBuffer(msg.toString().getBytes())); } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;1接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;2接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ctx.writeAndFlush(\u0026#34;不会吧不会吧，不会还有人都看到这里了还没三连吧\u0026#34;); //这里可以write任何对象 //ctx.channel().writeAndFlush(\u0026#34;啊对对对\u0026#34;); 或是通过Channel进行write也可以 } }); } 现在我们来试试看，搞两个出站的Handler，验证一下是不是上面的样子：\n@Override protected void initChannel(SocketChannel channel) { channel.pipeline() //直接获取pipeline，然后添加两个Handler .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;1接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); } }) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;2接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ctx.channel().writeAndFlush(\u0026#34;伞兵一号卢本伟\u0026#34;); //这里我们使用channel的write } }) .addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\u0026#34;1号出站：\u0026#34;+msg); } }) .addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { System.out.println(\u0026#34;2号出站：\u0026#34;+msg); ctx.write(msg); //继续write给其他的出站Handler，不然到这里就断了 } }); } 所以，出站操作在流水线上是反着来的，整个流水线操作大概流程如下:\n有关Channel及其处理相关操作，就先讲到这里。\nEventLoop和任务调度 #\r前面我们讲解了Channel，那么在EventLoop中具体是如何进行调度的呢？实际上我们之前在编写NIO的时候，就是一个while循环在源源不断地等待新的事件，而EventLoop也正是这种思想，它本质就是一个事件等待/处理线程。\n我们上面使用的就是EventLoopGroup，包含很多个EventLoop，我们每创建一个连接，就需要绑定到一个EventLoop上，之后EventLoop就会开始监听这个连接（只要连接不关闭，一直都是这个EventLoop负责此Channel），而一个EventLoop可以同时监听很多个Channel，实际上就是我们之前学习的Selector罢了。\n当然，EventLoop并不只是用于网络操作的，我们前面所说的EventLoop其实都是NioEventLoop，它是专用于网络通信的，除了网络通信之外，我们也可以使用普通的EventLoop来处理一些其他的事件。\n比如我们现在编写的服务端，虽然结构上和主从Reactor多线程模型差不多，但是我们发现，Handler似乎是和读写操作在一起进行的，而我们之前所说的模型中，Handler是在读写之外的单独线程中进行的：\npublic static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(1); //线程数先限制一下 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) //指定事件循环组 .channel(NioServerSocketChannel.class) //指定为NIO的ServerSocketChannel .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { //注意，这里的SocketChannel不是我们NIO里面的，是Netty的 @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); Thread.sleep(10000); //这里我们直接卡10秒假装在处理任务 ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes())); } }); } }); bootstrap.bind(8080); } 可以看到，如果在这里卡住了，那么就没办法处理EventLoop绑定的其他Channel了，所以我们这里就创建一个普通的EventLoop来专门处理读写之外的任务：\npublic static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(1); //线程数先限制一下 EventLoopGroup handlerGroup = new DefaultEventLoopGroup(); //使用DefaultEventLoop来处理其他任务 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); handlerGroup.submit(() -\u0026gt; { //由于继承自ScheduledExecutorService，我们直接提交任务就行了，是不是感觉贼方便 try { Thread.sleep(10000); } catch (InterruptedException e) { throw new RuntimeException(e); } ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes())); }); } }); } }); bootstrap.bind(8080); } 当然我们也可以写成一条流水线：\npublic static void main(String[] args) { EventLoopGroup bossGroup = new NioEventLoopGroup(), workerGroup = new NioEventLoopGroup(1); //线程数先限制一下 EventLoopGroup handlerGroup = new DefaultEventLoopGroup(); //使用DefaultEventLoop来处理其他任务 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap .group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel channel) { channel.pipeline() .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ctx.fireChannelRead(msg); } }).addLast(handlerGroup, new ChannelInboundHandlerAdapter(){ //在添加时，可以直接指定使用哪个EventLoopGroup @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { try { Thread.sleep(10000); } catch (InterruptedException e) { throw new RuntimeException(e); } ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes())); } }); } }); bootstrap.bind(8080); } 这样，我们就进一步地将EventLoop利用起来了。\n按照前面服务端的方式，我们来把Netty版本的客户端也给写了：\npublic static void main(String[] args) { Bootstrap bootstrap = new Bootstrap(); //客户端也是使用Bootstrap来启动 bootstrap .group(new NioEventLoopGroup()) //客户端就没那么麻烦了，直接一个EventLoop就行，用于处理发回来的数据 .channel(NioSocketChannel.class) //客户端肯定就是使用SocketChannel了 .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { //这里的数据处理方式和服务端是一样的 @Override protected void initChannel(SocketChannel channel) throws Exception { channel.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;\u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); } }); } }); Channel channel = bootstrap.connect(\u0026#34;localhost\u0026#34;, 8080).channel(); //连接后拿到对应的Channel对象 //注意上面连接操作是异步的，调用之后会继续往下走，下面我们就正式编写客户端的数据发送代码了 try(Scanner scanner = new Scanner(System.in)){ //还是和之前一样，扫了就发 while (true) { System.out.println(\u0026#34;\u0026lt;\u0026lt; 请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); if(text.isEmpty()) continue; channel.writeAndFlush(Unpooled.wrappedBuffer(text.getBytes())); //通过Channel对象发送数据 } } } 我们来测试一下吧：\nFuture和Promise #\r我们接着来看ChannelFuture，前面我们提到，Netty中Channel的相关操作都是异步进行的，并不是在当前线程同步执行，我们不能立即得到执行结果，如果需要得到结果，那么我们就必须要利用到Future。\n我们先来看看ChannelFutuer接口怎么定义的：\npublic interface ChannelFuture extends Future\u0026lt;Void\u0026gt; { Channel channel(); //我们可以直接获取此任务的Channel ChannelFuture addListener(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super Void\u0026gt;\u0026gt; var1); //当任务完成时，会直接执行GenericFutureListener的任务，注意执行的位置也是在EventLoop中 ChannelFuture addListeners(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super Void\u0026gt;\u0026gt;... var1); ChannelFuture removeListener(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super Void\u0026gt;\u0026gt; var1); ChannelFuture removeListeners(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super Void\u0026gt;\u0026gt;... var1); ChannelFuture sync() throws InterruptedException; //在当前线程同步等待异步任务完成，任务失败会抛出异常 ChannelFuture syncUninterruptibly(); //同上，但是无法响应中断 ChannelFuture await() throws InterruptedException; //同上，但是任务中断不会抛出异常，需要手动判断 ChannelFuture awaitUninterruptibly(); //不用我说了吧？ boolean isVoid(); //返回类型是否为void } 此接口是继承自Netty中的Future接口的（不是JDK的那个）：\npublic interface Future\u0026lt;V\u0026gt; extends java.util.concurrent.Future\u0026lt;V\u0026gt; { //再往上才是JDK的Future boolean isSuccess(); //用于判断任务是否执行成功的 boolean isCancellable(); Throwable cause(); //获取导致任务失败的异常 ... V getNow(); //立即获取结果，如果还未产生结果，得到null，不过ChannelFuture定义V为Void，就算完成了获取也是null boolean cancel(boolean var1); //取消任务 } Channel的很多操作都是异步完成的，直接返回一个ChannelFuture，比如Channel的write操作，返回的就是一个ChannelFuture对象：\n.addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(\u0026#34;接收到客户端发送的数据：\u0026#34;+buf.toString(StandardCharsets.UTF_8)); ChannelFuture future = ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes())); System.out.println(\u0026#34;任务完成状态：\u0026#34;+future.isDone()); //通过ChannelFuture来获取相关信息 } }); 包括我们的服务端启动也是返回的ChannelFuture：\n... } }); ChannelFuture future = bootstrap.bind(8080); System.out.println(\u0026#34;服务端启动状态：\u0026#34;+future.isDone()); System.out.println(\u0026#34;我是服务端启动完成之后要做的事情！\u0026#34;); } 可以看到，服务端的启动就比较慢了，所以在一开始直接获取状态会返回false，但是这个时候我们又需要等到服务端启动完成之后做一些事情，这个时候该怎么办呢？现在我们就有两种方案了：\n} }); ChannelFuture future = bootstrap.bind(8080); future.sync(); //让当前线程同步等待任务完成 System.out.println(\u0026#34;服务端启动状态：\u0026#34;+future.isDone()); System.out.println(\u0026#34;我是服务端启动完成之后要做的事情！\u0026#34;); } 第一种方案是直接让当前线程同步等待异步任务完成，我们可以使用sync()方法，这样当前线程会一直阻塞直到任务结束。第二种方案是添加一个监听器，等待任务完成时通知：\n} }); ChannelFuture future = bootstrap.bind(8080); //直接添加监听器，当任务完成时自动执行，但是注意执行也是异步的，不是在当前线程 future.addListener(f -\u0026gt; System.out.println(\u0026#34;我是服务端启动完成之后要做的事情！\u0026#34;)); } 包括客户端的关闭，也是异步进行的：\ntry(Scanner scanner = new Scanner(System.in)){ while (true) { System.out.println(\u0026#34;\u0026lt;\u0026lt; 请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); if(text.isEmpty()) continue; if(text.equals(\u0026#34;exit\u0026#34;)) { //输入exit就退出 ChannelFuture future = channel.close(); future.sync(); //等待Channel完全关闭 break; } channel.writeAndFlush(Unpooled.wrappedBuffer(text.getBytes())); } } catch (InterruptedException e) { throw new RuntimeException(e); } finally { group.shutdownGracefully(); //优雅退出EventLoop，其实就是把还没发送的数据之类的事情做完，当然也可以shutdownNow立即关闭 } 我们接着来看看Promise接口，它支持手动设定成功和失败的结果：\n//此接口也是继承自Netty中的Future接口 public interface Promise\u0026lt;V\u0026gt; extends Future\u0026lt;V\u0026gt; { Promise\u0026lt;V\u0026gt; setSuccess(V var1); //手动设定成功 boolean trySuccess(V var1); Promise\u0026lt;V\u0026gt; setFailure(Throwable var1); //手动设定失败 boolean tryFailure(Throwable var1); boolean setUncancellable(); //这些就和之前的Future是一样的了 Promise\u0026lt;V\u0026gt; addListener(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super V\u0026gt;\u0026gt; var1); Promise\u0026lt;V\u0026gt; addListeners(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super V\u0026gt;\u0026gt;... var1); Promise\u0026lt;V\u0026gt; removeListener(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super V\u0026gt;\u0026gt; var1); Promise\u0026lt;V\u0026gt; removeListeners(GenericFutureListener\u0026lt;? extends Future\u0026lt;? super V\u0026gt;\u0026gt;... var1); Promise\u0026lt;V\u0026gt; await() throws InterruptedException; Promise\u0026lt;V\u0026gt; awaitUninterruptibly(); Promise\u0026lt;V\u0026gt; sync() throws InterruptedException; Promise\u0026lt;V\u0026gt; syncUninterruptibly(); } 比如我们来测试一下：\npublic static void main(String[] args) throws ExecutionException, InterruptedException { Promise\u0026lt;String\u0026gt; promise = new DefaultPromise\u0026lt;\u0026gt;(new DefaultEventLoop()); System.out.println(promise.isSuccess()); //在一开始肯定不是成功的 promise.setSuccess(\u0026#34;lbwnb\u0026#34;); //设定成功 System.out.println(promise.isSuccess()); //再次获取，可以发现确实成功了 System.out.println(promise.get()); //获取结果，就是我们刚刚给进去的 } 可以看到我们可以手动指定成功状态，包括ChannelOutboundInvoker中的一些基本操作，都是支持ChannelPromise的：\n.addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; String text = buf.toString(StandardCharsets.UTF_8); System.out.println(\u0026#34;接收到客户端发送的数据：\u0026#34;+text); ChannelPromise promise = new DefaultChannelPromise(channel); System.out.println(promise.isSuccess()); ctx.writeAndFlush(Unpooled.wrappedBuffer(\u0026#34;已收到！\u0026#34;.getBytes()), promise); promise.sync(); //同步等待一下 System.out.println(promise.isSuccess()); } }); 最后结果就是我们想要的了，当然我们也可以像Future那样添加监听器，当成功时自动通知：\npublic static void main(String[] args) throws ExecutionException, InterruptedException { Promise\u0026lt;String\u0026gt; promise = new DefaultPromise\u0026lt;\u0026gt;(new DefaultEventLoop()); promise.addListener(f -\u0026gt; System.out.println(promise.get())); //注意是在上面的DefaultEventLoop执行的 System.out.println(promise.isSuccess()); promise.setSuccess(\u0026#34;lbwnb\u0026#34;); System.out.println(promise.isSuccess()); } 有关Future和Promise就暂时讲解到这里。\n编码器和解码器 #\r前面我们已经了解了Netty的大部分基础内容，我们接着来看看Netty内置的一些编码器和解码器。\n在前面的学习中，我们的数据发送和接收都是需要以ByteBuf形式传输，但是这样是不是有点太不方便了，咱们能不能参考一下JavaWeb那种搞个Filter，在我们开始处理数据之前，过过滤一次，并在过滤的途中将数据转换成我们想要的类型，也可以将发出的数据进行转换，这就要用到编码解码器了。\n我们先来看看最简的，字符串，如果我们要直接在客户端或是服务端处理字符串，可以直接添加一个字符串解码器到我们的流水线中：\n@Override protected void initChannel(SocketChannel channel) { channel.pipeline() //解码器本质上也算是一种ChannelInboundHandlerAdapter，用于处理入站请求 .addLast(new StringDecoder()) //当客户端发送来的数据只是简单的字符串转换的ByteBuf时，我们直接使用内置的StringDecoder即可转换 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //经过StringDecoder转换后，msg直接就是一个字符串，所以打印就行了 System.out.println(msg); } }); } 可以看到，使用起来还是非常方便的，我们只需要将其添加到流水线即可，实际上器本质就是一个ChannelInboundHandlerAdapter：\n我们看到它是继承自MessageToMessageDecoder，用于将传入的Message转换为另一种类型，我们也可以自行编写一个实现：\n/** * 我们也来搞一个自定义的 */ public class TestDecoder extends MessageToMessageDecoder\u0026lt;ByteBuf\u0026gt; { @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List\u0026lt;Object\u0026gt; list) throws Exception { System.out.println(\u0026#34;数据已收到，正在进行解码...\u0026#34;); String text = buf.toString(StandardCharsets.UTF_8); //直接转换为UTF8字符串 list.add(text); //解码后需要将解析后的数据丢进List中，如果丢进去多个数据，相当于数据被分成了多个，后面的Handler就需要每个都处理一次 } } 运行，可以看到：\n当然如果我们在List里面丢很多个数据的话：\npublic class TestDecoder extends MessageToMessageDecoder\u0026lt;ByteBuf\u0026gt; { @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List\u0026lt;Object\u0026gt; list) throws Exception { System.out.println(\u0026#34;数据已收到，正在进行解码...\u0026#34;); String text = buf.toString(StandardCharsets.UTF_8); //直接转换为UTF8字符串 list.add(text); list.add(text+\u0026#34;2\u0026#34;); list.add(text+\u0026#39;3\u0026#39;); //一条消息被解码成三条消息 } } 可以看到，后面的Handler会依次对三条数据都进行处理，当然，除了MessageToMessageDecoder之外，还有其他类型的解码器，比如ByteToMessageDecoder等，这里就不一一介绍了，Netty内置了很多的解码器实现来方便我们开发，比如HTTP（下一节介绍），SMTP、MQTT等，以及我们常用的Redis、Memcached、JSON等数据包。\n当然，有了解码器处理发来的数据，那发出去的数据肯定也是需要被处理的，所以编码器就出现了：\nchannel.pipeline() //解码器本质上也算是一种ChannelInboundHandlerAdapter，用于处理入站请求 .addLast(new StringDecoder()) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;收到客户端的数据：\u0026#34;+msg); ctx.channel().writeAndFlush(\u0026#34;可以，不跟你多BB\u0026#34;); //直接发字符串回去 } }) .addLast(new StringEncoder()); //使用内置的StringEncoder可以直接将出站的字符串数据编码成ByteBuf 和上面的StringDecoder一样，StringEncoder本质上就是一个ChannelOutboundHandlerAdapter：\n是不是感觉前面学习的Handler和Pipeline突然就变得有用了，直接一条线把数据处理安排得明明白白啊。\n现在我们把客户端也改成使用编码、解码器的样子：\npublic static void main(String[] args) { Bootstrap bootstrap = new Bootstrap(); bootstrap .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel channel) throws Exception { channel.pipeline() .addLast(new StringDecoder()) //解码器安排 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;\u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34; + msg); //直接接收字符串 } }) .addLast(new StringEncoder()); //编码器安排 } }); Channel channel = bootstrap.connect(\u0026#34;localhost\u0026#34;, 8080).channel(); try(Scanner scanner = new Scanner(System.in)){ while (true) { System.out.println(\u0026#34;\u0026lt;\u0026lt; 请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); if(text.isEmpty()) continue; channel.writeAndFlush(text); //直接发送字符串就行 } } } 这样我们的代码量又蹭蹭的减少了很多：\n当然，除了编码器和解码器之外，还有编解码器。？？缝合怪？？\n可以看到它是既继承了ChannelInboundHandlerAdapter也实现了ChannelOutboundHandler接口，又能处理出站也能处理入站请求，实际上就是将之前的给组合到一起了，比如我们也可以实现一个缝合在一起的StringCodec类：\n//需要指定两个泛型，第一个是入站的消息类型，还有一个是出站的消息类型，出站是String类型，我们要转成ByteBuf public class StringCodec extends MessageToMessageCodec\u0026lt;ByteBuf, String\u0026gt; { @Override protected void encode(ChannelHandlerContext channelHandlerContext, String buf, List\u0026lt;Object\u0026gt; list) throws Exception { System.out.println(\u0026#34;正在处理出站数据...\u0026#34;); list.add(Unpooled.wrappedBuffer(buf.getBytes())); //同样的，添加的数量就是出站的消息数量 } @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf buf, List\u0026lt;Object\u0026gt; list) throws Exception { System.out.println(\u0026#34;正在处理入站数据...\u0026#34;); list.add(buf.toString(StandardCharsets.UTF_8)); //和之前一样，直接一行解决 } } 可以看到实际上就是需要我们同时去实现编码和解码方法，继承MessageToMessageCodec类即可。\n当然，如果整条流水线上有很多个解码器或是编码器，那么也可以多次进行编码或是解码，比如：\npublic class StringToStringEncoder extends MessageToMessageEncoder\u0026lt;String\u0026gt; { @Override protected void encode(ChannelHandlerContext channelHandlerContext, String s, List\u0026lt;Object\u0026gt; list) throws Exception { System.out.println(\u0026#34;我是预处理编码器，就要皮这一下。\u0026#34;); list.add(\u0026#34;[已处理] \u0026#34;+s); } } channel.pipeline() //解码器本质上也算是一种ChannelInboundHandlerAdapter，用于处理入站请求 .addLast(new StringDecoder()) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;收到客户端的数据：\u0026#34;+msg); ctx.channel().writeAndFlush(\u0026#34;可以，不跟你多BB\u0026#34;); //直接发字符串回去 } }) .addLast(new StringEncoder()) //最后再转成ByteBuf .addLast(new StringToStringEncoder()); //先从我们自定义的开始 可以看到，数据在流水线上一层一层处理最后再回到的客户端：\n我们在一开始提到的粘包/拆包问题，也可以使用一个解码器解决：\nchannel.pipeline() .addLast(new FixedLengthFrameDecoder(10)) //第一种解决方案，使用定长数据包，每个数据包都要是指定长度 ... channel.pipeline() .addLast(new DelimiterBasedFrameDecoder(1024, Unpooled.wrappedBuffer(\u0026#34;!\u0026#34;.getBytes()))) //第二种，就是指定一个特定的分隔符，比如我们这里以感叹号为分隔符 //在收到分隔符之前的所有数据，都作为同一个数据包的内容 channel.pipeline() .addLast(new LengthFieldBasedFrameDecoder(1024, 0, 4)) //第三种方案，就是在头部添加长度信息，来确定当前发送的数据包具体长度是多少 //offset是从哪里开始，length是长度信息占多少字节，这里是从0开始读4个字节表示数据包长度 .addLast(new StringDecoder()) channel.pipeline() .addLast(new StringDecoder()) .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;\u0026gt;\u0026gt; 接收到客户端发送的数据：\u0026#34; + msg); } }) .addLast(new LengthFieldPrepender(4)) //客户端在发送时也需要将长度拼到前面去 .addLast(new StringEncoder()); 有关编码器和解码器的内容就先介绍到这里。\n实现HTTP协议通信 #\r前面我们介绍了Netty为我们提供的编码器和解码器，这里我们就来使用一下支持HTTP协议的编码器和解码器。\nchannel.pipeline() .addLast(new HttpRequestDecoder()) //Http请求解码器 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;收到客户端的数据：\u0026#34;+msg.getClass()); //看看是个啥类型 //收到浏览器请求后，我们需要给一个响应回去 FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); //HTTP版本为1.1，状态码就OK（200）即可 //直接向响应内容中写入数据 response.content().writeCharSequence(\u0026#34;Hello World!\u0026#34;, StandardCharsets.UTF_8); ctx.channel().writeAndFlush(response); //发送响应 ctx.channel().close(); //HTTP请求是一次性的，所以记得关闭 } }) .addLast(new HttpResponseEncoder()); //响应记得也要编码后发送哦 现在我们用浏览器访问一下我们的服务器吧：\n可以看到浏览器成功接收到服务器响应，然后控制台打印了以下类型：\n可以看到一次请求是一个DefaultHttpRequest+LastHttpContent$1，这里有两组是因为浏览器请求了一个地址之后紧接着请求了我们网站的favicon图标。\n这样把数据分开处理肯定是不行的，要是直接整合成一个多好，安排：\nchannel.pipeline() .addLast(new HttpRequestDecoder()) //Http请求解码器 .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) //搞一个聚合器，将内容聚合为一个FullHttpRequest，参数是最大内容长度 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { FullHttpRequest request = (FullHttpRequest) msg; System.out.println(\u0026#34;浏览器请求路径：\u0026#34;+request.uri()); //直接获取请求相关信息 FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); response.content().writeCharSequence(\u0026#34;Hello World!\u0026#34;, StandardCharsets.UTF_8); ctx.channel().writeAndFlush(response); ctx.channel().close(); } }) .addLast(new HttpResponseEncoder()); 再次访问，我们发现可以正常读取请求路径了：\n我们来试试看搞个静态页面代理玩玩，拿出我们的陈年老模板：\n全部放进Resource文件夹，一会根据浏览器的请求路径，我们就可以返回对应的页面了，先安排一个解析器，用于解析路径然后将静态页面的内容返回：\npublic class PageResolver { //直接单例模式 private static final PageResolver INSTANCE = new PageResolver(); private PageResolver(){} public static PageResolver getInstance(){ return INSTANCE; } //请求路径给进来，接着我们需要将页面拿到，然后转换成响应数据包发回去 public FullHttpResponse resolveResource(String path){ if(path.startsWith(\u0026#34;/\u0026#34;)) { //判断一下是不是正常的路径请求 path = path.equals(\u0026#34;/\u0026#34;) ? \u0026#34;index.html\u0026#34; : path.substring(1); //如果是直接请求根路径，那就默认返回index页面，否则就该返回什么路径的文件就返回什么 try(InputStream stream = this.getClass().getClassLoader().getResourceAsStream(path)) { if(stream != null) { //拿到文件输入流之后，才可以返回页面 byte[] bytes = new byte[stream.available()]; stream.read(bytes); return this.packet(HttpResponseStatus.OK, bytes); //数据先读出来，然后交给下面的方法打包 } } catch (IOException e){ e.printStackTrace(); } } //其他情况一律返回404 return this.packet(HttpResponseStatus.NOT_FOUND, \u0026#34;404 Not Found!\u0026#34;.getBytes()); } //包装成FullHttpResponse，把状态码和数据写进去 private FullHttpResponse packet(HttpResponseStatus status, byte[] data){ FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, status); response.content().writeBytes(data); return response; } } 现在我们的静态资源解析就写好了，接着：\nchannel.pipeline() .addLast(new HttpRequestDecoder()) //Http请求解码器 .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) //搞一个聚合器，将内容聚合为一个FullHttpRequest，参数是最大内容长度 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { FullHttpRequest request = (FullHttpRequest) msg; //请求进来了直接走解析 PageResolver resolver = PageResolver.getInstance(); ctx.channel().writeAndFlush(resolver.resolveResource(request.uri())); ctx.channel().close(); } }) .addLast(new HttpResponseEncoder()); 现在我们启动服务器来试试看吧：\n可以看到页面可以正常展示了，是不是有Tomcat哪味了。\n其他内置Handler介绍 #\rNetty也为我们内置了一些其他比较好用的Handler，比如我们要打印日志：\nchannel.pipeline() .addLast(new HttpRequestDecoder()) .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) .addLast(new LoggingHandler(LogLevel.INFO)) //添加一个日志Handler，在请求到来时会自动打印相关日志 ... 日志级别我们选择INFO，现在我们用浏览器访问一下：\n可以看到每次请求的内容和详细信息都会在日志中出现，包括详细的数据包解析过程，请求头信息都是完整地打印在控制台上的。\n我们也可以使用Handler对IP地址进行过滤，比如我们不希望某些IP地址连接我们的服务器：\nchannel.pipeline() .addLast(new HttpRequestDecoder()) .addLast(new HttpObjectAggregator(Integer.MAX_VALUE)) .addLast(new RuleBasedIpFilter(new IpFilterRule() { @Override public boolean matches(InetSocketAddress inetSocketAddress) { return !inetSocketAddress.getHostName().equals(\u0026#34;127.0.0.1\u0026#34;); //进行匹配，返回false表示匹配失败 //如果匹配失败，那么会根据下面的类型决定该干什么，比如我们这里判断是不是本地访问的，如果是那就拒绝 } @Override public IpFilterRuleType ruleType() { return IpFilterRuleType.REJECT; //类型，REJECT表示拒绝连接，ACCEPT表示允许连接 } })) 现在我们浏览器访问一下看看：\n我们也可以对那些长期处于空闲的进行处理：\nchannel.pipeline() .addLast(new StringDecoder()) .addLast(new IdleStateHandler(10, 10, 0)) //IdleStateHandler能够侦测连接空闲状态 //第一个参数表示连接多少秒没有读操作时触发事件，第二个是写操作，第三个是读写操作都算，0表示禁用 //事件需要在ChannelInboundHandlerAdapter中进行监听处理 .addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;收到客户端数据：\u0026#34;+msg); ctx.channel().writeAndFlush(\u0026#34;已收到！\u0026#34;); } @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception { //没想到吧，这个方法原来是在这个时候用的 if(evt instanceof IdleStateEvent) { IdleStateEvent event = (IdleStateEvent) evt; if(event.state() == IdleState.WRITER_IDLE) { System.out.println(\u0026#34;好久都没写了，看视频的你真的有认真在跟着敲吗\u0026#34;); } else if(event.state() == IdleState.READER_IDLE) { System.out.println(\u0026#34;已经很久很久没有读事件发生了，好寂寞\u0026#34;); } } } }) .addLast(new StringEncoder()); 可以看到，当我们超过一段时间不发送数据时，就会这样：\n通过这种机制，我们就可以直接关掉那些占着茅坑不拉屎的连接。\n启动流程源码解读 #\r前面我们完成了对Netty基本功能的讲解，我们最后就来看一下，Netty到底是如何启动以及进行数据处理的。\n首先我们知道，整个服务端是在bind之后启动的，那么我们就从这里开始下手，不多BB直接上源码：\npublic ChannelFuture bind(int inetPort) { return this.bind(new InetSocketAddress(inetPort)); //转换成InetSocketAddress对象 } 进来之后发现是调用的其他绑定方法，继续：\npublic ChannelFuture bind(SocketAddress localAddress) { this.validate(); //再次验证一下，看看EventLoopGroup和Channel指定了没 return this.doBind((SocketAddress)ObjectUtil.checkNotNull(localAddress, \u0026#34;localAddress\u0026#34;)); } 我们继续往下看：\nprivate ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = this.initAndRegister(); //上来第一句初始化然后注册 ... } 我们看看是怎么注册的：\nfinal ChannelFuture initAndRegister() { Channel channel = null; try { channel = this.channelFactory.newChannel(); //通过channelFactory创建新的Channel，实际上就是我们在一开始设定的NioServerSocketChannel this.init(channel); //接着对创建好的NioServerSocketChannel进行初始化 ... ChannelFuture regFuture = this.config().group().register(channel); //将通道注册到bossGroup中的一个EventLoop中 ... return regFuture; } 我们来看看是如何对创建好的ServerSocketChannel进行初始化的：\nvoid init(Channel channel) { setChannelOptions(channel, this.newOptionsArray(), logger); setAttributes(channel, this.newAttributesArray()); ChannelPipeline p = channel.pipeline(); ... //在流水线上添加一个Handler，在Handler初始化的时候向EventLoop中提交一个任务，将ServerBootstrapAcceptor添加到流水线上 //这样我们的ServerSocketChannel在客户端连接时就能Accept了 p.addLast(new ChannelHandler[]{new ChannelInitializer\u0026lt;Channel\u0026gt;() { public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = ServerBootstrap.this.config.handler(); if (handler != null) { pipeline.addLast(new ChannelHandler[]{handler}); } ch.eventLoop().execute(new Runnable() { public void run() { //这里提交一个任务，将ServerBootstrapAcceptor添加到ServerSocketChannel的pipeline中 pipeline.addLast(new ChannelHandler[]{new ServerBootstrapAcceptor(ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)}); } }); } }}); } 我们来看一下，ServerBootstrapAcceptor怎么处理的，直接看到它的channelRead方法：\n//当底层NIO的ServerSocketChannel的Selector有OP_ACCEPT事件到达时，NioEventLoop会接收客户端连接，创建SocketChannel，并触发channelRead回调 public void channelRead(ChannelHandlerContext ctx, Object msg) { //此时msg就是Accept连接创建之后的Channel对象 final Channel child = (Channel)msg; //这里直接将我们之前编写的childHandler添加到新创建的客户端连接的流水线中（是不是感觉突然就通了） child.pipeline().addLast(new ChannelHandler[]{this.childHandler}); AbstractBootstrap.setChannelOptions(child, this.childOptions, ServerBootstrap.logger); AbstractBootstrap.setAttributes(child, this.childAttrs); try { //直接向workGroup中的一个EventLoop注册新创建好的客户端连接Channel，等待读写事件 this.childGroup.register(child).addListener(new ChannelFutureListener() { //异步操作完成后，如果没有注册成功，就强制关闭这个Channel public void operationComplete(ChannelFuture future) throws Exception { if (!future.isSuccess()) { ServerBootstrap.ServerBootstrapAcceptor.forceClose(child, future.cause()); ... 所以，实际上就是我们之前讲解的主从Reactor多线程模型，只要前面理解了，这里其实很好推断。\n初始化完成之后，我们来看看注册，在之前NIO阶段我们也是需要将Channel注册到对应的Selector才可以开始选择：\npublic ChannelFuture register(Channel channel) { return this.register((ChannelPromise)(new DefaultChannelPromise(channel, this))); //转换成ChannelPromise继续 } public ChannelFuture register(ChannelPromise promise) { ObjectUtil.checkNotNull(promise, \u0026#34;promise\u0026#34;); promise.channel().unsafe().register(this, promise); //调用Channel的Unsafe接口实现进行注册 return promise; } 继续向下：\npublic final void register(EventLoop eventLoop, final ChannelPromise promise) { ... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) { this.register0(promise); //这里是继续调用register0方法在进行注册 } ... } } 继续：\nprivate void register0(ChannelPromise promise) { try { ... boolean firstRegistration = this.neverRegistered; AbstractChannel.this.doRegister(); //这里开始执行AbstractNioChannel中的doRegister方法进行注册 AbstractChannel.this.registered = true; AbstractChannel.this.pipeline.invokeHandlerAddedIfNeeded(); this.safeSetSuccess(promise); if (AbstractChannel.this.isActive()) { if (firstRegistration) { AbstractChannel.this.pipeline.fireChannelActive(); //这里是关键 } else if (AbstractChannel.this.config().isAutoRead()) { this.beginRead(); } } ... } 来到最后一级：\nprotected void doRegister() throws Exception { boolean selected = false; while(true) { try { //可以看到在这里终于是真正的进行了注册，javaChannel()得到NIO的Channel对象，然后调用register方法 //这里就和我们之前NIO一样了，将Channel注册到Selector中，可以看到Selector也是EventLoop中的 //但是注意，这里的ops参数是0，也就是不监听任何事件 this.selectionKey = this.javaChannel().register(this.eventLoop().unwrappedSelector(), 0, this); return; ... } } 我们回到上一级，在doRegister完成之后，会拿到selectionKey，但是注意这时还没有监听任何事件，我们接着看到下面的fireChannelActive方法：\npublic final ChannelPipeline fireChannelActive() { AbstractChannelHandlerContext.invokeChannelActive(this.head); //传的是流水线上的默认头结点 return this; } static void invokeChannelActive(final AbstractChannelHandlerContext next) { EventExecutor executor = next.executor(); if (executor.inEventLoop()) { next.invokeChannelActive(); //继续向下 } else { executor.execute(new Runnable() { public void run() { next.invokeChannelActive(); } }); } } private void invokeChannelActive() { if (this.invokeHandler()) { try { ((ChannelInboundHandler)this.handler()).channelActive(this); //依然是调用的头结点的channelActive方法进行处理 } catch (Throwable var2) { this.invokeExceptionCaught(var2); } } else { this.fireChannelActive(); } } public void channelActive(ChannelHandlerContext ctx) { //这里是头结点的 ctx.fireChannelActive(); this.readIfIsAutoRead(); //继续向下 } private void readIfIsAutoRead() { if (DefaultChannelPipeline.this.channel.config().isAutoRead()) { DefaultChannelPipeline.this.channel.read(); //继续不断向下 } } public void read(ChannelHandlerContext ctx) { this.unsafe.beginRead(); //最后这里会调用beginRead方法 } public final void beginRead() { this.assertEventLoop(); try { AbstractChannel.this.doBeginRead(); //这里就是调用AbstractNioChannel的doBeginRead方法了 } catch (final Exception var2) { this.invokeLater(new Runnable() { public void run() { AbstractChannel.this.pipeline.fireExceptionCaught(var2); } }); this.close(this.voidPromise()); } } protected void doBeginRead() throws Exception { SelectionKey selectionKey = this.selectionKey; //先拿到之前注册好的selectionKey if (selectionKey.isValid()) { this.readPending = true; int interestOps = selectionKey.interestOps(); //把监听的操作取出来 if ((interestOps \u0026amp; this.readInterestOp) == 0) { //如果没有监听任何操作 selectionKey.interestOps(interestOps | this.readInterestOp); //那就把readInterestOp事件进行监听，这里的readInterestOp实际上就是OP_ACCEPT } } } 这样，Channel在初始化完成之后也完成了底层的注册，已经可以开始等待事件了。\n我们现在回到之前的doBind方法的注册位置，现在注册完成之后，基本上整个主从Reactor结构就已经出来了，我们来看看还要做些什么：\nprivate ChannelFuture doBind(final SocketAddress localAddress) { final ChannelFuture regFuture = this.initAndRegister(); //目前初始化和注册都已经成功了 final Channel channel = regFuture.channel(); //由于是异步操作，我们通过ChannelFuture拿到对应的ServerSocketChannel对象 if (regFuture.cause() != null) { return regFuture; } else if (regFuture.isDone()) { //如果说初始化已经完成了 ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); //直接开始进行进一步的绑定 return promise; } else { //如果还没搞完，那就创Promis继续等待任务完成 final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { promise.setFailure(cause); } else { promise.registered(); AbstractBootstrap.doBind0(regFuture, channel, localAddress, promise); } } }); return promise; } } 可以看到最后都会走到doBind0方法：\nprivate static void doBind0(final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) { //最后会向Channel已经注册到的EventLoop中提交一个新的任务 channel.eventLoop().execute(new Runnable() { public void run() { if (regFuture.isSuccess()) { //这里才是真正调用Channel底层进行绑定操作 channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); } else { promise.setFailure(regFuture.cause()); } } }); } 至此，服务端的启动流程结束。我们前面还提到了NIO的空轮询问题，这里我们来看看Netty是如何解决的，我们直接定位到NioEventLoop中：\n//由于代码太多，这里省略大部分代码 while(true) { boolean var34; try { ... try { if (!this.hasTasks()) { strategy = this.select(curDeadlineNanos); //首先会在这里进行Selector.select()操作，跟NIO是一样的 } ... ++selectCnt; //每次唤醒都会让selectCnt自增 this.cancelledKeys = 0; ... if (!ranTasks \u0026amp;\u0026amp; strategy \u0026lt;= 0) { if (this.unexpectedSelectorWakeup(selectCnt)) { //这里会进行判断是否出现空轮询BUG ... 我们来看看是怎么进行判断的：\nprivate boolean unexpectedSelectorWakeup(int selectCnt) { if (Thread.interrupted()) { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Selector.select() returned prematurely because Thread.currentThread().interrupt() was called. Use NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.\u0026#34;); } return true; //如果selectCnt大于等于SELECTOR_AUTO_REBUILD_THRESHOLD（默认为512）那么会直接重建Selector } else if (SELECTOR_AUTO_REBUILD_THRESHOLD \u0026gt; 0 \u0026amp;\u0026amp; selectCnt \u0026gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) { logger.warn(\u0026#34;Selector.select() returned prematurely {} times in a row; rebuilding Selector {}.\u0026#34;, selectCnt, this.selector); this.rebuildSelector(); //当前的Selector出现BUG了，得重建一个Selector return true; } else { return false; } } 实际上，当每次空轮询发生时会有专门的计数器+1，如果空轮询的次数超过了512次，就认为其触发了空轮询bug，触发bug后，Netty直接重建一个Selector，将原来的Channel重新注册到新的 Selector上，将旧的 Selector关掉，这样就防止了无限循环。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/netty/netty/","section":"Docs","summary":"Netty框架 #\r前面我们学习了Java为我们提供的NIO框架，提供使用NIO提供的三大组件，我们就可以编写更加高性能的客户端/服务端网络程序了，甚至还可以自行规定一种通信协议进行通信。\nNIO框架存在的问题 #\r但是之前我们在使用NIO框架的时候，还是发现了一些问题，我们先来盘点一下。\n客户端关闭导致服务端空轮询 #\r可能在之前的实验中，你发现了这样一个问题：\n当我们的客户端主动与服务端断开连接时，会导致READ事件一直被触发，也就是说selector.select()会直接通过，并且是可读的状态，但是我们发现实际上读到是数据是一个空的（上面的图中在空轮询两次后抛出异常了，也有可能是无限的循环下去）所以这里我们得稍微处理一下：\n} else if(key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); //这里我们需要判断一下，如果read操作得到的结果是-1，那么说明服务端已经断开连接了 if(channel.read(buffer) \u0026lt; 0) { System.out.println(\u0026#34;客户端已经断开连接了：\u0026#34;+channel.getRemoteAddress()); channel.","title":"Netty","type":"doc"},{"content":"\rNIO基础 #\r**注意：**推荐完成JavaSE篇、JavaWeb篇的学习再开启这一部分的学习，如果在这之前完成了JVM篇，那么看起来就会比较轻松了。\n在JavaSE的学习中，我们了解了如何使用IO进行数据传输，Java IO是阻塞的，如果在一次读写数据调用时数据还没有准备好，或者目前不可写，那么读写操作就会被阻塞直到数据准备好或目标可写为止。Java NIO则是非阻塞的，每一次数据读写调用都会立即返回，并将目前可读（或可写）的内容写入缓冲区或者从缓冲区中输出，即使当前没有可用数据，调用仍然会立即返回并且不对缓冲区做任何操作。\nNIO框架是在JDK1.4推出的，它的出现就是为了解决传统IO的不足，这一期视频，我们就将围绕着NIO开始讲解。\n缓冲区 #\r一切的一切还要从缓冲区开始讲起，包括源码在内，其实这个不是很难，只是需要理清思路。\nBuffer类及其实现 #\rBuffer类是缓冲区的实现，类似于Java中的数组，也是用于存放和获取数据的。但是Buffer相比Java中的数组，功能就非常强大了，它包含一系列对于数组的快捷操作。\nBuffer是一个抽象类，它的核心内容：\npublic abstract class Buffer { // 这四个变量的关系: mark \u0026lt;= position \u0026lt;= limit \u0026lt;= capacity // 这些变量就是Buffer操作的核心了，之后我们学习的过程中可以看源码是如何操作这些变量的 private int mark = -1; private int position = 0; private int limit; private int capacity; // 直接缓冲区实现子类的数据内存地址（之后会讲解） long address; 我们来看看Buffer类的子类，包括我们认识到的所有基本类型（除了 boolean类型之外）：\nIntBuffer - int类型的缓冲区。 ShortBuffer - short类型的缓冲区。 LongBuffer - long类型的缓冲区。 FloatBuffer - float类型的缓冲区。 DoubleBuffer - double类型的缓冲区。 ByteBuffer - byte类型的缓冲区。 CharBuffer - char类型的缓冲区。 （注意我们之前在JavaSE中学习过的StringBuffer虽然也是这种命名方式，但是不属于Buffer体系，这里不会进行介绍）\n这里我们以IntBuffer为例，我们来看看如何创建一个Buffer类：\npublic static void main(String[] args) { //创建一个缓冲区不能直接new，而是需要使用静态方法去生成，有两种方式： //1. 申请一个容量为10的int缓冲区 IntBuffer buffer = IntBuffer.allocate(10); //2. 可以将现有的数组直接转换为缓冲区（包括数组中的数据） int[] arr = new int[]{1, 2, 3, 4, 5, 6}; IntBuffer buffer = IntBuffer.wrap(arr); } 那么它的内部是本质上如何进行操作的呢？我们来看看它的源码：\npublic static IntBuffer allocate(int capacity) { if (capacity \u0026lt; 0) //如果申请的容量小于0，那还有啥意思 throw new IllegalArgumentException(); return new HeapIntBuffer(capacity, capacity); //可以看到这里会直接创建一个新的IntBuffer实现类 //HeapIntBuffer是在堆内存中存放数据，本质上就数组，一会我们可以在深入看一下 } public static IntBuffer wrap(int[] array, int offset, int length) { try { //可以看到这个也是创建了一个新的HeapIntBuffer对象，并且给了初始数组以及截取的起始位置和长度 return new HeapIntBuffer(array, offset, length); } catch (IllegalArgumentException x) { throw new IndexOutOfBoundsException(); } } public static IntBuffer wrap(int[] array) { return wrap(array, 0, array.length); //调用的是上面的wrap方法 } 那么这个HeapIntBuffer又是如何实现的呢，我们接着来看：\nHeapIntBuffer(int[] buf, int off, int len) { // 注意这个构造方法不是public，是默认的访问权限 super(-1, off, off + len, buf.length, buf, 0); //你会发现这怎么又去调父类的构造方法了，绕来绕去 //mark是标记，off是当前起始下标位置，off+len是最大下标位置，buf.length是底层维护的数组真正长度，buf就是数组，最后一个0是起始偏移位置 } 我们又来看看IntBuffer中的构造方法是如何定义的：\nfinal int[] hb; // 只有在堆缓冲区实现时才会使用 final int offset; boolean isReadOnly; // 只有在堆缓冲区实现时才会使用 IntBuffer(int mark, int pos, int lim, int cap, // 注意这个构造方法不是public，是默认的访问权限 int[] hb, int offset) { super(mark, pos, lim, cap); //调用Buffer类的构造方法 this.hb = hb; //hb就是真正我们要存放数据的数组，堆缓冲区底层其实就是这么一个数组 this.offset = offset; //起始偏移位置 } 最后我们来看看Buffer中的构造方法：\nBuffer(int mark, int pos, int lim, int cap) { // 注意这个构造方法不是public，是默认的访问权限 if (cap \u0026lt; 0) //容量不能小于0，小于0还玩个锤子 throw new IllegalArgumentException(\u0026#34;Negative capacity: \u0026#34; + cap); this.capacity = cap; //设定缓冲区容量 limit(lim); //设定最大position位置 position(pos); //设定起始位置 if (mark \u0026gt;= 0) { //如果起始标记大于等于0 if (mark \u0026gt; pos) //并且标记位置大于起始位置，那么就抛异常（至于为啥不能大于我们后面再说） throw new IllegalArgumentException(\u0026#34;mark \u0026gt; position: (\u0026#34; + mark + \u0026#34; \u0026gt; \u0026#34; + pos + \u0026#34;)\u0026#34;); this.mark = mark; //否则设定mark位置（mark默认为-1） } } 通过对源码的观察，我们大致可以得到以下结构了：\n现在我们来总结一下上面这些结构的各自职责划分：\nBuffer：缓冲区的一些基本变量定义，比如当前的位置（position）、容量 (capacity)、最大限制 (limit)、标记 (mark)等，你肯定会疑惑这些变量有啥用，别着急，这些变量会在后面的操作中用到，我们逐步讲解。 IntBuffer等子类：定义了存放数据的数组（只有堆缓冲区实现子类才会用到）、是否只读等，也就是说数据的存放位置、以及对于底层数组的相关操作都在这里已经定义好了，并且已经实现了Comparable接口。 HeapIntBuffer堆缓冲区实现子类：数据存放在堆中，实际上就是用的父类的数组在保存数据，并且将父类定义的所有底层操作全部实现了。 这样，我们对于Buffer类的基本结构就有了一个大致的认识。\n缓冲区写操作 #\r前面我们了解了Buffer类的基本操作，现在我们来看一下如何向缓冲区中存放数据以及获取数据，数据的存放包括以下四个方法：\npublic abstract IntBuffer put(int i); - 在当前position位置插入数据，由具体子类实现 public abstract IntBuffer put(int index, int i); - 在指定位置存放数据，也是由具体子类实现 public final IntBuffer put(int[] src); - 直接存放所有数组中的内容（数组长度不能超出缓冲区大小） public IntBuffer put(int[] src, int offset, int length); - 直接存放数组中的内容，同上，但是可以指定存放一段范围 public IntBuffer put(IntBuffer src); - 直接存放另一个缓冲区中的内容 我们从最简的开始看，是在当前位置插入一个数据，那么这个当前位置是怎么定义的呢，我们来看看源码：\npublic IntBuffer put(int x) { hb[ix(nextPutIndex())] = x; //这个ix和nextPutIndex()很灵性，我们来看看具体实现 return this; } protected int ix(int i) { return i + offset; //将i的值加上我们之前设定的offset偏移量值，但是默认是0（非0的情况后面会介绍） } final int nextPutIndex() { int p = position; //获取Buffer类中的position位置（一开始也是0） if (p \u0026gt;= limit) //位置肯定不能超过底层数组最大长度，否则越界 throw new BufferOverflowException(); position = p + 1; //获取之后会使得Buffer类中的position+1 return p; //返回当前的位置 } 所以put操作实际上是将底层数组 hb在position位置上的数据进行设定。\n设定完成后，position自动后移：\n我们可以编写代码来看看：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.allocate(10); buffer .put(1) .put(2) .put(3); //我们依次存放三个数据试试看 System.out.println(buffer); } 通过断点调试，我们来看看实际的操作情况：\n可以看到我们不断地put操作，position会一直向后移动，当然如果超出最大长度，那么会直接抛出异常：\n接着我们来看看第二个put操作是如何进行，它能够在指定位置插入数据：\npublic IntBuffer put(int i, int x) { hb[ix(checkIndex(i))] = x; //这里依然会使用ix，但是会检查位置是否合法 return this; } final int checkIndex(int i) { // package-private if ((i \u0026lt; 0) || (i \u0026gt;= limit)) //插入的位置不能小于0并且不能大于等于底层数组最大长度 throw new IndexOutOfBoundsException(); return i; //没有问题就把i返回 } 实际上这个比我们之前的要好理解一些，注意全程不会操作position的值，这里需要注意一下。\n我们接着来看第三个put操作，它是直接在IntBuffer中实现的，是基于前两个put方法的子类实现来完成的：\npublic IntBuffer put(int[] src, int offset, int length) { checkBounds(offset, length, src.length); //检查截取范围是否合法，给offset、调用者指定长度、数组实际长度 if (length \u0026gt; remaining()) //接着判断要插入的数据量在缓冲区是否容得下，装不下也不行 throw new BufferOverflowException(); int end = offset + length; //计算出最终读取位置，下面开始for for (int i = offset; i \u0026lt; end; i++) this.put(src[i]); //注意是直接从postion位置开始插入，直到指定范围结束 return this; //ojbk } public final IntBuffer put(int[] src) { return put(src, 0, src.length); //因为不需要指定范围，所以直接0和length，然后调上面的，多捞哦 } public final int remaining() { //计算并获取当前缓冲区的剩余空间 int rem = limit - position; //最大容量减去当前位置，就是剩余空间 return rem \u0026gt; 0 ? rem : 0; //没容量就返回0 } static void checkBounds(int off, int len, int size) { // package-private if ((off | len | (off + len) | (size - (off + len))) \u0026lt; 0) //让我猜猜，看不懂了是吧 throw new IndexOutOfBoundsException(); //实际上就是看给定的数组能不能截取出指定的这段数据，如果都不够了那肯定不行啊 } 大致流程如下，首先来了一个数组要取一段数据全部丢进缓冲区：\n在检查没有什么问题并且缓冲区有容量时，就可以开始插入了：\n最后我们通过代码来看看：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.allocate(10); int[] arr = new int[]{1,2,3,4,5,6,7,8,9}; buffer.put(arr, 3, 4); //从下标3开始，截取4个元素 System.out.println(Arrays.toString(buffer.array())); //array方法可以直接获取到数组 } 可以看到最后结果为：\n当然我们也可以将一个缓冲区的内容保存到另一个缓冲区：\npublic IntBuffer put(IntBuffer src) { if (src == this) //不会吧不会吧，不会有人保存自己吧 throw new IllegalArgumentException(); if (isReadOnly()) //如果是只读的话，那么也是不允许插入操作的（我猜你们肯定会问为啥就这里会判断只读，前面四个呢） throw new ReadOnlyBufferException(); int n = src.remaining(); //给进来的src看看容量（注意这里不remaining的结果不是剩余容量，是转换后的，之后会说） if (n \u0026gt; remaining()) //这里判断当前剩余容量是否小于src容量 throw new BufferOverflowException(); for (int i = 0; i \u0026lt; n; i++) //也是从position位置开始继续写入 put(src.get()); //通过get方法一个一个读取数据出来，具体过程后面讲解 return this; } 我们来看看效果：\npublic static void main(String[] args) { IntBuffer src = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); IntBuffer buffer = IntBuffer.allocate(10); buffer.put(src); System.out.println(Arrays.toString(buffer.array())); } 但是如果是这样的话，会出现问题：\npublic static void main(String[] args) { IntBuffer src = IntBuffer.allocate(5); for (int i = 0; i \u0026lt; 5; i++) src.put(i); //手动插入数据 IntBuffer buffer = IntBuffer.allocate(10); buffer.put(src); System.out.println(Arrays.toString(buffer.array())); } 我们发现，结果和上面的不一样，并没有成功地将数据填到下面的IntBuffer中，这是为什么呢？实际上就是因为 remaining()的计算问题，因为这个方法是直接计算postion的位置，但是由于我们在写操作完成之后，position跑到后面去了，也就导致 remaining()结果最后算出来为0。\n因为这里不是写操作，是接下来需要从头开始进行读操作，所以我们得想个办法把position给退回到一开始的位置，这样才可以从头开始读取，那么怎么做呢？一般我们在写入完成后需要进行读操作时（后面都是这样，不只是这里），会使用 flip()方法进行翻转：\npublic final Buffer flip() { limit = position; //修改limit值，当前写到哪里，下次读的最终位置就是这里，limit的作用开始慢慢体现了 position = 0; //position归零 mark = -1; //标记还原为-1，但是现在我们还没用到 return this; } 这样，再次计算 remaining()的结果就是我们需要读取的数量了，这也是为什么put方法中要用 remaining()来计算的原因，我们再来测试一下：\npublic static void main(String[] args) { IntBuffer src = IntBuffer.allocate(5); for (int i = 0; i \u0026lt; 5; i++) src.put(i); IntBuffer buffer = IntBuffer.allocate(10); src.flip(); //我们可以通过flip来翻转缓冲区 buffer.put(src); System.out.println(Arrays.toString(buffer.array())); } 翻转之后再次进行转移，就正常了。\n缓冲区读操作 #\r前面我们看完了写操作，现在我们接着来看看读操作。读操作有四个方法：\npublic abstract int get(); - 直接获取当前position位置的数据，由子类实现 public abstract int get(int index); - 获取指定位置的数据，也是子类实现 public IntBuffer get(int[] dst) - 将数据读取到给定的数组中 public IntBuffer get(int[] dst, int offset, int length) - 同上，加了个范围 我们还是从最简单的开始看，第一个get方法的实现在IntBuffer类中：\npublic int get() { return hb[ix(nextGetIndex())]; //直接从数组中取就完事 } final int nextGetIndex() { // 好家伙，这不跟前面那个一模一样吗 int p = position; if (p \u0026gt;= limit) throw new BufferUnderflowException(); position = p + 1; return p; } 可以看到每次读取操作之后，也会将postion+1，直到最后一个位置，如果还要继续读，那么就直接抛出异常。\n我们来看看第二个：\npublic int get(int i) { return hb[ix(checkIndex(i))]; //这里依然是使用checkIndex来检查位置是否非法 } 我们来看看第三个和第四个：\npublic IntBuffer get(int[] dst, int offset, int length) { checkBounds(offset, length, dst.length); //跟put操作一样，也是需要检查是否越界 if (length \u0026gt; remaining()) //如果读取的长度比可以读的长度大，那肯定是不行的 throw new BufferUnderflowException(); int end = offset + length; //计算出最终读取位置 for (int i = offset; i \u0026lt; end; i++) dst[i] = get(); //开始从position把数据读到数组中，注意是在数组的offset位置开始 return this; } public IntBuffer get(int[] dst) { return get(dst, 0, dst.length); //不指定范围的话，那就直接用上面的 } 我们来看看效果：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); int[] arr = new int[10]; buffer.get(arr, 2, 5); System.out.println(Arrays.toString(arr)); } 可以看到成功地将数据读取到了数组中。\n当然如果我们需要直接获取数组，也可以使用 array()方法来拿到：\npublic final int[] array() { if (hb == null) //为空那说明底层不是数组实现的，肯定就没法转换了 throw new UnsupportedOperationException(); if (isReadOnly) //只读也是不让直接取出的，因为一旦取出去岂不是就能被修改了 throw new ReadOnlyBufferException(); return hb; //直接返回hb } 我们来试试看：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); System.out.println(Arrays.toString(buffer.array())); } 当然，既然都已经拿到了底层的 hb了，我们来看看如果直接修改之后是不是读取到的就是我们的修改之后的结果了：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); int[] arr = buffer.array(); arr[0] = 99999; //拿到数组对象直接改 System.out.println(buffer.get()); } 可以看到这种方式由于是直接拿到的底层数组，所有修改会直接生效在缓冲区中。\n当然除了常规的读取方式之外，我们也可以通过 mark()来实现跳转读取，这里需要介绍一下几个操作：\npublic final Buffer mark() - 标记当前位置 public final Buffer reset() - 让当前的position位置跳转到mark当时标记的位置 我们首先来看标记方法：\npublic final Buffer mark() { mark = position; //直接标记到当前位置，mark变量终于派上用场了，当然这里仅仅是标记 return this; } 我们再来看看重置方法：\npublic final Buffer reset() { int m = mark; //存一下当前的mark位置 if (m \u0026lt; 0) //因为mark默认是-1，要是没有进行过任何标记操作，那reset个毛 throw new InvalidMarkException(); position = m; //直接让position变成mark位置 return this; } 那比如我们在读取到1号位置时进行标记：\n接着我们使用reset方法就可以直接回退回去了：\n现在我们来测试一下：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); buffer.get(); //读取一位，那么position就变成1了 buffer.mark(); //这时标记，那么mark = 1 buffer.get(); //又读取一位，那么position就变成2了 buffer.reset(); //直接将position = mark，也就是变回1 System.out.println(buffer.get()); } 可以看到，读取的位置根据我们的操作进行了变化，有关缓冲区的读操作，就暂时讲到这里。\n缓冲区其他操作 #\r前面我们大致了解了一下缓冲区的读写操作，那么我们接着来看看，除了常规的读写操作之外，还有哪些其他的操作：\npublic abstract IntBuffer compact() - 压缩缓冲区，由具体实现类实现 public IntBuffer duplicate() - 复制缓冲区，会直接创建一个新的数据相同的缓冲区 public abstract IntBuffer slice() - 划分缓冲区，会将原本的容量大小的缓冲区划分为更小的出来进行操作 public final Buffer rewind() - 重绕缓冲区，其实就是把position归零，然后mark变回-1 public final Buffer clear() - 将缓冲区清空，所有的变量变如图9回最初的状态 我们先从压缩缓冲区开始看起，它会将整个缓冲区的大小和数据内容变成position位置到limit之间的数据，并移动到数组头部：\npublic IntBuffer compact() { int pos = position(); //获取当前位置 int lim = limit(); //获取当前最大position位置 assert (pos \u0026lt;= lim); //断言表达式，position必须小于最大位置，肯定的 int rem = (pos \u0026lt;= lim ? lim - pos : 0); //计算pos距离最大位置的长度 System.arraycopy(hb, ix(pos), hb, ix(0), rem); //直接将hb数组当前position位置的数据拷贝到头部去，然后长度改成刚刚计算出来的空间 position(rem); //直接将position移动到rem位置 limit(capacity()); //pos最大位置修改为最大容量 discardMark(); //mark变回-1 return this; } 比如现在的状态是：\n那么我们在执行 compact()方法之后，会进行截取，此时 limit - position = 6，那么就会截取第 4、5、6、7、8、9这6个数据然后丢到最前面，接着position跑到 7表示这是下一个继续的位置：\n现在我们通过代码来检验一下：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); for (int i = 0; i \u0026lt; 4; i++) buffer.get(); //先正常读4个 buffer.compact(); //压缩缓冲区 System.out.println(\u0026#34;压缩之后的情况：\u0026#34;+Arrays.toString(buffer.array())); System.out.println(\u0026#34;当前position位置：\u0026#34;+buffer.position()); System.out.println(\u0026#34;当前limit位置：\u0026#34;+buffer.limit()); } 可以看到最后的结果没有问题：\n我们接着来看第二个方法，那么如果我们现在需要复制一个内容一模一样的的缓冲区，该怎么做？直接使用 duplicate()方法就可以复制了：\npublic IntBuffer duplicate() { //直接new一个新的，但是是吧hb给丢进去了，而不是拷贝一个新的 return new HeapIntBuffer(hb, this.markValue(), this.position(), this.limit(), this.capacity(), offset); } 那么各位猜想一下，如果通过这种方式创了一个新的IntBuffer，那么下面的例子会出现什么结果：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); IntBuffer duplicate = buffer.duplicate(); System.out.println(buffer == duplicate); System.out.println(buffer.array() == duplicate.array()); } 由于buffer是重新new的，所以第一个为false，而底层的数组由于在构造的时候没有进行任何的拷贝而是直接传递，因此实际上两个缓冲区的底层数组是同一个对象。所以，一个发生修改，那么另一个就跟着变了：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5}); IntBuffer duplicate = buffer.duplicate(); buffer.put(0, 66666); System.out.println(duplicate.get()); } 现在我们接着来看下一个方法，slice()方法会将缓冲区进行划分：\npublic IntBuffer slice() { int pos = this.position(); //获取当前position int lim = this.limit(); //获取position最大位置 int rem = (pos \u0026lt;= lim ? lim - pos : 0); //求得剩余空间 return new HeapIntBuffer(hb, //返回一个新的划分出的缓冲区，但是底层的数组用的还是同一个 -1, 0, rem, //新的容量变成了剩余空间的大小 rem, pos + offset); //可以看到offset的地址不再是0了，而是当前的position加上原有的offset值 } 虽然现在底层依然使用的是之前的数组，但是由于设定了offset值，我们之前的操作似乎变得不太一样了：\n回顾前面我们所讲解的内容，在读取和存放时，会被 ix方法进行调整：\nprotected int ix(int i) { return i + offset; //现在offset为4，那么也就是说逻辑上的i是0但是得到真实位置却是4 } public int get() { return hb[ix(nextGetIndex())]; //最后会经过ix方法转换为真正在数组中的位置 } 当然，在逻辑上我们可以认为是这样的：\n现在我们来测试一下：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); for (int i = 0; i \u0026lt; 4; i++) buffer.get(); IntBuffer slice = buffer.slice(); System.out.println(\u0026#34;划分之后的情况：\u0026#34;+Arrays.toString(slice.array())); System.out.println(\u0026#34;划分之后的偏移地址：\u0026#34;+slice.arrayOffset()); System.out.println(\u0026#34;当前position位置：\u0026#34;+slice.position()); System.out.println(\u0026#34;当前limit位置：\u0026#34;+slice.limit()); while (slice.hasRemaining()) { //将所有的数据全部挨着打印出来 System.out.print(slice.get()+\u0026#34;, \u0026#34;); } } 可以看到，最终结果：\n最后两个方法就比较简单了，我们先来看 rewind()，它相当于是对position和mark进行了一次重置：\npublic final Buffer rewind() { position = 0; mark = -1; return this; } 接着是 clear()，它相当于是将整个缓冲区回归到最初的状态了：\npublic final Buffer clear() { position = 0; //同上 limit = capacity; //limit变回capacity mark = -1; return this; } 到这里，关于缓冲区的一些其他操作，我们就讲解到此。\n缓冲区比较 #\r缓冲区之间是可以进行比较的，我们可以看到equals方法和compareTo方法都是被重写了的，我们首先来看看 equals方法，注意，它是判断两个缓冲区剩余的内容是否一致：\npublic boolean equals(Object ob) { if (this == ob) //要是两个缓冲区是同一个对象，肯定一样 return true; if (!(ob instanceof IntBuffer)) //类型不是IntBuffer那也不用比了 return false; IntBuffer that = (IntBuffer)ob; //转换为IntBuffer int thisPos = this.position(); //获取当前缓冲区的相关信息 int thisLim = this.limit(); int thatPos = that.position(); //获取另一个缓冲区的相关信息 int thatLim = that.limit(); int thisRem = thisLim - thisPos; int thatRem = thatLim - thatPos; if (thisRem \u0026lt; 0 || thisRem != thatRem) //如果剩余容量小于0或是两个缓冲区的剩余容量不一样，也不行 return false; //注意比较的是剩余的内容 for (int i = thisLim - 1, j = thatLim - 1; i \u0026gt;= thisPos; i--, j--) //从最后一个开始倒着往回比剩余的区域 if (!equals(this.get(i), that.get(j))) return false; //只要发现不一样的就不用继续了，直接false return true; //上面的比较都没问题，那么就true } private static boolean equals(int x, int y) { return x == y; } 那么我们按照它的思路来验证一下：\npublic static void main(String[] args) { IntBuffer buffer1 = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); IntBuffer buffer2 = IntBuffer.wrap(new int[]{6, 5, 4, 3, 2, 1, 7, 8, 9, 0}); System.out.println(buffer1.equals(buffer2)); //直接比较 buffer1.position(6); buffer2.position(6); System.out.println(buffer1.equals(buffer2)); //比较从下标6开始的剩余内容 } 可以看到结果就是我们所想的那样：\n那么我们接着来看比较，compareTo方法，它实际上是 Comparable接口提供的方法，它实际上比较的也是pos开始剩余的内容：\npublic int compareTo(IntBuffer that) { int thisPos = this.position(); //获取并计算两个缓冲区的pos和remain int thisRem = this.limit() - thisPos; int thatPos = that.position(); int thatRem = that.limit() - thatPos; int length = Math.min(thisRem, thatRem); //选取一个剩余空间最小的出来 if (length \u0026lt; 0) //如果最小的小于0，那就返回-1 return -1; int n = thisPos + Math.min(thisRem, thatRem); //计算n的值当前的pos加上剩余的最小空间 for (int i = thisPos, j = thatPos; i \u0026lt; n; i++, j++) { //从两个缓冲区的当前位置开始，一直到n结束 int cmp = compare(this.get(i), that.get(j)); //比较 if (cmp != 0) return cmp; //只要出现不相同的，那么就返回比较出来的值 } return thisRem - thatRem; //如果没比出来个所以然，那么就比长度 } private static int compare(int x, int y) { return Integer.compare(x, y); } 这里我们就不多做介绍了。\n只读缓冲区 #\r接着我们来看看只读缓冲区，只读缓冲区就像其名称一样，它只能进行读操作，而不允许进行写操作。\n那么我们怎么创建只读缓冲区呢？\npublic abstract IntBuffer asReadOnlyBuffer(); - 基于当前缓冲区生成一个只读的缓冲区。 我们来看看此方法的具体实现：\npublic IntBuffer asReadOnlyBuffer() { return new HeapIntBufferR(hb, //注意这里并不是直接创建了HeapIntBuffer，而是HeapIntBufferR，并且直接复制的hb数组 this.markValue(), this.position(), this.limit(), this.capacity(), offset); } 那么这个HeapIntBufferR类跟我们普通的HeapIntBuffer有什么不同之处呢？\n可以看到它是继承自HeapIntBuffer的，那么我们来看看它的实现有什么不同：\nprotected HeapIntBufferR(int[] buf, int mark, int pos, int lim, int cap, int off) { super(buf, mark, pos, lim, cap, off); this.isReadOnly = true; } 可以看到在其构造方法中，除了直接调用父类的构造方法外，还会将 isReadOnly标记修改为true，我们接着来看put操作有什么不同之处：\npublic boolean isReadOnly() { return true; } public IntBuffer put(int x) { throw new ReadOnlyBufferException(); } public IntBuffer put(int i, int x) { throw new ReadOnlyBufferException(); } public IntBuffer put(int[] src, int offset, int length) { throw new ReadOnlyBufferException(); } public IntBuffer put(IntBuffer src) { throw new ReadOnlyBufferException(); } 可以看到所有的put方法全部凉凉，只要调用就会直接抛出ReadOnlyBufferException异常。但是其他get方法依然没有进行重写，也就是说get操作还是可以正常使用的，但是只要是写操作就都不行：\npublic static void main(String[] args) { IntBuffer buffer = IntBuffer.wrap(new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 0}); IntBuffer readBuffer = buffer.asReadOnlyBuffer(); System.out.println(readBuffer.isReadOnly()); System.out.println(readBuffer.get()); readBuffer.put(0, 666); } 可以看到结果为：\n这就是只读状态下的缓冲区。\nByteBuffer和CharBuffer #\r通过前面的学习，我们基本上已经了解了缓冲区的使用，但是都是基于IntBuffer进行讲解，现在我们来看看另外两种基本类型的缓冲区ByteBuffer和CharBuffer，因为ByteBuffer底层存放的是很多单个byte字节，所以会有更多的玩法，同样CharBuffer是一系列字节，所以也有很多便捷操作。\n我们先来看看ByteBuffer，我们可以直接点进去看：\npublic abstract class ByteBuffer extends Buffer implements Comparable\u0026lt;ByteBuffer\u0026gt; { final byte[] hb; // Non-null only for heap buffers final int offset; boolean isReadOnly; // Valid only for heap buffers .... 可以看到如果也是使用堆缓冲区子类实现，那么依然是一个 byte[]的形式保存数据。我们来尝试使用一下：\npublic static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(10); //除了直接丢byte进去之外，我们也可以丢其他的基本类型（注意容量消耗） buffer.putInt(Integer.MAX_VALUE); //丢个int的最大值进去，注意一个int占4字节 System.out.println(\u0026#34;当前缓冲区剩余字节数：\u0026#34;+buffer.remaining()); //只剩6个字节了 //我们来尝试读取一下，记得先翻转 buffer.flip(); while (buffer.hasRemaining()) { System.out.println(buffer.get()); //一共四个字节 } } 最后的结果为：\n可以看到第一个byte为127、然后三个都是-1，我们来分析一下：\n127 转换为二进制补码形式就是 01111111，而 -1转换为二进制补码形式为 11111111 那也就是说，第一个字节是01111111，而后续字节就是11111111，把它们拼接在一起：\n二进制补码表示 01111111 11111111 11111111 11111111 转换为十进制就是 2147483647，也就是int的最大值。 那么根据我们上面的推导，各位能否计算得到下面的结果呢？\npublic static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate(10); buffer.put((byte) 0); buffer.put((byte) 0); buffer.put((byte) 1); buffer.put((byte) -1); buffer.flip(); //翻转一下 System.out.println(buffer.getInt()); //以int形式获取，那么就是一次性获取4个字节 } 经过上面的计算，得到的结果就是：\n上面的数据以二进制补码的形式表示为：00000000 00000000 00000001 11111111 将其转换为十进制那么就是：256 + 255 = 511 好吧，再来个魔鬼问题，把第一个换成1呢：10000000 00000000 00000001 11111111，自己算。\n我们接着来看看CharBuffer，这种缓冲区实际上也是保存一大堆char类型的数据：\npublic static void main(String[] args) { CharBuffer buffer = CharBuffer.allocate(10); buffer.put(\u0026#34;lbwnb\u0026#34;); //除了可以直接丢char之外，字符串也可以一次性丢进入 System.out.println(Arrays.toString(buffer.array())); } 但是正是得益于char数组，它包含了很多的字符串操作，可以一次性存放一整个字符串。我们甚至还可以将其当做一个String来进行处理：\npublic static void main(String[] args) { CharBuffer buffer = CharBuffer.allocate(10); buffer.put(\u0026#34;lbwnb\u0026#34;); buffer.append(\u0026#34;!\u0026#34;); //可以像StringBuilder一样使用append来继续添加数据 System.out.println(\u0026#34;剩余容量：\u0026#34;+buffer.remaining()); //已经用了6个字符了 buffer.flip(); System.out.println(\u0026#34;整个字符串为：\u0026#34;+buffer); //直接将内容转换为字符串 System.out.println(\u0026#34;第3个字符是：\u0026#34;+buffer.charAt(2)); //直接像String一样charAt buffer //也可以转换为IntStream进行操作 .chars() .filter(i -\u0026gt; i \u0026lt; \u0026#39;l\u0026#39;) .forEach(i -\u0026gt; System.out.print((char) i)); } 当然除了一些常规操作之外，我们还可以直接将一个字符串作为参数创建：\npublic static void main(String[] args) { //可以直接使用wrap包装一个字符串，但是注意，包装出来之后是只读的 CharBuffer buffer = CharBuffer.wrap(\u0026#34;收藏等于学会~\u0026#34;); System.out.println(buffer); buffer.put(\u0026#34;111\u0026#34;); //这里尝试进行一下写操作 } 可以看到结果也是我们预料中的：\n对于这两个比较特殊的缓冲区，我们就暂时讲解到这里。\n直接缓冲区 #\r**注意：**推荐学习完成JVM篇再来学习这一部分。\n最后我们来看一下直接缓冲区，我们前面一直使用的都是堆缓冲区，也就是说实际上数据是保存在一个数组中的，如果你已经完成了JVM篇的学习，一定知道实际上占用的是堆内存，而我们也可以创建一个直接缓冲区，也就是申请堆外内存进行数据保存，采用操作系统本地的IO，相比堆缓冲区会快一些。\n那么怎么使用直接缓冲区呢？我们可以通过 allocateDirect方法来创建：\npublic static void main(String[] args) { //这里我们申请一个直接缓冲区 ByteBuffer buffer = ByteBuffer.allocateDirect(10); //使用方式基本和之前是一样的 buffer.put((byte) 66); buffer.flip(); System.out.println(buffer.get()); } 我们来看看这个 allocateDirect方法是如何创建一个直接缓冲区的：\npublic static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } 这个方法直接创建了一个新的DirectByteBuffer对象，那么这个类又是怎么进行创建的呢？\n可以看到它并不是直接继承自ByteBuffer，而是MappedByteBuffer，并且实现了接口DirectBuffer，我们先来看看这个接口：\npublic interface DirectBuffer { public long address(); //获取内存地址 public Object attachment(); //附加对象，这是为了保证某些情况下内存不被释放，我们后面细谈 public Cleaner cleaner(); //内存清理类 } public abstract class MappedByteBuffer extends ByteBuffer { //这三个方法目前暂时用不到，后面文件再说 public final MappedByteBuffer load(); public final boolean isLoaded(); public final MappedByteBuffer force(); } 接着我们来看看DirectByteBuffer类的成员变量：\n// 把Unsafe类取出来 protected static final Unsafe unsafe = Bits.unsafe(); // 在内存中直接创建的内存空间地址 private static final long arrayBaseOffset = (long)unsafe.arrayBaseOffset(byte[].class); // 是否具有非对齐访问能力，根据CPU架构而定，intel、AMD、AppleSilicon 都是支持的 protected static final boolean unaligned = Bits.unaligned(); // 直接缓冲区的内存地址，为了提升速度就放到Buffer类中去了 // protected long address; // 附加对象，一会有大作用 private final Object att; 接着我们来看看构造方法：\nDirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); //是否直接内存分页对齐，需要额外计算 int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); //计算出最终需要申请的大小 //判断堆外内存是否足够，够的话就作为保留内存 Bits.reserveMemory(size, cap); long base = 0; try { //通过Unsafe申请内存空间，并得到内存地址 base = unsafe.allocateMemory(size); } catch (OutOfMemoryError x) { //申请失败就取消一开始的保留内存 Bits.unreserveMemory(size, cap); throw x; } //批量将申请到的这一段内存每个字节都设定为0 unsafe.setMemory(base, size, (byte) 0); if (pa \u0026amp;\u0026amp; (base % ps != 0)) { // Round up to page boundary address = base + ps - (base \u0026amp; (ps - 1)); } else { //将address变量（在Buffer中定义）设定为base的地址 address = base; } //创建一个针对于此缓冲区的Cleaner，由于是堆外内存，所以现在由它来进行内存清理 cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null; } 可以看到在构造方法中，是直接通过Unsafe类来申请足够的堆外内存保存数据，那么当我们不使用此缓冲区时，内存会被如何清理呢？我们来看看这个Cleaner：\npublic class Cleaner extends PhantomReference\u0026lt;Object\u0026gt;{ //继承自鬼引用，也就是说此对象会存放一个没有任何引用的对象 //引用队列，PhantomReference构造方法需要 private static final ReferenceQueue\u0026lt;Object\u0026gt; dummyQueue = new ReferenceQueue\u0026lt;\u0026gt;(); //执行清理的具体流程 private final Runnable thunk; static private Cleaner first = null; //Cleaner双向链表，每创建一个Cleaner对象都会添加一个结点 private Cleaner next = null, prev = null; private static synchronized Cleaner add(Cleaner cl) { //添加操作会让新来的变成新的头结点 if (first != null) { cl.next = first; first.prev = cl; } first = cl; return cl; } //可以看到创建鬼引用的对象就是传进的缓冲区对象 private Cleaner(Object referent, Runnable thunk) { super(referent, dummyQueue); //清理流程实际上是外面的Deallocator this.thunk = thunk; } //通过此方法创建一个新的Cleaner public static Cleaner create(Object ob, Runnable thunk) { if (thunk == null) return null; return add(new Cleaner(ob, thunk)); //调用add方法将Cleaner添加到队列 } //清理操作 public void clean() { if (!remove(this)) return; //进行清理操作时会从双向队列中移除当前Cleaner，false说明已经移除过了，直接return try { thunk.run(); //这里就是直接执行具体清理流程 } catch (final Throwable x) { ... } } 那么我们先来看看具体的清理程序在做些什么，Deallocator是在直接缓冲区中声明的：\nprivate static class Deallocator implements Runnable { private static Unsafe unsafe = Unsafe.getUnsafe(); private long address; //内存地址 private long size; //大小 private int capacity; //申请的容量 private Deallocator(long address, long size, int capacity) { assert (address != 0); this.address = address; this.size = size; this.capacity = capacity; } public void run() { //具体的清理操作 if (address == 0) { // Paranoia return; } unsafe.freeMemory(address); //这里是直接调用了Unsafe进行内存释放操作 address = 0; //内存地址改为0，NULL Bits.unreserveMemory(size, capacity); //取消一开始的保留内存 } } 好了，现在我们可以明确在清理的时候实际上也是调用Unsafe类进行内存释放操作，那么，这个清理操作具体是在什么时候进行的呢？首先我们要明确，如果是普通的堆缓冲区，由于使用的数组，那么一旦此对象没有任何引用时，就随时都会被GC给回收掉，但是现在是堆外内存，只能我们手动进行内存回收，那么当DirectByteBuffer也失去引用时，会不会触发内存回收呢？\n答案是可以的，还记得我们刚刚看到Cleaner是PhantomReference的子类吗，而DirectByteBuffer是被鬼引用的对象，而具体的清理操作是Cleaner类的clean方法，莫非这两者有什么联系吗？\n你别说，还真有，我们直接看到PhantomReference的父类Reference，我们会发现这样一个类：\nprivate static class ReferenceHandler extends Thread { ... static { // 预加载并初始化 InterruptedException 和 Cleaner 类 // 以避免出现在循环运行过程中时由于内存不足而无法加载 ensureClassInitialized(InterruptedException.class); ensureClassInitialized(Cleaner.class); } public void run() { while (true) { tryHandlePending(true); //这里是一个无限循环调用tryHandlePending方法 } } } private T referent; /* 会被GC回收的对象，也就是我们给过来被引用的对象 */ volatile ReferenceQueue\u0026lt;? super T\u0026gt; queue; //引用队列，可以和下面的next搭配使用，形成链表 //Reference对象也是一个一个连起来的节点，这样才能放到ReferenceQueue中形成链表 volatile Reference next; //即将被GC的引用链表 transient private Reference\u0026lt;T\u0026gt; discovered; /* 由虚拟机操作 */ //pending与discovered一起构成了一个pending单向链表，标记为static类所有，pending为链表的头节点，discovered为链表当前 //Reference节点指向下一个节点的引用，这个队列是由JVM构建的，当对象除了被reference引用之外没有其它强引用了，JVM就会将指向 //需要回收的对象的Reference对象都放入到这个队列里面，这个队列会由下面的 Reference Hander 线程来处理。 private static Reference\u0026lt;Object\u0026gt; pending = null; static { //Reference类的静态代码块 ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread handler = new ReferenceHandler(tg, \u0026#34;Reference Handler\u0026#34;); //在一开始的时候就会创建 handler.setPriority(Thread.MAX_PRIORITY); //以最高优先级启动 handler.setDaemon(true); //此线程直接作为一个守护线程 handler.start(); //也就是说在一开始的时候这个守护线程就会启动 ... } 那么也就是说Reference Handler线程是在一开始就启动了，那么我们的关注点可以放在 tryHandlePending方法上，看看这玩意到底在做个啥：\nstatic boolean tryHandlePending(boolean waitForNotify) { Reference\u0026lt;Object\u0026gt; r; Cleaner c; try { synchronized (lock) { //加锁办事 //当Cleaner引用的DirectByteBuffer对象即将被回收时，pending会变成此Cleaner对象 //这里判断到pending不为null时就需要处理一下对象销毁了 if (pending != null) { r = pending; // \u0026#39;instanceof\u0026#39; 有时会导致内存溢出，所以将r从链表中移除之前就进行类型判断 // 如果是Cleaner类型就给到c c = r instanceof Cleaner ? (Cleaner) r : null; // 将pending更新为链表下一个待回收元素 pending = r.discovered; r.discovered = null; //r不再引用下一个节点 } else { //否则就进入等待 if (waitForNotify) { lock.wait(); } return waitForNotify; } } } catch (OutOfMemoryError x) { Thread.yield(); return true; } catch (InterruptedException x) { return true; } // 如果元素是Cleaner类型，c在上面就会被赋值，这里就会执行其clean方法（破案了） if (c != null) { c.clean(); return true; } ReferenceQueue\u0026lt;? super Object\u0026gt; q = r.queue; if (q != ReferenceQueue.NULL) q.enqueue(r); //这个是引用队列，实际上就是我们之前在JVM篇中讲解的入队机制 return true; } 通过对源码的解读，我们就了解了直接缓冲区的内存加载释放整个流程。和堆缓冲区一样，当直接缓冲区没有任何强引用时，就有机会被GC正常回收掉并自动释放申请的内存。\n我们接着来看看直接缓冲区的读写操作是如何进行的：\npublic byte get() { return ((unsafe.getByte(ix(nextGetIndex())))); //直接通过Unsafe类读取对应地址上的byte数据 } private long ix(int i) { return address + ((long)i \u0026lt;\u0026lt; 0); //ix现在是内存地址再加上i } 我们接着来看看写操作：\npublic ByteBuffer put(byte x) { unsafe.putByte(ix(nextPutIndex()), ((x))); return this; } 可以看到无论是读取还是写入操作都是通过Unsafe类操作对应的内存地址完成的。\n那么它的复制操作是如何实现的呢？\npublic ByteBuffer duplicate() { return new DirectByteBuffer(this, this.markValue(), this.position(), this.limit(), this.capacity(), 0); } DirectByteBuffer(DirectBuffer db, // 这里给的db是进行复制操作的DirectByteBuffer对象 int mark, int pos, int lim, int cap, int off) { super(mark, pos, lim, cap); address = db.address() + off; //直接继续使用之前申请的内存空间 cleaner = null; //因为用的是之前的内存空间，已经有对应的Cleaner了，这里不需要再搞一个 att = db; //将att设定为此对象 } 可以看到，如果是进行复制操作，那么会直接会继续使用执行复制操作的DirectByteBuffer申请的内存空间。不知道各位是否能够马上联想到一个问题，我们知道，如果执行复制操作的DirectByteBuffer对象失去了强引用被回收，那么就会触发Cleaner并进行内存释放，但是有个问题就是，这段内存空间可能复制出来的DirectByteBuffer对象还需要继续使用，这时肯定是不能进行回收的，所以说这里使用了att变量将之前的DirectByteBuffer对象进行引用，以防止其失去强引用被垃圾回收，所以只要不是原来的DirectByteBuffer对象和复制出来的DirectByteBuffer对象都失去强引用时，就不会导致这段内存空间被回收。\n这样，我们之前的未解之谜为啥有个 att也就得到答案了，有关直接缓冲区的介绍，就到这里为止。\n通道 #\r前面我们学习了NIO的基石——缓冲区，那么缓冲区具体用在什么地方呢，在本板块我们学习通道之后，相信各位就能知道了。那么，什么是通道呢？\n在传统IO中，我们都是通过流进行传输，数据会源源不断从流中传出；而在NIO中，数据是放在缓冲区中进行管理，再使用通道将缓冲区中的数据传输到目的地。\n通道接口层次 #\r通道的根基接口是 Channel，所有的派生接口和类都是从这里开始的，我们来看看它定义了哪些基本功能：\npublic interface Channel extends Closeable { //通道是否处于开启状态 public boolean isOpen(); //因为通道开启也需要关闭，所以实现了Closeable接口，所以这个方法懂的都懂 public void close() throws IOException; } 我们接着来看看它的一些子接口，首先是最基本的读写操作：\npublic interface ReadableByteChannel extends Channel { //将通道中的数据读取到给定的缓冲区中 public int read(ByteBuffer dst) throws IOException; } public interface WritableByteChannel extends Channel { //将给定缓冲区中的数据写入到通道中 public int write(ByteBuffer src) throws IOException; } 有了读写功能后，最后整合为了一个ByteChannel接口：\npublic interface ByteChannel extends ReadableByteChannel, WritableByteChannel{ } 在ByteChannel之下，还有更多的派生接口：\n//允许保留position和更改position的通道，以及对通道连接实体的相关操作 public interface SeekableByteChannel extends ByteChannel { ... //获取当前的position long position() throws IOException; //修改当前的position SeekableByteChannel position(long newPosition) throws IOException; //返回此通道连接到的实体（比如文件）的当前大小 long size() throws IOException; //将此通道连接到的实体截断（比如文件，截断之后，文件后面一半就没了）为给定大小 SeekableByteChannel truncate(long size) throws IOException; } 接着我们来看，除了读写之外，Channel还可以具有响应中断的能力：\npublic interface InterruptibleChannel extends Channel { //当其他线程调用此方法时，在此通道上处于阻塞状态的线程会直接抛出 AsynchronousCloseException 异常 public void close() throws IOException; } //这是InterruptibleChannel的抽象实现，完成了一部分功能 public abstract class AbstractInterruptibleChannel implements Channel, InterruptibleChannel { //加锁关闭操作用到 private final Object closeLock = new Object(); //当前Channel的开启状态 private volatile boolean open = true; protected AbstractInterruptibleChannel() { } //关闭操作实现 public final void close() throws IOException { synchronized (closeLock) { //同时只能有一个线程进行此操作，加锁 if (!open) //如果已经关闭了，那么就不用继续了 return; open = false; //开启状态变成false implCloseChannel(); //开始关闭通道 } } //该方法由 close 方法调用，以执行关闭通道的具体操作，仅当通道尚未关闭时才调用此方法，不会多次调用。 protected abstract void implCloseChannel() throws IOException; public final boolean isOpen() { return open; } //开始阻塞（有可能一直阻塞下去）操作之前，需要调用此方法进行标记， protected final void begin() { ... } //阻塞操作结束之后，也需要需要调用此方法，为了防止异常情况导致此方法没有被调用，建议放在finally中 protected final void end(boolean completed) ... } ... } 而之后的一些实现类，都是基于这些接口定义的方法去进行实现的，比如FileChannel：\n这样，我们就大致了解了一下通道相关的接口定义，那么我来看看具体是如何如何使用的。\n比如现在我们要实现从输入流中读取数据然后打印出来，那么之前传统IO的写法：\npublic static void main(String[] args) throws IOException { //数组创建好，一会用来存放从流中读取到的数据 byte[] data = new byte[10]; //直接使用输入流 InputStream in = System.in; while (true) { int len; while ((len = in.read(data)) \u0026gt;= 0) { //将输入流中的数据一次性读取到数组中 System.out.print(\u0026#34;读取到一批数据：\u0026#34;+new String(data, 0, len)); //读取了多少打印多少 } } } 而现在我们使用通道之后：\npublic static void main(String[] args) throws IOException { //缓冲区创建好，一会就靠它来传输数据 ByteBuffer buffer = ByteBuffer.allocate(10); //将System.in作为输入源，一会Channel就可以从这里读取数据，然后通过缓冲区装载一次性传递数据 ReadableByteChannel readChannel = Channels.newChannel(System.in); while (true) { //将通道中的数据写到缓冲区中，缓冲区最多一次装10个 readChannel.read(buffer); //写入操作结束之后，需要进行翻转，以便接下来的读取操作 buffer.flip(); //最后转换成String打印出来康康 System.out.println(\u0026#34;读取到一批数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); //回到最开始的状态 buffer.clear(); } } 乍一看，好像感觉也没啥区别，不就是把数组换成缓冲区了吗，效果都是一样的，数据也是从Channel中读取得到，并且通过缓冲区进行数据装载然后得到结果，但是，Channel不像流那样是单向的，它就像它的名字一样，一个通道可以从一端走到另一端，也可以从另一端走到这一端，我们后面进行介绍。\n文件传输FileChannel #\r前面我们介绍了通道的基本情况，这里我们就来尝试实现一下文件的读取和写入，在传统IO中，文件的写入和输出都是依靠FileOutputStream和FileInputStream来完成的：\npublic static void main(String[] args) throws IOException { try(FileOutputStream out = new FileOutputStream(\u0026#34;test.txt\u0026#34;); FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;)){ String data = \u0026#34;伞兵一号卢本伟准备就绪！\u0026#34;; out.write(data.getBytes()); //向文件的输出流中写入数据，也就是把数据写到文件中 out.flush(); byte[] bytes = new byte[in.available()]; in.read(bytes); //从文件的输入流中读取文件的信息 System.out.println(new String(bytes)); } } 而现在，我们只需要通过一个FileChannel就可以完成这两者的操作，获取文件通道的方式有以下几种：\npublic static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;); //但是这里的通道只支持读取或是写入操作 FileChannel channel = in.getChannel(); //创建一个容量为128的缓冲区 ByteBuffer buffer = ByteBuffer.allocate(128); //从通道中将数据读取到缓冲区中 channel.read(buffer); //翻转一下，接下来要读取了 buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } 可以看到通过输入流获取的文件通道读取是没有任何问题的，但是写入操作：\npublic static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;); //但是这里的通道只支持读取或是写入操作 FileChannel channel = in.getChannel(); //尝试写入一下 channel.write(ByteBuffer.wrap(\u0026#34;伞兵一号卢本伟准备就绪！\u0026#34;.getBytes())); } 直接报错，说明只支持读取操作，那么输出流呢？\npublic static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileOutputStream out = new FileOutputStream(\u0026#34;test.txt\u0026#34;); //但是这里的通道只支持读取或是写入操作 FileChannel channel = out.getChannel(); //尝试写入一下 channel.write(ByteBuffer.wrap(\u0026#34;伞兵一号卢本伟准备就绪！\u0026#34;.getBytes())); } 可以看到能够正常进行写入，但是读取呢？\npublic static void main(String[] args) throws IOException { //1. 直接通过输入或输出流获取对应的通道 FileOutputStream out = new FileOutputStream(\u0026#34;test.txt\u0026#34;); //但是这里的通道只支持读取或是写入操作 FileChannel channel = out.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(128); //从通道中将数据读取到缓冲区中 channel.read(buffer); //翻转一下，接下来要读取了 buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } 可以看到输出流生成的Channel又不支持读取，所以说本质上还是保持着输入输出流的特性，但是之前不是说Channel又可以输入又可以输出吗？这里我们来看看第二种方式：\n//RandomAccessFile能够支持文件的随机访问，并且实现了数据流 public class RandomAccessFile implements DataOutput, DataInput, Closeable { 我们可以通过RandomAccessFile来创建通道：\npublic static void main(String[] args) throws IOException { /* 通过RandomAccessFile进行创建，注意后面的mode有几种： r 以只读的方式使用 rw 读操作和写操作都可以 rws 每当进行写操作，同步的刷新到磁盘，刷新内容和元数据 rwd 每当进行写操作，同步的刷新到磁盘，刷新内容 */ try(RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;\u0026#34;)){ } } 现在我们来测试一下它的读写操作：\npublic static void main(String[] args) throws IOException { /* 通过RandomAccessFile进行创建，注意后面的mode有几种： r 以只读的方式使用 rw 读操作和写操作都可以 rws 每当进行写操作，同步的刷新到磁盘，刷新内容和元数据 rwd 每当进行写操作，同步的刷新到磁盘，刷新内容 */ try(RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); //这里设定为支持读写，这样创建的通道才能具有这些功能 FileChannel channel = f.getChannel()){ //通过RandomAccessFile创建一个通道 channel.write(ByteBuffer.wrap(\u0026#34;伞兵二号马飞飞准备就绪！\u0026#34;.getBytes())); System.out.println(\u0026#34;写操作完成之后文件访问位置：\u0026#34;+channel.position()); //注意读取也是从现在的位置开始 channel.position(0); //需要将位置变回到最前面，这样下面才能从文件的最开始进行读取 ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } } 可以看到，一个FileChannel既可以完成文件读取，也可以完成文件的写入。\n除了基本的读写操作，我们也可以直接对文件进行截断：\npublic static void main(String[] args) throws IOException { try(RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = f.getChannel()){ //截断文件，只留前20个字节 channel.truncate(20); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(new String(buffer.array(), 0, buffer.remaining())); } } 可以看到文件的内容直接被截断了，文件内容就只剩一半了。\n当然，如果我们要进行文件的拷贝，也是很方便的，只需要使用通道就可以，比如我们现在需要将一个通道的数据写入到另一个通道，就可以直接使用transferTo方法：\npublic static void main(String[] args) throws IOException { try(FileOutputStream out = new FileOutputStream(\u0026#34;test2.txt\u0026#34;); FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;)){ FileChannel inChannel = in.getChannel(); //获取到test文件的通道 inChannel.transferTo(0, inChannel.size(), out.getChannel()); //直接将test文件通道中的数据转到test2文件的通道中 } } 可以看到执行后，文件的内容全部被复制到另一个文件了。\n当然，反向操作也是可以的：\npublic static void main(String[] args) throws IOException { try(FileOutputStream out = new FileOutputStream(\u0026#34;test2.txt\u0026#34;); FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;)){ FileChannel inChannel = in.getChannel(); //获取到test文件的通道 out.getChannel().transferFrom(inChannel, 0, inChannel.size()); //直接将从test文件通道中传来的数据转给test2文件的通道 } } 当我们要编辑某个文件时，通过使用MappedByteBuffer类，可以将其映射到内存中进行编辑，编辑的内容会同步更新到文件中：\n//注意一定要是可写的，不然无法进行修改操作 try(RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = f.getChannel()){ //通过map方法映射文件的某一段内容，创建MappedByteBuffer对象 //比如这里就是从第四个字节开始，映射10字节内容到内存中 //注意这里需要使用MapMode.READ_WRITE模式，其他模式无法保存数据到文件 MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_WRITE, 4, 10); //我们可以直接对在内存中的数据进行编辑，也就是编辑Buffer中的内容 //注意这里写入也是从pos位置开始的，默认是从0开始，相对于文件就是从第四个字节开始写 //注意我们只映射了10个字节，也就是写的内容不能超出10字节了 buffer.put(\u0026#34;yyds\u0026#34;.getBytes()); //编辑完成后，通过force方法将数据写回文件的映射区域 buffer.force(); } 可以看到，文件的某一个区域已经被我们修改了，并且这里实际上使用的就是DirectByteBuffer直接缓冲区，效率还是很高的。\n文件锁FileLock #\r我们可以创建一个跨进程文件锁来防止多个进程之间的文件争抢操作（注意这里是进程，不是线程）FileLock是文件锁，它能保证同一时间只有一个进程（程序）能够修改它，或者都只可以读，这样就解决了多进程间的同步文件，保证了安全性。但是需要注意的是，它进程级别的，不是线程级别的，他可以解决多个进程并发访问同一个文件的问题，但是它不适用于控制同一个进程中多个线程对一个文件的访问。\n那么我们来看看如何使用文件锁：\npublic static void main(String[] args) throws IOException, InterruptedException { //创建RandomAccessFile对象，并拿到Channel RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = f.getChannel(); System.out.println(new Date() + \u0026#34; 正在尝试获取文件锁...\u0026#34;); //接着我们直接使用lock方法进行加锁操作（如果其他进程已经加锁，那么会一直阻塞在这里） //加锁操作支持对文件的某一段进行加锁，比如这里就是从0开始后的6个字节加锁，false代表这是一把独占锁 //范围锁甚至可以提前加到一个还未写入的位置上 FileLock lock = channel.lock(0, 6, false); System.out.println(new Date() + \u0026#34; 已获取到文件锁！\u0026#34;); Thread.sleep(5000); //假设要处理5秒钟 System.out.println(new Date() + \u0026#34; 操作完毕，释放文件锁！\u0026#34;); //操作完成之后使用release方法进行锁释放 lock.release(); } 有关共享锁和独占锁：\n进程对文件加独占锁后，当前进程对文件可读可写，独占此文件，其它进程是不能读该文件进行读写操作的。 进程对文件加共享锁后，进程可以对文件进行读操作，但是无法进行写操作，共享锁可以被多个进程添加，但是只要存在共享锁，就不能添加独占锁。 现在我们来启动两个进程试试看，我们需要在IDEA中配置一下两个启动项：\n现在我们依次启动它们：\n可以看到确实是两个进程同一时间只能有一个进行访问，而另一个需要等待锁释放。\n那么如果我们申请的是文件的不同部分呢？\n//其中一个进程锁 0 - 5 FileLock lock = channel.lock(0, 6, false); //另一个进程锁 6 - 11 FileLock lock = channel.lock(6, 6, false); 可以看到，两个进程这时就可以同时进行加锁操作了，因为它们锁的是不同的段落。\n那么要是交叉呢？\n//其中一个进程锁 0 - 5 FileLock lock = channel.lock(0, 6, false); //另一个进程锁 3 - 8 FileLock lock = channel.lock(3, 6, false); 可以看到交叉的情况下也是会出现阻塞的。\n接着我们来看看共享锁，共享锁允许多个进程同时加锁，但是不能进行写操作：\npublic static void main(String[] args) throws IOException, InterruptedException { RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = f.getChannel(); System.out.println(new Date() + \u0026#34; 正在尝试获取文件锁...\u0026#34;); //现在使用共享锁 FileLock lock = channel.lock(0, Long.MAX_VALUE, true); System.out.println(new Date() + \u0026#34; 已获取到文件锁！\u0026#34;); //进行写操作 channel.write(ByteBuffer.wrap(new Date().toString().getBytes())); System.out.println(new Date() + \u0026#34; 操作完毕，释放文件锁！\u0026#34;); //操作完成之后使用release方法进行锁释放 lock.release(); } 当我们进行写操作时：\n可以看到直接抛出异常，说另一个程序已锁定文件的一部分，进程无法访问（某些系统或是环境实测无效，比如UP主的arm架构MacOS就不生效，这个异常是在Windows环境下运行得到的）\n当然，我们也可以测试一下多个进行同时加共享锁：\npublic static void main(String[] args) throws IOException, InterruptedException { RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = f.getChannel(); System.out.println(new Date() + \u0026#34; 正在尝试获取文件锁...\u0026#34;); FileLock lock = channel.lock(0, Long.MAX_VALUE, true); System.out.println(new Date() + \u0026#34; 已获取到文件锁！\u0026#34;); Thread.sleep(5000); //假设要处理5秒钟 System.out.println(new Date() + \u0026#34; 操作完毕，释放文件锁！\u0026#34;); lock.release(); } 可以看到结果是多个进程都能加共享锁：\n当然，除了直接使用 lock()方法进行加锁之外，我们也可以使用 tryLock()方法以非阻塞方式获取文件锁，但是如果获取锁失败会得到null：\npublic static void main(String[] args) throws IOException, InterruptedException { RandomAccessFile f = new RandomAccessFile(\u0026#34;test.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel channel = f.getChannel(); System.out.println(new Date() + \u0026#34; 正在尝试获取文件锁...\u0026#34;); FileLock lock = channel.tryLock(0, Long.MAX_VALUE, false); System.out.println(lock); Thread.sleep(5000); //假设要处理5秒钟 lock.release(); } 可以看到，两个进程都去尝试获取独占锁：\n第一个成功加锁的进程获得了对应的锁对象，而第二个进程直接得到的是 null。\n到这里，有关文件锁的相关内容就差不多了。\n多路复用网络通信 #\r前面我们已经介绍了NIO框架的两大核心：Buffer和Channel，我们接着来看看最后一个内容。\n传统阻塞I/O网络通信 #\r说起网络通信，相信各位并不陌生，正是因为网络的存在我们才能走进现代化的社会，在JavaWeb阶段，我们学习了如何使用Socket建立TCP连接进行网络通信：\npublic static void main(String[] args) { try(ServerSocket server = new ServerSocket(8080)){ //将服务端创建在端口8080上 System.out.println(\u0026#34;正在等待客户端连接...\u0026#34;); Socket socket = server.accept(); System.out.println(\u0026#34;客户端已连接，IP地址为：\u0026#34;+socket.getInetAddress().getHostAddress()); BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream())); //通过 System.out.print(\u0026#34;接收到客户端数据：\u0026#34;); System.out.println(reader.readLine()); OutputStreamWriter writer = new OutputStreamWriter(socket.getOutputStream()); writer.write(\u0026#34;已收到！\u0026#34;); writer.flush(); }catch (IOException e){ e.printStackTrace(); } } public static void main(String[] args) { try (Socket socket = new Socket(\u0026#34;localhost\u0026#34;, 8080); Scanner scanner = new Scanner(System.in)){ System.out.println(\u0026#34;已连接到服务端！\u0026#34;); OutputStream stream = socket.getOutputStream(); OutputStreamWriter writer = new OutputStreamWriter(stream); //通过转换流来帮助我们快速写入内容 System.out.println(\u0026#34;请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); writer.write(text+\u0026#39;\\n\u0026#39;); //因为对方是readLine()这里加个换行符 writer.flush(); System.out.println(\u0026#34;数据已发送：\u0026#34;+text); BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream())); System.out.println(\u0026#34;收到服务器返回：\u0026#34;+reader.readLine()); }catch (IOException e){ System.out.println(\u0026#34;服务端连接失败！\u0026#34;); e.printStackTrace(); }finally { System.out.println(\u0026#34;客户端断开连接！\u0026#34;); } } 当然，我们也可以使用前面讲解的通道来进行通信：\npublic static void main(String[] args) { //创建一个新的ServerSocketChannel，一会直接使用SocketChannel进行网络IO操作 try (ServerSocketChannel serverChannel = ServerSocketChannel.open()){ //依然是将其绑定到8080端口 serverChannel.bind(new InetSocketAddress(8080)); //同样是调用accept()方法，阻塞等待新的连接到来 SocketChannel socket = serverChannel.accept(); //因为是通道，两端的信息都是可以明确的，这里获取远端地址，当然也可以获取本地地址 System.out.println(\u0026#34;客户端已连接，IP地址为：\u0026#34;+socket.getRemoteAddress()); //使用缓冲区进行数据接收 ByteBuffer buffer = ByteBuffer.allocate(128); socket.read(buffer); //SocketChannel同时实现了读写通道接口，所以可以直接进行双向操作 buffer.flip(); System.out.print(\u0026#34;接收到客户端数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); //直接向通道中写入数据就行 socket.write(ByteBuffer.wrap(\u0026#34;已收到！\u0026#34;.getBytes())); //记得关 socket.close(); } catch (IOException e) { throw new RuntimeException(e); } } public static void main(String[] args) { //创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel = SocketChannel.open(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 8080)); Scanner scanner = new Scanner(System.in)){ System.out.println(\u0026#34;已连接到服务端！\u0026#34;); System.out.println(\u0026#34;请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); //直接向通道中写入数据，真舒服 channel.write(ByteBuffer.wrap(text.getBytes())); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); //直接从通道中读取数据 buffer.flip(); System.out.println(\u0026#34;收到服务器返回：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); } catch (IOException e) { throw new RuntimeException(e); } } 虽然可以通过传统的Socket进行网络通信，但是我们发现，如果要进行IO操作，我们需要单独创建一个线程来进行处理，比如现在有很多个客户端，服务端需要同时进行处理，那么如果我们要处理这些客户端的请求，那么我们就只能单独为其创建一个线程来进行处理：\n虽然这样看起来比较合理，但是随着客户端数量的增加，如果要保持持续通信，那么就不能摧毁这些线程，而是需要一直保留（但是实际上很多时候只是保持连接，一直在阻塞等待客户端的读写操作，IO操作的频率很低，这样就白白占用了一条线程，很多时候都是站着茅坑不拉屎），但是我们的线程不可能无限制的进行创建，总有一天会耗尽服务端的资源，那么现在怎么办呢，关键是现在又有很多客户端源源不断地连接并进行操作，这时，我们就可以利用NIO为我们提供的多路复用编程模型。\n我们来看看NIO为我们提供的模型：\n服务端不再是一个单纯通过 accept()方法来创建连接的机制了，而是根据客户端不同的状态，Selector会不断轮询，只有客户端在对应的状态时，比如真正开始读写操作时，才会创建线程或进行处理（这样就不会一直阻塞等待某个客户端的IO操作了），而不是创建之后需要一直保持连接，即使没有任何的读写操作。这样就不会因为占着茅坑不拉屎导致线程无限制地创建下去了。\n通过这种方式，甚至单线程都能做到高效的复用，最典型的例子就是Redis了，因为内存的速度非常快，多线程上下文的开销就会显得有些拖后腿，还不如直接单线程简单高效，这也是为什么Redis单线程也能这么快的原因。\n因此，我们就从NIO框架的第三个核心内容：Selector，开始讲起。\n选择器与I/O多路复用 #\r前面我们大概了解了一下选择器，我们知道，选择器是当具体有某一个状态（比如读、写、请求）已经就绪时，才会进行处理，而不是让我们的程序主动地进行等待。\n既然我们现在需要实现IO多路复用，那么我们来看看常见的IO多路复用模型，也就是Selector的实现方案，比如现在有很多个用户连接到我们的服务器：\nselect：当这些连接出现具体的某个状态时，只是知道已经就绪了，但是不知道详具体是哪一个连接已经就绪，每次调用都进行线性遍历所有连接，时间复杂度为 O(n)，并且存在最大连接数限制。 poll：同上，但是由于底层采用链表，所以没有最大连接数限制。 epoll：采用事件通知方式，当某个连接就绪，能够直接进行精准通知（这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的，只要就绪会会直接回调callback函数，实现精准通知，但是只有Linux支持这种方式），时间复杂度 O(1)，Java在Linux环境下正是采用的这种模式进行实现的。 好了，既然多路复用模型了解完毕了，那么我们就来看看如何让我们的网络通信实现多路复用：\npublic static void main(String[] args) { try (ServerSocketChannel serverChannel = ServerSocketChannel.open(); Selector selector = Selector.open()){ //开启一个新的Selector，这玩意也是要关闭释放资源的 serverChannel.bind(new InetSocketAddress(8080)); //要使用选择器进行操作，必须使用非阻塞的方式，这样才不会像阻塞IO那样卡在accept()，而是直接通过，让选择器去进行下一步操作 serverChannel.configureBlocking(false); //将选择器注册到ServerSocketChannel中，后面是选择需要监听的时间，只有发生对应事件时才会进行选择，多个事件用 | 连接，注意，并不是所有的Channel都支持以下全部四个事件，可能只支持部分 //因为是ServerSocketChannel这里我们就监听accept就可以了，等待客户端连接 //SelectionKey.OP_CONNECT --- 连接就绪事件，表示客户端与服务器的连接已经建立成功 //SelectionKey.OP_ACCEPT --- 接收连接事件，表示服务器监听到了客户连接，服务器可以接收这个连接了 //SelectionKey.OP_READ --- 读 就绪事件，表示通道中已经有了可读的数据，可以执行读操作了 //SelectionKey.OP_WRITE --- 写 就绪事件，表示已经可以向通道写数据了（这玩意比较特殊，一般情况下因为都是可以写入的，所以可能会无限循环） serverChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { //无限循环等待新的用户网络操作 //每次选择都可能会选出多个已经就绪的网络操作，没有操作时会暂时阻塞 int count = selector.select(); System.out.println(\u0026#34;监听到 \u0026#34;+count+\u0026#34; 个事件\u0026#34;); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); //根据不同的事件类型，执行不同的操作即可 if(key.isAcceptable()) { //如果当前ServerSocketChannel已经做好准备处理Accept SocketChannel channel = serverChannel.accept(); System.out.println(\u0026#34;客户端已连接，IP地址为：\u0026#34;+channel.getRemoteAddress()); //现在连接就建立好了，接着我们需要将连接也注册选择器，比如我们需要当这个连接有内容可读时就进行处理 channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_READ); //这样就在连接建立时完成了注册 } else if(key.isReadable()) { //如果当前连接有可读的数据并且可以写，那么就开始处理 SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(\u0026#34;接收到客户端数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); //直接向通道中写入数据就行 channel.write(ByteBuffer.wrap(\u0026#34;已收到！\u0026#34;.getBytes())); //别关，说不定用户还要继续通信呢 } //处理完成后，一定记得移出迭代器，不然下次还有 iterator.remove(); } } } catch (IOException e) { throw new RuntimeException(e); } } 接着我们来编写一下客户客户端：\npublic static void main(String[] args) { //创建一个新的SocketChannel，一会通过通道进行通信 try (SocketChannel channel = SocketChannel.open(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 8080)); Scanner scanner = new Scanner(System.in)){ System.out.println(\u0026#34;已连接到服务端！\u0026#34;); while (true) { //咱给它套个无限循环，这样就能一直发消息了 System.out.println(\u0026#34;请输入要发送给服务端的内容：\u0026#34;); String text = scanner.nextLine(); //直接向通道中写入数据，真舒服 channel.write(ByteBuffer.wrap(text.getBytes())); System.out.println(\u0026#34;已发送！\u0026#34;); ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); //直接从通道中读取数据 buffer.flip(); System.out.println(\u0026#34;收到服务器返回：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); } } catch (IOException e) { throw new RuntimeException(e); } } 我们来看看效果：\n可以看到成功实现了，当然各位也可以跟自己的室友一起开客户端进行测试，现在，我们只用了一个线程，就能够同时处理多个请求，可见多路复用是多么重要。\n实现Reactor模式 #\r前面我们简单实现了多路复用网络通信，我们接着来了解一下Reactor模式，对我们的服务端进行优化。\n现在我们来看看如何进行优化，我们首先抽象出两个组件，Reactor线程和Handler处理器：\nReactor线程：负责响应IO事件，并分发到Handler处理器。新的事件包含连接建立就绪、读就绪、写就绪等。 Handler处理器：执行非阻塞的操作。 实际上我们之前编写的算是一种单线程Reactor的朴素模型（面向过程的写法），我们来看看标准的写法：\n客户端还是按照我们上面的方式连接到Reactor，并通过选择器走到Acceptor或是Handler，Acceptor主要负责客户端连接的建立，Handler负责读写操作，代码如下，首先是Handler：\npublic class Handler implements Runnable{ private final SocketChannel channel; public Handler(SocketChannel channel) { this.channel = channel; } @Override public void run() { try { ByteBuffer buffer = ByteBuffer.allocate(128); channel.read(buffer); buffer.flip(); System.out.println(\u0026#34;接收到客户端数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); channel.write(ByteBuffer.wrap(\u0026#34;已收到！\u0026#34;.getBytes())); }catch (IOException e){ e.printStackTrace(); } } } 接着是Acceptor，实际上就是把上面的业务代码搬个位置罢了：\n/** * Acceptor主要用于处理连接操作 */ public class Acceptor implements Runnable{ private final ServerSocketChannel serverChannel; private final Selector selector; public Acceptor(ServerSocketChannel serverChannel, Selector selector) { this.serverChannel = serverChannel; this.selector = selector; } @Override public void run() { try{ SocketChannel channel = serverChannel.accept(); System.out.println(\u0026#34;客户端已连接，IP地址为：\u0026#34;+channel.getRemoteAddress()); channel.configureBlocking(false); //这里在注册时，创建好对应的Handler，这样在Reactor中分发的时候就可以直接调用Handler了 channel.register(selector, SelectionKey.OP_READ, new Handler(channel)); }catch (IOException e){ e.printStackTrace(); } } } 这里我们在注册时丢了一个附加对象进去，这个附加对象会在选择器选择到此通道上时，可以通过 attachment()方法进行获取，对于我们简化代码有大作用，一会展示，我们接着来看看Reactor：\npublic class Reactor implements Closeable, Runnable{ private final ServerSocketChannel serverChannel; private final Selector selector; public Reactor() throws IOException{ serverChannel = ServerSocketChannel.open(); selector = Selector.open(); } @Override public void run() { try { serverChannel.bind(new InetSocketAddress(8080)); serverChannel.configureBlocking(false); //注册时，将Acceptor作为附加对象存放，当选择器选择后也可以获取到 serverChannel.register(selector, SelectionKey.OP_ACCEPT, new Acceptor(serverChannel, selector)); while (true) { int count = selector.select(); System.out.println(\u0026#34;监听到 \u0026#34;+count+\u0026#34; 个事件\u0026#34;); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { this.dispatch(iterator.next()); //通过dispatch方法进行分发 iterator.remove(); } } }catch (IOException e) { e.printStackTrace(); } } //通过此方法进行分发 private void dispatch(SelectionKey key){ Object att = key.attachment(); //获取attachment，ServerSocketChannel和对应的客户端Channel都添加了的 if(att instanceof Runnable) { ((Runnable) att).run(); //由于Handler和Acceptor都实现自Runnable接口，这里就统一调用一下 } //这样就实现了对应的时候调用对应的Handler或是Acceptor了 } //用了记得关，保持好习惯，就像看完视频要三连一样 @Override public void close() throws IOException { serverChannel.close(); selector.close(); } } 最后我们编写一下主类：\npublic static void main(String[] args) { //创建Reactor对象，启动，完事 try (Reactor reactor = new Reactor()){ reactor.run(); }catch (IOException e) { e.printStackTrace(); } } 这样，我们就实现了单线程Reactor模式，注意全程使用到的都只是一个线程，没有创建新的线程来处理任何事情。\n但是单线程始终没办法应对大量的请求，如果请求量上去了，单线程还是很不够用，接着我们来看看多线程Reactor模式，它创建了多个线程处理，我们可以将数据读取完成之后的操作交给线程池来执行：\n其实我们只需要稍微修改一下Handler就行了：\npublic class Handler implements Runnable{ //把线程池给安排了，10个线程 private static final ExecutorService POOL = Executors.newFixedThreadPool(10); private final SocketChannel channel; public Handler(SocketChannel channel) { this.channel = channel; } @Override public void run() { try { ByteBuffer buffer = ByteBuffer.allocate(1024); channel.read(buffer); buffer.flip(); POOL.submit(() -\u0026gt; { try { System.out.println(\u0026#34;接收到客户端数据：\u0026#34;+new String(buffer.array(), 0, buffer.remaining())); channel.write(ByteBuffer.wrap(\u0026#34;已收到！\u0026#34;.getBytes())); }catch (IOException e){ e.printStackTrace(); } }); } catch (IOException e) { throw new RuntimeException(e); } } } 这样，在数据读出之后，就可以将数据处理交给线程池执行。\n但是这样感觉还是划分的不够，一个Reactor需要同时处理来自客户端的所有操作请求，显得有些乏力，那么不妨我们将Reactor做成一主多从的模式，让主Reactor只负责Accept操作，而其他的Reactor进行各自的其他操作：\n现在我们来重新设计一下我们的代码，Reactor类就作为主节点，不进行任何修改，我们来修改一下其他的：\n//SubReactor作为从Reactor public class SubReactor implements Runnable, Closeable { //每个从Reactor也有一个Selector private final Selector selector; //创建一个4线程的线程池，也就是四个从Reactor工作 private static final ExecutorService POOL = Executors.newFixedThreadPool(4); private static final SubReactor[] reactors = new SubReactor[4]; private static int selectedIndex = 0; //采用轮询机制，每接受一个新的连接，就轮询分配给四个从Reactor static { //在一开始的时候就让4个从Reactor跑起来 for (int i = 0; i \u0026lt; 4; i++) { try { reactors[i] = new SubReactor(); POOL.submit(reactors[i]); } catch (IOException e) { e.printStackTrace(); } } } //轮询获取下一个Selector（Acceptor用） public static Selector nextSelector(){ Selector selector = reactors[selectedIndex].selector; selectedIndex = (selectedIndex + 1) % 4; return selector; } private SubReactor() throws IOException { selector = Selector.open(); } @Override public void run() { try { //启动后直接等待selector监听到对应的事件即可，其他的操作逻辑和Reactor一致 while (true) { int count = selector.select(); System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026gt;\u0026gt; 监听到 \u0026#34;+count+\u0026#34; 个事件\u0026#34;); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { this.dispatch(iterator.next()); iterator.remove(); } } }catch (IOException e) { e.printStackTrace(); } } private void dispatch(SelectionKey key){ Object att = key.attachment(); if(att instanceof Runnable) { ((Runnable) att).run(); } } @Override public void close() throws IOException { selector.close(); } } 我们接着来修改一下Acceptor类：\npublic class Acceptor implements Runnable{ private final ServerSocketChannel serverChannel; //只需要一个ServerSocketChannel就行了 public Acceptor(ServerSocketChannel serverChannel) { this.serverChannel = serverChannel; } @Override public void run() { try{ SocketChannel channel = serverChannel.accept(); //还是正常进行Accept操作，得到SocketChannel System.out.println(Thread.currentThread().getName()+\u0026#34; \u0026gt;\u0026gt; 客户端已连接，IP地址为：\u0026#34;+channel.getRemoteAddress()); channel.configureBlocking(false); Selector selector = SubReactor.nextSelector(); //选取下一个从Reactor的Selector selector.wakeup(); //在注册之前唤醒一下防止卡死 channel.register(selector, SelectionKey.OP_READ, new Handler(channel)); //注意现在注册的是从Reactor的Selector }catch (IOException e){ e.printStackTrace(); } } } 现在，SocketChannel相关的操作就由从Reactor进行处理了，而不是一律交给主Reactor进行操作。\n至此，我们已经了解了NIO的三大组件：Buffer、Channel、Selector，有关NIO基础相关的内容，就讲解到这里。下一章我们将继续讲解基于NIO实现的高性能网络通信框架Netty。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/netty/nio/","section":"Docs","summary":"NIO基础 #\r**注意：**推荐完成JavaSE篇、JavaWeb篇的学习再开启这一部分的学习，如果在这之前完成了JVM篇，那么看起来就会比较轻松了。\n在JavaSE的学习中，我们了解了如何使用IO进行数据传输，Java IO是阻塞的，如果在一次读写数据调用时数据还没有准备好，或者目前不可写，那么读写操作就会被阻塞直到数据准备好或目标可写为止。Java NIO则是非阻塞的，每一次数据读写调用都会立即返回，并将目前可读（或可写）的内容写入缓冲区或者从缓冲区中输出，即使当前没有可用数据，调用仍然会立即返回并且不对缓冲区做任何操作。\nNIO框架是在JDK1.4推出的，它的出现就是为了解决传统IO的不足，这一期视频，我们就将围绕着NIO开始讲解。\n缓冲区 #\r一切的一切还要从缓冲区开始讲起，包括源码在内，其实这个不是很难，只是需要理清思路。\nBuffer类及其实现 #\rBuffer类是缓冲区的实现，类似于Java中的数组，也是用于存放和获取数据的。但是Buffer相比Java中的数组，功能就非常强大了，它包含一系列对于数组的快捷操作。\nBuffer是一个抽象类，它的核心内容：\npublic abstract class Buffer { // 这四个变量的关系: mark \u0026lt;= position \u0026lt;= limit \u0026lt;= capacity // 这些变量就是Buffer操作的核心了，之后我们学习的过程中可以看源码是如何操作这些变量的 private int mark = -1; private int position = 0; private int limit; private int capacity; // 直接缓冲区实现子类的数据内存地址（之后会讲解） long address; 我们来看看Buffer类的子类，包括我们认识到的所有基本类型（除了 boolean类型之外）：","title":"NIO","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/nionetty/","section":"Series","summary":"","title":"NIO\u0026Netty","type":"series"},{"content":"\r消息队列 #\r经过前面的学习，我们已经了解了我们之前的技术在分布式环境下的应用，接着我们来看最后一章的内容。\n那么，什么是消息队列呢？\n我们之前如果需要进行远程调用，那么一般可以通过发送HTTP请求来完成，而现在，我们可以使用第二种方式，就是消息队列，它能够将发送方发送的信息放入队列中，当新的消息入队时，会通知接收方进行处理，一般消息发送方称为生产者，接收方称为消费者。\n这样我们所有的请求，都可以直接丢到消息队列中，再由消费者取出，不再是直接连接消费者的形式了，而是加了一个中间商，这也是一种很好的解耦方案，并且在高并发的情况下，由于消费者能力有限，消息队列也能起到一个削峰填谷的作用，堆积一部分的请求，再由消费者来慢慢处理，而不会像直接调用那样请求蜂拥而至。\n那么，消息队列具体实现有哪些呢：\nRabbitMQ - 性能很强，吞吐量很高，支持多种协议，集群化，消息的可靠执行特性等优势，很适合企业的开发。 Kafka - 提供了超高的吞吐量，ms级别的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。 RocketMQ - 阿里巴巴推出的消息队列，经历过双十一的考验，单机吞吐量高，消息的高可靠性，扩展性强，支持事务等，但是功能不够完整，语言支持性较差。 我们这里，主要讲解的是RabbitMQ消息队列。\nRabbitMQ 消息队列 #\r官方网站： https://www.rabbitmq.com\nRabbitMQ拥有数万计的用户，是最受欢迎的开源消息队列之一，从\rT-Mobile到\rRuntastic，RabbitMQ在全球范围内用于小型初创企业和大型企业。\nRabbitMQ轻量级，易于在本地和云端部署，它支持多种消息协议。RabbitMQ可以部署在分布式和联合配置中，以满足大规模、高可用性要求。\nRabbitMQ在许多操作系统和云环境中运行，并为\r大多数流行语言提供了\r广泛的开发者工具。\n我们首先还是来看看如何进行安装。\n安装消息队列 #\r下载地址： https://www.rabbitmq.com/download.html\n由于除了消息队列本身之外还需要Erlang环境（RabbitMQ就是这个语言开发的）所以我们就在我们的Ubuntu服务器上进行安装。\n首先是Erlang，比较大，1GB左右：\nsudo apt install erlang 接着安装RabbitMQ：\nsudo apt install rabbitmq-server 安装完成后，可以输入：\nsudo rabbitmqctl status 来查看当前的RabbitMQ运行状态，包括运行环境、内存占用、日志文件等信息：\nRuntime\rOS PID: 13718\rOS: Linux\rUptime (seconds): 65\rIs under maintenance?: false\rRabbitMQ version: 3.8.9\rNode name: rabbit@ubuntu-server-2\rErlang configuration: Erlang/OTP 23 [erts-11.1.8] [source] [64-bit] [smp:2:2] [ds:2:2:10] [async-threads:64]\rErlang processes: 280 used, 1048576 limit\rScheduler run queue: 1\rCluster heartbeat timeout (net_ticktime): 60 这样我们的RabbitMQ服务器就安装完成了，要省事还得是Ubuntu啊。\n可以看到默认有两个端口名被使用：\nListeners\rInterface: [::], port: 25672, protocol: clustering, purpose: inter-node and CLI tool communication\rInterface: [::], port: 5672, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0 我们一会主要使用的就是amqp协议的那个端口5672来进行连接，25672是集群化端口，之后我们也会用到。\n接着我们还可以将RabbitMQ的管理面板开启，这样话就可以在浏览器上进行实时访问和监控了：\nsudo rabbitmq-plugins enable rabbitmq_management 再次查看状态，可以看到多了一个管理面板，使用的是HTTP协议：\nListeners\rInterface: [::], port: 25672, protocol: clustering, purpose: inter-node and CLI tool communication\rInterface: [::], port: 5672, protocol: amqp, purpose: AMQP 0-9-1 and AMQP 1.0\rInterface: [::], port: 15672, protocol: http, purpose: HTTP API 我们打开浏览器直接访问一下：\n可以看到需要我们进行登录才可以进入，我们这里还需要创建一个用户才可以，这里就都用admin：\nsudo rabbitmqctl add_user 用户名 密码 将管理员权限给予我们刚刚创建好的用户：\nsudo rabbitmqctl set_user_tags admin administrator 创建完成之后，我们登录一下页面：\n进入了之后会显示当前的消息队列情况，包括版本号、Erlang版本等，这里需要介绍一下RabbitMQ的设计架构，这样我们就知道各个模块管理的是什么内容了：\n生产者（Publisher）和消费者（Consumer）： 不用多说了吧。 Channel： 我们的客户端连接都会使用一个Channel，再通过Channel去访问到RabbitMQ服务器，注意通信协议不是http，而是amqp协议。 Exchange： 类似于交换机一样的存在，会根据我们的请求，转发给相应的消息队列，每个队列都可以绑定到Exchange上，这样Exchange就可以将数据转发给队列了，可以存在很多个，不同的Exchange类型可以用于实现不同消息的模式。 Queue： 消息队列本体，生产者所有的消息都存放在消息队列中，等待消费者取出。 Virtual Host： 有点类似于环境隔离，不同环境都可以单独配置一个Virtual Host，每个Virtual Host可以包含很多个Exchange和Queue，每个Virtual Host相互之间不影响。 使用消息队列 #\r我们就从最简的的模型开始讲起：\n（一个生产者 -\u0026gt; 消息队列 -\u0026gt; 一个消费者）\n生产者只需要将数据丢进消息队列，而消费者只需要将数据从消息队列中取出，这样就实现了生产者和消费者的消息交互。我们现在来演示一下，首先进入到我们的管理页面，这里我们创建一个新的实验环境，只需要新建一个Virtual Host即可：\n添加新的虚拟主机之后，我们可以看到，当前admin用户的主机访问权限中新增了我们刚刚添加的环境：\n现在我们来看看交换机：\n交换机列表中自动为我们新增了刚刚创建好的虚拟主机相关的预设交换机，一共7个，这里我们首先介绍一下前面两个direct类型的交换机，一个是（AMQP default）还有一个是amq.direct，它们都是直连模式的交换机，我们来看看第一个：\n第一个交换机是所有虚拟主机都会自带的一个默认交换机，并且此交换机不可删除，此交换机默认绑定到所有的消息队列，如果是通过默认交换机发送消息，那么会根据消息的routingKey（之后我们发消息都会指定）决定发送给哪个同名的消息队列，同时也不能显示地将消息队列绑定或解绑到此交换机。\n我们可以看到，详细信息中，当前交换机特性是持久化的，也就是说就算机器重启，那么此交换机也会保留，如果不是持久化，那么一旦重启就会消失。实际上我们在列表中看到D的字样，就表示此交换机是持久化的，包含一会我们要讲解的消息队列列表也是这样，所有自动生成的交换机都是持久化的。\n我们接着来看第二个交换机，这个交换机是一个普通的直连交换机：\n这个交换机和我们刚刚介绍的默认交换机类型一致，并且也是持久化的，但是我们可以看到它是具有绑定关系的，如果没有指定的消息队列绑定到此交换机上，那么这个交换机无法正常将信息存放到指定的消息队列中，也是根据routingKey寻找消息队列（但是可以自定义）\n我们可以在下面直接操作，让某个队列绑定，这里我们先不进行操作。\n介绍完了两个最基本的交换机之后（其他类型的交换机我们会在后面进行介绍），我们接着来看消息队列：\n可以看到消息队列列表中没有任何的消息队列，我们可以来尝试添加一个新的消息队列：\n第一行，我们选择我们刚刚创建好的虚拟主机，在这个虚拟主机下创建此消息队列，接着我们将其类型定义为Classic类型，也就是经典类型（其他类型我们会在后面逐步介绍）名称随便起一个，然后持久化我们选择Transient暂时的（当然也可以持久化，看你自己）自动删除我们选择No（需要至少有一个消费者连接到这个队列，之后，一旦所有与这个队列连接的消费者都断开时，就会自动删除此队列）最下面的参数我们暂时不进行任何设置（之后会用到）\n现在，我们就创建好了一个经典的消息队列：\n点击此队列的名称，我们可以查看详细信息：\n详细相信中包括队列的当前负载状态、属性、消息队列占用的内存，消息数量等，一会我们发送消息时可以进一步进行观察。\n现在我们需要将此消息队列绑定到上面的第二个直连交换机，这样我们就可以通过此交换机向此消息队列发送消息了：\n这里填写之前第二个交换机的名称还有我们自定义的routingKey（最好还是和消息队列名称一致，这里是为了一会演示两个交换机区别用）我们直接点击绑定即可：\n绑定之后我们可以看到当前队列已经绑定对应的交换机了，现在我们可以前往交换机对此消息队列发送一个消息：\n回到交换机之后，可以卡到这边也是同步了当前的绑定信息，在下方，我们直接向此消息队列发送信息：\n点击发送之后，我们回到刚刚的交换机详细页面，可以看到已经有一条新的消息在队列中了：\n我们可以直接在消息队列这边获取消息队列中的消息，找到下方的Get message选项：\n可以看到有三个选择，首先第一个Ack Mode，这个是应答模式选择，一共有4个选项：\nNack message requeue true：拒绝消息，也就是说不会将消息从消息队列取出，并且重新排队，一次可以拒绝多个消息。 Ack message requeue false：确认应答，确认后消息会从消息队列中移除，一次可以确认多个消息。 Reject message requeue true/false：也是拒绝此消息，但是可以指定是否重新排队。 这里我们使用默认的就可以了，这样只会查看消息是啥，但是不会取出，消息依然存在于消息队列中，第二个参数是编码格式，使用默认的就可以了，最后就是要生效的操作数量，选择1就行：\n可以看到我们刚刚的消息已经成功读取到。\n现在我们再去第一个默认交换机中尝试发送消息试试看：\n如果我们使用之前自定义的routingKey，会显示没有路由，这是因为默认的交换机只会找对应名称的消息队列，我们现在向yyds发送一下试试看：\n可以看到消息成功发布了，我们来接收一下看看：\n可以看到成功发送到此消息队列中了。\n当然除了在交换机发送消息给消息队列之外，我们也可以直接在消息队列这里发：\n效果是一样的，注意这里我们可以选择是否将消息持久化，如果是持久化消息，那么就算服务器重启，此消息也会保存在消息队列中。\n最后如果我们不需要再使用此消息队列了，我们可以手动对其进行删除或是清空：\n点击Delete Queue删除我们刚刚创建好的yyds队列，到这里，我们对应消息队列的一些简单使用，就讲解完毕了。\n使用Java操作消息队列 #\r现在我们来看看如何通过Java连接到RabbitMQ服务器并使用消息队列进行消息发送（这里一起讲解，包括Java基础版本和SpringBoot版本），首先我们使用最基本的Java客户端连接方式：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.rabbitmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;amqp-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.14.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 依赖导入之后，我们来实现一下生产者和消费者，首先是生产者，生产者负责将信息发送到消息队列：\npublic static void main(String[] args) { //使用ConnectionFactory来创建连接 ConnectionFactory factory = new ConnectionFactory(); //设定连接信息，基操 factory.setHost(\u0026#34;192.168.0.12\u0026#34;); factory.setPort(5672); //注意这里写5672，是amqp协议端口 factory.setUsername(\u0026#34;admin\u0026#34;); factory.setPassword(\u0026#34;admin\u0026#34;); factory.setVirtualHost(\u0026#34;/test\u0026#34;); //创建连接 try(Connection connection = factory.newConnection()){ }catch (Exception e){ e.printStackTrace(); } } 这里我们可以直接在程序中定义并创建消息队列（实际上是和我们在管理页面创建一样的效果）客户端需要通过连接创建一个新的通道（Channel），同一个连接下可以有很多个通道，这样就不用创建很多个连接也能支持分开发送了。\ntry(Connection connection = factory.newConnection(); Channel channel = connection.createChannel()){ //通过Connection创建新的Channel //声明队列，如果此队列不存在，会自动创建 channel.queueDeclare(\u0026#34;yyds\u0026#34;, false, false, false, null); //将队列绑定到交换机 channel.queueBind(\u0026#34;yyds\u0026#34;, \u0026#34;amq.direct\u0026#34;, \u0026#34;my-yyds\u0026#34;); //发布新的消息，注意消息需要转换为byte[] channel.basicPublish(\u0026#34;amq.direct\u0026#34;, \u0026#34;my-yyds\u0026#34;, null, \u0026#34;Hello World!\u0026#34;.getBytes()); }catch (Exception e){ e.printStackTrace(); } 其中queueDeclare方法的参数如下：\nqueue：队列的名称（默认创建后routingKey和队列名称一致） durable：是否持久化。 exclusive：是否排他，如果一个队列被声明为排他队列，该队列仅对首次声明它的连接可见，并在连接断开时自动删除。排他队列是基于Connection可见，同一个Connection的不同Channel是可以同时访问同一个连接创建的排他队列，并且，如果一个Connection已经声明了一个排他队列，其他的Connection是不允许建立同名的排他队列的，即使该队列是持久化的，一旦Connection关闭或者客户端退出，该排他队列都会自动被删除。 autoDelete：是否自动删除。 arguments：设置队列的其他一些参数，这里我们暂时不需要什么其他参数。 其中queueBind方法参数如下：\nqueue：需要绑定的队列名称。 exchange：需要绑定的交换机名称。 routingKey：不用多说了吧。 其中basicPublish方法的参数如下：\nexchange: 对应的Exchange名称，我们这里就使用第二个直连交换机。 routingKey：这里我们填写绑定时指定的routingKey，其实和之前在管理页面操作一样。 props：其他的配置。 body：消息本体。 执行完成后，可以在管理页面中看到我们刚刚创建好的消息队列了：\n并且此消息队列已经成功与amq.direct交换机进行绑定：\n那么现在我们的消息队列中已经存在数据了，怎么将其读取出来呢？我们来看看如何创建一个消费者：\npublic static void main(String[] args) throws IOException, TimeoutException { ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\u0026#34;10.37.129.4\u0026#34;); factory.setPort(5672); factory.setUsername(\u0026#34;admin\u0026#34;); factory.setPassword(\u0026#34;admin\u0026#34;); factory.setVirtualHost(\u0026#34;/test\u0026#34;); //这里不使用try-with-resource，因为消费者是一直等待新的消息到来，然后按照 //我们设定的逻辑进行处理，所以这里不能在定义完成之后就关闭连接 Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //创建一个基本的消费者 channel.basicConsume(\u0026#34;yyds\u0026#34;, false, (s, delivery) -\u0026gt; { System.out.println(new String(delivery.getBody())); //basicAck是确认应答，第一个参数是当前的消息标签，后面的参数是 //是否批量处理消息队列中所有的消息，如果为false表示只处理当前消息 channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); //basicNack是拒绝应答，最后一个参数表示是否将当前消息放回队列，如果 //为false，那么消息就会被丢弃 //channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, false); //跟上面一样，最后一个参数为false，只不过这里省了 //channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false); }, s -\u0026gt; {}); } 其中basicConsume方法参数如下：\nqueue - 消息队列名称，直接指定。 autoAck - 自动应答，消费者从消息队列取出数据后，需要跟服务器进行确认应答，当服务器收到确认后，会自动将消息删除，如果开启自动应答，那么消息发出后会直接删除。 deliver - 消息接收后的函数回调，我们可以在回调中对消息进行处理，处理完成后，需要给服务器确认应答。 cancel - 当消费者取消订阅时进行的函数回调，这里暂时用不到。 现在我们启动一下消费者，可以看到立即读取到我们刚刚插入到队列中的数据：\n我们现在继续在消息队列中插入新的数据，这里直接在网页上进行操作就行了，同样的我们也可以在消费者端接受并进行处理。\n现在我们把刚刚创建好的消息队列删除。\n官方文档：https://docs.spring.io/spring-amqp/docs/current/reference/html/\n前面我们已经完成了RabbitMQ的安装和简单使用，并且通过Java连接到服务器。现在我们来尝试在SpringBoot中整合消息队列客户端，首先是依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着我们需要配置RabbitMQ的地址等信息：\nspring: rabbitmq: addresses: 192.168.0.4 username: admin password: admin virtual-host: /test 这样我们就完成了最基本信息配置，现在我们来看一下，如何像之前一样去声明一个消息队列，我们只需要一个配置类就行了：\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;directExchange\u0026#34;) //定义交换机Bean，可以很多个 public Exchange exchange(){ return ExchangeBuilder.directExchange(\u0026#34;amq.direct\u0026#34;).build(); } @Bean(\u0026#34;yydsQueue\u0026#34;) //定义消息队列 public Queue queue(){ return QueueBuilder .nonDurable(\u0026#34;yyds\u0026#34;) //非持久化类型 .build(); } @Bean(\u0026#34;binding\u0026#34;) public Binding binding(@Qualifier(\u0026#34;directExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue\u0026#34;) Queue queue){ //将我们刚刚定义的交换机和队列进行绑定 return BindingBuilder .bind(queue) //绑定队列 .to(exchange) //到交换机 .with(\u0026#34;my-yyds\u0026#34;) //使用自定义的routingKey .noargs(); } } 接着我们来创建一个生产者，这里我们直接编写在测试用例中：\n@SpringBootTest class SpringCloudMqApplicationTests { //RabbitTemplate为我们封装了大量的RabbitMQ操作，已经由Starter提供，因此直接注入使用即可 @Resource RabbitTemplate template; @Test void publisher() { //使用convertAndSend方法一步到位，参数基本和之前是一样的 //最后一个消息本体可以是Object类型，真是大大的方便 template.convertAndSend(\u0026#34;amq.direct\u0026#34;, \u0026#34;my-yyds\u0026#34;, \u0026#34;Hello World!\u0026#34;); } } 现在我们来运行一下这个测试用例：\n可以看到后台自动声明了我们刚刚定义好的消息队列和交换机以及对应的绑定关系，并且我们的数据也是成功插入到消息队列中：\n现在我们再来看看如何创建一个消费者，因为消费者实际上就是一直等待消息然后进行处理的角色，这里我们只需要创建一个监听器就行了，它会一直等待消息到来然后再进行处理：\n@Component //注册为Bean public class TestListener { @RabbitListener(queues = \u0026#34;yyds\u0026#34;) //定义此方法为队列yyds的监听器，一旦监听到新的消息，就会接受并处理 public void test(Message message){ System.out.println(new String(message.getBody())); } } 接着我们启动服务器：\n可以看到控制台成功输出了我们之前放入队列的消息，并且管理页面中也显示此消费者已经连接了：\n接着我们再通过管理页面添加新的消息看看，也是可以正常进行接受的。\n当然，如果我们需要确保消息能够被消费者接受并处理，然后得到消费者的反馈，也是可以的：\n@Test void publisher() { //会等待消费者消费然后返回响应结果 Object res = template.convertSendAndReceive(\u0026#34;amq.direct\u0026#34;, \u0026#34;my-yyds\u0026#34;, \u0026#34;Hello World!\u0026#34;); System.out.println(\u0026#34;收到消费者响应：\u0026#34;+res); } 消费者这边只需要返回一个对应的结果即可：\n@RabbitListener(queues = \u0026#34;yyds\u0026#34;) public String receiver(String data){ System.out.println(\u0026#34;一号消息队列监听器 \u0026#34;+data); return \u0026#34;收到!\u0026#34;; } 测试没有问题：\n那么如果我们需要直接接收一个JSON格式的消息，并且希望直接获取到实体类呢？\n@Data public class User { int id; String name; } @Configuration public class RabbitConfiguration { ... @Bean(\u0026#34;jacksonConverter\u0026#34;) //直接创建一个用于JSON转换的Bean public Jackson2JsonMessageConverter converter(){ return new Jackson2JsonMessageConverter(); } } 接着我们只需要指定转换器就可以了：\n@Component public class TestListener { //指定messageConverter为我们刚刚创建的Bean名称 @RabbitListener(queues = \u0026#34;yyds\u0026#34;, messageConverter = \u0026#34;jacksonConverter\u0026#34;) public void receiver(User user){ //直接接收User类型 System.out.println(user); } } 现在我们直接在管理页面发送：\n{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;LB\u0026#34;} !\r](\rhttps://tva1.sinaimg.cn/large/e6c9d24ely1h1byhcakabj221m0lwac0.jpg)\n可以看到成功完成了转换，并输出了用户信息：\n同样的，我们也可以直接发送User，因为我们刚刚已经配置了Jackson2JsonMessageConverter为Bean，所以直接使用就可以了：\n@Test void publisher() { template.convertAndSend(\u0026#34;amq.direct\u0026#34;, \u0026#34;yyds\u0026#34;, new User()); } 可以看到后台的数据类型为：\n这样，我们就通过SpringBoot实现了RabbitMQ的简单使用。\n死信队列 #\r消息队列中的数据，如果迟迟没有消费者来处理，那么就会一直占用消息队列的空间。比如我们模拟一下抢车票的场景，用户下单高铁票之后，会进行抢座，然后再进行付款，但是如果用户下单之后并没有及时的付款，这张票不可能一直让这个用户占用着，因为你不买别人还要买呢，所以会在一段时间后超时，让这张票可以继续被其他人购买。\n这时，我们就可以使用死信队列，将那些用户超时未付款的或是用户主动取消的订单，进行进一步的处理，以下类型的消息都会被判定为死信：\n消息被拒绝(basic.reject / basic.nack)，并且requeue = false 消息TTL过期 队列达到最大长度 那么如何构建这样的一种使用模式呢？实际上本质就是一个死信交换机+绑定的死信队列，当正常队列中的消息被判定为死信时，会被发送到对应的死信交换机，然后再通过交换机发送到死信队列中，死信队列也有对应的消费者去处理消息。\n这里我们直接在配置类中创建一个新的死信交换机和死信队列，并进行绑定：\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;directDlExchange\u0026#34;) public Exchange dlExchange(){ //创建一个新的死信交换机 return ExchangeBuilder.directExchange(\u0026#34;dlx.direct\u0026#34;).build(); } @Bean(\u0026#34;yydsDlQueue\u0026#34;) //创建一个新的死信队列 public Queue dlQueue(){ return QueueBuilder .nonDurable(\u0026#34;dl-yyds\u0026#34;) .build(); } @Bean(\u0026#34;dlBinding\u0026#34;) //死信交换机和死信队列进绑定 public Binding dlBinding(@Qualifier(\u0026#34;directDlExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsDlQueue\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;dl-yyds\u0026#34;) .noargs(); } ... @Bean(\u0026#34;yydsQueue\u0026#34;) public Queue queue(){ return QueueBuilder .nonDurable(\u0026#34;yyds\u0026#34;) .deadLetterExchange(\u0026#34;dlx.direct\u0026#34;) //指定死信交换机 .deadLetterRoutingKey(\u0026#34;dl-yyds\u0026#34;) //指定死信RoutingKey .build(); } ... } 接着我们将监听器修改为死信队列监听：\n@Component public class TestListener { @RabbitListener(queues = \u0026#34;dl-yyds\u0026#34;, messageConverter = \u0026#34;jacksonConverter\u0026#34;) public void receiver(User user){ System.out.println(user); } } 配置完成后，我们来尝试启动一下吧，注意启动之前记得把之前的队列给删了，这里要重新定义。\n队列列表中已经出现了我们刚刚定义好的死信队列，并且yyds队列也支持死信队列发送功能了，现在我们尝试向此队列发送一个消息，但是我们将其拒绝：\n可以看到拒绝后，如果不让消息重新排队，那么就会变成死信，直接被丢进死信队列中，可以看到在拒绝后：\n现在我们来看看第二种情况，RabbitMQ支持将超过一定时间没被消费的消息自动删除，这需要消息队列设定TTL值，如果消息的存活时间超过了Time To Live值，就会被自动删除，自动删除后的消息如果有死信队列，那么就会进入到死信队列中。\n现在我们将yyds消息队列设定TTL值（毫秒为单位）：\n@Bean(\u0026#34;yydsQueue\u0026#34;) public Queue queue(){ return QueueBuilder .nonDurable(\u0026#34;yyds\u0026#34;) .deadLetterExchange(\u0026#34;dlx.direct\u0026#34;) .deadLetterRoutingKey(\u0026#34;dl-yyds\u0026#34;) .ttl(5000) //如果5秒没处理，就自动删除 .build(); } 现在我们重启测试一下，注意修改了之后记得删除之前的yyds队列：\n可以看到现在yyds队列已经具有TTL特性了，我们现在来插入一个新的消息：\n可以看到消息5秒钟之后就不见了，而是被丢进了死信队列中。\n最后我们来看一下当消息队列长度达到最大的情况，现在我们将消息队列的长度进行限制：\n@Bean(\u0026#34;yydsQueue\u0026#34;) public Queue queue(){ return QueueBuilder .nonDurable(\u0026#34;yyds\u0026#34;) .deadLetterExchange(\u0026#34;dlx.direct\u0026#34;) .deadLetterRoutingKey(\u0026#34;dl-yyds\u0026#34;) .maxLength(3) //将最大长度设定为3 .build(); } 现在我们重启一下，然后尝试连续插入4个消息：\n可以看到yyds消息队列新增了Limit特性，也就是限定长度：\n@Test void publisher() { for (int i = 0; i \u0026lt; 4; i++) template.convertAndSend(\u0026#34;amq.direct\u0026#34;, \u0026#34;my-yyds\u0026#34;, new User()); } 可以看到因为长度限制为3，所以有一个消息直接被丢进了死信队列中，为了能够更直观地观察消息队列的机制，我们为User类新增一个时间字段：\n@Data public class User { int id; String name; String date = new Date().toString(); } 接着每隔一秒钟插入一个：\n@Test void publisher() throws InterruptedException { for (int i = 0; i \u0026lt; 4; i++) { Thread.sleep(1000); template.convertAndSend(\u0026#34;amq.direct\u0026#34;, \u0026#34;my-yyds\u0026#34;, new User()); } } 再次进行上述实验，可以发现如果到达队列长度限制，那么每次插入都会把位于队首的消息丢进死信队列，来腾出空间给新来的消息。\n工作队列模式 #\r注意： XX模式只是一种设计思路，并不是指的具体的某种实现，可以理解为实现XX模式需要怎么去写。\n前面我们了解了最简的一个消费者一个生产者的模式，接着我们来了解一下一个生产者多个消费者的情况：\n实际上这种模式就非常适合多个工人等待新的任务到来的场景，我们的任务有很多个，一个一个丢进消息队列，而此时工人有很多个，那么我们就可以将这些任务分配个各个工人，让他们各自负责一些任务，并且做的快的工人还可以做完成一些（能者多劳）。\n非常简单，我们只需要创建两个监听器即可：\n@Component public class TestListener { @RabbitListener(queues = \u0026#34;yyds\u0026#34;) public void receiver(String data){ //这里直接接收String类型的数据 System.out.println(\u0026#34;一号消息队列监听器 \u0026#34;+data); } @RabbitListener(queues = \u0026#34;yyds\u0026#34;) public void receiver2(String data){ System.out.println(\u0026#34;二号消息队列监听器 \u0026#34;+data); } } 可以看到我们发送消息时，会自动进行轮询分发：\n那么如果我们一开始就在消息队列中放入一部分消息在开启消费者呢？\n可以看到，如果是一开始就存在消息，会被一个消费者一次性全部消耗，这是因为我们没有对消费者的Prefetch count（预获取数量，一次性获取消息的最大数量）进行限制，也就是说我们现在希望的是消费者一次只能拿一个消息，而不是将所有的消息全部都获取。\n因此我们需要对这个数量进行一些配置，这里我们需要在配置类中定义一个自定义的ListenerContainerFactory，可以在这里设定消费者Channel的PrefetchCount的大小：\n@Resource private CachingConnectionFactory connectionFactory; @Bean(name = \u0026#34;listenerContainer\u0026#34;) public SimpleRabbitListenerContainerFactory listenerContainer(){ SimpleRabbitListenerContainerFactory factory = new SimpleRabbitListenerContainerFactory(); factory.setConnectionFactory(connectionFactory); factory.setPrefetchCount(1); //将PrefetchCount设定为1表示一次只能取一个 return factory; } 接着我们在监听器这边指定即可：\n@Component public class TestListener { @RabbitListener(queues = \u0026#34;yyds\u0026#34;, containerFactory = \u0026#34;listenerContainer\u0026#34;) public void receiver(String data){ System.out.println(\u0026#34;一号消息队列监听器 \u0026#34;+data); } @RabbitListener(queues = \u0026#34;yyds\u0026#34;, containerFactory = \u0026#34;listenerContainer\u0026#34;) public void receiver2(String data){ System.out.println(\u0026#34;二号消息队列监听器 \u0026#34;+data); } } 现在我们再次启动服务器，可以看到PrefetchCount被限定为1了：\n再次重复上述的实现，可以看到消息不会被一号消费者给全部抢走了：\n当然除了去定义两个相同的监听器之外，我们也可以直接在注解中定义，比如我们现在需要10个同样的消费者：\n@Component public class TestListener { @RabbitListener(queues = \u0026#34;yyds\u0026#34;, containerFactory = \u0026#34;listenerContainer\u0026#34;, concurrency = \u0026#34;10\u0026#34;) public void receiver(String data){ System.out.println(\u0026#34;一号消息队列监听器 \u0026#34;+data); } } 可以看到在管理页面中出现了10个消费者：\n至此，有关工作队列模式就讲到这里。\n发布订阅模式 #\r前面我们已经了解了RabbitMQ客户端的一些基本操作，包括普通的消息模式，接着我们来了解一下其他的模式，首先是发布订阅模式，它支持多种方式：\n比如我们在阿里云买了云服务器，但是最近快到期了，那么就会给你的手机、邮箱发送消息，告诉你需要去续费了，但是手机短信和邮件发送并不一定是同一个业务提供的，但是现在我们又希望能够都去执行，所以就可以用到发布订阅模式，简而言之就是，发布一次，消费多个。\n实现这种模式其实也非常简单，但是如果使用我们之前的直连交换机，肯定是不行的，我们这里需要用到另一种类型的交换机，叫做fanout（扇出）类型，这时一种广播类型，消息会被广播到所有与此交换机绑定的消息队列中。\n这里我们使用默认的交换机：\n这个交换机是一个fanout类型的交换机，我们就是要它就行了：\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;fanoutExchange\u0026#34;) public Exchange exchange(){ //注意这里是fanoutExchange return ExchangeBuilder.fanoutExchange(\u0026#34;amq.fanout\u0026#34;).build(); } @Bean(\u0026#34;yydsQueue1\u0026#34;) public Queue queue(){ return QueueBuilder.nonDurable(\u0026#34;yyds1\u0026#34;).build(); } @Bean(\u0026#34;binding\u0026#34;) public Binding binding(@Qualifier(\u0026#34;fanoutExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue1\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;yyds1\u0026#34;) .noargs(); } @Bean(\u0026#34;yydsQueue2\u0026#34;) public Queue queue2(){ return QueueBuilder.nonDurable(\u0026#34;yyds2\u0026#34;).build(); } @Bean(\u0026#34;binding2\u0026#34;) public Binding binding2(@Qualifier(\u0026#34;fanoutExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue2\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;yyds2\u0026#34;) .noargs(); } } 这里我们将两个队列都绑定到此交换机上，我们先启动看看效果：\n绑定没有什么问题，接着我们搞两个监听器，监听一下这两个队列：\n@Component public class TestListener { @RabbitListener(queues = \u0026#34;yyds1\u0026#34;) public void receiver(String data){ System.out.println(\u0026#34;一号消息队列监听器 \u0026#34;+data); } @RabbitListener(queues = \u0026#34;yyds2\u0026#34;) public void receiver2(String data){ System.out.println(\u0026#34;二号消息队列监听器 \u0026#34;+data); } } 现在我们通过交换机发送消息，看看是不是两个监听器都会接收到消息：\n可以看到确实是两个消息队列都能够接受到此消息：\n这样我们就实现了发布订阅模式。\n路由模式 #\r路由模式实际上我们一开始就已经实现了，我们可以在绑定时指定想要的routingKey只有生产者发送时指定了对应的routingKey才能到达对应的队列。\n当然除了我们之前的一次绑定之外，同一个消息队列可以多次绑定到交换机，并且使用不同的routingKey，这样只要满足其中一个都可以被发送到此消息队列中：\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;directExchange\u0026#34;) public Exchange exchange(){ return ExchangeBuilder.directExchange(\u0026#34;amq.direct\u0026#34;).build(); } @Bean(\u0026#34;yydsQueue\u0026#34;) public Queue queue(){ return QueueBuilder.nonDurable(\u0026#34;yyds\u0026#34;).build(); } @Bean(\u0026#34;binding\u0026#34;) //使用yyds1绑定 public Binding binding(@Qualifier(\u0026#34;directExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;yyds1\u0026#34;) .noargs(); } @Bean(\u0026#34;binding2\u0026#34;) //使用yyds2绑定 public Binding binding2(@Qualifier(\u0026#34;directExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;yyds2\u0026#34;) .noargs(); } } 启动后我们可以看到管理面板中出现了两个绑定关系：\n这里可以测试一下，随便使用哪个routingKey都可以。\n主题模式 #\r实际上这种模式就是一种模糊匹配的模式，我们可以将routingKey以模糊匹配的方式去进行转发。\n我们可以使用*或#来表示：\n* - 表示任意的一个单词 # - 表示0个或多个单词 这里我们来测试一下：\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;topicExchange\u0026#34;) //这里使用预置的Topic类型交换机 public Exchange exchange(){ return ExchangeBuilder.topicExchange(\u0026#34;amq.topic\u0026#34;).build(); } @Bean(\u0026#34;yydsQueue\u0026#34;) public Queue queue(){ return QueueBuilder.nonDurable(\u0026#34;yyds\u0026#34;).build(); } @Bean(\u0026#34;binding\u0026#34;) public Binding binding2(@Qualifier(\u0026#34;topicExchange\u0026#34;) Exchange exchange, @Qualifier(\u0026#34;yydsQueue\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) .with(\u0026#34;*.test.*\u0026#34;) .noargs(); } } 启动项目，可以看到只要是满足通配符条件的都可以成功转发到对应的消息队列：\n接着我们可以再试试看#通配符。\n除了我们这里使用的默认主题交换机之外，还有一个叫做amq.rabbitmq.trace的交换机：\n可以看到它也是topic类型的，那么这个交换机是做什么的呢？实际上这是用于帮助我们记录和追踪生产者和消费者使用消息队列的交换机，它是一个内部的交换机，那么如果使用呢？首先创建一个消息队列用于接收记录：\n接着我们需要在控制台将虚拟主机/test的追踪功能开启：\nsudo rabbitmqctl trace_on -p /test 开启后，我们将此队列绑定到上面的交换机上：\n由于发送到此交换机上的routingKey为routing key为 publish.交换机名称 和 deliver.队列名称，分别对应生产者投递到交换机的消息，和消费者从队列上获取的消息，因此这里使用#通配符进行绑定。\n现在我们来测试一下，比如还是往yyds队列发送消息：\n可以看到在发送消息，并且消费者已经处理之后，trace队列中新增了两条消息，那么我们来看看都是些什么消息：\n通过追踪，我们可以很明确地得知消息发送的交换机、routingKey、用户等信息，包括信息本身，同样的，消费者在取出数据时也有记录：\n我们可以明确消费者的地址、端口、具体操作的队列以及取出的消息信息等。\n到这里，我们就已经了解了3种类型的交换机。\n第四种交换机类型 #\r通过前面的学习，我们已经介绍了三种交换机类型，现在我们来介绍一下第四种交换机类型header，它是根据头部信息来决定的，在我们发送的消息中是可以携带一些头部信息的（类似于HTTP），我们可以根据这些头部信息来决定路由到哪一个消息队列中。\n@Configuration public class RabbitConfiguration { @Bean(\u0026#34;headerExchange\u0026#34;) //注意这里返回的是HeadersExchange public HeadersExchange exchange(){ return ExchangeBuilder .headersExchange(\u0026#34;amq.headers\u0026#34;) //RabbitMQ为我们预置了两个，这里用第一个就行 .build(); } @Bean(\u0026#34;yydsQueue\u0026#34;) public Queue queue(){ return QueueBuilder.nonDurable(\u0026#34;yyds\u0026#34;).build(); } @Bean(\u0026#34;binding\u0026#34;) public Binding binding2(@Qualifier(\u0026#34;headerExchange\u0026#34;) HeadersExchange exchange, //这里和上面一样的类型 @Qualifier(\u0026#34;yydsQueue\u0026#34;) Queue queue){ return BindingBuilder .bind(queue) .to(exchange) //使用HeadersExchange的to方法，可以进行进一步配置 //.whereAny(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;).exist(); 这个是只要存在任意一个指定的头部Key就行 //.whereAll(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;).exist(); 这个是必须存在所有指定的的头部Key .where(\u0026#34;test\u0026#34;).matches(\u0026#34;hello\u0026#34;); //比如我们现在需要消息的头部信息中包含test，并且值为hello才能转发给我们的消息队列 //.whereAny(Collections.singletonMap(\u0026#34;test\u0026#34;, \u0026#34;hello\u0026#34;)).match(); 传入Map也行，批量指定键值对 } } 现在我们来启动一下试试看：\n结果发现，消息可以成功发送到消息队列，这就是使用头部信息进行路由。\n这样，我们就介绍完了所有四种类型的交换机。\n集群搭建 #\r前面我们对于RabbitMQ的相关内容已经基本讲解完毕了，最后我们来尝试搭建一个集群，让RabbitMQ之间进行数据复制（镜像模式）稍微有点麻烦，跟着视频走吧。\n可能会用到的一些命令：\nsudo rabbitmqctl stop_app sudo rabbitmqctl join_cluster rabbit@ubuntu-server sudo rabbitmqctl start_app 实现复制即可。\nSpringCloud 消息组件 #\r前面我们已经学习了如何使用RabbitMQ消息队列，接着我们来简单介绍一下SpringCloud为我们提供的一些消息组件。\nSpringCloud Stream #\r官方文档： https://docs.spring.io/spring-cloud-stream/docs/3.2.2/reference/html/\n前面我们介绍了RabbitMQ，了解了消息队列相关的一些操作，但是可能我们会遇到不同的系统在用不同的消息队列，比如系统A用的Kafka、系统B用的RabbitMQ，但是我们现在又没有学习过Kafka，那么怎么办呢？有没有一种方式像JDBC一样，我们只需要关心SQL和业务本身，而不用关心数据库的具体实现呢？\nSpringCloud Stream能够做到，它能够屏蔽底层实现，我们使用统一的消息队列操作方式就能操作多种不同类型的消息队列。\n它屏蔽了RabbitMQ底层操作，让我们使用统一的Input和Output形式，以Binder为中间件，这样就算我们切换了不同的消息队列，也无需修改代码，而具体某种消息队列的底层实现是交给Stream在做的。\n这里我们创建一个新的项目来测试一下：\n依赖如下：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.1\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- RabbitMQ的Stream实现 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-stream-rabbit\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 首先我们来编写一下生产者，首先是配置文件：\nserver: port: 8001 spring: cloud: stream: binders: #此处配置要绑定的rabbitmq的服务信息 local-server: #绑定名称，随便起一个就行 type: rabbit #消息组件类型，这里使用的是RabbitMQ，就填写rabbit environment: #服务器相关信息，按照下面的方式填写就行，爆红别管 spring: rabbitmq: host: 192.168.0.6 port: 5672 username: admin password: admin virtual-host: /test bindings: test-out-0: destination: test.exchange 接着我们来编写一个Controller，一会访问一次这个接口，就向消息队列发送一个数据：\n@RestController public class PublishController { @Resource StreamBridge bridge; //通过bridge来发送消息 @RequestMapping(\u0026#34;/publish\u0026#34;) public String publish(){ //第一个参数其实就是RabbitMQ的交换机名称（数据会发送给这个交换机，到达哪个消息队列，不由我们决定） //这个交换机的命名稍微有一些规则: //输入: \u0026lt;名称\u0026gt; + -in- + \u0026lt;index\u0026gt; //输出: \u0026lt;名称\u0026gt; + -out- + \u0026lt;index\u0026gt; //这里我们使用输出的方式，来将数据发送到消息队列，注意这里的名称会和之后的消费者Bean名称进行对应 bridge.send(\u0026#34;test-out-0\u0026#34;, \u0026#34;HelloWorld!\u0026#34;); return \u0026#34;消息发送成功！\u0026#34;+new Date(); } } 现在我们来将生产者启动一下，访问一下接口：\n可以看到消息成功发送，我们来看看RabbitMQ这边的情况：\n新增了一个test-in-0交换机，并且此交换机是topic类型的：\n但是目前没有任何队列绑定到此交换机上，因此我们刚刚发送的消息实际上是没有给到任何队列的。\n接着我们来编写一下消费者，消费者的编写方式比较特别，只需要定义一个Consumer就可以了，其他配置保持一致：\n@Component public class ConsumerComponent { @Bean(\u0026#34;test\u0026#34;) //注意这里需要填写我们前面交换机名称中\u0026#34;名称\u0026#34;，这样生产者发送的数据才会正确到达 public Consumer\u0026lt;String\u0026gt; consumer(){ return System.out::println; } } 配置中需要修改一下目标交换机：\nserver: port: 8002 spring: cloud: stream: ... bindings: #因为消费者是输入，默认名称为 方法名-in-index，这里我们将其指定为我们刚刚定义的交换机 test-in-0: destination: test.exchange 接着我们直接启动就可以了，可以看到启动之后，自动为我们创建了一个新的队列：\n而这个队列实际上就是我们消费者等待数据到达的队列：\n可以看到当前队列直接绑定到了我们刚刚创建的交换机上，并且routingKey是直接写的#，也就是说一会消息会直接过来。\n现在我们再来访问一些消息发送接口：\n可以看到消费者成功地进行消费了：\n这样，我们就通过使用SpringCloud Stream来屏蔽掉底层RabbitMQ来直接进行消息的操作了。\nSpringCloud Bus #\r官方文档： https://cloud.spring.io/spring-cloud-bus/reference/html/\n实际上它就相当于是一个消息总线，可用于向各个服务广播某些状态的更改（比如云端配置更改，可以结合Config组件实现动态更新配置，当然我们前面学习的Nacos其实已经包含这个功能了）或其他管理指令。\n这里我们也是简单使用一下吧，Bus需要基于一个具体的消息队列实现，比如RabbitMQ或是Kafka，这里我们依然使用RabbitMQ。\n我们将最开始的微服务拆分项目继续使用，比如现在我们希望借阅服务的某个接口调用时，能够给用户服务和图书服务发送一个通知，首先是依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bus-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着我们只需要在配置文件中将RabbitMQ的相关信息配置：\nspring: rabbitmq: addresses: 192.168.0.6 username: admin password: admin virtual-host: /test management: endpoints: web: exposure: include: \u0026#34;*\u0026#34; #暴露端点，一会用于提醒刷新 然后启动我们的三个服务器，可以看到在管理面板中：\n新增了springCloudBug这样一个交换机，并且：\n自动生成了各自的消息队列，这样就可以监听并接收到消息了。\n现在我们访问一个端口：\n此端口是用于通知别人进行刷新，可以看到调用之后，消息队列中成功出现了一次消费：\n现在我们结合之前使用的Config配置中心，来看看是不是可以做到通知之后所有的配置动态刷新了。\n———————————————— 版权声明：本文为柏码知识库版权所有，禁止一切未经授权的转载、发布、出售等行为，违者将被追究法律责任。 原文链接：https://www.itbaima.cn/document/35v1hbsfcdgagdnw\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/rabbitmq/","section":"Docs","summary":"消息队列 #\r经过前面的学习，我们已经了解了我们之前的技术在分布式环境下的应用，接着我们来看最后一章的内容。\n那么，什么是消息队列呢？\n我们之前如果需要进行远程调用，那么一般可以通过发送HTTP请求来完成，而现在，我们可以使用第二种方式，就是消息队列，它能够将发送方发送的信息放入队列中，当新的消息入队时，会通知接收方进行处理，一般消息发送方称为生产者，接收方称为消费者。\n这样我们所有的请求，都可以直接丢到消息队列中，再由消费者取出，不再是直接连接消费者的形式了，而是加了一个中间商，这也是一种很好的解耦方案，并且在高并发的情况下，由于消费者能力有限，消息队列也能起到一个削峰填谷的作用，堆积一部分的请求，再由消费者来慢慢处理，而不会像直接调用那样请求蜂拥而至。\n那么，消息队列具体实现有哪些呢：\nRabbitMQ - 性能很强，吞吐量很高，支持多种协议，集群化，消息的可靠执行特性等优势，很适合企业的开发。 Kafka - 提供了超高的吞吐量，ms级别的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。 RocketMQ - 阿里巴巴推出的消息队列，经历过双十一的考验，单机吞吐量高，消息的高可靠性，扩展性强，支持事务等，但是功能不够完整，语言支持性较差。 我们这里，主要讲解的是RabbitMQ消息队列。\nRabbitMQ 消息队列 #\r官方网站： https://www.rabbitmq.com\nRabbitMQ拥有数万计的用户，是最受欢迎的开源消息队列之一，从\rT-Mobile到\rRuntastic，RabbitMQ在全球范围内用于小型初创企业和大型企业。\nRabbitMQ轻量级，易于在本地和云端部署，它支持多种消息协议。RabbitMQ可以部署在分布式和联合配置中，以满足大规模、高可用性要求。\nRabbitMQ在许多操作系统和云环境中运行，并为\r大多数流行语言提供了\r广泛的开发者工具。","title":"RabbitMq","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"\r微服务基础 #\r注意： 此阶段学习推荐的电脑配置，至少配备4核心CPU（主频3.0Ghz以上）+16GB内存，否则卡到你怀疑人生。\n前面我们讲解了SpringBoot框架，通过使用SpringBoot框架，我们的项目开发速度可以说是得到了质的提升。同时，我们对于项目的维护和理解，也会更加的轻松。可见，SpringBoot为我们的开发带来了巨大便捷。而这一部分，我们将基于SpringBoot，继续深入到企业实际场景，探讨微服务架构下的SpringCloud。这个部分我们会更加注重于架构设计上的讲解，弱化实现原理方面的研究。\n传统项目转型 #\r要说近几年最火热的话题，那还得是微服务，那么什么是微服务呢？\n我们可以先从技术的演变开始看起，在我们学习JavaWeb之后，一般的网站开发模式为Servlet+JSP，但是实际上我们在学习了SSM之后，会发现这种模式已经远远落后了，第一，一个公司不可能去招那么多同时会前端+后端的开发人员，就算招到，也并不一定能保证两个方面都比较擅长，相比前后端分开学习的开发人员，显然后者的学习成本更低，专注度更高。因此前后端分离成为了一种新的趋势。通过使用SpringBoot，我们几乎可以很快速地开发一个高性能的单体应用，只需要启动一个服务端，我们整个项目就开始运行了，各项功能融于一体，开发起来也更加轻松。\n但是随着我们项目的不断扩大，单体应用似乎显得有点乏力了。\n随着越来越多的功能不断地加入到一个SpringBoot项目中，随着接口不断增加，整个系统就要在同一时间内响应更多类型的请求，显然，这种扩展方式是不可能无限使用下去的，总有一天，这个SpringBoot项目会庞大到运行缓慢。并且所有的功能如果都集成在单端上，那么所有的请求都会全部汇集到一台服务器上，对此服务器造成巨大压力。\n可以试想一下，如果我们的电脑已经升级到i9-12900K，但是依然在运行项目的时候缓慢，无法同一时间响应成千上万的请求，那么这个问题就已经不是单纯升级机器配置可以解决的了。\n传统单体架构应用随着项目规模的扩大，实际上会暴露越来越多的问题，尤其是一台服务器无法承受庞大的单体应用部署，并且单体应用的维护也会越来越困难，我们得寻找一种新的开发架构来解决这些问题了。\nIn short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies.\nMartin Fowler在2014年提出了“微服务”架构，它是一种全新的架构风格。\n微服务把一个庞大的单体应用拆分为一个个的小型服务，比如我们原来的图书管理项目中，有登录、注册、添加、删除、搜索等功能，那么我们可以将这些功能单独做成一个个小型的SpringBoot项目，独立运行。 每个小型的微服务，都可以独立部署和升级，这样，就算整个系统崩溃，那么也只会影响一个服务的运行。 微服务之间使用HTTP进行数据交互，不再是单体应用内部交互了，虽然这样会显得更麻烦，但是带来的好处也是很直接的，甚至能突破语言限制，使用不同的编程语言进行微服务开发，只需要使用HTTP进行数据交互即可。 我们可以同时购买多台主机来分别部署这些微服务，这样，单机的压力就被分散到多台机器，并且每台机器的配置不一定需要太高，这样就能节省大量的成本，同时安全性也得到很大的保证。 甚至同一个微服务可以同时存在多个，这样当其中一个服务器出现问题时，其他服务器也在运行同样的微服务，这样就可以保证一个微服务的高可用。 当然，这里只是简单的演示一下微服务架构，实际开发中肯定是比这个复杂得多的。\n可见，采用微服务架构，更加能够应对当今时代下的种种考验，传统项目的开发模式，需要进行架构上的升级。\n走进SpringCloud #\r前面我们介绍了微服务架构的优点，那么同样的，这些优点的背后也存在着诸多的问题：\n要实现微服务并不是说只需要简单地将项目进行拆分，我们还需要考虑对各个微服务进行管理、监控等，这样我们才能够及时地寻找和排查问题。因此微服务往往需要的是一整套解决方案，包括服务注册和发现、容灾处理、负载均衡、配置管理等。 它不像单体架构那种方便维护，由于部署在多个服务器，我们不得不去保证各个微服务能够稳定运行，在管理难度上肯定是高于传统单体应用的。 在分布式的环境下，单体应用的某些功能可能会变得比较麻烦，比如分布式事务。 所以，为了更好地解决这些问题，SpringCloud正式登场。\nSpringCloud是Spring提供的一套分布式解决方案，集合了一些大型互联网公司的开源产品，包括诸多组件，共同组成SpringCloud框架。并且，它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、熔断机制、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。\n由于中小型公司没有独立开发自己的分布式基础设施的能力，使用SpringCloud解决方案能够以最低的成本应对当前时代的业务发展。\n可以看到，SpringCloud整体架构的亮点是非常明显的，分布式架构下的各个场景，都有对应的组件来处理，比如基于Netflix（奈飞）的开源分布式解决方案提供的组件：\nEureka - 实现服务治理（服务注册与发现），我们可以对所有的微服务进行集中管理，包括他们的运行状态、信息等。 Ribbon - 为服务之间相互调用提供负载均衡算法（现在被SpringCloudLoadBalancer取代） Hystrix - 断路器，保护系统，控制故障范围。暂时可以跟家里电闸的保险丝类比，当触电危险发生时能够防止进一步的发展。 Zuul - api网关，路由，负载均衡等多种作用，就像我们的路由器，可能有很多个设备都连接了路由器，但是数据包要转发给谁则是由路由器在进行（已经被SpringCloudGateway取代） Config - 配置管理，可以实现配置文件集中管理 当然，这里只是进行简单的了解即可，实际上微服务的玩法非常多，我们后面的学习中将会逐步进行探索。\n那么首先，我们就从注册中心开始说起。\nEureka 注册中心 #\r官方文档：https://docs.spring.io/spring-cloud-netflix/docs/current/reference/html/\n小贴士： 各位小伙伴在学习的过程中觉得有什么疑惑的可以直接查阅官方文档，我们会在每一个技术开始之前贴上官方文档的地址，方便各位进行查阅，同时在我们的课程中并不一定会完完整整地讲完整个框架的内容，有关详细的功能和使用方法文档中也是写的非常清楚的，感兴趣的可以深入学习哦。\n微服务项目结构 #\r现在我们重新设计一下之前的图书管理系统项目，将原有的大型（也许 项目进行拆分，注意项目拆分一定要尽可能保证单一职责，相同的业务不要在多个微服务中重复出现，如果出现需要借助其他业务完成的服务，那么可以使用服务之间相互调用的形式来实现（之后会介绍）：\n登录验证服务：用于处理用户注册、登录、密码重置等，反正就是一切与账户相关的内容，包括用户信息获取等。 图书管理服务：用于进行图书添加、删除、更新等操作，图书管理相关的服务，包括图书的存储等和信息获取。 图书借阅服务：交互性比较强的服务，需要和登陆验证服务和图书管理服务进行交互。 那么既然要将单体应用拆分为多个小型服务，我们就需要重新设计一下整个项目目录结构，这里我们就创建多个子项目，每一个子项目都是一个服务，这样由父项目统一管理依赖，就无需每个子项目都去单独管理依赖了，也更方便一点。\n我们首先创建一个普通的SpringBoot项目：\n然后不需要勾选任何依赖，直接创建即可，项目创建完成并初始化后，我们删除父工程的无用文件，只保留必要文件，像下面这样：\n接着我们就可以按照我们划分的服务，进行子工程创建了，创建一个新的Maven项目，注意父项目要指定为我们一开始创建的的项目，子项目命名随意：\n子项目创建好之后，接着我们在子项目中创建SpringBoot的启动主类：\n接着我们点击运行，即可启动子项目了，实际上这个子项目就一个最简单的SpringBoot web项目，注意启动之后最下方有弹窗，我们点击\u0026quot;使用 服务\u0026quot;，这样我们就可以实时查看当前整个大项目中有哪些微服务了：\n接着我们以同样的方法，创建其他的子项目，注意我们最好将其他子项目的端口设置得不一样，不然会导致端口占用，我们分别为它们创建application.yml文件：\n接着我们来尝试启动一下这三个服务，正常情况下都是可以直接启动的：\n可以看到它们分别运行在不同的端口上，这样，就方便不同的程序员编写不同的服务了，提交当前项目代码时的冲突率也会降低。\n接着我们来创建一下数据库，这里还是老样子，创建三个表即可，当然实际上每个微服务单独使用一个数据库服务器也是可以的，因为按照单一职责服务只会操作自己对应的表，这里UP主比较穷，就只用一个数据库演示了：\n创建好之后，结果如下，一共三张表，各位可以自行添加一些数据到里面，这就不贴出来了：\n如果各位嫌麻烦的话可以下载.sql文件自行导入。\n接着我们来稍微写一点业务，比如用户信息查询业务，我们先把数据库相关的依赖进行导入，这里依然使用Mybatis框架，首先在父项目中添加MySQL驱动和Lombok依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 由于不是所有的子项目都需要用到Mybatis，我们在父项目中只进行版本管理即可：\n\u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; 接着我们就可以在用户服务子项目中添加此依赖了：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 接着添加数据源信息（UP用到是阿里云的MySQL云数据库，各位注意修改一下数据库地址）：\nspring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://cloudstudy.mysql.cn-chengdu.rds.aliyuncs.com:3306/cloudstudy username: test password: 123456 接着我们来写用户查询相关的业务：\n@Data public class User { int uid; String name; String sex; } @Mapper public interface UserMapper { @Select(\u0026#34;select * from DB_USER where uid = #{uid}\u0026#34;) User getUserById(int uid); } public interface UserService { User getUserById(int uid); } @Service public class UserServiceImpl implements UserService { @Resource UserMapper mapper; @Override public User getUserById(int uid) { return mapper.getUserById(uid); } } @RestController public class UserController { @Resource UserService service; //这里以RESTFul风格为例 @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) public User findUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserById(uid); } } 现在我们访问即可拿到数据：\n同样的方式，我们完成一下图书查询业务，注意现在是在图书管理微服务中编写（别忘了导入Mybatis依赖以及配置数据源）：\n@Data public class Book { int bid; String title; String desc; } @Mapper public interface BookMapper { @Select(\u0026#34;select * from DB_BOOK where bid = #{bid}\u0026#34;) Book getBookById(int bid); } public interface BookService { Book getBookById(int bid); } @Service public class BookServiceImpl implements BookService { @Resource BookMapper mapper; @Override public Book getBookById(int bid) { return mapper.getBookById(bid); } } @RestController public class BookController { @Resource BookService service; @RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book findBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid){ return service.getBookById(bid); } } 同样进行一下测试：\n这样，我们一个完整项目的就拆分成了多个微服务，不同微服务之间是独立进行开发和部署的。\n服务间调用 #\r前面我们完成了用户信息查询和图书信息查询，现在我们来接着完成借阅服务。\n借阅服务是一个关联性比较强的服务，它不仅仅需要查询借阅信息，同时可能还需要获取借阅信息下的详细信息，比如具体那个用户借阅了哪本书，并且用户和书籍的详情也需要同时出现，那么这种情况下，我们就需要去访问除了借阅表以外的用户表和图书表。\n但是这显然是违反我们之前所说的单一职责的，相同的业务功能不应该重复出现，但是现在由需要在此服务中查询用户的信息和图书信息，那怎么办呢？我们可以让一个服务去调用另一个服务来获取信息。\n这样，图书管理微服务和用户管理微服务相对于借阅记录，就形成了一个生产者和消费者的关系，前者是生产者，后者便是消费者。\n现在我们先将借阅关联信息查询完善了：\n@Data public class Borrow { int id; int uid; int bid; } @Mapper public interface BorrowMapper { @Select(\u0026#34;select * from DB_BORROW where uid = #{uid}\u0026#34;) List\u0026lt;Borrow\u0026gt; getBorrowsByUid(int uid); @Select(\u0026#34;select * from DB_BORROW where bid = #{bid}\u0026#34;) List\u0026lt;Borrow\u0026gt; getBorrowsByBid(int bid); @Select(\u0026#34;select * from DB_BORROW where bid = #{bid} and uid = #{uid}\u0026#34;) Borrow getBorrow(int uid, int bid); } 现在有一个需求，需要查询用户的借阅详细信息，也就是说需要查询某个用户具体借了那些书，并且需要此用户的信息和所有已借阅的书籍信息一起返回，那么我们先来设计一下返回实体：\n@Data @AllArgsConstructor public class UserBorrowDetail { User user; List\u0026lt;Book\u0026gt; bookList; } 但是有一个问题，我们发现User和Book实体实际上是在另外两个微服务中定义的，相当于当前项目并没有定义这些实体类，那么怎么解决呢？\n因此，我们可以将所有服务需要用到的实体类单独放入另一个一个项目中，然后让这些项目引用集中存放实体类的那个项目，这样就可以保证每个微服务的实体类信息都可以共用了：\n然后只需要在对应的类中引用此项目作为依赖即可：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 之后新的公共实体类都可以在commons项目中进行定义了，现在我们接着来完成刚刚的需求，先定义接口：\npublic interface BorrowService { UserBorrowDetail getUserBorrowDetailByUid(int uid); } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); //那么问题来了，现在拿到借阅关联信息了，怎么调用其他服务获取信息呢？ } } 需要进行服务远程调用我们需要用到RestTemplate来进行：\n@Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); //RestTemplate支持多种方式的远程调用 RestTemplate template = new RestTemplate(); //这里通过调用getForObject来请求其他服务，并将结果自动进行封装 //获取User信息 User user = template.getForObject(\u0026#34;http://localhost:8082/user/\u0026#34;+uid, User.class); //获取每一本书的详细信息 List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; template.getForObject(\u0026#34;http://localhost:8080/book/\u0026#34;+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 现在我们再最后完善一下Controller：\n@RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\u0026#34;/borrow/{uid}\u0026#34;) UserBorrowDetail findUserBorrows(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserBorrowDetailByUid(uid); } } 在数据库中添加一点借阅信息，测试看看能不能正常获取（注意一定要保证三个服务都处于开启状态，否则远程调用会失败）：\n可以看到，结果正常，没有问题，远程调用成功。\n这样，一个简易的图书管理系统的分布式项目就搭建完成了，这里记得把整个项目压缩打包备份一下，下一章学习SpringCloud Alibaba也需要进行配置。\n服务注册与发现 #\r前面我们了解了如何对单体应用进行拆分，并且也学习了如何进行服务之间的相互调用，但是存在一个问题，就是虽然服务拆分完成，但是没有一个比较合理的管理机制，如果单纯只是这样编写，在部署和维护起来，肯定是很麻烦的。可以想象一下，如果某一天这些微服务的端口或是地址大规模地发生改变，我们就不得不将服务之间的调用路径大规模的同步进行修改，这是多么可怕的事情。我们需要削弱这种服务之间的强关联性，因此我们需要一个集中管理微服务的平台，这时就要借助我们这一部分的主角了。\nEureka能够自动注册并发现微服务，然后对服务的状态、信息进行集中管理，这样当我们需要获取其他服务的信息时，我们只需要向Eureka进行查询就可以了。\n像这样的话，服务之间的强关联性就会被进一步削弱。\n那么现在我们就来搭建一个Eureka服务器，只需要创建一个新的Maven项目即可，然后我们需要在父工程中添加一下SpringCloud的依赖，这里选用2021.0.1版本（Spring Cloud 最新的版本命名方式变更了，现在是 YEAR.x 这种命名方式，具体可以在官网查看：https://spring.io/projects/spring-cloud#learn）：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.1\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 接着我们为新创建的项目添加依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 下载内容有点多，首次导入请耐心等待一下。\n接着我们来创建主类，还是一样的操作：\n@EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 别着急启动！！！接着我们需要修改一下配置文件：\nserver: port: 8888 eureka: # 开启之前需要修改一下客户端设置（虽然是服务端 client: # 由于我们是作为服务端角色，所以不需要获取服务端，改为false，默认为true fetch-registry: false # 暂时不需要将自己也注册到Eureka register-with-eureka: false # 将eureka服务端指向自己 service-url: defaultZone: http://localhost:8888/eureka 好了，现在差不多可以启动了，启动完成后，直接输入地址+端口即可访问Eureka的管理后台：\n可以看到目前还没有任何的服务注册到Eureka，我们接着来配置一下我们的三个微服务，首先还是需要导入Eureka依赖（注意别导错了，名称里面有个starter的才是）：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后修改配置文件：\neureka: client: # 跟上面一样，需要指向Eureka服务端地址，这样才能进行注册 service-url: defaultZone: http://localhost:8888/eureka OK，无需在启动类添加注解，直接启动就可以了，然后打开Eureka的服务管理页面，可以看到我们刚刚开启的服务：\n可以看到8082端口上的服务器，已经成功注册到Eureka了，但是这个服务名称怎么会显示为UNKNOWN，我们需要修改一下：\nspring: application: name: userservice 当我们的服务启动之后，会每隔一段时间跟Eureka发送一次心跳包，这样Eureka就能够感知到我们的服务是否处于正常运行状态。\n现在我们用同样的方法，将另外两个微服务也注册进来：\n那么，现在我们怎么实现服务发现呢？\n也就是说，我们之前如果需要对其他微服务进行远程调用，那么就必须要知道其他服务的地址：\nUser user = template.getForObject(\u0026#34;http://localhost:8082/user/\u0026#34;+uid, User.class); 而现在有了Eureka之后，我们可以直接向其进行查询，得到对应的微服务地址，这里直接将服务名称替换即可：\n@Service public class BorrowServiceImpl implements BorrowService { @Resource BorrowMapper mapper; @Resource RestTemplate template; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); //这里不用再写IP，直接写服务名称userservice User user = template.getForObject(\u0026#34;http://userservice/user/\u0026#34;+uid, User.class); //这里不用再写IP，直接写服务名称bookservice List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; template.getForObject(\u0026#34;http://bookservice/book/\u0026#34;+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 接着我们手动将RestTemplate声明为一个Bean，然后添加@LoadBalanced注解，这样Eureka就会对服务的调用进行自动发现，并提供负载均衡：\n@Configuration public class BeanConfig { @Bean @LoadBalanced RestTemplate template(){ return new RestTemplate(); } } 现在我们就可以正常调用了：\n不对啊，不是说有负载均衡的能力吗，怎么个负载均衡呢？\n我们先来看看，同一个服务器实际上是可以注册很多个的，但是它们的端口不同，比如我们这里创建多个用户查询服务，我们现在将原有的端口配置修改一下，由IDEA中设定启动参数来决定，这样就可以多创建几个不同端口的启动项了：\n可以看到，在Eureka中，同一个服务出现了两个实例：\n现在我们稍微修改一下用户查询，然后进行远程调用，看看请求是不是均匀地分配到这两个服务端：\n@RestController public class UserController { @Resource UserService service; @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) public User findUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ System.out.println(\u0026#34;我被调用拉！\u0026#34;); return service.getUserById(uid); } } 可以看到，两个实例都能够均匀地被分配请求：\n这样，服务自动发现以及简单的负载均衡就实现完成了，并且，如果某个微服务挂掉了，只要存在其他同样的微服务实例在运行，那么就不会导致整个微服务不可用，极大地保证了安全性。\n注册中心高可用 #\r各位可否想过这样的一个问题？虽然Eureka能够实现服务注册和发现，但是如果Eureka服务器崩溃了，岂不是所有需要用到服务发现的微服务就GG了？\n为了避免，这种问题，我们也可以像上面那样，搭建Eureka集群，存在多个Eureka服务器，这样就算挂掉其中一个，其他的也还在正常运行，就不会使得服务注册与发现不可用。当然，要是物理黑客直接炸了整个机房，那还是算了吧。\n我们来看看如何搭建Eureka集群，这里由于机器配置不高，就搭建两个Eureka服务器组成集群。\n首先我们需要修改一下Eureka服务端的配置文件，这里我们创建两个配置文件，：\nserver: port: 8801 spring: application: name: eurekaserver eureka: instance: # 由于不支持多个localhost的Eureka服务器，但是又只有本地测试环境，所以就只能自定义主机名称了 # 主机名称改为eureka01 hostname: eureka01 client: fetch-registry: false # 去掉register-with-eureka选项，让Eureka服务器自己注册到其他Eureka服务器，这样才能相互启用 service-url: # 注意这里填写其他Eureka服务器的地址，不用写自己的 defaultZone: http://eureka01:8801/eureka server: port: 8802 spring: application: name: eurekaserver eureka: instance: hostname: eureka02 client: fetch-registry: false service-url: defaultZone: http://eureka01:8801/eureka 这里由于我们修改成自定义的地址，需要在hosts文件中将其解析到172.0.0.1才能回到localhost，Mac下文件路径为/etc/hosts，Windows下为C:\\Windows\\system32\\drivers\\etc\\hosts：\n对创建的两个配置文件分别添加启动配置，直接使用spring.profiles.active指定启用的配置文件即可：\n!\r](/Users/nagocoler/Library/Application Support/typora-user-images/image-20230306225853705.png)\n接着启动这两个注册中心，这两个Eureka管理页面都可以被访问，我们访问其中一个：\n可以看到下方replicas中已经包含了另一个Eureka服务器的地址，并且是可用状态。\n接着我们需要将我们的微服务配置也进行修改：\neureka: client: service-url: # 将两个Eureka的地址都加入，这样就算有一个Eureka挂掉，也能完成注册 defaultZone: http://localhost:8801/eureka, http://localhost:8802/eureka 可以看到，服务全部成功注册，并且两个Eureka服务端都显示为已注册：\n接着我们模拟一下，将其中一个Eureka服务器关闭掉，可以看到它会直接变成不可用状态：\n当然，如果这个时候我们重启刚刚关闭的Eureka服务器，会自动同步其他Eureka服务器的数据。\nLoadBalancer 负载均衡 #\r前面我们讲解了如何对服务进行拆分、如何通过Eureka服务器进行服务注册与发现，那么现在我们来看看，它的负载均衡到底是如何实现的，实际上之前演示的负载均衡是依靠LoadBalancer实现的。\n在2020年前的SpringCloud版本是采用Ribbon作为负载均衡实现，但是2020年的版本之后SpringCloud把Ribbon移除了，进而用自己编写的LoadBalancer替代。\n那么，负载均衡是如何进行的呢？\n负载均衡 #\r实际上，在添加@LoadBalanced注解之后，会启用拦截器对我们发起的服务调用请求进行拦截（注意这里是针对我们发起的请求进行拦截），叫做LoadBalancerInterceptor，它实现ClientHttpRequestInterceptor接口：\n@FunctionalInterface public interface ClientHttpRequestInterceptor { ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException; } 主要是对intercept方法的实现：\npublic ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException { URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, \u0026#34;Request URI does not contain a valid hostname: \u0026#34; + originalUri); return (ClientHttpResponse)this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution)); } 我们可以打个断点看看实际是怎么在执行的，可以看到：\n服务端会在发起请求时执行这些拦截器。\n那么这个拦截器做了什么事情呢，首先我们要明确，我们给过来的请求地址，并不是一个有效的主机名称，而是服务名称，那么怎么才能得到真正需要访问的主机名称呢，肯定是得找Eureka获取的。\n我们来看看loadBalancer.execute()做了什么，它的具体实现为BlockingLoadBalancerClient：\n//从上面给进来了服务的名称和具体的请求实体 public \u0026lt;T\u0026gt; T execute(String serviceId, LoadBalancerRequest\u0026lt;T\u0026gt; request) throws IOException { String hint = this.getHint(serviceId); LoadBalancerRequestAdapter\u0026lt;T, DefaultRequestContext\u0026gt; lbRequest = new LoadBalancerRequestAdapter(request, new DefaultRequestContext(request, hint)); Set\u0026lt;LoadBalancerLifecycle\u0026gt; supportedLifecycleProcessors = this.getSupportedLifecycleProcessors(serviceId); supportedLifecycleProcessors.forEach((lifecycle) -\u0026gt; { lifecycle.onStart(lbRequest); }); //可以看到在这里会调用choose方法自动获取对应的服务实例信息 ServiceInstance serviceInstance = this.choose(serviceId, lbRequest); if (serviceInstance == null) { supportedLifecycleProcessors.forEach((lifecycle) -\u0026gt; { lifecycle.onComplete(new CompletionContext(Status.DISCARD, lbRequest, new EmptyResponse())); }); //没有发现任何此服务的实例就抛异常（之前的测试中可能已经遇到了） throw new IllegalStateException(\u0026#34;No instances available for \u0026#34; + serviceId); } else { //成功获取到对应服务的实例，这时就可以发起HTTP请求获取信息了 return this.execute(serviceId, serviceInstance, lbRequest); } } 所以，实际上在进行负载均衡的时候，会向Eureka发起请求，选择一个可用的对应服务，然后会返回此服务的主机地址等信息：\n自定义负载均衡策略 #\rLoadBalancer默认提供了两种负载均衡策略：\nRandomLoadBalancer - 随机分配策略 (默认) RoundRobinLoadBalancer - 轮询分配策略 现在我们希望修改默认的负载均衡策略，可以进行指定，比如我们现在希望用户服务采用随机分配策略，我们需要先创建随机分配策略的配置类（不用加@Configuration）：\npublic class LoadBalancerConfig { //将官方提供的 RandomLoadBalancer 注册为Bean @Bean public ReactorLoadBalancer\u0026lt;ServiceInstance\u0026gt; randomLoadBalancer(Environment environment, LoadBalancerClientFactory loadBalancerClientFactory){ String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME); return new RandomLoadBalancer(loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class), name); } } 接着我们需要为对应的服务指定负载均衡策略，直接使用注解即可：\n@Configuration @LoadBalancerClient(value = \u0026#34;userservice\u0026#34;, //指定为 userservice 服务，只要是调用此服务都会使用我们指定的策略 configuration = LoadBalancerConfig.class) //指定我们刚刚定义好的配置类 public class BeanConfig { @Bean @LoadBalanced RestTemplate template(){ return new RestTemplate(); } } 接着我们在BlockingLoadBalancerClient中添加断点，观察是否采用我们指定的策略进行请求：\n发现访问userservice服务的策略已经更改为我们指定的策略了。\nOpenFeign实现负载均衡 #\r官方文档：https://docs.spring.io/spring-cloud-openfeign/docs/current/reference/html/\nFeign和RestTemplate一样，也是HTTP客户端请求工具，但是它的使用方式更加便捷。首先是依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着在启动类添加@EnableFeignClients注解：\n@SpringBootApplication @EnableFeignClients public class BorrowApplication { public static void main(String[] args) { SpringApplication.run(BorrowApplication.class, args); } } 那么现在我们需要调用其他微服务提供的接口，该怎么做呢？我们直接创建一个对应服务的接口类即可：\n@FeignClient(\u0026#34;userservice\u0026#34;) //声明为userservice服务的HTTP请求客户端 public interface UserClient { } 接着我们直接创建所需类型的方法，比如我们之前的：\nRestTemplate template = new RestTemplate(); User user = template.getForObject(\u0026#34;http://userservice/user/\u0026#34;+uid, User.class); 现在可以直接写成这样：\n@FeignClient(\u0026#34;userservice\u0026#34;) public interface UserClient { //路径保证和其他微服务提供的一致即可 @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) User getUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid); //参数和返回值也保持一致 } 接着我们直接注入使用（有Mybatis那味了）：\n@Resource UserClient userClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); //这里不用再写IP，直接写服务名称bookservice List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; template.getForObject(\u0026#34;http://bookservice/book/\u0026#34;+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } 访问，可以看到结果依然是正确的：\n并且我们可以观察一下两个用户微服务的调用情况，也是以负载均衡的形式进行的。\n按照同样的方法，我们接着将图书管理服务的调用也改成接口形式：\n最后我们的Service代码就变成了：\n@Service public class BorrowServiceImpl implements BorrowService { @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 继续访问进行测试：\nOK，正常。\n当然，Feign也有很多的其他配置选项，这里就不多做介绍了，详细请查阅官方文档。\nHystrix 服务熔断 #\r官方文档：https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/1.3.5.RELEASE/single/spring-cloud-netflix.html#_circuit_breaker_hystrix_clients\n我们知道，微服务之间是可以进行相互调用的，那么如果出现了下面的情况会导致什么问题？\n由于位于最底端的服务提供者E发生故障，那么此时会直接导致服务ABCD全线崩溃，就像雪崩了一样。\n这种问题实际上是不可避免的，由于多种因素，比如网络卡顿、系统故障、硬件问题等，都存在一定可能，会导致这种极端的情况发生。因此，我们需要寻找一个应对这种极端情况的解决方案。\n为了解决分布式系统的雪崩问题，SpringCloud提供了Hystrix熔断器组件，他就像我们家中的保险丝一样，当电流过载就会直接熔断，防止危险进一步发生，从而保证家庭用电安全。可以想象一下，如果整条链路上的服务已经全线崩溃，这时还在不断地有大量的请求到达，需要各个服务进行处理，肯定是会使得情况越来越糟糕的。\n我们来详细看看它的工作机制。\n服务降级 #\r首先我们来看看服务降级，注意一定要区分开服务降级和服务熔断的区别，服务降级并不会直接返回错误，而是可以提供一个补救措施，正常响应给请求者。这样相当于服务依然可用，但是服务能力肯定是下降了的。\n我们就基于借阅管理服务来进行讲解，我们不开启用户服务和图书服务，表示用户服务和图书服务已经挂掉了。\n这里我们导入Hystrix的依赖（此项目已经停止维护，SpringCloud依赖中已经不自带了，所以说需要自己单独导入）：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-hystrix\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.10.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接着我们需要在启动类添加注解开启：\n@SpringBootApplication @EnableHystrix //启用Hystrix public class BorrowApplication { public static void main(String[] args) { SpringApplication.run(BorrowApplication.class, args); } } 那么现在，由于用户服务和图书服务不可用，所以查询借阅信息的请求肯定是没办法正常响应的，这时我们可以提供一个备选方案，也就是说当服务出现异常时，返回我们的备选方案：\n@RestController public class BorrowController { @Resource BorrowService service; @HystrixCommand(fallbackMethod = \u0026#34;onError\u0026#34;) //使用@HystrixCommand来指定备选方案 @RequestMapping(\u0026#34;/borrow/{uid}\u0026#34;) UserBorrowDetail findUserBorrows(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserBorrowDetailByUid(uid); } //备选方案，这里直接返回空列表了 //注意参数和返回值要和上面的一致 UserBorrowDetail onError(int uid){ return new UserBorrowDetail(null, Collections.emptyList()); } } 可以看到，虽然我们的服务无法正常运行了，但是依然可以给浏览器正常返回响应数据：\n服务降级是一种比较温柔的解决方案，虽然服务本身的不可用，但是能够保证正常响应数据。\n服务熔断 #\r熔断机制是应对雪崩效应的一种微服务链路保护机制，当检测出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回”错误”的响应信息。当检测到该节点微服务响应正常后恢复调用链路。\n实际上，熔断就是在降级的基础上进一步升级形成的，也就是说，在一段时间内多次调用失败，那么就直接升级为熔断。\n我们可以添加两条输出语句：\n@RestController public class BorrowController { @Resource BorrowService service; @HystrixCommand(fallbackMethod = \u0026#34;onError\u0026#34;) @RequestMapping(\u0026#34;/borrow/{uid}\u0026#34;) UserBorrowDetail findUserBorrows(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ System.out.println(\u0026#34;开始向其他服务获取信息\u0026#34;); return service.getUserBorrowDetailByUid(uid); } UserBorrowDetail onError(int uid){ System.out.println(\u0026#34;服务错误，进入备选方法！\u0026#34;); return new UserBorrowDetail(null, Collections.emptyList()); } } 接着，我们在浏览器中疯狂点击刷新按钮，对此服务疯狂发起请求，可以看到后台：\n一开始的时候，会正常地去调用Controller对应的方法findUserBorrows，发现失败然后进入备选方法，但是我们发现在持续请求一段时间之后，没有再调用这个方法，而是直接调用备选方案，这便是升级到了熔断状态。\n我们可以继续不断点击，继续不断地发起请求：\n可以看到，过了一段时间之后，会尝试正常执行一次findUserBorrows，但是依然是失败状态，所以继续保持熔断状态。\n所以得到结论，它能够对一段时间内出现的错误进行侦测，当侦测到出错次数过多时，熔断器会打开，所有的请求会直接响应失败，一段时间后，只执行一定数量的请求，如果还是出现错误，那么则继续保持打开状态，否则说明服务恢复正常运行，关闭熔断器。\n我们可以测试一下，开启另外两个服务之后，继续点击：\n可以看到，当另外两个服务正常运行之后，当再次尝试调用findUserBorrows之后会成功，于是熔断机制就关闭了，服务恢复运行。\n总结一下：\nOpenFeign实现降级 #\rHystrix也可以配合Feign进行降级，我们可以对应接口中定义的远程调用单独进行降级操作。\n比如我们还是以用户服务挂掉为例，那么这个时候肯定是会远程调用失败的，也就是说我们的Controller中的方法在执行过程中会直接抛出异常，进而被Hystrix监控到并进行服务降级。\n而实际上导致方法执行异常的根源就是远程调用失败，所以我们换个思路，既然用户服务调用失败，那么我就给这个远程调用添加一个替代方案，如果此远程调用失败，那么就直接上替代方案。那么怎么实现替代方案呢？我们知道Feign都是以接口的形式来声明远程调用，那么既然远程调用已经失效，我们就自行对其进行实现，创建一个实现类，对原有的接口方法进行替代方案实现：\n@Component //注意，需要将其注册为Bean，Feign才能自动注入 public class UserFallbackClient implements UserClient{ @Override public User getUserById(int uid) { //这里我们自行对其进行实现，并返回我们的替代方案 User user = new User(); user.setName(\u0026#34;我是替代方案\u0026#34;); return user; } } 实现完成后，我们只需要在原有的接口中指定失败替代实现即可：\n//fallback参数指定为我们刚刚编写的实现类 @FeignClient(value = \u0026#34;userservice\u0026#34;, fallback = UserFallbackClient.class) public interface UserClient { @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) User getUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid); } 现在去掉BorrowController的@HystrixCommand注解和备选方法：\n@RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\u0026#34;/borrow/{uid}\u0026#34;) UserBorrowDetail findUserBorrows(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserBorrowDetailByUid(uid); } } 最后我们在配置文件中开启熔断支持：\nfeign: circuitbreaker: enabled: true 启动服务，调用接口试试看：\n可以看到，现在已经采用我们的替代方案作为结果。\n监控页面部署 #\r除了对服务的降级和熔断处理，我们也可以对其进行实时监控，只需要安装监控页面即可，这里我们创建一个新的项目，导入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-hystrix-dashboard\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.10.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接着添加配置文件：\nserver: port: 8900 hystrix: dashboard: # 将localhost添加到白名单，默认是不允许的 proxy-stream-allow-list: \u0026#34;localhost\u0026#34; 接着创建主类，注意需要添加@EnableHystrixDashboard注解开启管理页面：\n@SpringBootApplication @EnableHystrixDashboard public class HystrixDashBoardApplication { public static void main(String[] args) { SpringApplication.run(HystrixDashBoardApplication.class, args); } } 启动Hystrix管理页面服务，然后我们需要在要进行监控的服务中添加Actuator依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Actuator是SpringBoot程序的监控系统，可以实现健康检查，记录信息等。在使用之前需要引入spring-boot-starter-actuator，并做简单的配置即可。\n添加此依赖后，我们可以在IDEA中查看运行情况：\n然后在配置文件中配置Actuator添加暴露：\nmanagement: endpoints: web: exposure: include: \u0026#39;*\u0026#39; 接着我们打开刚刚启动的管理页面，地址为：http://localhost:8900/hystrix/\n在中间填写要监控的服务：比如借阅服务：http://localhost:8301/actuator/hystrix.stream，注意后面要添加/actuator/hystrix.stream，然后点击Monitor Stream即可进入监控页面：\n可以看到现在都是Loading状态，这是因为还没有开始统计，我们现在尝试调用几次我们的服务：\n可以看到，在调用之后，监控页面出现了信息：\n可以看到5次访问都是正常的，所以显示为绿色，接着我们来尝试将图书服务关闭，这样就会导致服务降级甚至熔断，然后再多次访问此服务看看监控会如何变化：\n可以看到，错误率直接飙升到100%，并且一段时间内持续出现错误，中心的圆圈也变成了红色，我们继续进行访问：\n在出现大量错误的情况下保持持续访问，可以看到此时已经将服务熔断，Circuit更改为Open状态，并且图中的圆圈也变得更大，表示压力在持续上升。\nGateway 路由网关 #\r官网地址：https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/\n说到路由，想必各位一定最先想到的就是家里的路由器了，那么我们家里的路由器充当的是一个什么角色呢？\n我们知道，如果我们需要连接互联网，那么就需要将手机或是电脑连接到家里的路由器才可以，而路由器则连接光猫，光猫再通过光纤连接到互联网，也就是说，互联网方向发送过来的数据，需要经过路由器才能到达我们的设备。而路由器充当的就是数据包中转站，所有的局域网设备都无法直接与互联网连接，而是需要经过路由器进行中转，我们一般说路由器下的网络是内网，而互联网那一端是外网。\n我们的局域网设备，无法被互联网上的其他设备直接访问，肯定是能够保证到安全性的。并互联网发送过来的数据，需要经过路由器进行解析，识别到底是哪一个设备的数据包，然后再发送给对应的设备。\n而我们的微服务也是这样，一般情况下，可能并不是所有的微服务都需要直接暴露给外部调用，这时我们就可以使用路由机制，添加一层防护，让所有的请求全部通过路由来转发到各个微服务，并且转发给多个相同微服务实例也可以实现负载均衡。\n在之前，路由的实现一般使用Zuul，但是已经停更，而现在新出现了由SpringCloud官方开发的Gateway路由，它相比Zuul不仅性能上得到了一定的提升，并且是官方推出，契合性也会更好，所以我们这里就主要讲解Gateway。\n部署网关 #\r现在我们来创建一个新的项目，作为我们的网关，这里需要添加两个依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-gateway\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 第一个依赖就是网关的依赖，而第二个则跟其他微服务一样，需要注册到Eureka才能生效，注意别添加Web依赖，使用的是WebFlux框架。\n然后我们来完善一下配置文件：\nserver: port: 8500 eureka: client: service-url: defaultZone: http://localhost:8801/eureka, http://localhost:8802/eureka spring: application: name: gateway 现在就可以启动了：\n但是现在还没有配置任何的路由功能，我们接着将路由功能进行配置：\nspring: cloud: gateway: # 配置路由，注意这里是个列表，每一项都包含了很多信息 routes: - id: borrow-service # 路由名称 uri: lb://borrowservice # 路由的地址，lb表示使用负载均衡到微服务，也可以使用http正常转发 predicates: # 路由规则，断言什么请求会被路由 - Path=/borrow/** # 只要是访问的这个路径，一律都被路由到上面指定的服务 路由规则的详细列表（断言工厂列表）在这里：https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gateway-request-predicates-factories，可以指定多种类型，包括指定时间段、Cookie携带情况、Header携带情况、访问的域名地址、访问的方法、路径、参数、访问者IP等。也可以使用配置类进行配置，但是还是推荐直接配置文件，省事。\n接着启动网关，搭载Arm架构芯片的Mac电脑可能会遇到这个问题：\n这是因为没有找到适用于此架构的动态链接库，不影响使用，无视即可，希望以后的版本能修复吧。\n可以看到，我们现在可以直接通过路由来访问我们的服务了：\n注意此时依然可以通过原有的服务地址进行访问：\n这样我们就可以将不需要外网直接访问的微服务全部放到内网环境下，而只依靠网关来对外进行交涉。\n路由过滤器 #\r路由过滤器支持以某种方式修改传入的 HTTP 请求或传出的 HTTP 响应，路由过滤器的范围是某一个路由，跟之前的断言一样，Spring Cloud Gateway 也包含许多内置的路由过滤器工厂，详细列表：https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gatewayfilter-factories\n比如我们现在希望在请求到达时，在请求头中添加一些信息再转发给我们的服务，那么这个时候就可以使用路由过滤器来完成，我们只需要对配置文件进行修改：\nspring: application: name: gateway cloud: gateway: routes: - id: borrow-service uri: lb://borrowservice predicates: - Path=/borrow/** # 继续添加新的路由配置，这里就以书籍管理服务为例 # 注意-要对齐routes: - id: book-service uri: lb://bookservice predicates: - Path=/book/** filters: # 添加过滤器 - AddRequestHeader=Test, HelloWorld! # AddRequestHeader 就是添加请求头信息，其他工厂请查阅官网 接着我们在BookController中获取并输出一下，看看是不是成功添加了：\n@RestController public class BookController { @Resource BookService service; @RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book findBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid, HttpServletRequest request){ System.out.println(request.getHeader(\u0026#34;Test\u0026#34;)); return service.getBookById(bid); } } 现在我们通过Gateway访问我们的图书管理服务：\n可以看到这里成功获取到由网关添加的请求头信息了。\n除了针对于某一个路由配置过滤器之外，我们也可以自定义全局过滤器，它能够作用于全局。但是我们需要通过代码的方式进行编写，比如我们要实现拦截没有携带指定请求参数的请求：\n@Component //需要注册为Bean public class TestFilter implements GlobalFilter { @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { //只需要实现此方法 return null; } } 接着我们编写判断：\n@Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { //先获取ServerHttpRequest对象，注意不是HttpServletRequest ServerHttpRequest request = exchange.getRequest(); //打印一下所有的请求参数 System.out.println(request.getQueryParams()); //判断是否包含test参数，且参数值为1 List\u0026lt;String\u0026gt; value = request.getQueryParams().get(\u0026#34;test\u0026#34;); if(value != null \u0026amp;\u0026amp; value.contains(\u0026#34;1\u0026#34;)) { //将ServerWebExchange向过滤链的下一级传递（跟JavaWeb中介绍的过滤器其实是差不多的） return chain.filter(exchange); }else { //直接在这里不再向下传递，然后返回响应 return exchange.getResponse().setComplete(); } } 可以看到结果：\n成功实现规则判断和拦截操作。\n当然，过滤器肯定是可以存在很多个的，所以我们可以手动指定过滤器之间的顺序：\n@Component public class TestFilter implements GlobalFilter, Ordered { //实现Ordered接口 @Override public int getOrder() { return 0; } 注意Order的值越小优先级越高，并且无论是在配置文件中编写的单个路由过滤器还是全局路由过滤器，都会受到Order值影响（单个路由的过滤器Order值按从上往下的顺序从1开始递增），最终是按照Order值决定哪个过滤器优先执行，当Order值一样时 全局路由过滤器执行 优于 单独的路由过滤器执行。\nConfig 配置中心 #\r官方文档： https://docs.spring.io/spring-cloud-config/docs/current/reference/html/\n经过前面的学习，我们对于一个分布式应用的技术选型和搭建已经了解得比较多了，但是各位有没有发现一个问题，如果我们的微服务项目需要部署很多个实例，那么配置文件我们岂不是得一个一个去改，可能十几个实例还好，要是有几十个上百个呢？那我们一个一个去配置，岂不直接猝死在工位上。\n所以，我们需要一种更加高级的集中化地配置文件管理工具，集中地对配置文件进行配置。\nSpring Cloud Config 为分布式系统中的外部配置提供服务器端和客户端支持。使用 Config Server，您可以集中管理所有环境中应用程序的外部配置。\n实际上Spring Cloud Config就是一个配置中心，所有的服务都可以从配置中心取出配置，而配置中心又可以从GitHub远程仓库中获取云端的配置文件，这样我们只需要修改GitHub中的配置即可对所有的服务进行配置管理了。\n部署配置中心 #\r这里我们接着创建一个新的项目，并导入依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-config-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-eureka-client\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 老规矩，启动类：\n@SpringBootApplication @EnableConfigServer public class ConfigApplication { public static void main(String[] args) { SpringApplication.run(ConfigApplication.class, args); } } 接着就是配置文件：\nserver: port: 8700 spring: application: name: configserver eureka: client: service-url: defaultZone: http://localhost:8801/eureka, http://localhost:8802/eureka 先启动一次看看，能不能成功：\n这里我们以本地仓库为例（就不用GitHub了，卡到怀疑人生了），首先在项目目录下创建一个本地Git仓库，打开终端，在桌面上创建一个新的本地仓库：\n然后我们在文件夹中随便创建一些配置文件，注意名称最好是{服务名称}-{环境}.yml：\n然后我们在配置文件中，添加本地仓库的一些信息（远程仓库同理），详细使用教程：https://docs.spring.io/spring-cloud-config/docs/current/reference/html/#_git_backend\nspring: cloud: config: server: git: # 这里填写的是本地仓库地址，远程仓库直接填写远程仓库地址 http://git... uri: file://${user.home}/Desktop/config-repo # 默认分支设定为你自己本地或是远程分支的名称 default-label: main 然后启动我们的配置服务器，通过以下格式进行访问：\nhttp://localhost:8700/{服务名称}/{环境}/{Git分支} http://localhost:8700/{Git分支}/{服务名称}-{环境}.yml 比如我们要访问图书服务的生产环境代码，可以使用 http://localhost:8700/bookservice/prod/main 链接，它会显示详细信息：\n也可以使用 http://localhost:8700/main/bookservice-prod.yml 链接，它仅显示配置文件原文：\n当然，除了使用Git来保存之外，还支持一些其他的方式，详细情况请查阅官网。\n客户端配置 #\r服务端配置完成之后，我们接着来配置一下客户端，那么现在我们的服务既然需要从服务器读取配置文件，那么就需要进行一些配置，我们删除原来的application.yml文件（也可以保留，最后无论是远端配置还是本地配置都会被加载），改用bootstrap.yml（在application.yml之前加载，可以实现配置文件远程获取）：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; spring: cloud: config: # 名称，其实就是文件名称 name: bookservice # 配置服务器的地址 uri: http://localhost:8700 # 环境 profile: prod # 分支 label: main 配置完成之后，启动图书服务：\n可以看到已经从远端获取到了配置，并进行启动。\n微服务CAP原则 #\r经过前面的学习，我们对SpringCloud Netflix以及SpringCloud官方整个生态下的组件认识也差不多了，入门教学就到此为止，下一章将开启真正精彩的正片部分，本章的最后我们还是来了解一些理论上的知识。\nCAP原则又称CAP定理，指的是在一个分布式系统中，存在Consistency（一致性）、Availability（可用性）、Partition tolerance（分区容错性），三者不可同时保证，最多只能保证其中的两者。\n一致性（C）：在分布式系统中的所有数据备份，在同一时刻都是同样的值（所有的节点无论何时访问都能拿到最新的值）\n可用性（A）：系统中非故障节点收到的每个请求都必须得到响应（比如我们之前使用的服务降级和熔断，其实就是一种维持可用性的措施，虽然服务返回的是没有什么意义的数据，但是不至于用户的请求会被服务器忽略）\n分区容错性（P）：一个分布式系统里面，节点之间组成的网络本来应该是连通的，然而可能因为一些故障（比如网络丢包等，这是很难避免的），使得有些节点之间不连通了，整个网络就分成了几块区域，数据就散布在了这些不连通的区域中（这样就可能出现某些被分区节点存放的数据访问失败，我们需要来容忍这些不可靠的情况）\n总的来说，数据存放的节点数越多，分区容忍性就越高，但是要复制更新的次数就越多，一致性就越难保证。同时为了保证一致性，更新所有节点数据所需要的时间就越长，那么可用性就会降低。\n所以说，只能存在以下三种方案：\nAC 可用性+一致性 #\r要同时保证可用性和一致性，代表着某个节点数据更新之后，需要立即将结果通知给其他节点，并且要尽可能的快，这样才能及时响应保证可用性，这就对网络的稳定性要求非常高，但是实际情况下，网络很容易出现丢包等情况，并不是一个可靠的传输，如果需要避免这种问题，就只能将节点全部放在一起，但是这显然违背了分布式系统的概念，所以对于我们的分布式系统来说，很难接受。\nCP 一致性+分区容错性 #\r为了保证一致性，那么就得将某个节点的最新数据发送给其他节点，并且需要等到所有节点都得到数据才能进行响应，同时有了分区容错性，那么代表我们可以容忍网络的不可靠问题，所以就算网络出现卡顿，那么也必须等待所有节点完成数据同步，才能进行响应，因此就会导致服务在一段时间内完全失效，所以可用性是无法得到保证的。\nAP 可用性+分区容错性 #\r既然CP可能会导致一段时间内服务得不到任何响应，那么要保证可用性，就只能放弃节点之间数据的高度统一，也就是说可以在数据不统一的情况下，进行响应，因此就无法保证一致性了。虽然这样会导致拿不到最新的数据，但是只要数据同步操作在后台继续运行，一定能够在某一时刻完成所有节点数据的同步，那么就能实现最终一致性，所以AP实际上是最能接受的一种方案。\n比如我们实现的Eureka集群，它使用的就是AP方案，Eureka各个节点都是平等的，少数节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka客户端在向某个Eureka服务端注册时如果发现连接失败，则会自动切换至其他节点。只要有一台Eureka服务器正常运行，那么就能保证服务可用**（A），只不过查询到的信息可能不是最新的（C）**\n在之后的章节，我们还会继续了解这些理论的其他实际应用。\n———————————————— 版权声明：本文为柏码知识库版权所有，禁止一切未经授权的转载、发布、出售等行为，违者将被追究法律责任。 原文链接：https://www.itbaima.cn/document/35v1hbsfcdgagdnw\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/cloud/%E4%B8%80/","section":"Docs","summary":"微服务基础 #\r注意： 此阶段学习推荐的电脑配置，至少配备4核心CPU（主频3.0Ghz以上）+16GB内存，否则卡到你怀疑人生。\n前面我们讲解了SpringBoot框架，通过使用SpringBoot框架，我们的项目开发速度可以说是得到了质的提升。同时，我们对于项目的维护和理解，也会更加的轻松。可见，SpringBoot为我们的开发带来了巨大便捷。而这一部分，我们将基于SpringBoot，继续深入到企业实际场景，探讨微服务架构下的SpringCloud。这个部分我们会更加注重于架构设计上的讲解，弱化实现原理方面的研究。\n传统项目转型 #\r要说近几年最火热的话题，那还得是微服务，那么什么是微服务呢？\n我们可以先从技术的演变开始看起，在我们学习JavaWeb之后，一般的网站开发模式为Servlet+JSP，但是实际上我们在学习了SSM之后，会发现这种模式已经远远落后了，第一，一个公司不可能去招那么多同时会前端+后端的开发人员，就算招到，也并不一定能保证两个方面都比较擅长，相比前后端分开学习的开发人员，显然后者的学习成本更低，专注度更高。因此前后端分离成为了一种新的趋势。通过使用SpringBoot，我们几乎可以很快速地开发一个高性能的单体应用，只需要启动一个服务端，我们整个项目就开始运行了，各项功能融于一体，开发起来也更加轻松。\n但是随着我们项目的不断扩大，单体应用似乎显得有点乏力了。\n随着越来越多的功能不断地加入到一个SpringBoot项目中，随着接口不断增加，整个系统就要在同一时间内响应更多类型的请求，显然，这种扩展方式是不可能无限使用下去的，总有一天，这个SpringBoot项目会庞大到运行缓慢。并且所有的功能如果都集成在单端上，那么所有的请求都会全部汇集到一台服务器上，对此服务器造成巨大压力。\n可以试想一下，如果我们的电脑已经升级到i9-12900K，但是依然在运行项目的时候缓慢，无法同一时间响应成千上万的请求，那么这个问题就已经不是单纯升级机器配置可以解决的了。\n传统单体架构应用随着项目规模的扩大，实际上会暴露越来越多的问题，尤其是一台服务器无法承受庞大的单体应用部署，并且单体应用的维护也会越来越困难，我们得寻找一种新的开发架构来解决这些问题了。\nIn short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API.","title":"SpringCloud 1","type":"doc"},{"content":"\r微服务进阶 #\r前面我们了解了微服务的一套解决方案，但是它是基于Netflix的解决方案，实际上我们发现，很多框架都已经停止维护了，来看看目前我们所认识到的SpringCloud各大组件的维护情况：\n注册中心： Eureka（属于Netflix，2.x版本不再开源，1.x版本仍在更新） 服务调用： Ribbon（属于Netflix，停止更新，已经彻底被移除）、SpringCloud Loadbalancer（属于SpringCloud官方，目前的默认方案） 服务降级： Hystrix（属于Netflix，停止更新，已经彻底被移除） 路由网关： Zuul（属于Netflix，停止更新，已经彻底被移除）、Gateway（属于SpringCloud官方，推荐方案） 配置中心： Config（属于SpringCloud官方） 可见，我们之前使用的整套解决方案中，超过半数的组件都已经处于不可用状态，并且部分组件都是SpringCloud官方出手提供框架进行解决，因此，寻找一套更好的解决方案势在必行，也就引出了我们本章的主角：SpringCloud Alibaba\n阿里巴巴作为业界的互联网大厂，给出了一套全新的解决方案，官方网站（中文）：https://spring-cloud-alibaba-group.github.io/github-pages/2021/zh-cn/index.html\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。\n目前 Spring Cloud Alibaba 提供了如下功能:\n服务限流降级：支持 WebServlet、WebFlux, OpenFeign、RestTemplate、Dubbo 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。 服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。 分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。 Rpc服务：扩展 Spring Cloud 客户端 RestTemplate 和 OpenFeign，支持调用 Dubbo RPC 服务 消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。 分布式事务：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。 阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。 阿里云短信服务：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。 可以看到，SpringCloudAlibaba实际上是对我们的SpringCloud组件增强功能，是SpringCloud的增强框架，可以兼容SpringCloud原生组件和SpringCloudAlibaba的组件。\n开始学习之前，把我们之前打包好的拆分项目解压，我们将基于它进行讲解。\nNacos 更加全能的注册中心 #\rNacos（Naming Configuration Service）是一款阿里巴巴开源的服务注册与发现、配置管理的组件，相当于是Eureka+Config的组合形态。\n安装与部署 #\rNacos服务器是独立安装部署的，因此我们需要下载最新的Nacos服务端程序，下载地址：https://github.com/alibaba/nacos，连不上可以到视频下方云盘中下载。\n可以看到目前最新的版本是1.4.3版本（2022年2月27日发布的），我们直接下载zip文件即可。\n接着我们将文件进行解压，得到以下内容：\n我们直接将其拖入到项目文件夹下，便于我们一会在IDEA内部启动，接着添加运行配置：\n其中-m standalone表示单节点模式，Mac和Linux下记得将解释器设定为/bin/bash，由于Nacos在Mac/Linux默认是后台启动模式，我们修改一下它的bash文件，让它变成前台启动，这样IDEA关闭了Nacos就自动关闭了，否则开发环境下很容易忘记关：\n# 注释掉 nohup $JAVA ${JAVA_OPT} nacos.nacos \u0026gt;\u0026gt; ${BASE_DIR}/logs/start.out 2\u0026gt;\u0026amp;1 \u0026amp; # 替换成下面的 $JAVA ${JAVA_OPT} nacos.nacos 接着我们点击启动：\nOK，启动成功，可以看到它的管理页面地址也是给我们贴出来了： http://localhost:8848/nacos/index.html，访问这个地址：\n默认的用户名和管理员密码都是nacos，直接登陆即可，可以看到进入管理页面之后功能也是相当丰富：\n至此，Nacos的安装与部署完成。\n服务注册与发现 #\r现在我们要实现基于Nacos的服务注册与发现，那么就需要导入SpringCloudAlibaba相关的依赖，我们在父工程将依赖进行管理：\n\u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 这里引入最新的SpringCloud依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.1\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 这里引入最新的SpringCloudAlibaba依赖，2021.0.1.0版本支持SpringBoot2.6.X --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.1.0\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt; 接着我们就可以在子项目中添加服务发现依赖了，比如我们以图书服务为例：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 和注册到Eureka一样，我们也需要在配置文件中配置Nacos注册中心的地址：\nserver: # 之后所有的图书服务节点就81XX端口 port: 8101 spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://cloudstudy.mysql.cn-chengdu.rds.aliyuncs.com:3306/cloudstudy username: test password: 123456 # 应用名称 bookservice application: name: bookservice cloud: nacos: discovery: # 配置Nacos注册中心地址 server-addr: localhost:8848 接着启动我们的图书服务，可以在Nacos的服务列表中找到：\n按照同样的方法，我们接着将另外两个服务也注册到Nacos中：\n接着我们使用OpenFeign，实现服务发现远程调用以及负载均衡，导入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 这里需要单独导入LoadBalancer依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-loadbalancer\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 编写接口：\n@FeignClient(\u0026#34;userservice\u0026#34;) public interface UserClient { @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) User getUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid); } @FeignClient(\u0026#34;bookservice\u0026#34;) public interface BookClient { @RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book getBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid); } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } @EnableFeignClients @SpringBootApplication public class BorrowApplication { public static void main(String[] args) { SpringApplication.run(BorrowApplication.class, args); } } 接着我们进行测试：\n测试正常，可以自动发现服务，接着我们来多配置几个实例，去掉图书服务和用户服务的端口配置：\n然后我们在图书服务和用户服务中添加一句打印方便之后查看：\n@RequestMapping(\u0026#34;/user/{uid}\u0026#34;) public User findUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ System.out.println(\u0026#34;调用用户服务\u0026#34;); return service.getUserById(uid); } 现在将全部服务启动： 可以看到Nacos中的实例数量已经显示为2：\n接着我们调用借阅服务，看看能否负载均衡远程调用：\nOK，负载均衡远程调用没有问题，这样我们就实现了基于Nacos的服务的注册与发现，实际上大致流程与Eureka一致。\n值得注意的是，Nacos区分了临时实例和非临时实例：\n那么临时和非临时有什么区别呢？\n临时实例：和Eureka一样，采用心跳机制向Nacos发送请求保持在线状态，一旦心跳停止，代表实例下线，不保留实例信息。 非临时实例：由Nacos主动进行联系，如果连接失败，那么不会移除实例信息，而是将健康状态设定为false，相当于会对某个实例状态持续地进行监控。 我们可以通过配置文件进行修改临时实例：\nspring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 # 将ephemeral修改为false，表示非临时实例 ephemeral: false 接着我们在Nacos中查看，可以发现实例已经不是临时的了：\n如果这时我们关闭此实例，那么会变成这样：\n只是将健康状态变为false，而不会删除实例的信息。\n集群分区 #\r实际上集群分区概念在之前的Eureka中也有出现，比如：\neureka: client: fetch-registry: false register-with-eureka: false service-url: defaultZone: http://localhost:8888/eureka # 这个defaultZone是个啥玩意，为什么要用这个名称？为什么要要用这样的形式来声明注册中心？ 在一个分布式应用中，相同服务的实例可能会在不同的机器、位置上启动，比如我们的用户管理服务，可能在成都有1台服务器部署、重庆有一台服务器部署，而这时，我们在成都的服务器上启动了借阅服务，那么如果我们的借阅服务现在要调用用户服务，就应该优先选择同一个区域的用户服务进行调用，这样会使得响应速度更快。\n因此，我们可以对部署在不同机房的服务进行分区，可以看到实例的分区是默认：\n我们可以直接在配置文件中进行修改：\nspring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 # 修改为重庆地区的集群 cluster-name: Chongqing 当然由于我们这里使用的是不同的启动配置，直接在启动配置中添加环境变量spring.cloud.nacos.discovery.cluster-name也行，这里我们将用户服务和图书服务两个区域都分配一个，借阅服务就配置为成都地区：\n修改完成之后，我们来尝试重新启动一下（Nacos也要重启），观察Nacos中集群分布情况：\n可以看到现在有两个集群，并且都有一个实例正在运行。我们接着去调用借阅服务，但是发现并没有按照区域进行优先调用，而依然使用的是轮询模式的负载均衡调用。\n我们必须要提供Nacos的负载均衡实现才能开启区域优先调用机制，只需要在配制文件中进行修改即可：\nspring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: Chengdu # 将loadbalancer的nacos支持开启，集成Nacos负载均衡 loadbalancer: nacos: enabled: true 现在我们重启借阅服务，会发现优先调用的是同区域的用户和图书服务，现在我们可以将成都地区的服务下线：\n可以看到，在下线之后，由于本区域内没有可用服务了，借阅服务将会调用重庆区域的用户服务。\n除了根据区域优先调用之外，同一个区域内的实例也可以单独设置权重，Nacos会优先选择权重更大的实例进行调用，我们可以直接在管理页面中进行配置：\n或是在配置文件中进行配置：\nspring: application: name: borrowservice cloud: nacos: discovery: server-addr: localhost:8848 cluster-name: Chengdu # 权重大小，越大越优先调用，默认为1 weight: 0.5 通过配置权重，某些性能不太好的机器就能够更少地被使用，而更多的使用那些网络良好性能更高的主机上的实例。\n配置中心 #\r前面我们学习了SpringCloud Config，我们可以通过配置服务来加载远程配置，这样我们就可以在远端集中管理配置文件。\n实际上我们可以在bootstrap.yml中配置远程配置文件获取，然后再进入到配置文件加载环节，而Nacos也支持这样的操作，使用方式也比较类似，比如我们现在想要将借阅服务的配置文件放到Nacos进行管理，那么这个时候就需要在Nacos中创建配置文件：\n将借阅服务的配置文件全部（当然正常情况下是不会全部CV的，只会复制那些需要经常修改的部分，这里为了省事就直接全部CV了）复制过来，注意Data ID的格式跟我们之前一样，应用名称-环境.yml，如果只编写应用名称，那么代表此配置文件无论在什么环境下都会使用，然后每个配置文件都可以进行分组，也算是一种分类方式：\n完成之后点击发布即可：\n然后在项目中导入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着我们在借阅服务中添加bootstrap.yml文件：\nspring: application: # 服务名称和配置文件保持一致 name: borrowservice profiles: # 环境也是和配置文件保持一致 active: dev cloud: nacos: config: # 配置文件后缀名 file-extension: yml # 配置中心服务器地址，也就是Nacos地址 server-addr: localhost:8848 现在我们启动服务试试看：\n可以看到成功读取配置文件并启动了，实际上使用上来说跟之前的Config是基本一致的。\nNacos还支持配置文件的热更新，比如我们在配置文件中添加了一个属性，而这个时候可能需要实时修改，并在后端实时更新，那么这种该怎么实现呢？我们创建一个新的Controller：\n@RestController public class TestController { @Value(\u0026#34;${test.txt}\u0026#34;) //我们从配置文件中读取test.txt的字符串值，作为test接口的返回值 String txt; @RequestMapping(\u0026#34;/test\u0026#34;) public String test(){ return txt; } } 我们修改一下配置文件，然后重启服务器：\n可以看到已经可以正常读取了：\n现在我们将配置文件的值进行修改：\n再次访问接口，会发现没有发生变化：\n但是后台是成功检测到值更新了，但是值却没改变：\n那么如何才能实现配置热更新呢？我们可以像下面这样：\n@RestController @RefreshScope //添加此注解就能实现自动刷新了 public class TestController { @Value(\u0026#34;${test.txt}\u0026#34;) String txt; @RequestMapping(\u0026#34;/test\u0026#34;) public String test(){ return txt; } } 重启服务器，再次重复上述实验，成功。\n命名空间 #\r我们还可以将配置文件或是服务实例划分到不同的命名空间中，其实就是区分开发、生产环境或是引用归属之类的：\n这里我们创建一个新的命名空间：\n可以看到在dev命名空间下，没有任何配置文件和服务：\n我们在不同的命名空间下，实例和配置都是相互之间隔离的，我们也可以在配置文件中指定当前的命名空间。\n实现高可用 #\r由于Nacos暂不支持Arm架构芯片的Mac集群搭建，本小节用Linxu云主机（Nacos比较吃内存，2个Nacos服务器集群，至少2G内存）环境演示。\n通过前面的学习，我们已经了解了如何使用Nacos以及Nacos的功能等，最后我们来看看，如果像之前Eureka一样，搭建Nacos集群，实现高可用。\n官方方案：https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html\nhttp://ip1:port/openAPI 直连ip模式，机器挂则需要修改ip才可以使用。\nhttp://SLB:port/openAPI 挂载SLB模式(内网SLB，不可暴露到公网，以免带来安全风险)，直连SLB即可，下面挂server真实ip，可读性不好。\nhttp://nacos.com:port/openAPI 域名 + SLB模式(内网SLB，不可暴露到公网，以免带来安全风险)，可读性好，而且换ip方便，推荐模式\n我们来看看它的架构设计，它推荐我们在所有的Nacos服务端之前建立一个负载均衡，我们通过访问负载均衡服务器来间接访问到各个Nacos服务器。实际上就，是比如有三个Nacos服务器做集群，但是每个服务不可能把每个Nacos都去访问一次进行注册，实际上只需要在任意一台Nacos服务器上注册即可，Nacos服务器之间会自动同步信息，但是如果我们随便指定一台Nacos服务器进行注册，如果这台Nacos服务器挂了，但是其他Nacos服务器没挂，这样就没办法完成注册了，但是实际上整个集群还是可用的状态。\n所以这里就需要在所有Nacos服务器之前搭建一个SLB（服务器负载均衡），这样就可以避免上面的问题了。但是我们知道，如果要实现外界对服务访问的负载均衡，我们就得用比如之前说到的Gateway来实现，而这里实际上我们可以用一个更加方便的工具：Nginx，来实现（之前我们没讲过，但是使用起来很简单，放心后面会带着大家使用）\n关于SLB最上方还有一个DNS（我们在计算机网络这门课程中学习过），这个是因为SLB是裸IP，如果SLB服务器修改了地址，那么所有微服务注册的地址也得改，所以这里是通过加域名，通过域名来访问，让DNS去解析真实IP，这样就算改变IP，只需要修改域名解析记录即可，域名地址是不会变化的。\n最后就是Nacos的数据存储模式，在单节点的情况下，Nacos实际上是将数据存放在自带的一个嵌入式数据库中：\n而这种模式只适用于单节点，在多节点集群模式下，肯定是不能各存各的，所以，Nacos提供了MySQL统一存储支持，我们只需要让所有的Nacos服务器连接MySQL进行数据存储即可，官方也提供好了SQL文件。\n现在就可以开始了，第一步，我们直接导入数据库即可，文件在conf目录中：\n我们来将其导入到数据库，可以看到生成了很多的表：\n然后我们来创建两个Nacos服务器，做一个迷你的集群，这里使用scp命令将nacos服务端上传到Linux服务器（注意需要提前安装好JRE 8或更高版本的环境）：\n解压之后，我们对其配置文件进行修改，首先是application.properties配置文件，修改以下内容，包括MySQL服务器的信息：\n### Default web server port: server.port=8801 #*************** Config Module Related Configurations ***************# ### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://cloudstudy.mysql.cn-chengdu.rds.aliyuncs.com:3306/nacos?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user.0=nacos db.password.0=nacos 然后修改集群配置，这里需要重命名一下：\n端口记得使用内网IP地址：\n最后我们修改一下Nacos的内存分配以及前台启动，直接修改startup.sh文件（内存有限，玩不起高的）：\n保存之后，将nacos复制一份，并将端口修改为8802，接着启动这两个Nacos服务器。\n然后我们打开管理面板，可以看到两个节点都已经启动了：\n这样，我们第二步就完成了，接着我们需要添加一个SLB，这里我们用Nginx做反向代理：\nNginx (engine x) 是一个高性能的\rHTTP和\r反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。它相当于在内网与外网之间形成一个网关，所有的请求都可以由Nginx服务器转交给内网的其他服务器。\n这里我们直接安装：\nsudo apt install nginx 可以看到直接请求80端口之后得到，表示安装成功：\n现在我们需要让其代理我们刚刚启动的两个Nacos服务器，我们需要对其进行一些配置。配置文件位于/etc/nginx/nginx.conf，添加以下内容：\n#添加我们在上游刚刚创建好的两个nacos服务器\rupstream nacos-server {\rserver 10.0.0.12:8801;\rserver 10.0.0.12:8802;\r}\rserver {\rlisten 80;\rserver_name 1.14.121.107;\rlocation /nacos {\rproxy_pass http://nacos-server;\r}\r} 重启Nginx服务器，成功连接：\n然后我们将所有的服务全部修改为云服务器上Nacos的地址，启动试试看。\n这样，我们就搭建好了Nacos集群。\nSentinel 流量防卫兵 #\r注意： 这一章有点小绕，思路理清。\n经过之前的学习，我们了解了微服务存在的雪崩问题，也就是说一个微服务出现问题，有可能导致整个链路直接不可用，这种时候我们就需要进行及时的熔断和降级，这些策略，我们之前通过使用Hystrix来实现。\nSpringCloud Alibaba也有自己的微服务容错组件，但是它相比Hystrix更加的强大。\n随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\nSentinel 具有以下特征:\n丰富的应用场景：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。 完备的实时监控：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Apache Dubbo、gRPC、Quarkus 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。同时 Sentinel 提供 Java/Go/C++ 等多语言的原生实现。 完善的 SPI 扩展机制：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。 安装与部署 #\r和Nacos一样，它是独立安装和部署的，下载地址：https://github.com/alibaba/Sentinel/releases\n注意下载下来之后是一个jar文件（其实就是个SpringBoot项目），我们需要在IDEA中添加一些运行配置：\n接着就可以直接启动啦，当然默认端口占用8080，如果需要修改，可以添加环境变量：\n启动之后，就可以访问到Sentinel的监控页面了，用户名和密码都是sentinel，地址：http://localhost:8858/#/dashboard\n这样就成功开启监控页面了，接着我们需要让我们的服务连接到Sentinel控制台，老规矩，导入依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后在配置文件中添加Sentinel相关信息（实际上Sentinel是本地在进行管理，但是我们可以连接到监控页面，这样就可以图形化操作了）：\nspring: application: name: userservice cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: # 添加监控页面地址即可 dashboard: localhost:8858 现在启动我们的服务，然后访问一次服务，这样Sentinel中就会存在信息了（懒加载机制，不会一上来就加载）：\n现在我们就可以在Sentinel控制台中对我们的服务运行情况进行实时监控了，可以看到监控的内容非常的多，包括时间点、QPS(每秒查询率)、响应时间等数据。\n按照上面的方式，我们将所有的服务全部连接到Sentinel管理面板中。\n流量控制 #\r前面我们完成了对Sentinel的搭建与连接，接着我们来看看Sentinel的第一个功能，流量控制。\n我们的机器不可能无限制的接受和处理客户端的请求，如果不加以限制，当发生高并发情况时，系统资源将很快被耗尽。为了避免这种情况，我们就可以添加流量控制（也可以说是限流）当一段时间内的流量到达一定的阈值的时候，新的请求将不再进行处理，这样不仅可以合理地应对高并发请求，同时也能在一定程度上保护服务器不受到外界的恶意攻击。\n那么要实现限流，正常情况下，我们该采取什么样的策略呢？\n方案一：快速拒绝，既然不再接受新的请求，那么我们可以直接返回一个拒绝信息，告诉用户访问频率过高。 方案二：预热，依然基于方案一，但是由于某些情况下高并发请求是在某一时刻突然到来，我们可以缓慢地将阈值提高到指定阈值，形成一个缓冲保护。 方案三：排队等待，不接受新的请求，但是也不直接拒绝，而是进队列先等一下，如果规定时间内能够执行，那么就执行，要是超时就算了。 针对于是否超过流量阈值的判断，这里我们提4种算法：\n漏桶算法\n顾名思义，就像一个桶开了一个小孔，水流进桶中的速度肯定是远大于水流出桶的速度的，这也是最简单的一种限流思路：\n我们知道，桶是有容量的，所以当桶的容量已满时，就装不下水了，这时就只有丢弃请求了。\n利用这种思想，我们就可以写出一个简单的限流算法。\n令牌桶算法\n只能说有点像信号量机制。现在有一个令牌桶，这个桶是专门存放令牌的，每隔一段时间就向桶中丢入一个令牌（速度由我们指定）当新的请求到达时，将从桶中删除令牌，接着请求就可以通过并给到服务，但是如果桶中的令牌数量不足，那么不会删除令牌，而是让此数据包等待。\n可以试想一下，当流量下降时，令牌桶中的令牌会逐渐积累，这样如果突然出现高并发，那么就能在短时间内拿到大量的令牌。\n固定时间窗口算法\n我们可以对某一个时间段内的请求进行统计和计数，比如在14:15到14:16这一分钟内，请求量不能超过100，也就是一分钟之内不能超过100次请求，那么就可以像下面这样进行划分：\n虽然这种模式看似比较合理，但是试想一下这种情况：\n14:15:59的时候来了100个请求 14:16:01的时候又来了100个请求 出现上面这种情况，符合固定时间窗口算法的规则，所以这200个请求都能正常接受，但是，如果你反应比较快，应该发现了，我们其实希望的是60秒内只有100个请求，但是这种情况却是在3秒内出现了200个请求，很明显已经违背了我们的初衷。\n因此，当遇到临界点时，固定时间窗口算法存在安全隐患。\n滑动时间窗口算法\n相对于固定窗口算法，滑动时间窗口算法更加灵活，它会动态移动窗口，重新进行计算：\n虽然这样能够避免固定时间窗口的临界问题，但是这样显然是比固定窗口更加耗时的。\n好了，了解完了我们的限流策略和判定方法之后，我们在Sentinel中进行实际测试一下，打开管理页面的簇点链路模块：\n这里演示对我们的借阅接口进行限流，点击流控，会看到让我们添加流控规则：\n阈值类型：QPS就是每秒钟的请求数量，并发线程数是按服务当前使用的线程数据进行统计的。 流控模式：当达到阈值时，流控的对象，这里暂时只用直接。 流控效果：就是我们上面所说的三种方案。 这里我们选择QPS、阈值设定为1，流控模式选择直接、流控效果选择快速失败，可以看到，当我们快速地进行请求时，会直接返回失败信息：\n这里各位最好自行尝试一下其他的流控效果，熟悉和加深印象。\n最后我们来看看这些流控模式有什么区别：\n直接：只针对于当前接口。 关联：当其他接口超过阈值时，会导致当前接口被限流。 链路：更细粒度的限流，能精确到具体的方法。 我们首先来看看关联，比如现在我们对自带的/error接口进行限流：\n注意限流是作用于关联资源的，一旦发现关联资源超过阈值，那么就会对当前的资源进行限流，我们现在来测试一下，这里使用PostMan的Runner连续对关联资源发起请求：\n开启Postman，然后我们会发现借阅服务已经凉凉：\n当我们关闭掉Postman的任务后，恢复正常。\n最后我们来讲解一下链路模式，它能够更加精准的进行流量控制，链路流控模式指的是，当从指定接口过来的资源请求达到限流条件时，开启限流，这里得先讲解一下@SentinelResource的使用。\n我们可以对某一个方法进行限流控制，无论是谁在何处调用了它，这里需要使用到@SentinelResource，一旦方法被标注，那么就会进行监控，比如我们这里创建两个请求映射，都来调用Service的被监控方法：\n@RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\u0026#34;/borrow/{uid}\u0026#34;) UserBorrowDetail findUserBorrows(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserBorrowDetailByUid(uid); } @RequestMapping(\u0026#34;/borrow2/{uid}\u0026#34;) UserBorrowDetail findUserBorrows2(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserBorrowDetailByUid(uid); } } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override @SentinelResource(\u0026#34;getBorrow\u0026#34;) //监控此方法，无论被谁执行都在监控范围内，这里给的value是自定义名称，这个注解可以加在任何方法上，包括Controller中的请求映射方法，跟HystrixCommand贼像 public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 接着添加配置：\nspring: application: name: borrowservice cloud: sentinel: transport: dashboard: localhost:8858 # 关闭Context收敛，这样被监控方法可以进行不同链路的单独控制 web-context-unify: false 然后我们在Sentinel控制台中添加流控规则，注意是针对此方法，可以看到已经自动识别到borrow接口下调用了这个方法：\n最后我们在浏览器中对这两个接口都进行测试，会发现，无论请求哪个接口，只要调用了Service中的getUserBorrowDetailByUid这个方法，都会被限流。注意限流的形式是后台直接抛出异常，至于怎么处理我们后面再说。\n那么这个链路选项实际上就是决定只限流从哪个方向来的调用，比如我们只对borrow2这个接口对getUserBorrowDetailByUid方法的调用进行限流，那么我们就可以为其指定链路：\n然后我们会发现，限流效果只对我们配置的链路接口有效，而其他链路是不会被限流的。\n除了直接对接口进行限流规则控制之外，我们也可以根据当前系统的资源使用情况，决定是否进行限流：\n系统规则支持以下的模式：\nLoad 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 这里就不进行演示了。\n限流和异常处理 #\r现在我们已经了解了如何进行限流操作，那么限流状态下的返回结果该怎么修改呢，我们看到被限流之后返回的是Sentinel默认的数据，现在我们希望自定义改如何操作？\n这里我们先创建好被限流状态下需要返回的内容，定义一个请求映射：\n@RequestMapping(\u0026#34;/blocked\u0026#34;) JSONObject blocked(){ JSONObject object = new JSONObject(); object.put(\u0026#34;code\u0026#34;, 403); object.put(\u0026#34;success\u0026#34;, false); object.put(\u0026#34;massage\u0026#34;, \u0026#34;您的请求频率过快，请稍后再试！\u0026#34;); return object; } 接着我们在配置文件中将此页面设定为限流页面：\nspring: cloud: sentinel: transport: dashboard: localhost:8858 # 将刚刚编写的请求映射设定为限流页面 block-page: /blocked 这样，当被限流时，就会被重定向到指定页面：\n那么，对于方法级别的限流呢？经过前面的学习我们知道，当某个方法被限流时，会直接在后台抛出异常，那么这种情况我们该怎么处理呢，比如我们之前在Hystrix中可以直接添加一个替代方案，这样当出现异常时会直接执行我们的替代方法并返回，Sentinel也可以。\n比如我们还是在getUserBorrowDetailByUid方法上进行配置：\n@Override @SentinelResource(value = \u0026#34;getBorrow\u0026#34;, blockHandler = \u0026#34;blocked\u0026#34;) //指定blockHandler，也就是被限流之后的替代解决方案，这样就不会使用默认的抛出异常的形式了 public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } //替代方案，注意参数和返回值需要保持一致，并且参数最后还需要额外添加一个BlockException public UserBorrowDetail blocked(int uid, BlockException e) { return new UserBorrowDetail(null, Collections.emptyList()); } 可以看到，一旦被限流将执行替代方案，最后返回的结果就是：\n注意blockHandler只能处理限流情况下抛出的异常，包括下面即将要介绍的热点参数限流也是同理，如果是方法本身抛出的其他类型异常，不在管控范围内，但是可以通过其他参数进行处理：\n@RequestMapping(\u0026#34;/test\u0026#34;) @SentinelResource(value = \u0026#34;test\u0026#34;, fallback = \u0026#34;except\u0026#34;, //fallback指定出现异常时的替代方案 exceptionsToIgnore = IOException.class) //忽略那些异常，也就是说这些异常出现时不使用替代方案 String test(){ throw new RuntimeException(\u0026#34;HelloWorld！\u0026#34;); } //替代方法必须和原方法返回值和参数一致，最后可以添加一个Throwable作为参数接受异常 String except(Throwable t){ return t.getMessage(); } 这样，其他的异常也可以有替代方案了：\n特别注意这种方式会在没有配置blockHandler的情况下，将Sentinel机制内（也就是限流的异常）的异常也一并处理了，如果配置了blockHandler，那么在出现限流时，依然只会执行blockHandler指定的替代方案（因为限流是在方法执行之前进行的）\n热点参数限流 #\r我们还可以对某一热点数据进行精准限流，比如在某一时刻，不同参数被携带访问的频率是不一样的：\nhttp://localhost:8301/test?a=10 访问100次 http://localhost:8301/test?b=10 访问0次 http://localhost:8301/test?c=10 访问3次 由于携带参数a的请求比较多，我们就可以只对携带参数a的请求进行限流。\n这里我们创建一个新的测试请求映射：\n@RequestMapping(\u0026#34;/test\u0026#34;) @SentinelResource(\u0026#34;test\u0026#34;) //注意这里需要添加@SentinelResource才可以，用户资源名称就使用这里定义的资源名称 String findUserBorrows2(@RequestParam(value = \u0026#34;a\u0026#34;, required = false) int a, @RequestParam(value = \u0026#34;b\u0026#34;, required = false) int b, @RequestParam(value = \u0026#34;c\u0026#34;,required = false) int c) { return \u0026#34;请求成功！a = \u0026#34;+a+\u0026#34;, b = \u0026#34;+b+\u0026#34;, c = \u0026#34;+c; } 启动之后，我们在Sentinel里面进行热点配置：\n然后开始访问我们的测试接口，可以看到在携带参数a时，当访问频率超过设定值，就会直接被限流，这里是直接在后台抛出异常：\n而我们使用其他参数或是不带a参数，那么就不会出现这种问题了：\n除了直接对某个参数精准限流外，我们还可以对参数携带的指定值单独设定阈值，比如我们现在不仅希望对参数a限流，而且还希望当参数a的值为10时，QPS达到5再进行限流，那么就可以设定例外：\n这样，当请求携带参数a，且参数a的值为10时，阈值将按照我们指定的特例进行计算。\n服务熔断和降级 #\r还记得我们前所说的服务降级吗，也就是说我们需要在整个微服务调用链路出现问题的时候，及时对服务进行降级，以防止问题进一步恶化。\n那么，各位是否有思考过，如果在某一时刻，服务B出现故障（可能就卡在那里了），而这时服务A依然有大量的请求，在调用服务B，那么，由于服务A没办法再短时间内完成处理，新来的请求就会导致线程数不断地增加，这样，CPU的资源很快就会被耗尽。\n那么要防止这种情况，就只能进行隔离了，这里我们提两种隔离方案：\n线程池隔离\n线程池隔离实际上就是对每个服务的远程调用单独开放线程池，比如服务A要调用服务B，那么只基于固定数量的线程池，这样即使在短时间内出现大量请求，由于没有线程可以分配，所以就不会导致资源耗尽了。\n信号量隔离\n信号量隔离是使用Semaphore类实现的（如果不了解，可以观看本系列 并发编程篇 视频教程），思想基本上与上面是相同的，也是限定指定的线程数量能够同时进行服务调用，但是它相对于线程池隔离，开销会更小一些，使用效果同样优秀，也支持超时等。\nSentinel也正是采用的这种方案实现隔离的。\n好了，说回我们的熔断和降级，当下游服务因为某种原因变得不可用或响应过慢时，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务而是快速返回或是执行自己的替代方案，这便是服务降级。\n整个过程分为三个状态：\n关闭：熔断器不工作，所有请求全部该干嘛干嘛。 打开：熔断器工作，所有请求一律降级处理。 半开：尝试进行一下下正常流程，要是还不行继续保持打开状态，否则关闭。 那么我们来看看Sentinel中如何进行熔断和降级操作，打开管理页面，我们可以自由新增熔断规则：\n其中，熔断策略有三种模式：\n慢调用比例： 如果出现那种半天都处理不完的调用，有可能就是服务出现故障，导致卡顿，这个选项是按照最大响应时间（RT）进行判定，如果一次请求的处理时间超过了指定的RT，那么就被判定为慢调用，在一个统计时长内，如果请求数目大于最小请求数目，并且被判定为慢调用的请求比例已经超过阈值，将触发熔断。经过熔断时长之后，将会进入到半开状态进行试探（这里和Hystrix一致）\n然后修改一下接口的执行，我们模拟一下慢调用：\n@RequestMapping(\u0026#34;/borrow2/{uid}\u0026#34;) UserBorrowDetail findUserBorrows2(@PathVariable(\u0026#34;uid\u0026#34;) int uid) throws InterruptedException { Thread.sleep(1000); return null; } 重启，然后我们创建一个新的熔断规则：\n可以看到，超时直接触发了熔断，进入到阻止页面：\n异常比例： 这个与慢调用比例类似，不过这里判断的是出现异常的次数，与上面一样，我们也来进行一些小测试：\n@RequestMapping(\u0026#34;/borrow2/{uid}\u0026#34;) UserBorrowDetail findUserBorrows2(@PathVariable(\u0026#34;uid\u0026#34;) int uid) { throw new RuntimeException(); } 启动服务器，接着添加我们的熔断规则：\n现在我们进行访问，会发现后台疯狂报错，然后就熔断了：\n异常数： 这个和上面的唯一区别就是，只要达到指定的异常数量，就熔断，这里我们修改一下熔断规则：\n现在我们再次不断访问此接口，可以发现，效果跟之前其实是差不多的，只是判断的策略稍微不同罢了：\n那么熔断规则如何设定我们了解了，那么，如何自定义服务降级呢？之前在使用Hystrix的时候，如果出现异常，可以执行我们的替代方案，Sentinel也是可以的。\n同样的，我们只需要在@SentinelResource中配置blockHandler参数（那这里跟前面那个方法限流的配置不是一毛一样吗？没错，因为如果添加了@SentinelResource注解，那么这里会进行方法级别细粒度的限制，和之前方法级别限流一样，会在降级之后直接抛出异常，如果不添加则返回默认的限流页面，blockHandler的目的就是处理这种Sentinel机制上的异常，所以这里其实和之前的限流配置是一个道理，因此下面熔断配置也应该对value自定义名称的资源进行配置，才能作用到此方法上）：\n@RequestMapping(\u0026#34;/borrow2/{uid}\u0026#34;) @SentinelResource(value = \u0026#34;findUserBorrows2\u0026#34;, blockHandler = \u0026#34;test\u0026#34;) UserBorrowDetail findUserBorrows2(@PathVariable(\u0026#34;uid\u0026#34;) int uid) { throw new RuntimeException(); } UserBorrowDetail test(int uid, BlockException e){ return new UserBorrowDetail(new User(), Collections.emptyList()); } 接着我们对进行熔断配置，注意是对我们添加的@SentinelResource中指定名称的findUserBorrows2进行配置：\nOK，可以看到熔断之后，服务降级之后的效果：\n最后我们来看一下如何让Feign的也支持Sentinel，前面我们使用Hystrix的时候，就可以直接对Feign的每个接口调用单独进行服务降级，而使用Sentinel，也是可以的，首先我们需要在配置文件中开启支持：\nfeign: sentinel: enabled: true 之后的步骤其实和之前是一模一样的，首先创建实现类：\n@Component public class UserClientFallback implements UserClient{ @Override public User getUserById(int uid) { User user = new User(); user.setName(\u0026#34;我是替代方案\u0026#34;); return user; } } 然后直接启动就可以了，中途的时候我们吧用户服务全部下掉，可以看到正常使用替代方案：\n这样Feign的配置就OK了，那么传统的RestTemplate呢？我们可以使用@SentinelRestTemplate注解实现：\n@Bean @LoadBalanced @SentinelRestTemplate(blockHandler = \u0026#34;handleException\u0026#34;, blockHandlerClass = ExceptionUtil.class, fallback = \u0026#34;fallback\u0026#34;, fallbackClass = ExceptionUtil.class) //这里同样可以设定fallback等参数 public RestTemplate restTemplate() { return new RestTemplate(); } 这里就不多做赘述了。\nSeata与分布式事务 #\r重难点内容，坑也多得离谱，最好保持跟UP一样的版本，官方文档： https://seata.io/zh-cn/docs/overview/what-is-seata.html\n在前面的阶段中，我们学习过事务，还记得我们之前谈到的数据库事务的特性吗？\n原子性： 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性： 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性： 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读已提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性： 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 那么各位试想一下，在分布式环境下，有可能出现这样一个问题，比如我们下单购物，那么整个流程可能是这样的：先调用库存服务对库存进行减扣 -\u0026gt; 然后订单服务开始下单 -\u0026gt; 最后用户账户服务进行扣款，虽然看似是一个很简单的一个流程，但是如果没有事务的加持，很有可能会由于中途出错，比如整个流程中订单服务出现问题，那么就会导致库存扣了，但是实际上这个订单并没有生成，用户也没有付款。\n上面这种情况时间就是一种多服务多数据源的分布式事务模型（比较常见），因此，为了解决这种情况，我们就得实现分布式事务，让这整个流程保证原子性。\nSpringCloud Alibaba为我们提供了用于处理分布式事务的组件Seata。\nSeata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。\n实际上，就是多了一个中间人来协调所有服务的事务。\n项目环境搭建 #\r这里我们对我们之前的图书管理系统进行升级：\n每个用户最多只能同时借阅2本不同的书。 图书馆中所有的书都有3本。 用户借书流程：先调用图书服务书籍数量-1 -\u0026gt; 添加借阅记录 -\u0026gt; 调用用户服务用户可借阅数量-1 那么首先我们对数据库进行修改，这里为了简便，就直接在用户表中添加一个字段用于存储用户能够借阅的书籍数量：\n然后修改书籍信息，也是直接添加一个字段用于记录剩余数量：\n接着我们去编写一下对应的服务吧，首先是用户服务：\n@Mapper public interface UserMapper { @Select(\u0026#34;select * from DB_USER where uid = #{uid}\u0026#34;) User getUserById(int uid); @Select(\u0026#34;select book_count from DB_USER where uid = #{uid}\u0026#34;) int getUserBookRemain(int uid); @Update(\u0026#34;update DB_USER set book_count = #{count} where uid = #{uid}\u0026#34;) int updateBookCount(int uid, int count); } @Service public class UserServiceImpl implements UserService { @Resource UserMapper mapper; @Override public User getUserById(int uid) { return mapper.getUserById(uid); } @Override public int getRemain(int uid) { return mapper.getUserBookRemain(uid); } @Override public boolean setRemain(int uid, int count) { return mapper.updateBookCount(uid, count) \u0026gt; 0; } } @RestController public class UserController { @Resource UserService service; @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) public User findUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserById(uid); } @RequestMapping(\u0026#34;/user/remain/{uid}\u0026#34;) public int userRemain(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getRemain(uid); } @RequestMapping(\u0026#34;/user/borrow/{uid}\u0026#34;) public boolean userBorrow(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ int remain = service.getRemain(uid); return service.setRemain(uid, remain - 1); } } 然后是图书服务，其实跟用户服务差不多：\n@Mapper public interface BookMapper { @Select(\u0026#34;select * from DB_BOOK where bid = #{bid}\u0026#34;) Book getBookById(int bid); @Select(\u0026#34;select count from DB_BOOK where bid = #{bid}\u0026#34;) int getRemain(int bid); @Update(\u0026#34;update DB_BOOK set count = #{count} where bid = #{bid}\u0026#34;) int setRemain(int bid, int count); } @Service public class BookServiceImpl implements BookService { @Resource BookMapper mapper; @Override public Book getBookById(int bid) { return mapper.getBookById(bid); } @Override public boolean setRemain(int bid, int count) { return mapper.setRemain(bid, count) \u0026gt; 0; } @Override public int getRemain(int bid) { return mapper.getRemain(bid); } } @RestController public class BookController { @Resource BookService service; @RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book findBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid){ return service.getBookById(bid); } @RequestMapping(\u0026#34;/book/remain/{bid}\u0026#34;) public int bookRemain(@PathVariable(\u0026#34;bid\u0026#34;) int uid){ return service.getRemain(uid); } @RequestMapping(\u0026#34;/book/borrow/{bid}\u0026#34;) public boolean bookBorrow(@PathVariable(\u0026#34;bid\u0026#34;) int uid){ int remain = service.getRemain(uid); return service.setRemain(uid, remain - 1); } } 最后完善我们的借阅服务：\n@FeignClient(value = \u0026#34;userservice\u0026#34;) public interface UserClient { @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) User getUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid); @RequestMapping(\u0026#34;/user/borrow/{uid}\u0026#34;) boolean userBorrow(@PathVariable(\u0026#34;uid\u0026#34;) int uid); @RequestMapping(\u0026#34;/user/remain/{uid}\u0026#34;) int userRemain(@PathVariable(\u0026#34;uid\u0026#34;) int uid); } @FeignClient(\u0026#34;bookservice\u0026#34;) public interface BookClient { @RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book getBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid); @RequestMapping(\u0026#34;/book/borrow/{bid}\u0026#34;) boolean bookBorrow(@PathVariable(\u0026#34;bid\u0026#34;) int bid); @RequestMapping(\u0026#34;/book/remain/{bid}\u0026#34;) int bookRemain(@PathVariable(\u0026#34;bid\u0026#34;) int bid); } @RestController public class BorrowController { @Resource BorrowService service; @RequestMapping(\u0026#34;/borrow/{uid}\u0026#34;) UserBorrowDetail findUserBorrows(@PathVariable(\u0026#34;uid\u0026#34;) int uid){ return service.getUserBorrowDetailByUid(uid); } @RequestMapping(\u0026#34;/borrow/take/{uid}/{bid}\u0026#34;) JSONObject borrow(@PathVariable(\u0026#34;uid\u0026#34;) int uid, @PathVariable(\u0026#34;bid\u0026#34;) int bid){ service.doBorrow(uid, bid); JSONObject object = new JSONObject(); object.put(\u0026#34;code\u0026#34;, \u0026#34;200\u0026#34;); object.put(\u0026#34;success\u0026#34;, false); object.put(\u0026#34;message\u0026#34;, \u0026#34;借阅成功！\u0026#34;); return object; } } @Service public class BorrowServiceImpl implements BorrowService{ @Resource BorrowMapper mapper; @Resource UserClient userClient; @Resource BookClient bookClient; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = userClient.getUserById(uid); List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; bookClient.getBookById(b.getBid())) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } @Override public boolean doBorrow(int uid, int bid) { //1. 判断图书和用户是否都支持借阅 if(bookClient.bookRemain(bid) \u0026lt; 1) throw new RuntimeException(\u0026#34;图书数量不足\u0026#34;); if(userClient.userRemain(uid) \u0026lt; 1) throw new RuntimeException(\u0026#34;用户借阅量不足\u0026#34;); //2. 首先将图书的数量-1 if(!bookClient.bookBorrow(bid)) throw new RuntimeException(\u0026#34;在借阅图书时出现错误！\u0026#34;); //3. 添加借阅信息 if(mapper.getBorrow(uid, bid) != null) throw new RuntimeException(\u0026#34;此书籍已经被此用户借阅了！\u0026#34;); if(mapper.addBorrow(uid, bid) \u0026lt;= 0) throw new RuntimeException(\u0026#34;在录入借阅信息时出现错误！\u0026#34;); //4. 用户可借阅-1 if(!userClient.userBorrow(uid)) throw new RuntimeException(\u0026#34;在借阅时出现错误！\u0026#34;); //完成 return true; } } 这样，只要我们的图书借阅过程中任何一步出现问题，都会抛出异常。\n我们来测试一下：\n再次尝试借阅，后台会直接报错：\n抛出异常，但是我们发现一个问题，借阅信息添加失败了，但是图书的数量依然被-1，也就是说正常情况下，我们是希望中途出现异常之后，之前的操作全部回滚的：\n而这里由于是在另一个服务中进行的数据库操作，所以传统的@Transactional注解无效，这时就得借助Seata提供分布式事务了。\n分布式事务解决方案 #\r要开始实现分布式事务，我们得先从理论上开始下手，我们来了解一下常用的分布式事务解决方案。\nXA分布式事务协议 - 2PC（两阶段提交实现）\n这里的PC实际上指的是Prepare和Commit，也就是说它分为两个阶段，一个是准备一个是提交，整个过程的参与者一共有两个角色，一个是事务的执行者，一个是事务的协调者，实际上整个分布式事务的运作都需要依靠协调者来维持：\n在准备和提交阶段，会进行：\n准备阶段：\n一个分布式事务是由协调者来开启的，首先协调者会向所有的事务执行者发送事务内容，等待所有的事务执行者答复。\n各个事务执行者开始执行事务操作，但是不进行提交，并将undo和redo信息记录到事务日志中。\n如果事务执行者执行事务成功，那么就告诉协调者成功Yes，否则告诉协调者失败No，不能提交事务。\n提交阶段：\n当所有的执行者都反馈完成之后，进入第二阶段。\n协调者会检查各个执行者的反馈内容，如果所有的执行者都返回成功，那么就告诉所有的执行者可以提交事务了，最后再释放锁资源。\n如果有至少一个执行者返回失败或是超时，那么就让所有的执行者都回滚，分布式事务执行失败。\n虽然这种方式看起来比较简单，但是存在以下几个问题：\n事务协调者是非常核心的角色，一旦出现问题，将导致整个分布式事务不能正常运行。 如果提交阶段发生网络问题，导致某些事务执行者没有收到协调者发来的提交命令，将导致某些执行者提交某些执行者没提交，这样肯定是不行的。 XA分布式事务协议 - 3PC（三阶段提交实现）\n三阶段提交是在二阶段提交基础上的改进版本，主要是加入了超时机制，同时在协调者和执行者中都引入了超时机制。\n三个阶段分别进行：\nCanCommit阶段：\n协调者向执行者发送CanCommit请求，询问是否可以执行事务提交操作，然后开始等待执行者的响应。\n执行者接收到请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态，否则返回No\nPreCommit阶段：\n协调者根据执行者的反应情况来决定是否可以进入第二阶段事务的PreCommit操作。\n如果所有的执行者都返回Yes，则协调者向所有执行者发送PreCommit请求，并进入Prepared阶段，执行者接收到请求后，会执行事务操作，并将undo和redo信息记录到事务日志中，如果成功执行，则返回成功响应。\n如果所有的执行者至少有一个返回No，则协调者向所有执行者发送abort请求，所有的执行者在收到请求或是超过一段时间没有收到任何请求时，会直接中断事务。\nDoCommit阶段：\n该阶段进行真正的事务提交。\n协调者接收到所有执行者发送的成功响应，那么他将从PreCommit状态进入到DoCommit状态，并向所有执行者发送doCommit请求，执行者接收到doCommit请求之后，开始执行事务提交，并在完成事务提交之后释放所有事务资源，并最后向协调者发送确认响应，协调者接收到所有执行者的确认响应之后，完成事务（如果因为网络问题导致执行者没有收到doCommit请求，执行者会在超时之后直接提交事务，虽然执行者只是猜测协调者返回的是doCommit请求，但是因为前面的两个流程都正常执行，所以能够在一定程度上认为本次事务是成功的，因此会直接提交）\n协调者没有接收至少一个执行者发送的成功响应（也可能是响应超时），那么就会执行中断事务，协调者会向所有执行者发送abort请求，执行者接收到abort请求之后，利用其在PreCommit阶段记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源，执行者完成事务回滚之后，向协调者发送确认消息， 协调者接收到参与者反馈的确认消息之后，执行事务的中断。\n相比两阶段提交，三阶段提交的优势是显而易见的，当然也有缺点：\n3PC在2PC的第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。 一旦参与者无法及时收到来自协调者的信息之后，会默认执行Commit，这样就不会因为协调者单方面的故障导致全局出现问题。 但是我们知道，实际上超时之后的Commit决策本质上就是一个赌注罢了，如果此时协调者发送的是abort请求但是超时未接收，那么就会直接导致数据一致性问题。 TCC（补偿事务）\n补偿事务TCC就是Try、Confirm、Cancel，它对业务有侵入性，一共分为三个阶段，我们依次来解读一下。\nTry阶段：\n比如我们需要在借书时，将书籍的库存-1，并且用户的借阅量也-1，但是这个操作，除了直接对库存和借阅量进行修改之外，还需要将减去的值，单独存放到冻结表中，但是此时不会创建借阅信息，也就是说只是预先把关键的东西给处理了，预留业务资源出来。\nConfirm阶段：\n如果Try执行成功无误，那么就进入到Confirm阶段，接着之前，我们就该创建借阅信息了，只能使用Try阶段预留的业务资源，如果创建成功，那么就对Try阶段冻结的值，进行解冻，整个流程就完成了。当然，如果失败了，那么进入到Cancel阶段。\nCancel阶段：\n不用猜了，那肯定是把冻结的东西还给人家，因为整个借阅操作压根就没成功。就像你付了款买了东西但是网络问题，导致交易失败，钱不可能不还给你吧。\n跟XA协议相比，TCC就没有协调者这一角色的参与了，而是自主通过上一阶段的执行情况来确保正常，充分利用了集群的优势，性能也是有很大的提升。但是缺点也很明显，它与业务具有一定的关联性，需要开发者去编写更多的补偿代码，同时并不一定所有的业务流程都适用于这种形式。\nSeata机制简介 #\r前面我们了解了一些分布式事务的解决方案，那么我们来看一下Seata是如何进行分布式事务的处理的。\n官网给出的是这样的一个架构图，那么图中的RM、TM、TC代表着什么意思呢？\nRM（Resource Manager）：用于直接执行本地事务的提交和回滚。 TM（Transaction Manager）：TM是分布式事务的核心管理者。比如现在我们需要在借阅服务中开启全局事务，来让其自身、图书服务、用户服务都参与进来，也就是说一般全局事务发起者就是TM。 TC（Transaction Manager）这个就是我们的Seata服务器，用于全局控制，比如在XA模式下就是一个协调者的角色，而一个分布式事务的启动就是由TM向TC发起请求，TC再来与其他的RM进行协调操作。 TM请求TC开启一个全局事务，TC会生成一个XID作为该全局事务的编号，XID会在微服务的调用链路中传播，保证将多个微服务的子事务关联在一起；RM请求TC将本地事务注册为全局事务的分支事务，通过全局事务的XID进行关联；TM请求TC告诉XID对应的全局事务是进行提交还是回滚；TC驱动RM将XID对应的自己的本地事务进行提交还是回滚；\nSeata支持4种事务模式，官网文档：https://seata.io/zh-cn/docs/overview/what-is-seata.html\nAT：本质上就是2PC的升级版，在 AT 模式下，用户只需关心自己的 “业务SQL”\n一阶段，Seata 会拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。 二阶段如果确认提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可，当然如果需要回滚，那么就用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。 TCC：和我们上面讲解的思路是一样的。\nXA：同上，但是要求数据库本身支持这种模式才可以。\nSaga：用于处理长事务，每个执行者需要实现事务的正向操作和补偿操作：\n那么，以AT模式为例，我们的程序如何才能做到不对业务进行侵入的情况下实现分布式事务呢？实际上，Seata客户端，是通过对数据源进行代理实现的，使用的是DataSourceProxy类，所以在程序这边，我们只需要将对应的代理类注册为Bean即可（0.9版本之后支持自动进行代理，不用我们手动操作）\n接下来，我们就以AT模式为例进行讲解。\n使用file模式部署 #\rSeata也是以服务端形式进行部署的，然后每个服务都是客户端，服务端下载地址：https://github.com/seata/seata/releases/download/v1.4.2/seata-server-1.4.2.zip\n把源码也下载一下：https://github.com/seata/seata/archive/refs/heads/develop.zip\n下载完成之后，放入到IDEA项目目录中，添加启动配置，这里端口使用8868：\nSeata服务端支持本地部署或是基于注册发现中心部署（比如Nacos、Eureka等），这里我们首先演示一下最简单的本地部署，不需要对Seata的配置文件做任何修改。\nSeata存在着事务分组机制：\n事务分组：seata的资源逻辑，可以按微服务的需要，在应用程序（客户端）对自行定义事务分组，每组取一个名字。 集群：seata-server服务端一个或多个节点组成的集群cluster。 应用程序（客户端）使用时需要指定事务逻辑分组与Seata服务端集群（默认为default）的映射关系。 为啥要设计成通过事务分组再直接映射到集群？干嘛不直接指定集群呢？获取事务分组到映射集群的配置。这样设计后，事务分组可以作为资源的逻辑隔离单位，出现某集群故障时可以快速failover，只切换对应分组，可以把故障缩减到服务级别，但前提也是你有足够server集群。\n接着我们需要将我们的各个服务作为Seate的客户端，只需要导入依赖即可：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-seata\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后添加配置：\nseata: service: vgroup-mapping: # 这里需要对事务组做映射，默认的分组名为 应用名称-seata-service-group，将其映射到default集群 # 这个很关键，一定要配置对，不然会找不到服务 bookservice-seata-service-group: default grouplist: default: localhost:8868 这样就可以直接启动了，但是注意现在只是单纯地连接上，并没有开启任何的分布式事务。\n现在我们接着来配置开启分布式事务，首先在启动类添加注解，此注解会添加一个后置处理器将数据源封装为支持分布式事务的代理数据源（虽然官方表示配置文件中已经默认开启了自动代理，但是UP主实测1.4.2版本下只能打注解的方式才能生效）：\n@EnableAutoDataSourceProxy @SpringBootApplication public class BookApplication { public static void main(String[] args) { SpringApplication.run(BookApplication.class, args); } } 接着我们需要在开启分布式事务的方法上添加@GlobalTransactional注解：\n@GlobalTransactional @Override public boolean doBorrow(int uid, int bid) { //这里打印一下XID看看，其他的服务业添加这样一个打印，如果一会都打印的是同一个XID，表示使用的就是同一个事务 System.out.println(RootContext.getXID()); if(bookClient.bookRemain(bid) \u0026lt; 1) throw new RuntimeException(\u0026#34;图书数量不足\u0026#34;); if(userClient.userRemain(uid) \u0026lt; 1) throw new RuntimeException(\u0026#34;用户借阅量不足\u0026#34;); if(!bookClient.bookBorrow(bid)) throw new RuntimeException(\u0026#34;在借阅图书时出现错误！\u0026#34;); if(mapper.getBorrow(uid, bid) != null) throw new RuntimeException(\u0026#34;此书籍已经被此用户借阅了！\u0026#34;); if(mapper.addBorrow(uid, bid) \u0026lt;= 0) throw new RuntimeException(\u0026#34;在录入借阅信息时出现错误！\u0026#34;); if(!userClient.userBorrow(uid)) throw new RuntimeException(\u0026#34;在借阅时出现错误！\u0026#34;); return true; } 还没结束，我们前面说了，Seata会分析修改数据的sql，同时生成对应的反向回滚SQL，这个回滚记录会存放在undo_log 表中。所以要求每一个Client 都有一个对应的undo_log表（也就是说每个服务连接的数据库都需要创建这样一个表，这里由于我们三个服务都用的同一个数据库，所以说就只用在这个数据库中创建undo_log表即可），表SQL定义如下：\nCREATE TABLE `undo_log` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `branch_id` BIGINT(20) NOT NULL, `xid` VARCHAR(100) NOT NULL, `context` VARCHAR(128) NOT NULL, `rollback_info` LONGBLOB NOT NULL, `log_status` INT(11) NOT NULL, `log_created` DATETIME NOT NULL, `log_modified` DATETIME NOT NULL, `ext` VARCHAR(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8; 创建完成之后，我们现在就可以启动三个服务了，我们来测试一下当出现异常的时候是不是会正常回滚：\n首先第一次肯定是正常完成借阅操作的，接着我们再次进行请求，肯定会出现异常：\n如果能在栈追踪信息中看到seata相关的包，那么说明分布式事务已经开始工作了，通过日志我们可以看到，出现了回滚操作：\n并且数据库中确实是回滚了扣除操作：\n这样，我们就通过Seata简单地实现了分布式事务。\n使用nacos模式部署 #\r前面我们实现了本地Seata服务的file模式部署，现在我们来看看如何让其配合Nacos进行部署，利用Nacos的配置管理和服务发现机制，Seata能够更好地工作。\n我们先单独为Seata配置一个命名空间：\n我们打开conf目录中的registry.conf配置文件：\nregistry { # 注册配置 # 可以看到这里可以选择类型，默认情况下是普通的file类型，也就是本地文件的形式进行注册配置 # 支持的类型如下，对应的类型在下面都有对应的配置 # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \u0026#34;nacos\u0026#34; # 采用nacos方式会将seata服务端也注册到nacos中，这样客户端就可以利用服务发现自动找到seata服务 # 就不需要我们手动指定IP和端口了，不过看似方便，坑倒是不少，后面再说 nacos { # 应用名称，这里默认就行 application = \u0026#34;seata-server\u0026#34; # Nacos服务器地址 serverAddr = \u0026#34;localhost:8848\u0026#34; # 这里使用的是SEATA_GROUP组，一会注册到Nacos中就是这个组 group = \u0026#34;SEATA_GROUP\u0026#34; # 这里就使用我们上面单独为seata配置的命名空间，注意填的是ID namespace = \u0026#34;89fc2145-4676-48b8-9edd-29e867879bcb\u0026#34; # 集群名称，这里还是使用default cluster = \u0026#34;default\u0026#34; # Nacos的用户名和密码 username = \u0026#34;nacos\u0026#34; password = \u0026#34;nacos\u0026#34; } #... 注册信息配置完成之后，接着我们需要将配置文件也放到Nacos中，让Nacos管理配置，这样我们就可以对配置进行热更新了，一旦环境需要变化，只需要直接在Nacos中修改即可。\nconfig { # 这里我们也使用nacos # file、nacos 、apollo、zk、consul、etcd3 type = \u0026#34;nacos\u0026#34; nacos { # 跟上面一样的配法 serverAddr = \u0026#34;127.0.0.1:8848\u0026#34; namespace = \u0026#34;89fc2145-4676-48b8-9edd-29e867879bcb\u0026#34; group = \u0026#34;SEATA_GROUP\u0026#34; username = \u0026#34;nacos\u0026#34; password = \u0026#34;nacos\u0026#34; # 这个不用改，默认就行 dataId = \u0026#34;seataServer.properties\u0026#34; } 接着，我们需要将配置导入到Nacos中，我们打开一开始下载的源码script/config-center/nacos目录，这是官方提供的上传脚本，我们直接运行即可（windows下没对应的bat就很蛋疼，可以使用git命令行来运行一下），这里我们使用这个可交互的版本：\n按照提示输入就可以了，不输入就使用的默认值，不知道为啥最新版本有四个因为参数过长还导入失败了，就离谱，不过不影响。\n导入成功之后，可以在对应的命名空间下看到对应的配置（为啥非要一个一个配置项单独搞，就不能写一起吗）：\n注意，还没完，我们还需要将对应的事务组映射配置也添加上，DataId格式为service.vgroupMapping.事务组名称，比如我们就使用默认的名称，值全部依然使用default即可：\n现在我们就完成了服务端的Nacos配置，接着我们需要对客户端也进行Nacos配置：\nseata: # 注册 registry: # 使用Nacos type: nacos nacos: # 使用Seata的命名空间，这样才能正确找到Seata服务，由于组使用的是SEATA_GROUP，配置默认值就是，就不用配了 namespace: 89fc2145-4676-48b8-9edd-29e867879bcb username: nacos password: nacos # 配置 config: type: nacos nacos: namespace: 89fc2145-4676-48b8-9edd-29e867879bcb username: nacos password: nacos 现在我们就可以启动这三个服务了，可以在Nacos中看到Seata以及三个服务都正常注册了：\n接着我们就可以访问一下服务试试看了：\n可以看到效果和上面是一样的，不过现在我们的注册和配置都继承在Nacos中进行了。\n我们还可以配置一下事务会话信息的存储方式，默认是file类型，那么就会在运行目录下创建file_store目录，我们可以将其搬到数据库中存储，只需要修改一下配置即可：\n将store.session.mode和store.mode的值修改为db\n接着我们对数据库信息进行一下配置：\n数据库驱动 数据库URL 数据库用户名密码 其他的默认即可：\n接着我们需要将对应的数据库进行创建，创建seata数据库，然后直接CV以下语句：\n-- -------------------------------- The script used when storeMode is \u0026#39;db\u0026#39; -------------------------------- -- the table to store GlobalSession data CREATE TABLE IF NOT EXISTS `global_table` ( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_status_gmt_modified` (`status` , `gmt_modified`), KEY `idx_transaction_id` (`transaction_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; -- the table to store BranchSession data CREATE TABLE IF NOT EXISTS `branch_table` ( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; -- the table to store lock data CREATE TABLE IF NOT EXISTS `lock_table` ( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(128), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `status` TINYINT NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;0:locked ,1:rollbacking\u0026#39;, `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_status` (`status`), KEY `idx_branch_id` (`branch_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; CREATE TABLE IF NOT EXISTS `distributed_lock` ( `lock_key` CHAR(20) NOT NULL, `lock_value` VARCHAR(20) NOT NULL, `expire` BIGINT, primary key (`lock_key`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES (\u0026#39;HandleAllSession\u0026#39;, \u0026#39; \u0026#39;, 0); 完成之后，重启Seata服务端即可：\n看到了数据源初始化成功，现在已经在使用数据库进行会话存储了。\n如果Seata服务端出现报错，可能是我们自定义事务组的名称太长了：\n将globle_table表的字段transaction_server_group长度适当增加一下即可：\n到此，关于基于nacos模式下的Seata部署，就完成了。\n虽然我们这里实现了分布式事务，但是还是给各位同学提出一个问题（可以把自己所认为的结果打在弹幕上），就我们目前这样的程序设计，在高并发下，真的安全吗？比如同一时间100个同学抢同一个书，但是我们知道同一个书就只有3本，如果这时真的同时来了100个请求要借书，会正常地只借出3本书吗？如果不正常，该如何处理？\n———————————————— 版权声明：本文为柏码知识库版权所有，禁止一切未经授权的转载、发布、出售等行为，违者将被追究法律责任。 原文链接：https://www.itbaima.cn/document/35v1hbsfcdgagdnw\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/cloud/%E4%B8%89/","section":"Docs","summary":"微服务进阶 #\r前面我们了解了微服务的一套解决方案，但是它是基于Netflix的解决方案，实际上我们发现，很多框架都已经停止维护了，来看看目前我们所认识到的SpringCloud各大组件的维护情况：\n注册中心： Eureka（属于Netflix，2.x版本不再开源，1.x版本仍在更新） 服务调用： Ribbon（属于Netflix，停止更新，已经彻底被移除）、SpringCloud Loadbalancer（属于SpringCloud官方，目前的默认方案） 服务降级： Hystrix（属于Netflix，停止更新，已经彻底被移除） 路由网关： Zuul（属于Netflix，停止更新，已经彻底被移除）、Gateway（属于SpringCloud官方，推荐方案） 配置中心： Config（属于SpringCloud官方） 可见，我们之前使用的整套解决方案中，超过半数的组件都已经处于不可用状态，并且部分组件都是SpringCloud官方出手提供框架进行解决，因此，寻找一套更好的解决方案势在必行，也就引出了我们本章的主角：SpringCloud Alibaba\n阿里巴巴作为业界的互联网大厂，给出了一套全新的解决方案，官方网站（中文）：https://spring-cloud-alibaba-group.github.io/github-pages/2021/zh-cn/index.html\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。","title":"SpringCloud 2","type":"doc"},{"content":"\r微服务应用 #\r前面我们已经完成了SpringCloudAlibaba的学习，我们对一个微服务项目的架构体系已经有了一定的了解，那么本章我们将在应用层面继续探讨微服务。\n分布式权限校验 #\r虽然完成前面的部分，我们已经可以自己去编写一个比较中规中矩的微服务项目了，但是还有一个问题我们没有解决，登录问题。假如现在要求用户登录之后，才能进行图书的查询、借阅等操作，那么我们又该如何设计这个系统呢？\n回顾我们之前进行权限校验的原理，服务器是如何判定一个请求是来自哪个用户的呢？\n首先浏览器会向服务端发送请求，访问我们的网站。 服务端收到请求后，会创建一个SESSION ID，并暂时存储在服务端，然后会发送给浏览器作为Cookie保存。 之后浏览器会一直携带此Cookie访问服务器，这样在收到请求后，就能根据携带的Cookie中的SESSION ID判断是哪个用户了。 这样服务端和浏览器之间可以轻松地建立会话了。 但是我们想一下，我们现在采用的是分布式的系统，那么在用户服务进行登录之后，其他服务比如图书服务和借阅服务，它们会知道用户登录了吗？\n实际上我们登录到用户服务之后，Session中的用户数据只会在用户服务的应用中保存，而在其他服务中，并没有对应的信息，但是我们现在希望的是，所有的服务都能够同步这些Session信息，这样我们才能实现在用户服务登录之后其他服务都能知道，那么我们该如何实现Session的同步呢？\n我们可以在每台服务器上都复制一份Session，但是这样显然是很浪费时间的，并且用户验证数据占用的内存会成倍的增加。 将Session移出服务器，用统一存储来存放，比如我们可以直接在Redis或是MySQL中存放用户的Session信息，这样所有的服务器在需要获取Session信息时，统一访问Redis或是MySQL即可，这样就能保证所有服务都可以同步Session了（是不是越来越感觉只要有问题，没有什么是加一个中间件解决不了的） 那么，我们就着重来研究一下，然后实现2号方案，这里我们就使用Redis作为Session统一存储，我们把一开始的压缩包重新解压一次，又来从头开始编写吧。\n这里我们就只使用Nacos就行了，和之前一样，我们把Nacos的包导入一下，然后进行一些配置：\n现在我们需要为每个服务都添加验证机制，首先导入依赖：\n\u0026lt;!-- SpringSession Redis支持 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 添加Redis的Starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后我们依然使用SpringSecurity框架作为权限校验框架：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 接着我们在每个服务都编写一下对应的配置文件：\nspring: session: # 存储类型修改为redis store-type: redis redis: # Redis服务器的信息，该咋写咋写 host: 1.14.121.107 这样，默认情况下，每个服务的接口都会被SpringSecurity所保护，只有登录成功之后，才可以被访问。\n我们来打开Nacos看看：\n可以看到三个服务都正常注册了，接着我们去访问图书服务：\n可以看到，访问失败，直接把我们给重定向到登陆页面了，也就是说必须登陆之后才能访问，同样的方式去访问其他服务，也是一样的效果。\n由于现在是统一Session存储，那么我们就可以在任意一个服务登录之后，其他服务都可以正常访问，现在我们在当前页面登录，登录之后可以看到图书服务能够正常访问了：\n同时用户服务也能正常访问了：\n我们可以查看一下Redis服务器中是不是存储了我们的Session信息：\n虽然看起来好像确实没啥问题了，但是借阅服务炸了，我们来看看为什么：\n在RestTemplate进行远程调用的时候，由于我们的请求没有携带对应SESSION的Cookie，所以导致验证失败，访问不成功，返回401，所以虽然这种方案看起来比较合理，但是在我们的实际使用中，还是存在一些不便的。\nOAuth 2.0 实现单点登录 #\r注意： 第一次接触可能会比较难，不太好理解，需要多实践和观察。\n前面我们虽然使用了统一存储来解决Session共享问题，但是我们发现就算实现了Session共享，依然存在一些问题，由于我们每个服务都有自己的验证模块，实际上整个系统是存在冗余功能的、同时还有我们上面出现的问题，那么能否实现只在一个服务进行登录，就可以访问其他的服务呢？\n实际上之前的登录模式称为多点登录，而我们希望的是实现单点登陆，因此，我们得找一个更好的解决方案。\n这里我们首先需要了解一种全新的登录方式：OAuth 2.0，我们经常看到一些网站支持第三方登录，比如淘宝、咸鱼我们就可以使用支付宝进行登录，腾讯游戏可以用QQ或是微信登陆，以及微信小程序都可以直接使用微信进行登录。我们知道它们并不是属于同一个系统，比如淘宝和咸鱼都不属于支付宝这个应用，但是由于需要获取支付宝的用户信息，这时我们就需要使用 OAuth2.0 来实现第三方授权，基于第三方应用访问用户信息的权限（本质上就是给别人调用自己服务接口的权限)，那么它是如何实现的呢？\n四种授权模式 #\r我们还是从理论开始讲解，OAuth 2.0一共有四种授权模式：\n客户端模式（Client Credentials）\n这是最简单的一种模式，我们可以直接向验证服务器请求一个Token（这里可能有些小伙伴对Token的概念不是很熟悉，Token相当于是一个令牌，我们需要在验证服务器**（User Account And Authentication）**服务拿到令牌之后，才能去访问资源，比如用户信息、借阅信息等，这样资源服务器才能知道我们是谁以及是否成功登录了）\n当然，这里的前端页面只是一个例子，它还可以是其他任何类型的客户端，比如App、小程序甚至是第三方应用的服务。\n虽然这种模式比较简便，但是已经失去了用户验证的意义，压根就不是给用户校验准备的，而是更适用于服务内部调用的场景。\n密码模式（Resource Owner Password Credentials）\n密码模式相比客户端模式，就多了用户名和密码的信息，用户需要提供对应账号的用户名和密码，才能获取到Token。\n虽然这样看起来比较合理，但是会直接将账号和密码泄露给客户端，需要后台完全信任客户端不会拿账号密码去干其他坏事，所以这也不是我们常见的。\n隐式授权模式（Implicit Grant）\n首先用户访问页面时，会重定向到认证服务器，接着认证服务器给用户一个认证页面，等待用户授权，用户填写信息完成授权后，认证服务器返回Token。\n它适用于没有服务端的第三方应用页面，并且相比前面一种形式，验证都是在验证服务器进行的，敏感信息不会轻易泄露，但是Token依然存在泄露的风险。\n授权码模式（Authrization Code）\n这种模式是最安全的一种模式，也是推荐使用的一种，比如我们手机上的很多App都是使用的这种模式。\n相比隐式授权模式，它并不会直接返回Token，而是返回授权码，真正的Token是通过应用服务器访问验证服务器获得的。在一开始的时候，应用服务器（客户端通过访问自己的应用服务器来进而访问其他服务）和验证服务器之间会共享一个secret，这个东西没有其他人知道，而验证服务器在用户验证完成之后，会返回一个授权码，应用服务器最后将授权码和secret一起交给验证服务器进行验证，并且Token也是在服务端之间传递，不会直接给到客户端。\n这样就算有人中途窃取了授权码，也毫无意义，因为，Token的获取必须同时携带授权码和secret，但是secret第三方是无法得知的，并且Token不会直接丢给客户端，大大减少了泄露的风险。\n但是乍一看，OAuth 2.0不应该是那种第三方应用为了请求我们的服务而使用的吗，而我们这里需要的只是实现同一个应用内部服务之间的认证，其实我也可以利用 OAuth2.0 来实现单点登录，只是少了资源服务器这一角色，客户端就是我们的整个系统，接下来就让我们来实现一下。\n搭建验证服务器 #\r第一步就是最重要的，我们需要搭建一个验证服务器，它是我们进行权限校验的核心，验证服务器有很多的第三方实现也有Spring官方提供的实现，这里我们使用Spring官方提供的验证服务器。\n这里我们将最开始保存好的项目解压，就重新创建一个新的项目，首先我们在父项目中添加最新的SpringCloud依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.1\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 接着创建一个新的模块auth-service，添加依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- OAuth2.0依赖，不再内置了，所以得我们自己指定一下版本 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-oauth2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 接着我们修改一下配置文件：\nserver: port: 8500 servlet: #为了防止一会在服务之间跳转导致Cookie打架（因为所有服务地址都是localhost，都会存JSESSIONID） #这里修改一下context-path，这样保存的Cookie会使用指定的路径，就不会和其他服务打架了 #但是注意之后的请求都得在最前面加上这个路径 context-path: /sso 接着我们需要编写一下配置类，这里需要两个配置类，一个是OAuth2的配置类，还有一个是SpringSecurity的配置类：\n@Configuration public class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .anyRequest().authenticated() // .and() .formLogin().permitAll(); //使用表单登录 } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); auth .inMemoryAuthentication() //直接创建一个用户，懒得搞数据库了 .passwordEncoder(encoder) .withUser(\u0026#34;test\u0026#34;).password(encoder.encode(\u0026#34;123456\u0026#34;)).roles(\u0026#34;USER\u0026#34;); } @Bean //这里需要将AuthenticationManager注册为Bean，在OAuth配置中使用 @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } @EnableAuthorizationServer //开启验证服务器 @Configuration public class OAuth2Configuration extends AuthorizationServerConfigurerAdapter { @Resource private AuthenticationManager manager; private final BCryptPasswordEncoder encoder = new BCryptPasswordEncoder(); /** * 这个方法是对客户端进行配置，一个验证服务器可以预设很多个客户端， * 之后这些指定的客户端就可以按照下面指定的方式进行验证 * @param clients 客户端配置工具 */ @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() //这里我们直接硬编码创建，当然也可以像Security那样自定义或是使用JDBC从数据库读取 .withClient(\u0026#34;web\u0026#34;) //客户端名称，随便起就行 .secret(encoder.encode(\u0026#34;654321\u0026#34;)) //只与客户端分享的secret，随便写，但是注意要加密 .autoApprove(false) //自动审批，这里关闭，要的就是一会体验那种感觉 .scopes(\u0026#34;book\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;borrow\u0026#34;) //授权范围，这里我们使用全部all .authorizedGrantTypes(\u0026#34;client_credentials\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;implicit\u0026#34;, \u0026#34;authorization_code\u0026#34;, \u0026#34;refresh_token\u0026#34;); //授权模式，一共支持5种，除了之前我们介绍的四种之外，还有一个刷新Token的模式 //这里我们直接把五种都写上，方便一会实验，当然各位也可以单独只写一种一个一个进行测试 //现在我们指定的客户端就支持这五种类型的授权方式了 } @Override public void configure(AuthorizationServerSecurityConfigurer security) { security .passwordEncoder(encoder) //编码器设定为BCryptPasswordEncoder .allowFormAuthenticationForClients() //允许客户端使用表单验证，一会我们POST请求中会携带表单信息 .checkTokenAccess(\u0026#34;permitAll()\u0026#34;); //允许所有的Token查询请求 } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .authenticationManager(manager); //由于SpringSecurity新版本的一些底层改动，这里需要配置一下authenticationManager，才能正常使用password模式 } } 接着我们就可以启动服务器了：\n然后我们使用Postman进行接口测试，首先我们从最简单的客户端模式进行测试，客户端模式只需要提供id和secret即可直接拿到Token，注意需要再添加一个grant_type来表明我们的授权方式，默认请求路径为http://localhost:8500/sso/oauth/token：\n发起请求后，可以看到我们得到了Token，它是以JSON格式给到我们的：\n我们还可以访问 http://localhost:8500/sso/oauth/check_token 来验证我们的Token是否有效：\n可以看到active为true，表示我们刚刚申请到的Token是有效的。\n接着我们来测试一下第二种password模式，我们还需要提供具体的用户名和密码，授权模式定义为password即可：\n接着我们需要在请求头中添加Basic验证信息，这里我们直接填写id和secret即可：\n可以看到在请求头中自动生成了Basic验证相关内容：\n响应成功，得到Token信息，并且这里还多出了一个refresh_token，这是用于刷新Token的，我们之后会进行讲解。\n查询Token信息之后还可以看到登录的具体用户以及角色权限等。\n接着我们来看隐式授权模式，这种模式我们需要在验证服务器上进行登录操作，而不是直接请求Token，验证登录请求地址：http://localhost:8500/sso/oauth/authorize?client_id=web\u0026amp;response_type=token\n注意response_type一定要是token类型，这样才会直接返回Token，浏览器发起请求后，可以看到熟悉而又陌生的界面，没错，实际上这里就是使用我们之前讲解的SpringSecurity进行登陆，当然也可以配置一下记住我之类的功能，这里就不演示了：\n但是登录之后我们发现出现了一个错误：\n这是因为登录成功之后，验证服务器需要将结果给回客户端，所以需要提供客户端的回调地址，这样浏览器就会被重定向到指定的回调地址并且请求中会携带Token信息，这里我们随便配置一个回调地址：\n@Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient(\u0026#34;web\u0026#34;) .secret(encoder.encode(\u0026#34;654321\u0026#34;)) .autoApprove(false) .scopes(\u0026#34;book\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;borrow\u0026#34;) .redirectUris(\u0026#34;http://localhost:8201/login\u0026#34;) //可以写多个，当有多个时需要在验证请求中指定使用哪个地址进行回调 .authorizedGrantTypes(\u0026#34;client_credentials\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;implicit\u0026#34;, \u0026#34;authorization_code\u0026#34;, \u0026#34;refresh_token\u0026#34;); } 接着重启验证服务器，再次访问：\n可以看到这里会让我们选择哪些范围进行授权，就像我们在微信小程序中登陆一样，会让我们授予用户信息权限、支付权限、信用查询权限等，我们可以自由决定要不要给客户端授予访问这些资源的权限，这里我们全部选择授予：\n授予之后，可以看到浏览器被重定向到我们刚刚指定的回调地址中，并且携带了Token信息，现在我们来校验一下看看：\n可以看到，Token也是有效的。\n最后我们来看看第四种最安全的授权码模式，这种模式其实流程和上面是一样的，但是请求的是code类型：http://localhost:8500/sso/oauth/authorize?client_id=web\u0026amp;response_type=code\n可以看到访问之后，依然会进入到回调地址，但是这时给的就是授权码了，而不是直接给Token，那么这个Token该怎么获取呢？\n按照我们之前讲解的原理，我们需要携带授权码和secret一起请求，才能拿到Token，正常情况下是由回调的服务器进行处理，这里我们就在Postman中进行，我们复制刚刚得到的授权码，接口依然是localhost:8500/sso/oauth/token：\n可以看到结果也是正常返回了Token信息：\n这样我们四种最基本的Token请求方式就实现了。\n最后还有一个是刷新令牌使用的，当我们的Token过期时，我们就可以使用这个refresh_token来申请一个新的Token：\n但是执行之后我们发现会直接出现一个内部错误：\n查看日志发现，这里还需要我们单独配置一个UserDetailsService，我们直接把Security中的实例注册为Bean：\n@Bean @Override public UserDetailsService userDetailsServiceBean() throws Exception { return super.userDetailsServiceBean(); } 然后在Endpoint中设置：\n@Resource UserDetailsService service; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .userDetailsService(service) .authenticationManager(manager); } 最后再次尝试刷新Token：\nOK，成功刷新Token，返回了一个新的。\n基于@EnableOAuth2Sso实现 #\r前面我们将验证服务器已经搭建完成了，现在我们就来实现一下单点登陆吧，SpringCloud为我们提供了客户端的直接实现，我们只需要添加一个注解和少量配置即可将我们的服务作为一个单点登陆应用，使用的是第四种授权码模式。\n一句话来说就是，这种模式只是将验证方式由原本的默认登录形式改变为了统一在授权服务器登陆的形式。\n首先还是依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-oauth2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 我们只需要直接在启动类上添加即可：\n@EnableOAuth2Sso @SpringBootApplication public class BookApplication { public static void main(String[] args) { SpringApplication.run(BookApplication.class, args); } } 我们不需要进行额外的配置类，因为这个注解已经帮我们做了：\n@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @EnableOAuth2Client @EnableConfigurationProperties({OAuth2SsoProperties.class}) @Import({OAuth2SsoDefaultConfiguration.class, OAuth2SsoCustomConfiguration.class, ResourceServerTokenServicesConfiguration.class}) public @interface EnableOAuth2Sso { } 可以看到它直接注册了OAuth2SsoDefaultConfiguration，而这个类就是帮助我们对Security进行配置的：\n@Configuration @Conditional({NeedsWebSecurityCondition.class}) public class OAuth2SsoDefaultConfiguration extends WebSecurityConfigurerAdapter { //直接继承的WebSecurityConfigurerAdapter，帮我们把验证设置都写好了 private final ApplicationContext applicationContext; public OAuth2SsoDefaultConfiguration(ApplicationContext applicationContext) { this.applicationContext = applicationContext; } 接着我们需要在配置文件中配置我们的验证服务器相关信息：\nsecurity: oauth2: client: #不多说了 client-id: web client-secret: 654321 #Token获取地址 access-token-uri: http://localhost:8500/sso/oauth/token #验证页面地址 user-authorization-uri: http://localhost:8500/sso/oauth/authorize resource: #Token信息获取和校验地址 token-info-uri: http://localhost:8500/sso/oauth/check_token 现在我们就开启图书服务，调用图书接口：\n可以看到在发现没有登录验证时，会直接跳转到授权页面，进行授权登录，之后才可以继续访问图书服务：\n那么用户信息呢？是否也一并保存过来了？我们这里直接获取一下SpringSecurity的Context查看用户信息，获取方式跟我们之前的视频中讲解的是一样的：\n@RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book findBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid){ //通过SecurityContextHolder将用户信息取出 SecurityContext context = SecurityContextHolder.getContext(); System.out.println(context.getAuthentication()); return service.getBookById(bid); } 再次访问图书管理接口，可以看到：\n这里使用的不是之前的UsernamePasswordAuthenticationToken也不是RememberMeAuthenticationToken，而是新的OAuth2Authentication，它保存了验证服务器的一些信息，以及经过我们之前的登陆流程之后，验证服务器发放给客户端的Token信息，并通过Token信息在验证服务器进行验证获取用户信息，最后保存到Session中，表示用户已验证，所以本质上还是要依赖浏览器存Cookie的。\n接下来我们将所有的服务都使用这种方式进行验证，别忘了把重定向地址给所有服务都加上：\n@Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients .inMemory() .withClient(\u0026#34;web\u0026#34;) .secret(encoder.encode(\u0026#34;654321\u0026#34;)) .autoApprove(true) //这里把自动审批开了，就不用再去手动选同意了 .scopes(\u0026#34;book\u0026#34;, \u0026#34;user\u0026#34;, \u0026#34;borrow\u0026#34;) .redirectUris(\u0026#34;http://localhost:8101/login\u0026#34;, \u0026#34;http://localhost:8201/login\u0026#34;, \u0026#34;http://localhost:8301/login\u0026#34;) .authorizedGrantTypes(\u0026#34;client_credentials\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;implicit\u0026#34;, \u0026#34;authorization_code\u0026#34;, \u0026#34;refresh_token\u0026#34;); } 这样我们就可以实现只在验证服务器登陆，如果登陆过其他的服务都可以访问了。\n但是我们发现一个问题，就是由于SESSION不同步，每次切换不同的服务进行访问都会重新导验证服务器去验证一次：\n这里有两个方案：\n像之前一样做SESSION统一存储 设置context-path路径，每个服务单独设置，就不会打架了 但是这样依然没法解决服务间调用的问题，所以仅仅依靠单点登陆的模式不太行。\n基于@EnableResourceServer实现 #\r前面我们讲解了将我们的服务作为单点登陆应用直接实现单点登陆，那么现在我们如果是以第三方应用进行访问呢？这时我们就需要将我们的服务作为资源服务了，作为资源服务就不会再提供验证的过程，而是直接要求请求时携带Token，而验证过程我们这里就继续用Postman来完成，这才是我们常见的模式。\n一句话来说，跟上面相比，我们只需要携带Token就能访问这些资源服务器了，客户端被独立了出来，用于携带Token去访问这些服务。\n我们也只需要添加一个注解和少量配置即可：\n@EnableResourceServer @SpringBootApplication public class BookApplication { public static void main(String[] args) { SpringApplication.run(BookApplication.class, args); } } 配置中只需要：\nsecurity: oauth2: client: #基操 client-id: web client-secret: 654321 resource: #因为资源服务器得验证你的Token是否有访问此资源的权限以及用户信息，所以只需要一个验证地址 token-info-uri: http://localhost:8500/sso/oauth/check_token 配置完成后，我们启动服务器，直接访问会发现：\n这是由于我们的请求头中没有携带Token信息，现在有两种方式可以访问此资源：\n在URL后面添加access_token请求参数，值为Token值 在请求头中添加Authorization，值为Bearer +Token值 我们先来试试看最简的一种：\n另一种我们需要使用Postman来完成：\n添加验证信息后，会帮助我们转换成请求头信息：\n这样我们就将资源服务器搭建完成了。\n我们接着来看如何对资源服务器进行深度自定义，我们可以为其编写一个配置类，比如我们现在希望用户授权了某个Scope才可以访问此服务：\n@Configuration public class ResourceConfiguration extends ResourceServerConfigurerAdapter { //继承此类进行高度自定义 @Override public void configure(HttpSecurity http) throws Exception { //这里也有HttpSecurity对象，方便我们配置SpringSecurity http .authorizeRequests() .anyRequest().access(\u0026#34;#oauth2.hasScope(\u0026#39;lbwnb\u0026#39;)\u0026#34;); //添加自定义规则 //Token必须要有我们自定义scope授权才可以访问此资源 } } 可以看到当没有对应的scope授权时，那么会直接返回insufficient_scope错误：\n不知道各位是否有发现，实际上资源服务器完全没有必要将Security的信息保存在Session中了，因为现在只需要将Token告诉资源服务器，那么资源服务器就可以联系验证服务器，得到用户信息，就不需要使用之前的Session存储机制了，所以你会发现HttpSession中没有SPRING_SECURITY_CONTEXT，现在Security信息都是通过连接资源服务器获取。\n接着我们将所有的服务都\n但是还有一个问题没有解决，我们在使用RestTemplate进行服务间的远程调用时，会得到以下错误：\n实际上这是因为在服务调用时没有携带Token信息，我们得想个办法把用户传来的Token信息在进行远程调用时也携带上，因此，我们可以直接使用OAuth2RestTemplate，它会在请求其他服务时携带当前请求的Token信息。它继承自RestTemplate，这里我们直接定义一个Bean：\n@Configuration public class WebConfiguration { @Resource OAuth2ClientContext context; @Bean public OAuth2RestTemplate restTemplate(){ return new OAuth2RestTemplate(new ClientCredentialsResourceDetails(), context); } } 接着我们直接替换掉之前的RestTemplate即可：\n@Service public class BorrowServiceImpl implements BorrowService { @Resource BorrowMapper mapper; @Resource OAuth2RestTemplate template; @Override public UserBorrowDetail getUserBorrowDetailByUid(int uid) { List\u0026lt;Borrow\u0026gt; borrow = mapper.getBorrowsByUid(uid); User user = template.getForObject(\u0026#34;http://localhost:8101/user/\u0026#34;+uid, User.class); //获取每一本书的详细信息 List\u0026lt;Book\u0026gt; bookList = borrow .stream() .map(b -\u0026gt; template.getForObject(\u0026#34;http://localhost:8201/book/\u0026#34;+b.getBid(), Book.class)) .collect(Collectors.toList()); return new UserBorrowDetail(user, bookList); } } 可以看到服务成功调用了：\n现在我们来将Nacos加入，并通过Feign实现远程调用。\n依赖还是贴一下，不然找不到：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2021.0.1.0\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-loadbalancer\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 所有服务都已经注册成功了：\n接着我们配置一下借阅服务的负载均衡：\n@Configuration public class WebConfiguration { @Resource OAuth2ClientContext context; @LoadBalanced //和RestTemplate一样直接添加注解就行了 @Bean public OAuth2RestTemplate restTemplate(){ return new OAuth2RestTemplate(new ClientCredentialsResourceDetails(), context); } } 现在我们来把它替换为Feign，老样子，两个客户端：\n@FeignClient(\u0026#34;user-service\u0026#34;) public interface UserClient { @RequestMapping(\u0026#34;/user/{uid}\u0026#34;) User getUserById(@PathVariable(\u0026#34;uid\u0026#34;) int uid); } @FeignClient(\u0026#34;book-service\u0026#34;) public interface BookClient { @RequestMapping(\u0026#34;/book/{bid}\u0026#34;) Book getBookById(@PathVariable(\u0026#34;bid\u0026#34;) int bid); } 但是配置完成之后，又出现刚刚的问题了，OpenFeign也没有携带Token进行访问：\n那么怎么配置Feign携带Token访问呢？遇到这种问题直接去官方查：https://docs.spring.io/spring-cloud-openfeign/docs/current/reference/html/#oauth2-support，非常简单，两个配置就搞定：\nfeign: oauth2: #开启Oauth支持，这样就会在请求头中携带Token了 enabled: true #同时开启负载均衡支持 load-balanced: true 重启服务器，可以看到结果OK了：\n这样我们就成功将之前的三个服务作为资源服务器了，注意和我们上面的作为客户端是不同的，将服务直接作为客户端相当于只需要验证通过即可，并且还是要保存Session信息，相当于只是将登录流程换到统一的验证服务器上进行罢了。而将其作为资源服务器，那么就需要另外找客户端（可以是浏览器、小程序、App、第三方服务等）来访问，并且也是需要先进行验证然后再通过携带Token进行访问，这种模式是我们比较常见的模式。\n使用jwt存储Token #\r官网：https://jwt.io\nJSON Web Token令牌（JWT）是一个开放标准（\rRFC 7519），它定义了一种紧凑和自成一体的方式，用于在各方之间作为JSON对象安全地传输信息。这些信息可以被验证和信任，因为它是数字签名的。JWT可以使用密钥（使用HMAC算法）或使用RSA或ECDSA进行公钥/私钥对进行签名。\n实际上，我们之前都是携带Token向资源服务器发起请求后，资源服务器由于不知道我们Token的用户信息，所以需要向验证服务器询问此Token的认证信息，这样才能得到Token代表的用户信息，但是各位是否考虑过，如果每次用户请求都去查询用户信息，那么在大量请求下，验证服务器的压力可能会非常的大。而使用JWT之后，Token中会直接保存用户信息，这样资源服务器就不再需要询问验证服务器，自行就可以完成解析，我们的目标是不联系验证服务器就能直接完成验证。\nJWT令牌的格式如下：\n一个JWT令牌由3部分组成：标头(Header)、有效载荷(Payload)和签名(Signature)。在传输的时候，会将JWT的3部分分别进行Base64编码后用.进行连接形成最终需要传输的字符串。\n标头：包含一些元数据信息，比如JWT签名所使用的加密算法，还有类型，这里统一都是JWT。 有效载荷：包括用户名称、令牌发布时间、过期时间、JWT ID等，当然我们也可以自定义添加字段，我们的用户信息一般都在这里存放。 签名：首先需要指定一个密钥，该密钥仅仅保存在服务器中，保证不能让其他用户知道。然后使用Header中指定的算法对Header和Payload进行base64加密之后的结果通过密钥计算哈希值，然后就得出一个签名哈希。这个会用于之后验证内容是否被篡改。 这里还是补充一下一些概念，因为很多东西都是我们之前没有接触过的：\nBase64： 就是包括小写字母a-z、大写字母A-Z、数字0-9、符号\u0026quot;+\u0026quot;、\u0026quot;/\u0026ldquo;一共64个字符的字符集（末尾还有1个或多个=用来凑够字节数），任何的符号都可以转换成这个字符集中的字符，这个转换过程就叫做Base64编码，编码之后会生成只包含上述64个字符的字符串。相反，如果需要原本的内容，我们也可以进行Base64解码，回到原有的样子。\npublic void test(){ String str = \u0026#34;你们可能不知道只用20万赢到578万是什么概念\u0026#34;; //Base64不只是可以对字符串进行编码，任何byte[]数据都可以，编码结果可以是byte[]，也可以是字符串 String encodeStr = Base64.getEncoder().encodeToString(str.getBytes()); System.out.println(\u0026#34;Base64编码后的字符串：\u0026#34;+encodeStr); System.out.println(\u0026#34;解码后的字符串：\u0026#34;+new String(Base64.getDecoder().decode(encodeStr))); } 注意Base64不是加密算法，只是一种信息的编码方式而已。\n加密算法： 加密算法分为对称加密和非对称加密，其中**对称加密（Symmetric Cryptography）**比较好理解，就像一把锁配了两把钥匙一样，这两把钥匙你和别人都有一把，然后你们直接传递数据，都会把数据用锁给锁上，就算传递的途中有人把数据窃取了，也没办法解密，因为钥匙只有你和对方有，没有钥匙无法进行解密，但是这样有个问题，既然解密的关键在于钥匙本身，那么如果有人不仅窃取了数据，而且对方那边的治安也不好，于是顺手就偷走了钥匙，那你们之间发的数据不就凉凉了吗。\n因此，**非对称加密（Asymmetric Cryptography）**算法出现了，它并不是直接生成一把钥匙，而是生成一个公钥和一个私钥，私钥只能由你保管，而公钥交给对方或是你要发送的任何人都行，现在你需要把数据传给对方，那么就需要使用私钥进行加密，但是，这个数据只能使用对应的公钥进行解密，相反，如果对方需要给你发送数据，那么就需要用公钥进行加密，而数据只能使用私钥进行解密，这样的话就算对方的公钥被窃取，那么别人发给你的数据也没办法解密出来，因为需要私钥才能解密，而只有你才有私钥。\n因此，非对称加密的安全性会更高一些，包括HTTPS的隐私信息正是使用非对称加密来保障传输数据的安全（当然HTTPS并不是单纯地使用非对称加密完成的，感兴趣的可以去了解一下）\n对称加密和非对称加密都有很多的算法，比如对称加密，就有：DES、IDEA、RC2，非对称加密有：RSA、DAS、ECC\n不可逆加密算法： 常见的不可逆加密算法有MD5, HMAC, SHA-1, SHA-224, SHA-256, SHA-384, 和SHA-512, 其中SHA-224、SHA-256、SHA-384，和SHA-512我们可以统称为SHA2加密算法，SHA加密算法的安全性要比MD5更高，而SHA2加密算法比SHA1的要高，其中SHA后面的数字表示的是加密后的字符串长度，SHA1默认会产生一个160位的信息摘要。经过不可逆加密算法得到的加密结果，是无法解密回去的，也就是说加密出来是什么就是什么了。本质上，其就是一种哈希函数，用于对一段信息产生摘要，以防止被篡改。\n实际上这种算法就常常被用作信息摘要计算，同样的数据通过同样的算法计算得到的结果肯定也一样，而如果数据被修改，那么计算的结果肯定就不一样了。\n这里我们就可以利用jwt，将我们的Token采用新的方式进行存储：\n这里我们使用最简单的一种方式，对称密钥，我们需要对验证服务器进行一些修改：\n@Bean public JwtAccessTokenConverter tokenConverter(){ //Token转换器，将其转换为JWT JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(\u0026#34;lbwnb\u0026#34;); //这个是对称密钥，一会资源服务器那边也要指定为这个 return converter; } @Bean public TokenStore tokenStore(JwtAccessTokenConverter converter){ //Token存储方式现在改为JWT存储 return new JwtTokenStore(converter); //传入刚刚定义好的转换器 } @Resource TokenStore store; @Resource JwtAccessTokenConverter converter; private AuthorizationServerTokenServices serverTokenServices(){ //这里对AuthorizationServerTokenServices进行一下配置 DefaultTokenServices services = new DefaultTokenServices(); services.setSupportRefreshToken(true); //允许Token刷新 services.setTokenStore(store); //添加刚刚的TokenStore services.setTokenEnhancer(converter); //添加Token增强，其实就是JwtAccessTokenConverter，增强是添加一些自定义的数据到JWT中 return services; } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints .tokenServices(serverTokenServices()) //设定为刚刚配置好的AuthorizationServerTokenServices .userDetailsService(service) .authenticationManager(manager); } 然后我们就可以重启验证服务器了：\n可以看到成功获取了AccessToken，但是这里的格式跟我们之前的格式就大不相同了，因为现在它是JWT令牌，我们可以对其进行一下Base64解码：\n可以看到所有的验证信息包含在内，现在我们对资源服务器进行配置：\nsecurity: oauth2: resource: jwt: key-value: lbwnb #注意这里要跟验证服务器的密钥一致，这样算出来的签名才会一致 然后启动资源服务器，请求一下接口试试看：\n请求成功，得到数据：\n注意如果Token有误，那么会得到：\nRedis与分布式 #\r在SpringBoot阶段，我们学习了Redis，它是一个基于内存的高性能数据库，我们当时已经学习了包括基本操作、常用数据类型、持久化、事务和锁机制以及使用Java与Redis进行交互等，利用它的高性能，我们还使用它来做Mybatis的二级缓存、以及Token的持久化存储。而这一部分，我们将继续深入，探讨Redis在分布式开发场景下的应用。\n主从复制 #\r在分布式场景下，我们可以考虑让Redis实现主从模式：\n主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(Master)，后者称为从节点(Slave)，数据的复制是单向的，只能由主节点到从节点。Master以写为主，Slave 以读为主。\n这样的好处肯定是显而易见的：\n实现了读写分离，提高了性能。 在写少读多的场景下，我们甚至可以安排很多个从节点，这样就能够大幅度的分担压力，并且就算挂掉一个，其他的也能使用。 那么我们现在就来尝试实现一下，这里我们还是在Windows下进行测试，打开Redis文件夹，我们要开启两个Redis服务器，修改配置文件redis.windows.conf：\n# Accept connections on the specified port, default is 6379 (IANA #815344).\r# If port 0 is specified Redis will not listen on a TCP socket.\rport 6001 一个服务器的端口设定为6001，复制一份，另一个的端口为6002，接着我们指定配置文件进行启动，打开cmd：\n现在我们的两个服务器就启动成功了，接着我们可以使用命令查看当前服务器的主从状态，我们打开客户端：\n输入info replication命令来查看当前的主从状态，可以看到默认的角色为：master，也就是说所有的服务器在启动之后都是主节点的状态。那么现在我们希望让6002作为从节点，通过一个命令即可：\n可以看到，在输入replicaof 127.0.0.1 6001命令后，就会将6001服务器作为主节点，而当前节点作为6001的从节点，并且角色也会变成：slave，接着我们来看看6001的情况：\n可以看到从节点信息中已经出现了6002服务器，也就是说现在我们的6001和6002就形成了主从关系（还包含一个偏移量，这个偏移量反应的是从节点的同步情况）\n主服务器和从服务器都会维护一个复制偏移量，主服务器每次向从服务器中传递 N 个字节的时候，会将自己的复制偏移量加上 N。从服务器中收到主服务器的 N 个字节的数据，就会将自己额复制偏移量加上 N，通过主从服务器的偏移量对比可以很清楚的知道主从服务器的数据是否处于一致，如果不一致就需要进行增量同步了。\n那么我们现在可以来测试一下，在主节点新增数据，看看是否会同步到从节点：\n可以看到，我们在6001服务器插入的a，可以在从节点6002读取到，那么，从节点新增的数据在主节点能得到吗？我们来测试一下：\n可以看到，从节点压根就没办法进行数据插入，节点的模式为只读模式。那么如果我们现在不想让6002作为6001的从节点了呢？\n可以看到，通过输入replicaof no one，即可变回Master角色。接着我们再来启动一台6003服务器，流程是一样的：\n可以看到，在连接之后，也会直接同步主节点的数据，因此无论是已经处于从节点状态还是刚刚启动完成的服务器，都会从主节点同步数据，实际上整个同步流程为：\n从节点执行replicaof ip port命令后，从节点会保存主节点相关的地址信息。 从节点通过每秒运行的定时任务发现配置了新的主节点后，会尝试与该节点建立网络连接，专门用于接收主节点发送的复制命令。 连接成功后，第一次会将主节点的数据进行全量复制，之后采用增量复制，持续将新来的写命令同步给从节点。 当我们的主节点关闭后，从节点依然可以读取数据：\n但是从节点会疯狂报错：\n当然每次都去敲个命令配置主从太麻烦了，我们可以直接在配置文件中配置，添加这样行即可：\nreplicaof 127.0.0.1 6001 这里我们给6002和6003服务器都配置一下，现在我们重启三个服务器。\n当然，除了作为Master节点的从节点外，我们还可以将其作为从节点的从节点，比如现在我们让6003作为6002的从节点：\n也就是说，现在差不多是这样的的一个情况：\n采用这种方式，优点肯定是显而易见的，但是缺点也很明显，整个传播链路一旦中途出现问题，那么就会导致后面的从节点无法及时同步。\n哨兵模式 #\r前面我们讲解了Redis实现主从复制的一些基本操作，那么我们接着来看哨兵模式。\n经过之前的学习，我们发现，实际上最关键的还是主节点，因为一旦主节点出现问题，那么整个主从系统将无法写入，因此，我们得想一个办法，处理一下主节点故障的情况。实际上我们可以参考之前的服务治理模式，比如Nacos和Eureka，所有的服务都会被实时监控，那么只要出现问题，肯定是可以及时发现的，并且能够采取响应的补救措施，这就是我们即将介绍的哨兵：\n注意这里的哨兵不是我们之前学习SpringCloud Alibaba的那个，是专用于Redis的。哨兵会对所有的节点进行监控，如果发现主节点出现问题，那么会立即让从节点进行投票，选举一个新的主节点出来，这样就不会由于主节点的故障导致整个系统不可写（注意要实现这样的功能最小的系统必须是一主一从，再小的话就没有意义了）\n那么怎么启动一个哨兵呢？我们只需要稍微修改一下配置文件即可，这里直接删除全部内容，添加：\nsentinel monitor lbwnb 127.0.0.1 6001 1 其中第一个和第二个是固定，第三个是为监控对象名称，随意，后面就是主节点的相关信息，包括IP地址和端口，最后一个1我们暂时先不说，然后我们使用此配置文件启动服务器，可以看到启动后：\n可以看到以哨兵模式启动后，会自动监控主节点，然后还会显示那些节点是作为从节点存在的。\n现在我们直接把主节点关闭，看看会发生什么事情：\n可以看到从节点还是正常的在报错，一开始的时候不会直接重新进行选举而是继续尝试重连（因为有可能只是网络小卡一下，没必要这么敏感），但是我们发现，经过一段时间之后，依然无法连接，哨兵输出了以下内容：\n可以看到哨兵发现主节点已经有一段时间不可用了，那么就会开始进行重新选举，6003节点被选为了新的主节点，并且之前的主节点6001变成了新的主节点的从节点：\n当我们再次启动6001时，会发现，它自动变成了6003的从节点，并且会将数据同步过来：\n那么，这个选举规则是怎样的呢？是在所有的从节点中随机选取还是遵循某种规则呢？\n首先会根据优先级进行选择，可以在配置文件中进行配置，添加replica-priority配置项（默认是100），越小表示优先级越高。 如果优先级一样，那就选择偏移量最大的 要是还选不出来，那就选择runid（启动时随机生成的）最小的。 要是哨兵也挂了咋办？没事，咱们可以多安排几个哨兵，只需要把哨兵的配置复制一下，然后修改端口，这样就可以同时启动多个哨兵了，我们启动3个哨兵（一主二从三哨兵），这里我们吧最后一个值改为2：\nsentinel monitor lbwnb 192.168.0.8 6001 2 这个值实际上代表的是当有几个哨兵认为主节点挂掉时，就判断主节点真的挂掉了\n现在我们把6001节点挂掉，看看这三个哨兵会怎么样：\n可以看到都显示将master切换为6002节点了。\n那么，在哨兵重新选举新的主节点之后，我们Java中的Redis的客户端怎么感知到呢？我们来看看，首先还是导入依赖：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; public class Main { public static void main(String[] args) { //这里我们直接使用JedisSentinelPool来获取Master节点 //需要把三个哨兵的地址都填入 try (JedisSentinelPool pool = new JedisSentinelPool(\u0026#34;lbwnb\u0026#34;, new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;192.168.0.8:26741\u0026#34;, \u0026#34;192.168.0.8:26740\u0026#34;, \u0026#34;192.168.0.8:26739\u0026#34;)))) { Jedis jedis = pool.getResource(); //直接询问并得到Jedis对象，这就是连接的Master节点 jedis.set(\u0026#34;test\u0026#34;, \u0026#34;114514\u0026#34;); //直接写入即可，实际上就是向Master节点写入 Jedis jedis2 = pool.getResource(); //再次获取 System.out.println(jedis2.get(\u0026#34;test\u0026#34;)); //读取操作 } catch (Exception e) { e.printStackTrace(); } } } 这样，Jedis对象就可以通过哨兵来获取，当Master节点更新后，也能得到最新的。\n集群搭建 #\r如果我们服务器的内存不够用了，但是现在我们的Redis又需要继续存储内容，那么这个时候就可以利用集群来实现扩容。\n因为单机的内存容量最大就那么多，已经没办法再继续扩展了，但是现在又需要存储更多的内容，这时我们就可以让N台机器上的Redis来分别存储各个部分的数据（每个Redis可以存储1/N的数据量），这样就实现了容量的横向扩展。同时每台Redis还可以配一个从节点，这样就可以更好地保证数据的安全性。\n那么问题来，现在用户来了一个写入的请求，数据该写到哪个节点上呢？我们来研究一下集群的机制：\n首先，一个Redis集群包含16384个插槽，集群中的每个Redis 实例负责维护一部分插槽以及插槽所映射的键值数据，那么这个插槽是什么意思呢？\n实际上，插槽就是键的Hash计算后的一个结果，注意这里出现了计算机网络中的CRC循环冗余校验，这里采用CRC16，能得到16个bit位的数据，也就是说算出来之后结果是0-65535之间，再进行取模，得到最终结果：\nRedis key的路由计算公式：slot = CRC16（key） % 16384\n结果的值是多少，就应该存放到对应维护的Redis下，比如Redis节点1负责0-25565的插槽，而这时客户端插入了一个新的数据a=10，a在Hash计算后结果为666，那么a就应该存放到1号Redis节点中。简而言之，本质上就是通过哈希算法将插入的数据分摊到各个节点的，所以说哈希算法真的是处处都有用啊。\n那么现在我们就来搭建一个简单的Redis集群，这里创建6个配置，注意开启集群模式：\n# Normal Redis instances can\u0026#39;t be part of a Redis Cluster; only nodes that are\r# started as cluster nodes can. In order to start a Redis instance as a\r# cluster node enable the cluster support uncommenting the following:\r#\rcluster-enabled yes 接着记得把所有的持久化文件全部删除，所有的节点内容必须是空的。\n然后输入redis-cli.exe --cluster create --cluster-replicas 1 127.0.0.1:6001 127.0.0.1:6002 127.0.0.1:6003 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003，这里的--cluster-replicas 1指的是每个节点配一个从节点：\n输入之后，会为你展示客户端默认分配的方案，并且会询问你当前的方案是否合理。可以看到6001/6002/6003都被选为主节点，其他的为从节点，我们直接输入yes即可：\n最后分配成功，可以看到插槽的分配情况：\n现在我们随便连接一个节点，尝试插入一个值：\n在插入时，出现了一个错误，实际上这就是因为a计算出来的哈希值（插槽），不归当前节点管，我们得去管这个插槽的节点执行，通过上面的分配情况，我们可以得到15495属于节点6003管理：\n在6003节点插入成功，当然我们也可以使用集群方式连接，这样我们无论在哪个节点都可以插入，只需要添加-c表示以集群模式访问：\n可以看到，在6001节点成功对a的值进行了更新，只不过还是被重定向到了6003节点进行插入。\n我们可以输入cluster nodes命令来查看当前所有节点的信息：\n那么现在如果我们让某一个主节点挂掉会怎么样？现在我们把6001挂掉：\n可以看到原本的6001从节点7001，晋升为了新的主节点，而之前的6001已经挂了，现在我们将6001重启试试看：\n可以看到6001变成了7001的从节点，那么要是6001和7001都挂了呢？\n这时我们尝试插入新的数据：\n可以看到，当存在节点不可用时，会无法插入新的数据，现在我们将6001和7001恢复：\n可以看到恢复之后又可以继续正常使用了。\n最后我们来看一下如何使用Java连接到集群模式下的Redis，我们需要用到JedisCluster对象：\npublic class Main { public static void main(String[] args) { //和客户端一样，随便连一个就行，也可以多写几个，构造方法有很多种可以选择 try(JedisCluster cluster = new JedisCluster(new HostAndPort(\u0026#34;192.168.0.8\u0026#34;, 6003))){ System.out.println(\u0026#34;集群实例数量：\u0026#34;+cluster.getClusterNodes().size()); cluster.set(\u0026#34;a\u0026#34;, \u0026#34;yyds\u0026#34;); System.out.println(cluster.get(\u0026#34;a\u0026#34;)); } } } 操作基本和Jedis对象一样，这里就不多做赘述了。\n分布式锁 #\r在我们的传统单体应用中，经常会用到锁机制，目的是为了防止多线程竞争导致的并发问题，但是现在我们在分布式环境下，又该如何实现锁机制呢？可能一条链路上有很多的应用，它们都是独立运行的，这时我们就可以借助Redis来实现分布式锁。\n还记得我们上一章最后提出的问题吗？\n@Override public boolean doBorrow(int uid, int bid) { //1. 判断图书和用户是否都支持借阅，如果此时来了10个线程，都进来了，那么都能够判断为可以借阅 if(bookClient.bookRemain(bid) \u0026lt; 1) throw new RuntimeException(\u0026#34;图书数量不足\u0026#34;); if(userClient.userRemain(uid) \u0026lt; 1) throw new RuntimeException(\u0026#34;用户借阅量不足\u0026#34;); //2. 首先将图书的数量-1，由于上面10个线程同时进来，同时判断可以借阅，那么这个10个线程就同时将图书数量-1，那库存岂不是直接变成负数了？？？ if(!bookClient.bookBorrow(bid)) throw new RuntimeException(\u0026#34;在借阅图书时出现错误！\u0026#34;); ... } 实际上在高并发下，我们看似正常的借阅流程，会出现问题，比如现在同时来了10个同学要借同一本书，但是现在只有3本，而我们的判断规则是，首先看书够不够，如果此时这10个请求都已经走到这里，并且都判定为可以进行借阅，那么问题就出现了，接下来这10个请求都开始进行借阅操作，导致库存直接爆表，形成超借问题（在电商系统中也存在同样的超卖问题）\n因此，为了解决这种问题，我们就可以利用分布式锁来实现。那么Redis如何去实现分布式锁呢？\n在Redis存在这样一个命令：\nsetnx key value 这个命令看起来和set命令差不多，但是它有一个机制，就是只有当指定的key不存在的时候，才能进行插入，实际上就是set if not exists的缩写。\n可以看到，当客户端1设定a之后，客户端2使用setnx会直接失败。\n当客户端1将a删除之后，客户端2就可以使用setnx成功插入了。\n利用这种特性，我们就可以在不同的服务中实现分布式锁，那么问题来了，要是某个服务加了锁但是卡顿了呢，或是直接崩溃了，那这把锁岂不是永远无法释放了？因此我们还可以考虑加个过期时间：\nset a 666 EX 5 NX 这里使用set命令，最后加一个NX表示是使用setnx的模式，和上面是一样的，但是可以通过EX设定过期时间，这里设置为5秒，也就是说如果5秒还没释放，那么就自动删除。\n当然，添加了过期时间，带了的好处是显而易见的，但是同时也带来了很多的麻烦，我们来设想一下这种情况：\n因此，单纯只是添加过期时间，会出现这种把别人加的锁谁卸了的情况，要解决这种问题也很简单，我们现在的目标就是保证任务只能删除自己加的锁，如果是别人加的锁是没有资格删的，所以我们可以吧a的值指定为我们任务专属的值，比如可以使用UUID之类的，如果在主动删除锁的时候发现值不是我们当前任务指定的，那么说明可能是因为超时，其他任务已经加锁了。\n如果你在学习本篇之前完成了JUC并发编程篇的学习，那么一定会有一个疑惑，如果在超时之前那一刹那进入到释放锁的阶段，获取到值肯定还是自己，但是在即将执行删除之前，由于超时机制导致被删除并且其他任务也加锁了，那么这时再进行删除，仍然会导致删除其他任务加的锁。\n实际上本质还是因为锁的超时时间不太好衡量，如果超时时间能够设定地比较恰当，那么就可以避免这种问题了。\n要解决这个问题，我们可以借助一下Redisson框架，它是Redis官方推荐的Java版的Redis客户端。它提供的功能非常多，也非常强大，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期，它为我们提供了很多种分布式锁的实现，使用起来也类似我们在JUC中学习的锁，这里我们尝试使用一下它的分布式锁功能。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.17.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.netty\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;netty-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.75.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 首先我们来看看不加锁的情况下：\npublic static void main(String[] args) { for (int i = 0; i \u0026lt; 10; i++) { new Thread(() -\u0026gt; { try(Jedis jedis = new Jedis(\u0026#34;192.168.0.10\u0026#34;, 6379)){ for (int j = 0; j \u0026lt; 100; j++) { //每个客户端获取a然后增加a的值再写回去，如果不加锁那么肯定会出问题 int a = Integer.parseInt(jedis.get(\u0026#34;a\u0026#34;)) + 1; jedis.set(\u0026#34;a\u0026#34;, a+\u0026#34;\u0026#34;); } } }).start(); } } 这里没有直接用incr而是我们自己进行计算，方便模拟，可以看到运行结束之后a的值并不是我们想要的：\n现在我们来给它加一把锁，注意这个锁是基于Redis的，不仅仅只可以用于当前应用，是能够垮系统的：\npublic static void main(String[] args) { Config config = new Config(); config.useSingleServer().setAddress(\u0026#34;redis://192.168.0.10:6379\u0026#34;); //配置连接的Redis服务器，也可以指定集群 RedissonClient client = Redisson.create(config); //创建RedissonClient客户端 for (int i = 0; i \u0026lt; 10; i++) { new Thread(() -\u0026gt; { try(Jedis jedis = new Jedis(\u0026#34;192.168.0.10\u0026#34;, 6379)){ RLock lock = client.getLock(\u0026#34;testLock\u0026#34;); //指定锁的名称，拿到锁对象 for (int j = 0; j \u0026lt; 100; j++) { lock.lock(); //加锁 int a = Integer.parseInt(jedis.get(\u0026#34;a\u0026#34;)) + 1; jedis.set(\u0026#34;a\u0026#34;, a+\u0026#34;\u0026#34;); lock.unlock(); //解锁 } } System.out.println(\u0026#34;结束！\u0026#34;); }).start(); } } 可以看到结果没有问题：\n注意，如果用于存放锁的Redis服务器挂了，那么肯定是会出问题的，这个时候我们就可以使用RedLock，它的思路是，在多个Redis服务器上保存锁，只需要超过半数的Redis服务器获取到锁，那么就真的获取到锁了，这样就算挂掉一部分节点，也能保证正常运行，这里就不做演示了。\nMySQL与分布式 #\r前面我讲解了Redis在分布式场景的下的相关应用，接着我们来看看MySQL数据库在分布式场景下的应用。\n主从复制 #\r当我们使用MySQL的时候，也可以采取主从复制的策略，它的实现思路基本和Redis相似，也是采用增量复制的方式，MySQL会在运行的过程中，会记录二进制日志，所有的DML和DDL操作都会被记录进日志中，主库只需要将记录的操作复制给从库，让从库也运行一次，那么就可以实现主从复制。但是注意它不会在一开始进行全量复制，所以最好再开始主从之前将数据库的内容保持一致。\n和之前一样，一旦我们实现了主从复制，那么就算主库出现故障，从库也能正常提供服务，并且还可以实现读写分离等操作。这里我们就使用两台主机来搭建一主一从的环境，首先确保两台服务器都安装了MySQL数据库并且都已经正常运行了：\n接着我们需要创建对应的账号，一会方便从库进行访问的用户：\nCREATE USER test identified with mysql_native_password by \u0026#39;123456\u0026#39;; 接着我们开启一下外网访问：\nsudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 修改配置文件：\n# If MySQL is running as a replication slave, this should be # changed. Ref https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_tmpdir # tmpdir = /tmp # # Instead of skip-networking the default is now to listen only on # localhost which is more compatible and is not less secure. # bind-address = 127.0.0.1 这里注释掉就行 现在我们重启一下MySQL服务：\nsudo systemctl restart mysql.service 现在我们首先来配置主库，主库只需要为我们刚刚创建好的用户分配一个主从复制的权限即可：\ngrant replication slave on *.* to test; FLUSH PRIVILEGES; 然后我们可以输入命令来查看主库的相关情况：\n这样主库就搭建完成了，接着我们需要将从库进行配置，首先是配置文件：\n# The following can be used as easy to replay backup logs or for replication. # note: if you are setting up a replication slave, see README.Debian about # other settings you may need to change. # 这里需要将server-id配置为其他的值（默认是1）所有Mysql主从实例的id必须唯一，不能打架，不然一会开启会失败 server-id = 2 进入数据库，输入：\nchange replication source to SOURCE_HOST=\u0026#39;192.168.0.8\u0026#39;,SOURCE_USER=\u0026#39;test\u0026#39;,SOURCE_PASSWORD=\u0026#39;123456\u0026#39;,SOURCE_LOG_FILE=\u0026#39;binlog.000004\u0026#39;,SOURCE_LOG_POS=591; 注意后面的logfile和pos就是我们上面从主库中显示的信息。\n执行完成后，显示OK表示没有问题，接着输入：\nstart replica; 现在我们的从机就正式启动了，现在我们输入：\nshow replica status\\G; 来查看当前从机状态，可以看到：\n最关键的是下面的Replica_IO_Running和Replica_SQL_Running必须同时为Yes才可以，实际上从库会创建两个线程，一个线程负责与主库进行通信，获取二进制日志，暂时存放到一个中间表（Relay_Log）中，而另一个线程则是将中间表保存的二进制日志的信息进行执行，然后插入到从库中。\n最后配置完成，我们来看看在主库进行操作会不会同步到从库：\n可以看到在主库中创建的数据库，被同步到从库中了，我们再来试试看创建表和插入数据：\nuse yyds; create table test ( `id` int primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); 现在我们随便插入一点数据：\n这样，我们的MySQL主从就搭建完成了，那么如果主机此时挂了会怎么样？\n可以看到IO线程是处于重连状态，会等待主库重新恢复运行。\n分库分表 #\r在大型的互联网系统中，可能单台MySQL的存储容量无法满足业务的需求，这时候就需要进行扩容了。\n和之前的问题一样，单台主机的硬件资源是存在瓶颈的，不可能无限制地纵向扩展，这时我们就得通过多台实例来进行容量的横向扩容，我们可以将数据分散存储，让多台主机共同来保存数据。\n那么问题来了，怎么个分散法？\n垂直拆分： 我们的表和数据库都可以进行垂直拆分，所谓垂直拆分，就是将数据库中所有的表，按照业务功能拆分到各个数据库中（是不是感觉跟前面两章的学习的架构对应起来了）而对于一张表，也可以通过外键之类的机制，将其拆分为多个表。\n水平拆分： 水平拆分针对的不是表，而是数据，我们可以让很多个具有相同表的数据库存放一部分数据，相当于是将数据分散存储在各个节点上。\n那么要实现这样的拆分操作，我们自行去编写代码工作量肯定是比较大的，因此目前实际上已经有一些解决方案了，比如我们可以使用MyCat（也是一个数据库中间件，相当于挂了一层代理，再通过MyCat进行分库分表操作数据库，只需要连接就能使用，类似的还有ShardingSphere-Proxy）或是Sharding JDBC（应用程序中直接对SQL语句进行分析，然后转换成分库分表操作，需要我们自己编写一些逻辑代码），这里我们就讲解一下Sharding JDBC。\nSharding JDBC #\r官方文档（中文）： https://shardingsphere.apache.org/document/5.1.0/cn/overview/#shardingsphere-jdbc\n定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务，它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。\n适用于任何基于 JDBC 的 ORM 框架，如：JPA, Hibernate, Mybatis, Spring JDBC Template 或直接使用 JDBC； 支持任何第三方的数据库连接池，如：DBCP, C3P0, BoneCP, HikariCP 等； 支持任意实现 JDBC 规范的数据库，目前支持 MySQL，PostgreSQL，Oracle，SQLServer 以及任何可使用 JDBC 访问的数据库。 这里我们主要演示一下水平分表方式，我们直接创建一个新的SpringBoot项目即可，依赖如下：\n\u0026lt;dependencies\u0026gt; \u0026lt;!-- ShardingJDBC依赖，那必须安排最新版啊，希望你们看视频的时候还是5.X版本 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shardingsphere\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shardingsphere-jdbc-core-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 数据库我们这里直接用上节课的即可，因为只需要两个表结构一样的数据库即可，正好上节课进行了同步，所以我们直接把从库变回正常状态就可以了：\nstop replica; 接着我们把两个表的root用户密码改一下，一会用这个用户连接数据库：\nupdate user set authentication_string=\u0026#39;\u0026#39; where user=\u0026#39;root\u0026#39;; update user set host = \u0026#39;%\u0026#39; where user = \u0026#39;root\u0026#39;; alter user root identified with mysql_native_password by \u0026#39;123456\u0026#39;; FLUSH PRIVILEGES; 接着我们来看，如果直接尝试开启服务器，那肯定是开不了的，因为我们要配置数据源：\n那么数据源该怎么配置呢？现在我们是一个分库分表的状态，需要配置两个数据源：\nspring: shardingsphere: datasource: # 有几个数据就配几个，这里是名称，按照下面的格式，名称+数字的形式 names: db0,db1 # 为每个数据源单独进行配置 db0: # 数据源实现类，这里使用默认的HikariDataSource type: com.zaxxer.hikari.HikariDataSource # 数据库驱动 driver-class-name: com.mysql.cj.jdbc.Driver # 不用我多说了吧 jdbc-url: jdbc:mysql://192.168.0.8:3306/yyds username: root password: 123456 db1: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://192.168.0.13:3306/yyds username: root password: 123456 如果启动没有问题，那么就是配置成功了：\n接着我们需要对项目进行一些编写，添加我们的用户实体类和Mapper：\n@Data @AllArgsConstructor public class User { int id; String name; String passwd; } @Mapper public interface UserMapper { @Select(\u0026#34;select * from test where id = #{id}\u0026#34;) User getUserById(int id); @Insert(\u0026#34;insert into test(id, name, passwd) values(#{id}, #{name}, #{passwd})\u0026#34;) int addUser(User user); } 实际上这些操作都是常规操作，在编写代码时关注点依然放在业务本身上，现在我们就来编写配置文件，我们需要告诉ShardingJDBC要如何进行分片，首先明确：现在是两个数据库都有test表存放用户数据，我们目标是将用户信息分别存放到这两个数据库的表中。\n不废话了，直接上配置：\nspring: shardingsphere: rules: sharding: tables: #这里填写表名称，程序中对这张表的所有操作，都会采用下面的路由方案 #比如我们上面Mybatis就是对test表进行操作，所以会走下面的路由方案 test: #这里填写实际的路由节点，比如现在我们要分两个库，那么就可以把两个库都写上，以及对应的表 #也可以使用表达式，比如下面的可以简写为 db$-\u0026gt;{0..1}.test actual-data-nodes: db0.test,db1.test #这里是分库策略配置 database-strategy: #这里选择标准策略，也可以配置复杂策略，基于多个键进行分片 standard: #参与分片运算的字段，下面的算法会根据这里提供的字段进行运算 sharding-column: id #这里填写我们下面自定义的算法名称 sharding-algorithm-name: my-alg sharding-algorithms: #自定义一个新的算法，名称随意 my-alg: #算法类型，官方内置了很多种，这里演示最简单的一种 type: MOD props: sharding-count: 2 props: #开启日志，一会方便我们观察 sql-show: true 其中，分片算法有很多内置的，可以在这里查询：https://shardingsphere.apache.org/document/5.1.0/cn/user-manual/shardingsphere-jdbc/builtin-algorithm/sharding/，这里我们使用的是MOD，也就是取模分片算法，它会根据主键的值进行取模运算，比如我们这里填写的是2，那么就表示对主键进行模2运算，根据数据源的名称，比如db0就是取模后为0，db1就是取模后为1（官方文档描述的并不是很清楚），也就是说，最终实现的效果就是单数放在db1，双数放在db0，当然它还支持一些其他的算法，这里就不多介绍了。\n那么现在我们编写一个测试用例来看看，是否能够按照我们上面的规则进行路由：\n@SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { for (int i = 0; i \u0026lt; 10; i++) { //这里ID自动生成1-10，然后插入数据库 mapper.addUser(new User(i, \u0026#34;xxx\u0026#34;, \u0026#34;ccc\u0026#34;)); } } } 现在我们可以开始运行了：\n测试通过，我们来看看数据库里面是不是按照我们的规则进行数据插入的：\n可以看到这两张表，都成功按照我们指定的路由规则进行插入了，我们来看看详细的路由情况，通过控制台输出的SQL就可以看到：\n可以看到所有的SQL语句都有一个Logic SQL（这个就是我们在Mybatis里面写的，是什么就是什么）紧接着下面就是Actual SQL，也就是说每个逻辑SQL最终会根据我们的策略转换为实际SQL，比如第一条数据，它的id是0，那么实际转换出来的SQL会在db0这个数据源进行插入。\n这样我们就很轻松地实现了分库策略。\n分库完成之后，接着我们来看分表，比如现在我们的数据库中有test_0和test_1两张表，表结构一样，但是我们也是希望能够根据id取模运算的结果分别放到这两个不同的表中，实现思路其实是差不多的，这里首先需要介绍一下两种表概念：\n逻辑表： 相同结构的水平拆分数据库（表）的逻辑名称，是 SQL 中表的逻辑标识。 例：订单数据根据主键尾数拆分为 10 张表，分别是 t_order_0 到 t_order_9，他们的逻辑表名为 t_order 真实表： 在水平拆分的数据库中真实存在的物理表。 即上个示例中的 t_order_0 到 t_order_9 现在我们就以一号数据库为例，那么我们在里面创建上面提到的两张表，之前的那个test表删不删都可以，就当做不存在就行了：\ncreate table test_0 ( `id` int primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); create table test_1 ( `id` int primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); 接着我们不要去修改任何的业务代码，Mybatis里面写的是什么依然保持原样，即使我们的表名已经变了，我们需要做的是通过路由来修改原有的SQL，配置如下：\nspring: shardingsphere: rules: sharding: tables: test: actual-data-nodes: db0.test_$-\u0026gt;{0..1} #现在我们来配置一下分表策略，注意这里是table-strategy上面是database-strategy table-strategy: #基本都跟之前是一样的 standard: sharding-column: id sharding-algorithm-name: my-alg sharding-algorithms: my-alg: #这里我们演示一下INLINE方式，我们可以自行编写表达式来决定 type: INLINE props: #比如我们还是希望进行模2计算得到数据该去的表 #只需要给一个最终的表名称就行了test_，后面的数字是表达式取模算出的 #实际上这样写和MOD模式一模一样 algorithm-expression: test_$-\u0026gt;{id % 2} #没错，查询也会根据分片策略来进行，但是如果我们使用的是范围查询，那么依然会进行全量查询 #这个我们后面紧接着会讲，这里先写上吧 allow-range-query-with-inline-sharding: false 现在我们来测试一下，看看会不会按照我们的策略进行分表插入：\n可以看到，根据我们的算法，原本的逻辑表被修改为了最终进行分表计算后的结果，我们来查看一下数据库：\n插入我们了解完毕了，我们来看看查询呢：\n@SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { System.out.println(mapper.getUserById(0)); System.out.println(mapper.getUserById(1)); } } 可以看到，根据我们配置的策略，查询也会自动选择对应的表进行，是不是感觉有内味了。\n那么如果是范围查询呢？\n@Select(\u0026#34;select * from test where id between #{start} and #{end}\u0026#34;) List\u0026lt;User\u0026gt; getUsersByIdRange(int start, int end); @SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { System.out.println(mapper.getUsersByIdRange(3, 5)); } } 我们来看看执行结果会怎么样：\n可以看到INLINE算法默认是不支持进行全量查询的，我们得将上面的配置项改成true：\nallow-range-query-with-inline-sharding: true 再次进行测试：\n可以看到，最终出来的SQL语句是直接对两个表都进行查询，然后求出一个并集出来作为最后的结果。\n当然除了分片之外，还有广播表和绑定表机制，用于多种业务场景下，这里就不多做介绍了，详细请查阅官方文档。\n分布式序列算法 #\r前面我们讲解了如何进行分库分表，接着我们来看看分布式序列算法。\n在复杂分布式系统中，特别是微服构架中，往往需要对大量的数据和消息进行唯一标识。随着系统的复杂，数据的增多，分库分表成为了常见的方案，对数据分库分表后需要有一个唯一ID来标识一条数据或消息（如订单号、交易流水、事件编号等），此时一个能够生成全局唯一ID的系统是非常必要的。\n比如我们之前创建过学生信息表、图书借阅表、图书管理表，所有的信息都会有一个ID作为主键，并且这个ID有以下要求：\n为了区别于其他的数据，这个ID必须是全局唯一的。 主键应该尽可能的保持有序，这样会大大提升索引的查询效率。 那么我们在分布式系统下，如何保证ID的生成满足上面的需求呢？\n使用UUID： UUID是由一组32位数的16进制数字随机构成的，我们可以直接使用JDK为我们提供的UUID类来创建：\npublic static void main(String[] args) { String uuid = UUID.randomUUID().toString(); System.out.println(uuid); } 结果为73d5219b-dc0f-4282-ac6e-8df17bcd5860，生成速度非常快，可以看到确实是能够保证唯一性，因为每次都不一样，而且这么长一串那重复的概率真的是小的可怜。\n但是它并不满足我们上面的第二个要求，也就是说我们需要尽可能的保证有序，而这里我们得到的都是一些无序的ID。\n雪花算法（Snowflake）：\n我们来看雪花算法，它会生成一个一个64bit大小的整型的ID，int肯定是装不下了。\n可以看到它主要是三个部分组成，时间+工作机器ID+序列号，时间以毫秒为单位，41个bit位能表示约70年的时间，时间纪元从2016年11月1日零点开始，可以使用到2086年，工作机器ID其实就是节点ID，每个节点的ID都不相同，那么就可以区分出来，10个bit位可以表示最多1024个节点，最后12位就是每个节点下的序列号，因此每台机器每毫秒就可以有4096个系列号。\n这样，它就兼具了上面所说的唯一性和有序性了，但是依然是有缺点的，第一个是时间问题，如果机器时间出现倒退，那么就会导致生成重复的ID，并且节点容量只有1024个，如果是超大规模集群，也是存在隐患的。\nShardingJDBC支持以上两种算法为我们自动生成ID，文档：https://shardingsphere.apache.org/document/5.1.0/cn/user-manual/shardingsphere-jdbc/builtin-algorithm/keygen/\n这里，我们就是要ShardingJDBC来让我们的主键ID以雪花算法进行生成，首先是配置数据库，因为我们默认的id是int类型，装不下64位的，改一下：\nALTER TABLE `yyds`.`test` MODIFY COLUMN `id` bigint NOT NULL FIRST; 接着我们需要修改一下Mybatis的插入语句，因为现在id是由ShardingJDBC自动生成，我们就不需要自己加了：\n@Insert(\u0026#34;insert into test(name, passwd) values(#{name}, #{passwd})\u0026#34;) int addUser(User user); 接着我们在配置文件中将我们的算法写上：\nspring: shardingsphere: datasource: sharding: tables: test: actual-data-nodes: db0.test,db1.test #这里还是使用分库策略 database-strategy: standard: sharding-column: id sharding-algorithm-name: my-alg #这里使用自定义的主键生成策略 key-generate-strategy: column: id key-generator-name: my-gen key-generators: #这里写我们自定义的主键生成算法 my-gen: #使用雪花算法 type: SNOWFLAKE props: #工作机器ID，保证唯一就行 worker-id: 666 sharding-algorithms: my-alg: type: MOD props: sharding-count: 2 接着我们来编写一下测试用例：\n@SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { for (int i = 0; i \u0026lt; 20; i++) { mapper.addUser(new User(\u0026#34;aaa\u0026#34;, \u0026#34;bbb\u0026#34;)); } } } 可以看到日志：\n在插入的时候，将我们的SQL语句自行添加了一个id字段，并且使用的是雪花算法生成的值，并且也是根据我们的分库策略在进行插入操作。\n读写分离 #\r最后我们来看看读写分离，我们之前实现了MySQL的主从，那么我们就可以将主库作为读，从库作为写：\n这里我们还是将数据库变回主从状态，直接删除当前的表，我们重新来过：\ndrop table test; 我们需要将从库开启只读模式，在MySQL配置中进行修改：\nread-only = 1 这样从库就只能读数据了（但是root账号还是可以写数据），接着我们重启服务器：\nsudo systemctl restart mysql.service 然后进入主库，看看状态：\n现在我们配置一下从库：\nchange replication source to SOURCE_HOST=\u0026#39;192.168.0.13\u0026#39;,SOURCE_USER=\u0026#39;test\u0026#39;,SOURCE_PASSWORD=\u0026#39;123456\u0026#39;,SOURCE_LOG_FILE=\u0026#39;binlog.000007\u0026#39;,SOURCE_LOG_POS=19845; start replica; 现在我们在主库创建表：\ncreate table test ( `id` bigint primary key, `name` varchar(255) NULL, `passwd` varchar(255) NULL ); 然后我们就可以配置ShardingJDBC了，打开配置文件：\nspring: shardingsphere: rules: #配置读写分离 readwrite-splitting: data-sources: #名称随便写 user-db: #使用静态类型，动态Dynamic类型可以自动发现auto-aware-data-source-name，这里不演示 type: Static props: #配置写库（只能一个） write-data-source-name: db0 #配置从库（多个，逗号隔开） read-data-source-names: db1 #负载均衡策略，可以自定义 load-balancer-name: my-load load-balancers: #自定义的负载均衡策略 my-load: type: ROUND_ROBIN 注意把之前改的用户实体类和Mapper改回去，这里我们就不用自动生成ID的了。所有的负载均衡算法地址：https://shardingsphere.apache.org/document/5.1.0/cn/user-manual/shardingsphere-jdbc/builtin-algorithm/load-balance/\n现在我们就来测试一下吧：\n@SpringBootTest class ShardingJdbcTestApplicationTests { @Resource UserMapper mapper; @Test void contextLoads() { mapper.addUser(new User(10, \u0026#34;aaa\u0026#34;, \u0026#34;bbb\u0026#34;)); System.out.println(mapper.getUserById(10)); } } 运行看看SQL日志：\n可以看到，当我们执行插入操作时，会直接向db0进行操作，而读取操作是会根据我们的配置，选择db1进行操作。\n至此，微服务应用章节到此结束。\n———————————————— 版权声明：本文为柏码知识库版权所有，禁止一切未经授权的转载、发布、出售等行为，违者将被追究法律责任。 原文链接：https://www.itbaima.cn/document/35v1hbsfcdgagdnw\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/cloud/%E4%BA%8C/","section":"Docs","summary":"微服务应用 #\r前面我们已经完成了SpringCloudAlibaba的学习，我们对一个微服务项目的架构体系已经有了一定的了解，那么本章我们将在应用层面继续探讨微服务。\n分布式权限校验 #\r虽然完成前面的部分，我们已经可以自己去编写一个比较中规中矩的微服务项目了，但是还有一个问题我们没有解决，登录问题。假如现在要求用户登录之后，才能进行图书的查询、借阅等操作，那么我们又该如何设计这个系统呢？\n回顾我们之前进行权限校验的原理，服务器是如何判定一个请求是来自哪个用户的呢？\n首先浏览器会向服务端发送请求，访问我们的网站。 服务端收到请求后，会创建一个SESSION ID，并暂时存储在服务端，然后会发送给浏览器作为Cookie保存。 之后浏览器会一直携带此Cookie访问服务器，这样在收到请求后，就能根据携带的Cookie中的SESSION ID判断是哪个用户了。 这样服务端和浏览器之间可以轻松地建立会话了。 但是我们想一下，我们现在采用的是分布式的系统，那么在用户服务进行登录之后，其他服务比如图书服务和借阅服务，它们会知道用户登录了吗？\n实际上我们登录到用户服务之后，Session中的用户数据只会在用户服务的应用中保存，而在其他服务中，并没有对应的信息，但是我们现在希望的是，所有的服务都能够同步这些Session信息，这样我们才能实现在用户服务登录之后其他服务都能知道，那么我们该如何实现Session的同步呢？\n我们可以在每台服务器上都复制一份Session，但是这样显然是很浪费时间的，并且用户验证数据占用的内存会成倍的增加。 将Session移出服务器，用统一存储来存放，比如我们可以直接在Redis或是MySQL中存放用户的Session信息，这样所有的服务器在需要获取Session信息时，统一访问Redis或是MySQL即可，这样就能保证所有服务都可以同步Session了（是不是越来越感觉只要有问题，没有什么是加一个中间件解决不了的） 那么，我们就着重来研究一下，然后实现2号方案，这里我们就使用Redis作为Session统一存储，我们把一开始的压缩包重新解压一次，又来从头开始编写吧。\n这里我们就只使用Nacos就行了，和之前一样，我们把Nacos的包导入一下，然后进行一些配置：\n现在我们需要为每个服务都添加验证机制，首先导入依赖：\n\u0026lt;!-- SpringSession Redis支持 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 添加Redis的Starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.","title":"SpringCloud 3","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/sql/","section":"Series","summary":"","title":"sql","type":"series"},{"content":"\r设计模式（创建型） #\r软件设计模式（Design pattern），又称设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性、程序的重用性。\n肯特·贝克和\r沃德·坎宁安在1987年利用克里斯托佛·亚历山大在建筑设计领域里的思想开发了设计模式并把此思想应用在Smalltalk中的图形用户接口的生成中。一年后Erich Gamma在他的\r苏黎世大学博士毕业论文中开始尝试把这种思想改写为适用于软件开发。与此同时James Coplien 在1989年至1991 年也在利用相同的思想致力于C++的开发，而后于1991年发表了他的著作Advanced C++ Idioms。就在这一年Erich Gamma 得到了博士学位，然后去了美国，在那与Richard Helm, Ralph Johnson ,John Vlissides合作出版了Design Patterns - Elements of Reusable Object-Oriented Software 一书，在此书中共收录了23个设计模式。这四位作者在软件开发领域里也以他们的匿名著称Gang of Four(四人帮，简称GoF),并且是他们在此书中的协作导致了软件设计模式的突破。\n我们先来看看有关对象创建的几种设计模式。\n工厂方法模式 #\r首当其冲的是最简单的一种设计模式——工厂方法模式，我们知道，如果需要创建一个对象，那么最简单的方式就是直接new一个即可。而工厂方法模式代替了传统的直接new的形式，那么为什么要替代传统的new形式呢？\n可以想象一下，如果所有的对象我们都通过new的方式去创建，那么当我们的程序中大量使用此对象时，突然有一天这个对象的构造方法或是类名发生了修改，那我们岂不是得挨个去进行修改？根据迪米特法则，我们应该尽可能地少与其他类进行交互，所以我们可以将那些需要频繁出现的对象创建，封装到一个工厂类中，当我们需要对象时，直接调用工厂类中的工厂方法来为我们生成对象，这样，就算类出现了变动，我们也只需要修改工厂中的代码即可，而不是大面积地进行修改。\n同时，可能某些对象的创建并不只是一个new就可以搞定，可能还需要更多的步骤来准备构造方法需要的参数，所以我们来看看如何使用简单工厂模式来创建对象，既然是工厂，那么我们就来创建点工厂需要生产的东西：\npublic abstract class Fruit { //水果抽象类 private final String name; public Fruit(String name){ this.name = name; } @Override public String toString() { return name+\u0026#34;@\u0026#34;+hashCode(); //打印一下当前水果名称，还有对象的hashCode } } public class Apple extends Fruit{ //苹果，继承自水果 public Apple() { super(\u0026#34;苹果\u0026#34;); } } public class Orange extends Fruit{ //橘子，也是继承自水果 public Orange() { super(\u0026#34;橘子\u0026#34;); } } 正常情况下，我们直接new就可以得到对象了：\npublic class Main { public static void main(String[] args) { Apple apple = new Apple(); System.out.println(apple); } } 现在我们将对象的创建封装到工厂中：\npublic class FruitFactory { /** * 这里就直接来一个静态方法根据指定类型进行创建 * @param type 水果类型 * @return 对应的水果对象 */ public static Fruit getFruit(String type) { switch (type) { case \u0026#34;苹果\u0026#34;: return new Apple(); case \u0026#34;橘子\u0026#34;: return new Orange(); default: return null; } } } 现在我们就可以使用此工厂来创建对象了：\npublic class Main { public static void main(String[] args) { Fruit fruit = FruitFactory.getFruit(\u0026#34;橘子\u0026#34;); //直接问工厂要，而不是我们自己去创建 System.out.println(fruit); } } 不过这样还是有一些问题，我们前面提到了开闭原则，一个软件实体，比如类、模块和函数应该对扩展开放，对修改关闭，但是如果我们现在需要新增一种水果，比如桃子，那么这时我们就得去修改工厂提供的工厂方法了，但是这样是不太符合开闭原则的，因为工厂实际上是针对于调用方提供的，所以我们应该尽可能对修改关闭。\n所以，我们就利用对扩展开放，对修改关闭的性质，将简单工厂模式改进为工厂方法模式，那现在既然不让改，那么我们就看看如何去使用扩展的形式：\npublic abstract class FruitFactory\u0026lt;T extends Fruit\u0026gt; { //将水果工厂抽象为抽象类，添加泛型T由子类指定水果类型 public abstract T getFruit(); //不同的水果工厂，通过此方法生产不同的水果 } public class AppleFactory extends FruitFactory\u0026lt;Apple\u0026gt; { //苹果工厂，直接返回Apple，一步到位 @Override public Apple getFruit() { return new Apple(); } } 这样，我们就可以使用不同类型的工厂来生产不同类型的水果了，并且如果新增了水果类型，直接创建一个新的工厂类就行，不需要修改之前已经编写好的内容。\npublic class Main { public static void main(String[] args) { test(new AppleFactory()::getFruit); //比如我们现在要吃一个苹果，那么就直接通过苹果工厂来获取苹果 } //此方法模拟吃掉一个水果 private static void test(Supplier\u0026lt;Fruit\u0026gt; supplier){ System.out.println(supplier.get()+\u0026#34; 被吃掉了，真好吃。\u0026#34;); } } 这样，我们就简单实现了工厂方法模式，通过工厂来屏蔽对象的创建细节，使用者只需要关心如何去使用对象即可。\n抽象工厂模式 #\r前面我们介绍了工厂方法模式，通过定义顶层抽象工厂类，通过继承的方式，针对于每一个产品都提供一个工厂类用于创建。\n不过这种模式只适用于简单对象，当我们需要生产许多个产品族的时候，这种模式就有点乏力了，比如：\n实际上这些产品都是成族出现的，比如小米的产品线上有小米12，小米平板等，华为的产品线上也有华为手机、华为平板，但是如果按照我们之前工厂方法模式来进行设计，那就需要单独设计9个工厂来生产上面这些产品，显然这样就比较浪费时间的。\n但是现在有什么方法能够更好地处理这种情况呢？我们就可以使用抽象工厂模式，我们可以将多个产品，都放在一个工厂中进行生成，按不同的产品族进行划分，比如小米，那么我就可以安排一个小米工厂，而这个工厂里面就可以生产整条产品线上的内容，包括小米手机、小米平板、小米路由等。\n所以，我们只需要建立一个抽象工厂即可：\npublic class Router { } public class Table { } public class Phone { } public abstract class AbstractFactory { public abstract Phone getPhone(); public abstract Table getTable(); public abstract Router getRouter(); } 一个工厂可以生产同一个产品族的所有产品，这样按族进行分类，显然比之前的工厂方法模式更好。\n不过，缺点还是有的，如果产品族新增了产品，那么我就不得不去为每一个产品族的工厂都去添加新产品的生产方法，违背了开闭原则。\n建造者模式 #\r建造者模式也是非常常见的一种设计模式，我们经常看到有很多的框架都为我们提供了形如XXXBuilder的类型，我们一般也是使用这些类来创建我们需要的对象。\n比如，我们在JavaSE中就学习过的StringBuiler类：\npublic static void main(String[] args) { StringBuilder builder = new StringBuilder(); //创建一个StringBuilder来逐步构建一个字符串 builder.append(666); //拼接一个数字 builder.append(\u0026#34;老铁\u0026#34;); //拼接一个字符串 builder.insert(2, \u0026#39;?\u0026#39;); //在第三个位置插入一个字符 System.out.println(builder.toString()); //差不多成形了，最后转换为字符串 } 实际上我们是通过建造者来不断配置参数或是内容，当我们配置完所有内容后，最后再进行对象的构建。\n相比直接去new一个新的对象，建造者模式的重心更加关注在如何完成每一步的配置，同时如果一个类的构造方法参数过多，我们通过建造者模式来创建这个对象，会更加优雅。\n比如我们现在有一个学生类：\npublic class Student { int id; int age; int grade; String name; String college; String profession; List\u0026lt;String\u0026gt; awards; public Student(int id, int age, int grade, String name, String college, String profession, List\u0026lt;String\u0026gt; awards) { this.id = id; this.age = age; this.grade = grade; this.name = name; this.college = college; this.profession = profession; this.awards = awards; } } 可以看到这个学生类的属性是非常多的，所以构造方法不是一般的长，如果我们现在直接通过new的方式去创建：\npublic static void main(String[] args) { Student student = new Student(1, 18, 3, \u0026#34;小明\u0026#34;, \u0026#34;计算机学院\u0026#34;, \u0026#34;计算机科学与技术\u0026#34;, Arrays.asList(\u0026#34;ICPC-ACM 区域赛 金牌\u0026#34;, \u0026#34;LPL 2022春季赛 冠军\u0026#34;)); } 可以看到，我们光是填参数就麻烦，我们还得一个一个对应着去填，一不小心可能就把参数填到错误的位置了。\n所以，我们现在可以使用建造者模式来进行对象的创建：\npublic class Student { ... //一律使用建造者来创建，不对外直接开放 private Student(int id, int age, int grade, String name, String college, String profession, List\u0026lt;String\u0026gt; awards) { ... } public static StudentBuilder builder(){ //通过builder方法直接获取建造者 return new StudentBuilder(); } public static class StudentBuilder{ //这里就直接创建一个内部类 //Builder也需要将所有的参数都进行暂时保存，所以Student怎么定义的这里就怎么定义 int id; int age; int grade; String name; String college; String profession; List\u0026lt;String\u0026gt; awards; public StudentBuilder id(int id){ //直接调用建造者对应的方法，为对应的属性赋值 this.id = id; return this; //为了支持链式调用，这里直接返回建造者本身，下同 } public StudentBuilder age(int age){ this.age = age; return this; } ... public StudentBuilder awards(String... awards){ this.awards = Arrays.asList(awards); return this; } public Student build(){ //最后我们只需要调用建造者提供的build方法即可根据我们的配置返回一个对象 return new Student(id, age, grade, name, college, profession, awards); } } } 现在，我们就可以使用建造者来为我们生成对象了：\npublic static void main(String[] args) { Student student = Student.builder() //获取建造者 .id(1) //逐步配置各个参数 .age(18) .grade(3) .name(\u0026#34;小明\u0026#34;) .awards(\u0026#34;ICPC-ACM 区域赛 金牌\u0026#34;, \u0026#34;LPL 2022春季赛 冠军\u0026#34;) .build(); //最后直接建造我们想要的对象 } 这样，我们就可以让这些参数对号入座了，并且也比之前的方式优雅许多。\n单例模式 #\r单例模式其实在之前的课程中已经演示过很多次了，这也是使用频率非常高的一种模式。\n那么，什么是单例模式呢？顾名思义，单例那么肯定就是只有一个实例对象，在我们的整个程序中，同一个类始终只会有一个对象来进行操作。比如数据库连接类，实际上我们只需要创建一个对象或是直接使用静态方法就可以了，没必要去创建多个对象。\n这里还是还原一下我们之前使用的简单单例模式：\npublic class Singleton { private final static Singleton INSTANCE = new Singleton(); //用于引用全局唯一的单例对象，在一开始就创建好 private Singleton() {} //不允许随便new，需要对象直接找getInstance public static Singleton getInstance(){ //获取全局唯一的单例对象 return INSTANCE; } } 这样，当我们需要获取此对象时，只能通过getInstance()来获取唯一的对象：\npublic static void main(String[] args) { Singleton singleton = Singleton.getInstance(); } 当然，单例模式除了这种写法之外，还有其他写法，这种写法被称为饿汉式单例，也就是说在一开始类加载时就创建好了，我们来看看另一种写法——懒汉式：\npublic class Singleton { private static Singleton INSTANCE; //在一开始先不进行对象创建 private Singleton() {} //不用多说了吧 public static Singleton getInstance(){ //将对象的创建延后到需要时再进行 if(INSTANCE == null) { //如果实例为空，那么就进行创建，不为空说明已经创建过了，那么就直接返回 INSTANCE = new Singleton(); } return INSTANCE; } } 可以看到，懒汉式就真的是条懒狗，你不去用它，它是不会给你提前准备单例对象的（延迟加载，懒加载），当我们需要获取对象时，才会进行检查并创建。虽然饿汉式和懒汉式写法不同，但是最后都是成功实现了单例模式。\n不过，这里需要特别提醒一下，由于懒汉式是在方法中进行的初始化，在多线程环境下，可能会出现问题（建议学完JUC篇视频教程再来观看）大家可以试想一下，如果这个时候有多个线程同时调用了getInstance()方法，那么会出现什么问题呢？\n可以看到，在多线程环境下，如果三条线程同时调用getInstance()方法，会同时进行INSTANCE == null的判断，那么此时由于确实还没有进行任何实例化，所以导致三条线程全部判断为true（而饿汉式由于在类加载时就创建完成，不会存在这样的问题）此时问题就来了，我们既然要使用单例模式，那么肯定是只希望对象只被初始化一次的，但是现在由于多线程的机制，导致对象被多次创建。\n所以，为了避免线程安全问题，针对于懒汉式单例，我们还得进行一些改进：\npublic static synchronized Singleton getInstance(){ //方法必须添加synchronized关键字加锁 if(INSTANCE == null) { INSTANCE = new Singleton(); } return INSTANCE; } 既然多个线程要调用，那么我们就直接加一把锁，在方法上添加synchronized关键字即可，这样同一时间只能有一个线程进入了。虽然这样简单粗暴，但是在高并发的情况下，效率肯定是比较低的，我们来看看如何进行优化：\npublic static Singleton getInstance(){ if(INSTANCE == null) { synchronized (Singleton.class) { //实际上只需要对赋值这一步进行加锁即可 INSTANCE = new Singleton(); } } return INSTANCE; } 不过这样还不完美，因为这样还是有可能多个线程同时判断为null而进入等锁的状态，所以，我们还得加一层内层判断：\npublic static Singleton getInstance(){ if(INSTANCE == null) { synchronized (Singleton.class) { if(INSTANCE == null) INSTANCE = new Singleton(); //内层还要进行一次检查，双重检查锁定 } } return INSTANCE; } 不过我们还少考虑了一样内容，其实IDEA此时应该是给了黄标了：\n可以看到，这种情况下，IDEA会要求我们添加一个volatile给INSTANCE，各位还记得这个关键字有什么作用吗？没错，我们还需要保证INSTANCE在线程之间的可见性，这样当其他线程进入之后才会拿INSTANCE由其他线程更新的最新值去判断，这样，就差不多完美了。\n那么，有没有一种更好的，不用加锁的方式也能实现延迟加载的写法呢？我们可以使用静态内部类：\npublic class Singleton { private Singleton() {} private static class Holder { //由静态内部类持有单例对象，但是根据类加载特性，我们仅使用Singleton类时，不会对静态内部类进行初始化 private final static Singleton INSTANCE = new Singleton(); } public static Singleton getInstance(){ //只有真正使用内部类时，才会进行类初始化 return Holder.INSTANCE; //直接获取内部类中的 } } 这种方式显然是最完美的懒汉式解决方案，没有进行任何的加锁操作，也能保证线程安全，不过要实现这种写法，跟语言本身也有一定的关联，并不是所有的语言都支持这种写法。\n原型模式 #\r原型模式实际上与对象的拷贝息息相关，原型模式使用原型实例指定待创建对象的类型，并且通过复制这个原型来创建新的对象。也就是说，原型对象作为模板，通过克隆操作，来产生更多的对象，就像细胞的复制一样。\n开始之前，我们先介绍一下对象的深拷贝和浅拷贝，首先我们来看浅拷贝：\n**浅拷贝：**对于类中基本数据类型，会直接复制值给拷贝对象；对于引用类型，只会复制对象的地址，而实际上指向的还是原来的那个对象，拷贝个基莫。\npublic static void main(String[] args) { int a = 10; int b = a; //基本类型浅拷贝 System.out.println(a == b); Object o = new Object(); Object k = o; //引用类型浅拷贝，拷贝的仅仅是对上面对象的引用 System.out.println(o == k); } **深拷贝：**无论是基本类型还是引用类型，深拷贝会将引用类型的所有内容，全部拷贝为一个新的对象，包括对象内部的所有成员变量，也会进行拷贝。\n在Java中，我们就可以使用Cloneable接口提供的拷贝机制，来实现原型模式：\npublic class Student implements Cloneable{ //注意需要实现Cloneable接口 @Override public Object clone() throws CloneNotSupportedException { //提升clone方法的访问权限 return super.clone(); } } 接着我们来看看克隆的对象是不是原来的对象：\npublic static void main(String[] args) throws CloneNotSupportedException { Student student0 = new Student(); Student student1 = (Student) student0.clone(); System.out.println(student0); System.out.println(student1); } 可以看到，通过clone()方法克隆的对象并不是原来的对象，我们来看看如果对象内部有属性会不会一起进行克隆：\npublic class Student implements Cloneable{ String name; public Student(String name){ this.name = name; } public String getName() { return name; } @Override public Object clone() throws CloneNotSupportedException { return super.clone(); } } public static void main(String[] args) throws CloneNotSupportedException { Student student0 = new Student(\u0026#34;小明\u0026#34;); Student student1 = (Student) student0.clone(); System.out.println(student0.getName() == student1.getName()); } 可以看到，虽然Student对象成功拷贝，但是其内层对象并没有进行拷贝，依然只是对象引用的复制，所以Java为我们提供的clone方法只会进行浅拷贝。那么如何才能实现深拷贝呢？\n@Override public Object clone() throws CloneNotSupportedException { //这里我们改进一下，针对成员变量也进行拷贝 Student student = (Student) super.clone(); student.name = new String(name); return student; //成员拷贝完成后，再返回 } 这样，我们就实现了深拷贝。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/design/%E5%88%9B%E5%BB%BA%E5%9E%8B/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BA%8C%E5%88%9B%E5%BB%BA%E5%9E%8B/","section":"Docs","summary":"设计模式（创建型） #\r软件设计模式（Design pattern），又称设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性、程序的重用性。\n肯特·贝克和\r沃德·坎宁安在1987年利用克里斯托佛·亚历山大在建筑设计领域里的思想开发了设计模式并把此思想应用在Smalltalk中的图形用户接口的生成中。一年后Erich Gamma在他的\r苏黎世大学博士毕业论文中开始尝试把这种思想改写为适用于软件开发。与此同时James Coplien 在1989年至1991 年也在利用相同的思想致力于C++的开发，而后于1991年发表了他的著作Advanced C++ Idioms。就在这一年Erich Gamma 得到了博士学位，然后去了美国，在那与Richard Helm, Ralph Johnson ,John Vlissides合作出版了Design Patterns - Elements of Reusable Object-Oriented Software 一书，在此书中共收录了23个设计模式。这四位作者在软件开发领域里也以他们的匿名著称Gang of Four(四人帮，简称GoF),并且是他们在此书中的协作导致了软件设计模式的突破。","title":"创建型","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/tags/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/","section":"Tags","summary":"","title":"代码随想录","type":"tags"},{"content":"确定区间\n左闭右闭\nleft = 0; right = nums.size() - 1; while(left \u0026lt;= right){ // 区间为空 结束循环 ： (l \u0026gt; r) //左右相等是合法区间，比如【1，1】只有 元素1 mid = left + (right-left)\u0026gt;\u0026gt;2; if(nums[mid]\u0026gt;target){ right = mid -1;//为了不包含原来的nums[mid],所以减一 }else if(nums[mid]\u0026lt;target){ left = mid +1; }else return mid; } return -1; class Solution { public int search(int[] nums, int target) { int left = 0; int right = nums.length-1; while(left \u0026lt;= right){ int mid =left + (right-left) /2; if(nums[mid] \u0026gt; target){ right=mid-1; }else if(nums[mid] \u0026lt; target){ left = mid +1; }else{ return mid; } } return -1; } } 左闭右开\n//左闭右开不是合法区间，比如【1，1)没有 元素1 left = 0; right = nums.size() ;//左闭右开，本来就不包含 while(left \u0026lt; right){ // 区间为空 结束循环 ： (l == r) mid = left + (right-left)/2; if(nums[mid]\u0026gt;target){ // nums[mid] \u0026gt;= target 查询[l,mid） right = mid;//左闭右开，本来就不包含 }else if(nums[mid]\u0026lt;target){ // 查询[mid+1,r), left = mid +1; }else{ return mid; } } return -1; ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E4%BA%8C%E5%88%86%E6%B3%95/","section":"Algorithms","summary":"确定区间\n左闭右闭\nleft = 0; right = nums.size() - 1; while(left \u0026lt;= right){ // 区间为空 结束循环 ： (l \u0026gt; r) //左右相等是合法区间，比如【1，1】只有 元素1 mid = left + (right-left)\u0026gt;\u0026gt;2; if(nums[mid]\u0026gt;target){ right = mid -1;//为了不包含原来的nums[mid],所以减一 }else if(nums[mid]\u0026lt;target){ left = mid +1; }else return mid; } return -1; class Solution { public int search(int[] nums, int target) { int left = 0; int right = nums.","title":"二分法","type":"algorithm"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/%E7%AC%94%E8%AE%B0/featured/","section":"笔记s","summary":"","title":"封面测试","type":"笔记"},{"content":"master公式：\n在编程中，递归是非常常见的一种算法，由于代码简洁而应用广泛，但递归相比顺序执行或循环程序，时间复杂度难以计算，而master公式就是用于计算递归程序的时间复杂度。\nT(N) = a*T(N/b) + O(N^d);\n​ 下面对参数进行解释:\nb：子过程的样本量 a：子过程的计算次数 O(N^d)：子结果合并的时间复杂度 满足如上公式的程序都可以根据master公式计算时间复杂度：\nlog(b，a) \u0026gt; d ：时间复杂度为O(N^log(b，a)) log(b，a) = d ：时间复杂度为O(N^d * logN) log(b，a) \u0026lt; d ：时间复杂度为O(N^d)\n在学习归并排序之前，我们先学习一个简单的算法:当我们求一个值的中值时，可以使用：\nint mid = L + ((R - L) \u0026raquo; 1); 注意使用位运算更好，之后采用这种方法来计算平均数\n​ 这样可以避免内存泄露。\n归并排序：\n思想很简单，写一个临时数组，比较需要传入的对应元素，小的先放好，大的后放。\n","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E7%AE%97%E6%B3%95/c/","section":"Algorithms","summary":"master公式：\n在编程中，递归是非常常见的一种算法，由于代码简洁而应用广泛，但递归相比顺序执行或循环程序，时间复杂度难以计算，而master公式就是用于计算递归程序的时间复杂度。\nT(N) = a*T(N/b) + O(N^d);\n​ 下面对参数进行解释:\nb：子过程的样本量 a：子过程的计算次数 O(N^d)：子结果合并的时间复杂度 满足如上公式的程序都可以根据master公式计算时间复杂度：\nlog(b，a) \u0026gt; d ：时间复杂度为O(N^log(b，a)) log(b，a) = d ：时间复杂度为O(N^d * logN) log(b，a) \u0026lt; d ：时间复杂度为O(N^d)\n在学习归并排序之前，我们先学习一个简单的算法:当我们求一个值的中值时，可以使用：\nint mid = L + ((R - L) \u0026raquo; 1); 注意使用位运算更好，之后采用这种方法来计算平均数","title":"复杂度","type":"algorithm"},{"content":"字母异位词\nclass Solution { public: bool isAnagram(string s, string t) { int record[26] = {0}; for (int i = 0; i \u0026lt; s.size(); i++) { // 并不需要记住字符a的ASCII，只要求出一个相对数值就可以了 record[s[i] - \u0026#39;a\u0026#39;]++; } for (int i = 0; i \u0026lt; t.size(); i++) { record[t[i] - \u0026#39;a\u0026#39;]--; } for (int i = 0; i \u0026lt; 26; i++) { if (record[i] != 0) { // record数组如果有的元素不为零0，说明字符串s和t 一定是谁多了字符或者谁少了字符。 return false; } } // record数组所有元素都为零0，说明字符串s和t是字母异位词 return true; } }; 重叠数\nclass Solution { public: vector\u0026lt;int\u0026gt; intersection(vector\u0026lt;int\u0026gt;\u0026amp; nums1, vector\u0026lt;int\u0026gt;\u0026amp; nums2) { vector\u0026lt;int\u0026gt; res(0); if (nums1.size()==0||nums2.size()==0){ return res; } unordered_set\u0026lt;int\u0026gt; setp; unordered_set\u0026lt;int\u0026gt; setq; for (int i = 0; i \u0026lt; nums1.size(); ++i) { setp.insert(nums1[i]); } //在前面的数组中出现过 for (int i = 0; i \u0026lt; nums2.size(); ++i) { if (setp.find(nums2[i]) != setp.end()) { setq.insert(nums2[i]); } } return vector\u0026lt;int\u0026gt;(setq.begin(),setq.end()); } }; 两数之和\nclass Solution { public: vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { unordered_map\u0026lt;int,int\u0026gt; map;//k：元素，v：下标 for (int i = 0; i \u0026lt; nums.size(); ++i){ if (map.find(target-nums[i])!=map.end()){ return {map.find(target-nums[i])-\u0026gt;second,i}; } map.insert(pair\u0026lt;int,int\u0026gt;(nums[i], i)); } return {}; } }; 三数之和\nvector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt; \u0026amp;nums) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; res; //排序 sort(nums.begin(), nums.end()); for (int i = 0; i \u0026lt; nums.size(); ++i) { if (nums[0] \u0026gt; 0) { break; } unordered_set\u0026lt;int\u0026gt; set; //去重 if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i - 1] == nums[i]) { continue; } for (int j = i + 1; j \u0026lt; nums.size(); ++j) { int target = 0 - (nums[i] + nums[j]); if (set.find(target) != set.end()) { res.push_back(vector\u0026lt;int\u0026gt;{nums[i], nums[j], target}); } else { res.push_back(vector\u0026lt;int\u0026gt;{nums[j]}); } } } return res; }; 寻找最近的三数之和：\n/**\n给你一个长度为 n 的整数数组 nums 和 一个目标值 target。请你从 nums 中选出三个整数，使它们的和与 target 最接近。\n返回这三个数的和。\n假定每组输入只存在恰好一个解。\n示例 1：\n输入：nums = [-1,2,1,-4], target = 1 输出：2 解释：与 target 最接近的和是 2 (-1 + 2 + 1 = 2) 。 */\nclass Solution { public: int threeSumClosest(vector\u0026lt;int\u0026gt; \u0026amp;nums, int target) { sort(nums.begin(), nums.end()); int len = nums.size(); int closestNum = nums[0] + nums[1] + nums[2]; for (int i = 0; i \u0026lt; len; ++i) { int j = i + 1; int k = len - 1; while (j \u0026lt; k) { int sum = nums[i] + nums[j] + nums[k]; if (sum == target) { return target;//刚好相等，直接返回目标元素 } if (abs(target - sum) \u0026lt; abs(target - closestNum)) { closestNum = sum; } if (sum \u0026gt; target) { k--; } else { j++; } } } return closestNum; } }; class Solution { public int threeSumClosest(int[] nums, int target) { Arrays.sort(nums); int best=Integer.MAX_VALUE; int n=nums.length;//数组长度 for(int i=0;i\u0026lt;n;i++){ int j=i+1,k=n-1; //二分 while(j\u0026lt;k){ int sum=nums[i]+nums[j]+nums[k]; if(sum==target) return target;//刚好相等，直接返回目标元素 if(Math.abs(target-sum)\u0026lt;Math.abs(best-target)){ best=sum; }else if(sum\u0026gt;target){ k--; }else{ j++; } } } return best; } } ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E5%93%88%E5%B8%8C%E7%AF%87/","section":"Algorithms","summary":"字母异位词\nclass Solution { public: bool isAnagram(string s, string t) { int record[26] = {0}; for (int i = 0; i \u0026lt; s.size(); i++) { // 并不需要记住字符a的ASCII，只要求出一个相对数值就可以了 record[s[i] - \u0026#39;a\u0026#39;]++; } for (int i = 0; i \u0026lt; t.","title":"哈希篇","type":"algorithm"},{"content":"\r设计模式（结构型） #\r结构型设计模式关注如何将现有的类或对象组织在一起形成更加强大的结构。并且根据我们前面学习的合成复用原则，我们该如何尽可能地使用关联关系来代替继承关系是我们本版块需要重点学习的内容。\n类/对象适配器模式 #\r在生活中，我们经常遇到这样的一个问题：笔记本太轻薄了，以至于没有RJ45网口和USB A口（比如Macbook为了轻薄甚至全是type-c形式的雷电口）但是现在我们因为工作需要，又得使用这些接口来连接线缆，这时我们想到的第一个解决方案，就是去买一个转接口（扩展坞），扩展坞可以将type-c口转换为其他类型的接口供我们使用，实际上这就是一种适配模式。\n由于我们的电脑没有这些接口，但是提供了type-c类型的接口，虽然接口类型不一样，但是同样可以做其他接口能做的事情，比如USB文件传输、有线网络连接等，所以，这个时候，我们只需要添加一个中间人来帮我们转换一下接口形态即可。包括我们常用的充电头，为什么叫电源适配器呢？我们知道传统的供电是220V交流电，但是我们的手机可能只需要5V的电压进行充电，虽然现在有电，但是不能直接充，我们也不可能让电力公司专门为我们提供一个5V的直流电使用。这时电源适配器就开始发挥作用了，比如苹果的祖传5V1A充电头，实际上就是将220V交流电转换为5V的直流电进行传输，这样就相当于在220V交流电和我们的手机之前，做了一个适配器的角色。\n在我们的Java程序中，也会经常遇到这样的问题，比如：\npublic class TestSupplier { //手机供应商 public String doSupply(){ return \u0026#34;iPhone 14 Pro\u0026#34;; } } public class Main { public static void main(String[] args) { TestSupplier supplier = new TestSupplier(); test( ? ); //我们没有Target类型的手机供应商，只有其他的，那这里该填个啥 } public static void test(Target target){ //现在我们需要调用test方法，但是test方法需要Target类型的手机供应商 System.out.println(\u0026#34;成功得到：\u0026#34;+target.supply()); } } public interface Target { //现在的手机供应商，并不是test方法所需要的那种类型 String supply(); } 这个时候，我们就可以使用适配器模式了，适配器模式分为类适配器和对象适配器，我们首先来看看如何使用类适配器解决这种问题，我们直接创建一个适配器类：\npublic class TestAdapter extends TestSupplier implements Target { //让我们的适配器继承TestSupplier并且实现Target接口 @Override public String supply() { //接着实现supply方法，直接使用TestSupplier提供的实现 return super.doSupply(); } } 这样，我们就得到了一个Target类型的实现类，并且同时采用的是TestSupplier提供的实现。\npublic static void main(String[] args) { TestAdapter adapter = new TestAdapter(); test(adapter); } public static void test(Target target){ System.out.println(\u0026#34;成功得到：\u0026#34;+target.supply()); } 不过，这种实现方式需要占用一个继承坑位，如果此时Target不是接口而是抽像类的话，由于Java不支持多继承，那么就无法实现了。同时根据合成复用原则，我们应该更多的通过合成的方式去实现功能，所以我们来看看第二种，也是用的比较多的一种模式，对象适配器：\npublic class TestAdapter implements Target{ //现在不再继承TestSupplier，仅实现Target TestSupplier supplier; public TestAdapter(TestSupplier supplier){ this.supplier = supplier; } @Override public String supply() { return supplier.doSupply(); } } 现在，我们就将对象以组合的形式存放在TestAdapter中，依然是通过存放的对象调用具体实现。\n桥接模式 #\r相信各位都去奶茶店买过奶茶，在购买奶茶的时候，店员首先会问我们，您需要什么类型的奶茶，比如我们此时点了一杯啵啵芋圆奶茶，接着店员会直接问我们需要大杯、中杯还是小杯，最后还会询问我们需要加什么配料，比如椰果、珍珠等，最后才会给我们制作奶茶。\n那么现在让你来设计一下这种模式的Java类，该怎么做呢？首先我们要明确，一杯奶茶除了类型之外，还分大中小杯，甚至可能还分加什么配料，这个时候，如果我们按照接口实现的写法：\npublic interface Tea { //由具体类型的奶茶实现 String getType(); //不同的奶茶返回的类型不同 } public interface Size { //分大杯小杯中杯 String getSize(); } 比如现在我们创建一个新的类型：\n/** * 大杯芋圆啵啵奶茶 */ public class LargeKissTea implements Tea, Size{ @Override public String getSize() { return \u0026#34;大杯\u0026#34;; } @Override public String getType() { return \u0026#34;芋圆啵啵奶茶\u0026#34;; } } 虽然这样设计起来还挺合理的，但是如果现在我们的奶茶品种多起来了，并且每种奶茶都有大中小杯，现在一共有两个维度需要考虑，那么我们岂不是得一个一个去创建这些类？甚至如果还要考虑配料，那么光创建类就得创建不知道多少个了。显然这种设计不太好，我们得换个方式。\n这时，就可以使用我们的桥接模式了，现在我们面临的问题是，维度太多，不可能各种类型各种尺寸的奶茶都去创建一个类，那么我们就还是单独对这些接口进行简单的扩展，单独对不同的维度进行控制，但是如何实现呢？我们不妨将奶茶的类型作为最基本的抽象类，然后对尺寸、配料等属性进行桥接：\npublic abstract class AbstractTea { protected Size size; //尺寸作为桥接属性存放在类中 protected AbstractTea(Size size){ //在构造时需要知道尺寸属性 this.size = size; } public abstract String getType(); //具体类型依然是由子类决定 } 不过这个抽象类提供的方法还不全面，仅仅只有Tea的getType方法，我们还需要添加其他维度的方法，所以继续编写一个子类：\npublic abstract class RefinedAbstractTea extends AbstractTea{ protected RefinedAbstractTea(Size size) { super(size); } public String getSize(){ //添加尺寸维度获取方式 return size.getSize(); } } 现在我们只需要单独为Size创建子类即可：\npublic class Large implements Size{ @Override public String getSize() { return \u0026#34;大杯\u0026#34;; } } 现在我们如果需要一个大杯的啵啵芋圆奶茶，只需要：\npublic class KissTea extends RefinedAbstractTea{ //创建一个啵啵芋圆奶茶的子类 protected KissTea(Size size) { //在构造时需要指定具体的大小实现 super(size); } @Override public String getType() { return \u0026#34;啵啵芋圆奶茶\u0026#34;; //返回奶茶类型 } } 现在我们就将两个维度拆开，可以分别进行配置了：\npublic static void main(String[] args) { KissTea tea = new KissTea(new Large()); System.out.println(tea.getType()); System.out.println(tea.getSize()); } 通过桥接模式，使得抽象和实现可以沿着各自的维度来进行变化，不再是固定的绑定关系。\n组合模式 #\r组合模式实际上就是将多个组件进行组合，让用户可以对它们进行一致性处理。比如我们的文件夹，一个文件夹中可以有很多个子文件夹或是文件：\n它就像是一个树形结构一样，有分支有叶子，而组合模式则是可以对整个树形结构上的所有节点进行递归处理，比如我们现在希望将所有文件夹中的文件的名称前面都添加一个前缀，那么就可以使用组合模式。\n组合模式的示例如下，这里我们就用文件和文件夹的例子来讲解：\n/** * 首先创建一个组件抽象，组件可以包含组件，组件有自己的业务方法 */ public abstract class Component { public abstract void addComponent(Component component); //添加子组件 public abstract void removeComponent(Component component); //删除子组件 public abstract Component getChild(int index); //获取子组件 public abstract void test(); //执行对应的业务方法，比如修改文件名称 } 接着我们来编写两种实现类：\npublic class Directory extends Component{ //目录可以包含多个文件或目录 List\u0026lt;Component\u0026gt; child = new ArrayList\u0026lt;\u0026gt;(); //这里我们使用List来存放目录中的子组件 @Override public void addComponent(Component component) { child.add(component); } @Override public void removeComponent(Component component) { child.remove(component); } @Override public Component getChild(int index) { return child.get(index); } @Override public void test() { child.forEach(Component::test); //将继续调用所有子组件的test方法执行业务 } } public class File extends Component{ //文件就相当于是树叶，无法再继续添加子组件了 @Override public void addComponent(Component component) { throw new UnsupportedOperationException(); //不支持这些操作了 } @Override public void removeComponent(Component component) { throw new UnsupportedOperationException(); } @Override public Component getChild(int index) { throw new UnsupportedOperationException(); } @Override public void test() { System.out.println(\u0026#34;文件名称修改成功！\u0026#34;+this); //具体的名称修改操作 } } 最后，我们来测试一下：\npublic static void main(String[] args) { Directory outer = new Directory(); //新建一个外层目录 Directory inner = new Directory(); //新建一个内层目录 outer.addComponent(inner); outer.addComponent(new File()); //在内层目录和外层目录都添加点文件，注意别导错包了 inner.addComponent(new File()); inner.addComponent(new File()); outer.test(); //开始执行文件名称修改操作 } 可以看到我们对最外层目录进行操作后，会递归向下处理当前目录和子目录中所有的文件。\n装饰模式 #\r装饰模式就像其名字一样，为了对现有的类进行装饰。比如一张相片就一张纸，如果直接贴在墙上，总感觉少了点什么，但是我们给其添加一个好看的相框，就会变得非常对味。装饰模式的核心就在于不改变一个对象本身功能的基础上，给对象添加额外的行为，并且它是通过组合的形式完成的，而不是传统的继承关系。\n比如我们现在有一个普通的功能类：\npublic abstract class Base { //顶层抽象类，定义了一个test方法执行业务 public abstract void test(); } public class BaseImpl extends Base{ @Override public void test() { System.out.println(\u0026#34;我是业务方法\u0026#34;); //具体的业务方法 } } 不过现在的实现类太单调了，我们来添加一点装饰上去：\npublic class Decorator extends Base{ //装饰者需要将装饰目标组合到类中 protected Base base; public Decorator(Base base) { this.base = base; } @Override public void test() { base.test(); //这里暂时还是使用目标的原本方法实现 } } public class DecoratorImpl extends Decorator{ //装饰实现 public DecoratorImpl(Base base) { super(base); } @Override public void test() { //对原本的方法进行装饰，我们可以在前后都去添加额外操作 System.out.println(\u0026#34;装饰方法：我是操作前逻辑\u0026#34;); super.test(); System.out.println(\u0026#34;装饰方法：我是操作后逻辑\u0026#34;); } } 这样，我们就通过装饰模式对类的功能进行了扩展：\npublic static void main(String[] args) { Base base = new BaseImpl(); Decorator decorator = new DecoratorImpl(base); //将Base实现装饰一下 Decorator outer = new DecoratorImpl(decorator); //装饰者还可以嵌套 decorator.test(); outer.test(); } 这样我们就实现了装饰模式。\n代理模式 #\r代理模式和装饰模式很像，初学者很容易搞混，所以这里我们得紧接着来讲解一下。首先请记住，当无法直接访问某个对象或访问某个对象存在困难时，我们就可以通过一个代理对象来间接访问。\n实际上代理在我们生活中处处都存在，比如手机厂商要去销售手机，但是手机厂商本身没有什么渠道可以大规模地进行售卖，很难与这些消费者进行对接，这时就得交给代理商去进行出售，比如Apple在中国的直营店很少，但是在中国的授权经销商却很多，手机厂商通过交给旗下代理商的形式来进行更大规模的出售。比如我们经常要访问Github，但是直接连接会发现很难连的上，这时我们加了一个代理就可以轻松访问，也是在体现代理的作用。\n同时，代理类需要保证客户端使用的透明性，也就是说操作起来需要与原本的真实对象相同，比如我们访问Github只需要输入网址即可访问，而添加代理之后，也是使用同样的方式去访问Github，所以操作起来是一样的。包括Spring框架其实也是依靠代理模式去实现的AOP记录日志等。\n比如现在有一个目标类，但是我们现在需要通过代理来使用它：\npublic abstract class Subject { public abstract void test(); } public class SubjectImpl extends Subject{ //此类无法直接使用，需要我们进行代理 @Override public void test() { System.out.println(\u0026#34;我是测试方法！\u0026#34;); } } 现在我们为其建立一个代理类：\npublic class Proxy extends Subject{ //为了保证和Subject操作方式一样，保证透明性，也得继承 Subject target; //被代理的对象（甚至可以多重代理） public Proxy(Subject subject){ this.target = subject; } @Override public void test() { //由代理去执行被代理对象的方法，并且我们还可以在前后添油加醋 System.out.println(\u0026#34;代理前绕方法\u0026#34;); target.test(); System.out.println(\u0026#34;代理后绕方法\u0026#34;); } } 乍一看，这不跟之前的装饰模式一模一样吗？\n对装饰器模式来说，装饰者和被装饰者都实现同一个接口/抽象类。对代理模式来说，代理类和被代理的类都实现同一个接口/抽象类，在结构上确实没有啥区别。但是他们的作用不同，装饰器模式强调的是增强自身，在被装饰之后你能够在被增强的类上使用增强后的功能，增强后你还是你，只不过被强化了而已；代理模式强调要让别人帮你去做事情，以及添加一些本身与你业务没有太多关系的事情（记录日志、设置缓存等）重点在于让别人帮你做。\n装饰模式和代理模式的不同之处在于思想。\n当然实现代理模式除了我们上面所说的这种方式之外，我们还可以使用JDK为我们提供的动态代理机制，我们不再需要手动编写继承关系创建代理类，它能够在运行时通过反射机制为我们自动生成代理类：\npublic interface Subject { //JDK提供的动态代理只支持接口 void test(); } public class SubjectImpl implements Subject{ @Override public void test() { System.out.println(\u0026#34;我是测试方法！\u0026#34;); } } 接着我们需要创建一个动态代理的处理逻辑：\npublic class TestProxy implements InvocationHandler { //代理类，需要实现InvocationHandler接口 private final Object object; //这里需要保存一下被代理的对象，下面需要用到 public TestProxy(Object object) { this.object = object; } @Override //此方法就是调用代理对象的对应方法时会进入，这里我们就需要编写如何进行代理了 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //method就是调用的代理对象的哪一个方法，args是实参数组 System.out.println(\u0026#34;代理的对象：\u0026#34;+proxy.getClass()); //proxy就是生成的代理对象了，我们看看是什么类型的 Object res = method.invoke(object, args); //在代理中调用被代理对象原本的方法，因为你是代理，还是得执行一下别人的业务，当然也可以不执行，但是这样就失去代理的意义了，注意要用上面的object System.out.println(\u0026#34;方法调用完成，返回值为：\u0026#34;+res); //看看返回值是什么 return res; //返回返回值 } } 最后我们来看看如何创建一个代理类：\npublic static void main(String[] args) { SubjectImpl subject = new SubjectImpl(); //被代理的大冤种 InvocationHandler handler = new TestProxy(subject); Subject proxy = (Subject) Proxy.newProxyInstance( subject.getClass().getClassLoader(), //需要传入被代理的类的类加载器 subject.getClass().getInterfaces(), //需要传入被代理的类的接口列表 handler); //最后传入我们实现的代理处理逻辑实现类 proxy.test(); //比如现在我们调用代理类的test方法，那么就会进入到我们上面TestProxy中invoke方法，走我们的代理逻辑 } 运行一次，可以看到调用代理类的方法，最终会走到我们的invoke方法中进行：\n根据接口，代理对象是com.sun.proxy.$Proxy0类（看名字就知道不对劲），这个类是动态生成的，我们也找不到具体的源代码。\n不过JDK提供的动态代理只能使用接口，如果换成我们一开始的抽象类，就没办法了，这时我们可以使用一些第三方框架来实现更多方式的动态代理，比如Spring都在使用的CGLib框架，Maven依赖如下：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;cglib\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;cglib\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 由于CGlib底层使用ASM框架（JVM篇视频教程有介绍）进行字节码编辑，所以能够实现不仅仅局限于对接口的代理：\npublic class TestProxy implements MethodInterceptor { //首先还是编写我们的代理逻辑 private final Object target; //这些和之前JDK动态代理写法是一样的 public TestProxy(Object target) { this.target = target; } @Override //我们也是需要在这里去编写我们的代理逻辑 public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\u0026#34;现在是由CGLib进行代理操作！\u0026#34;+o.getClass()); return method.invoke(target, objects); //也是直接调用代理对象的方法即可 } } 接着我们来创建一下代理类：\npublic static void main(String[] args) { SubjectImpl subject = new SubjectImpl(); Enhancer enhancer = new Enhancer(); //增强器，一会就需要依靠增强器来为我们生成动态代理对象 enhancer.setSuperclass(SubjectImpl.class); //直接选择我们需要代理的类型，直接不需要接口或是抽象类，SuperClass作为代理类的父类存在，这样我们就可以按照指定类型的方式去操作代理类了 enhancer.setCallback(new TestProxy(subject)); //设定我们刚刚编写好的代理逻辑 SubjectImpl proxy = (SubjectImpl) enhancer.create(); //直接创建代理类 proxy.test(); //调用代理类的test方法 } 可以看到，效果其实是差不多的：\n可以看到代理类是包名.SubjectImpl$$EnhancerByCGLIB$$47f6ed3a，也是动态生成的一个类，所以我们无法去查看源码，不过此类是继承自我们指定的类型的。\n外观模式 #\r你是否经历过类似的情况：今年计算机学院的奖学金评定工作开始了，由于你去年一不小心拿了个ACM的区域赛金牌，觉得自己又行了，于是也想参与到奖学金的争夺中，首先你的辅导员会通知你去打印你的获奖材料，然后你高高兴兴拿给辅导员之后，辅导员又给了你一张表，让你打印了之后填写一下，包括你的个人信息还有一些个人介绍，完成后，你本以为可以坐等发奖了，结果辅导员又跟你说我们评定还要去某某地方盖章，盖完章还要去找谁谁谁签字，最后还要参加一下答辩\u0026hellip; 看着如此复杂的流程，你瞬间不想搞了。\n实际上我们生活中很多时候都是这样，可能在办一件事情的时候，由于部门职能的不同，你得各个部门到处跑，你肯定会抱怨一句，就不能有个人来统一一下吗，就不能在一个地方一起把事情都办了吗？这时，我们就可以用到外观模式了。\n外观模式充分体现了迪米特法则。可能我们的整个项目有很多个子系统，但是我们可以在这些子系统的上面加一个门面（Facade）当我们外部需要与各个子系统交互时，无需再去直接使用各个子系统，而是与门面进行交互，再由门面与后面的各个子系统操作，这样，我们以后需要办什么事情，就统一找门面就行了。这样的好处是，首先肯定方便了代码的编写，统一找门面就行，不需要去详细了解子系统，并且，当子系统需要修改时，也只需要修改门面中的逻辑，不需要大面积的变动，遵循迪米特法则尽可能少的交互。\n比如现在我们设计了三个子系统，分别是排队、结婚、领证，正常情况下我们是需要分别去找这三个部门去完成的，但是现在我们通过门面统一来完成：\npublic class SubSystemA { public void test1(){ System.out.println(\u0026#34;排队\u0026#34;); } } public class SubSystemB { public void test2(){ System.out.println(\u0026#34;结婚\u0026#34;); } } public class SubSystemC { public void test3(){ System.out.println(\u0026#34;领证\u0026#34;); } } 现在三个系统太复杂了，我们添加一个门面：\npublic class Facade { SubSystemA a = new SubSystemA(); SubSystemB b = new SubSystemB(); SubSystemC c = new SubSystemC(); public void marry(){ //红白喜事一条龙服务 a.test1(); b.test2(); c.test3(); } } 现在我们只需要一个门面就能直接把事情办完了：\npublic static void main(String[] args) { Facade facade = new Facade(); facade.marry(); } 通过使用外观模式，我们就大大降低了类与类直接的关联程度，并且简化了流程。\n享元模式 #\r最后我们来看看享元模式（Flyweight），那么这个\u0026quot;享元\u0026quot;代表什么意思呢？我们先来看看下面的问题：\npublic static void main(String[] args) { String str1 = \u0026#34;abcdefg\u0026#34;; String str2 = \u0026#34;abcd\u0026#34;; } 我们发现上面的例子中，两个字符串虽然长短不同，但是却包含了一段相同的部分，那么现在我们如果要对内存进行优化：\npublic static void main(String[] args) { String str1 = \u0026#34;efg\u0026#34;; //由于str1包含str2，所以我们可以去掉重复的部分，当需要原本的str1时，再合在一起 String str2 = \u0026#34;abcd\u0026#34;; System.out.println(\u0026#34;str1 = \u0026#34;+str2+str1); } 而享元模式就是这个思想，我们可以将那些重复出现的内容作为共享部分取出，这样当我们拥有大量对象时，我们把其中共同的部分抽取出来，由于提取的部分是多个对象共享只有一份，那么就可以减轻内存的压力。包括我们的围棋，实际上我们只需要知道棋盘上的各个位置是黑棋还是白棋，实际上没有毕业创建很多个棋子对象，我们只需要去复用一个黑棋和一个白棋子对象即可。\n比如现在我们有两个服务，但是他们都需要使用数据库工具类来操作，实际上这个工具类没必要创建多个，我们这时就可以使用享元模式，让数据库工具类作为享元类，通过享元工厂来提供一个共享的数据库工具类：\npublic class DBUtil { public void selectDB(){ System.out.println(\u0026#34;我是数据库操作...\u0026#34;); } } public class DBUtilFactory { private static final DBUtil UTIL = new DBUtil(); //享元对象被存放在工厂中 public static DBUtil getFlyweight(){ //获取享元对象 return UTIL; } } 最后当我们需要使用享元对象时，直接找享元工厂要就行了：\npublic class UserService { //用户服务 public void service(){ DBUtil util = DBUtilFactory.getFlyweight(); //通过享元工厂拿到DBUtil对象 util.selectDB(); //该干嘛干嘛 } } 当然，这只是简单的享元模式实现，实际上我们一开始举例的String类，也在使用享元模式进行优化，比如下面的代码：\npublic static void main(String[] args) { String str1 = \u0026#34;abcd\u0026#34;; String str2 = \u0026#34;abcd\u0026#34;; String str3 = \u0026#34;ab\u0026#34; + \u0026#34;cd\u0026#34;; System.out.println(str1 == str2); System.out.println(str1 == str3); //猜猜这三个对象是不是都是同一个？ } 虽然我们这里定义了三个字符串，但是我们发现，这三个对象指向的都是同一个对象，这是为什么呢？实际上这正是Java语言实现了数据的共享，想要了解具体实现请前往JVM篇视频教程。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/design/%E7%BB%93%E6%9E%84%E5%9E%8B/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%89%E7%BB%93%E6%9E%84%E5%9E%8B/","section":"Docs","summary":"设计模式（结构型） #\r结构型设计模式关注如何将现有的类或对象组织在一起形成更加强大的结构。并且根据我们前面学习的合成复用原则，我们该如何尽可能地使用关联关系来代替继承关系是我们本版块需要重点学习的内容。\n类/对象适配器模式 #\r在生活中，我们经常遇到这样的一个问题：笔记本太轻薄了，以至于没有RJ45网口和USB A口（比如Macbook为了轻薄甚至全是type-c形式的雷电口）但是现在我们因为工作需要，又得使用这些接口来连接线缆，这时我们想到的第一个解决方案，就是去买一个转接口（扩展坞），扩展坞可以将type-c口转换为其他类型的接口供我们使用，实际上这就是一种适配模式。\n由于我们的电脑没有这些接口，但是提供了type-c类型的接口，虽然接口类型不一样，但是同样可以做其他接口能做的事情，比如USB文件传输、有线网络连接等，所以，这个时候，我们只需要添加一个中间人来帮我们转换一下接口形态即可。包括我们常用的充电头，为什么叫电源适配器呢？我们知道传统的供电是220V交流电，但是我们的手机可能只需要5V的电压进行充电，虽然现在有电，但是不能直接充，我们也不可能让电力公司专门为我们提供一个5V的直流电使用。这时电源适配器就开始发挥作用了，比如苹果的祖传5V1A充电头，实际上就是将220V交流电转换为5V的直流电进行传输，这样就相当于在220V交流电和我们的手机之前，做了一个适配器的角色。\n在我们的Java程序中，也会经常遇到这样的问题，比如：\npublic class TestSupplier { //手机供应商 public String doSupply(){ return \u0026#34;iPhone 14 Pro\u0026#34;; } } public class Main { public static void main(String[] args) { TestSupplier supplier = new TestSupplier(); test( ?","title":"结构型","type":"doc"},{"content":"ADT模型\n\u0026lt;--java--\u0026gt; public class ListNode { // 结点的值 int val; // 下一个结点 ListNode next; // 节点的构造函数(无参) public ListNode() { } // 节点的构造函数(有一个参数) public ListNode(int val) { this.val = val; } // 节点的构造函数(有两个参数) public ListNode(int val, ListNode next) { this.val = val; this.next = next; } } \u0026lt;--Cpp--\u0026gt; struct ListNode{ int val; ListNode *next; ListNode() : val(0), next(nullptr) {} ListNode(int x) : val(x), next(nullptr) {} // 节点的构造函数 //所以如果不定义构造函数使用默认构造函数的话，在初始化的时候就不能直接给变量赋值！ ListNode(int x, ListNode *next) : val(x), next(next) {} }; // // Created by Rainy-Heights on 2024/3/20. // #include \u0026#34;../cunion.h\u0026#34; /** * Definition for singly-linked list. */ class Solution { public: ListNode* removeElements(ListNode* head, int val) { ListNode *dummyHead=new ListNode(0);//创建虚拟头节点 dummyHead-\u0026gt;next=head;//虚拟头节点的下一个节点指向头节点 ListNode *cur=dummyHead;//当前节点,用于遍历,为了能够删除头节点，需要知道头结点的上一个节点也就是dummyHead //删除一般节点 while (cur!= NULL\u0026amp;\u0026amp;cur-\u0026gt;next!= NULL){ if (cur-\u0026gt;next-\u0026gt;val==val){ cur-\u0026gt;next=cur-\u0026gt;next-\u0026gt;next; } else{ cur=cur-\u0026gt;next; } } head=dummyHead-\u0026gt;next; delete(dummyHead); //删除头节点，使用虚拟节点 return head;//返回头节点即可 } }; int main(){ ListNode *node=new ListNode(0); ListNode *head=node; vector\u0026lt;int\u0026gt; v={1,2,6,3,4,5,6}; for (int i = 0; i \u0026lt; 7; ++i) { head-\u0026gt;val=v[i]; cout\u0026lt;\u0026lt;v[i]\u0026lt;\u0026lt;endl; head-\u0026gt;next=new ListNode; head=head-\u0026gt;next; } // head-\u0026gt;initNode(head,8); Solution *solution; ListNode *res=solution-\u0026gt;removeElements(node,6); while (res-\u0026gt;next!= NULL){ cout\u0026lt;\u0026lt;res-\u0026gt;val\u0026lt;\u0026lt;endl; res=res-\u0026gt;next; } } ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","section":"Algorithms","summary":"ADT模型\n\u0026lt;--java--\u0026gt; public class ListNode { // 结点的值 int val; // 下一个结点 ListNode next; // 节点的构造函数(无参) public ListNode() { } // 节点的构造函数(有一个参数) public ListNode(int val) { this.val = val; } // 节点的构造函数(有两个参数) public ListNode(int val, ListNode next) { this.","title":"链表的基本操作","type":"algorithm"},{"content":"翻转链表\nclass Solution { public: //翻转链表 //输入：head = [1,2,3,4,5] //输出：[5,4,3,2,1] //双指针法 ListNode *reverseList(ListNode *head) { ListNode *cur = head; ListNode *pre = NULL; ListNode *tmp = cur;//保存变量 while (cur) { tmp = cur-\u0026gt;next;//保存原来的下一个指向 cur-\u0026gt;next = pre;//将下一个指向改为pre pre = cur;//修改pre往前移动一格 cur = tmp;//修改cur往前移动一格 } return pre; } //递归法 ListNode *reverse(ListNode *cur,ListNode *pre){ if(cur == NULL) return pre; ListNode *tmp= NULL; tmp=cur-\u0026gt;next; cur-\u0026gt;next=pre; return reverse(tmp,cur); } }; 环形链表\n#include \u0026#34;../cunion.h\u0026#34; class Solution { public: ListNode *detectCycle(ListNode *head) { ListNode * dummyHead=new ListNode(); dummyHead-\u0026gt;next=head; ListNode *fast=dummyHead-\u0026gt;next; ListNode *slow=dummyHead-\u0026gt;next; while (fast!= nullptr\u0026amp;\u0026amp; fast-\u0026gt;next!= nullptr){ fast=fast-\u0026gt;next-\u0026gt;next; slow=slow-\u0026gt;next; if (fast==slow){ ListNode *pos=fast; ListNode *run=head; while (run!=pos){ pos=pos-\u0026gt;next; run=run-\u0026gt;next; } return run; } } return nullptr; } }; 交换链表\n#include \u0026#34;../cunion.h\u0026#34; class Solution { public: //输入：head = [1,2,3,4] //输出：[2,1,4,3] ListNode* swapPairs(ListNode* head) { ListNode *pre=new ListNode(0); pre-\u0026gt;next=head; ListNode *cur=pre; ListNode *tmp=cur; ListNode *tmp1=cur; while (cur-\u0026gt;next != nullptr \u0026amp;\u0026amp; cur-\u0026gt;next-\u0026gt;next != nullptr){ tmp=cur-\u0026gt;next-\u0026gt;next; tmp1=tmp-\u0026gt;next; tmp-\u0026gt;next=cur-\u0026gt;next; cur-\u0026gt;next=tmp1; cur=tmp1; } return pre-\u0026gt;next; } }; 链表相交\n// // Created by 春江花朝秋月夜 on 2024/3/23. // #include \u0026#34;../cunion.h\u0026#34; class Solution { public: ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) { ListNode *A = headA; ListNode *B = headB; int lenA = len(A); int lenB = len(B); ListNode *curA = headA; ListNode *curB = headB; if (lenA \u0026gt; lenB) { int diff = lenA - lenB; return findInsect(curA,curB,diff); } else if (lenB \u0026gt; lenA) { int diff = lenB - lenA; return findInsect(curB,curA,diff); } else if (lenA == lenB) { return findInsect(curA,curB,0); } return nullptr; } ListNode *findInsect(ListNode *left,ListNode *right,int diff){ while (diff--){ left=left-\u0026gt;next; } if (left!=right){ while (left!= nullptr){ if (left==right){ return left; } left=left-\u0026gt;next; right=right-\u0026gt;next; } } else{ return left; } return nullptr; } int len(ListNode *node) { int len = 0; while (node != nullptr) { node = node-\u0026gt;next; len++; } return len; } }; 删除链表的倒数第n个节点\n// // Created by 春江花朝秋月夜 on 2024/3/21. // //删除链表的倒数第n个节点 #include \u0026#34;../cunion.h\u0026#34; class Solution { public: ListNode *removeNthFromEnd(ListNode *head, int n) { ListNode *dummyHead = new ListNode(0, head); int len = 0; ListNode *node = dummyHead-\u0026gt;next; while (node) { len++; node = node-\u0026gt;next; } ListNode *travelNode = dummyHead-\u0026gt;next; //因为是通过倒数来实现计数，所以索引从1开始 for (int i = 1; i \u0026lt; len - i + 1; ++i) { travelNode = travelNode-\u0026gt;next; } travelNode-\u0026gt;next = travelNode-\u0026gt;next-\u0026gt;next; return dummyHead-\u0026gt;next; } //使用双指针来解决这个问题！！！ ListNode* removeNthFromEndWithDouble(ListNode* head, int n) { ListNode *dummyHead=new ListNode(0); dummyHead-\u0026gt;next=head;//虚拟头节点 ListNode *fast=dummyHead; ListNode *slow=dummyHead; //fast向前移动n步 while (fast!= NULL\u0026amp;\u0026amp;n--){ fast=fast-\u0026gt;next; } fast = fast-\u0026gt;next; // fast再提前走一步，因为需要让slow指向删除节点的上一个节点 while (fast != NULL) { fast = fast-\u0026gt;next; slow = slow-\u0026gt;next; } slow-\u0026gt;next=slow-\u0026gt;next-\u0026gt;next; return dummyHead-\u0026gt;next; } }; /** 采用虚拟头节点来解决的方法： * ListNode *removeNthFromEnd(ListNode *head, int n) { //使用双指针来解决这个问题！！！ ListNode *dummyHead = new ListNode(0, head); int len = 0; ListNode *node = dummyHead-\u0026gt;next; while (node) { len++; node = node-\u0026gt;next; } ListNode *travelNode = dummyHead-\u0026gt;next; //因为是通过倒数来实现计数，所以索引从1开始 for (int i = 1; i \u0026lt; len - i + 1; ++i) { travelNode = travelNode-\u0026gt;next; } travelNode-\u0026gt;next = travelNode-\u0026gt;next-\u0026gt;next; return dummyHead-\u0026gt;next; } */ ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E9%93%BE%E8%A1%A8%E7%AF%87/","section":"Algorithms","summary":"翻转链表\nclass Solution { public: //翻转链表 //输入：head = [1,2,3,4,5] //输出：[5,4,3,2,1] //双指针法 ListNode *reverseList(ListNode *head) { ListNode *cur = head; ListNode *pre = NULL; ListNode *tmp = cur;//保存变量 while (cur) { tmp = cur-\u0026gt;next;//保存原来的下一个指向 cur-\u0026gt;next = pre;//将下一个指向改为pre pre = cur;//修改pre往前移动一格 cur = tmp;//修改cur往前移动一格 } return pre; } //递归法 ListNode *reverse(ListNode *cur,ListNode *pre){ if(cur == NULL) return pre; ListNode *tmp= NULL; tmp=cur-\u0026gt;next; cur-\u0026gt;next=pre; return reverse(tmp,cur); } }; 环形链表","title":"链表篇","type":"algorithm"},{"content":"\r处理边界条件？\n循环不可靠！找到循环不变量！\n#include \u0026#34;../cunion.h\u0026#34; class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; generateMatrix(int n) { int num = 1; //注意这里是全闭区间 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; matrix(n, vector\u0026lt;int\u0026gt;(n)); int left = 0, right = n - 1, top = 0, bottom = n - 1; while (left \u0026lt;= right \u0026amp;\u0026amp; top \u0026lt;= bottom) { //从左往右 for (int column = left; column \u0026lt;= right; ++column) { matrix[top][column] = num; num++; } for (int row = top + 1; row \u0026lt;= bottom; ++row) { matrix[row][right] = num; num++; } //从右往左 if (left \u0026lt; right \u0026amp;\u0026amp; top \u0026lt; bottom) { for (int column = right - 1; column \u0026gt; left; --column) { matrix[bottom][column] = num; num++; } for (int row = bottom; row \u0026gt; top; --row) { matrix[row][left] = num; num++; } } left++; right--; top++; bottom--; } return matrix; } }; int main() { Solution *solution; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; vo = solution-\u0026gt;generateMatrix(4); for (int i = 0; i \u0026lt; vo.size(); ++i) { for (int j = 0; j \u0026lt; vo[i].size(); ++j) { printf(\u0026#34;%d \u0026#34;, vo[i][j]); } cout \u0026lt;\u0026lt; endl; } } class Solution { public int[][] generateMatrix(int n) { int [][]matrix=new int[n][n]; int left=0,right=n-1,top=0,bottom=n-1; int num=1; while(left\u0026lt;=right\u0026amp;\u0026amp;top\u0026lt;=bottom){ //从左往右： for(int column =left;column\u0026lt;=right;column++){ matrix[top][column]=num; num++; } //从上到下： for(int row =top+1;row\u0026lt;=bottom;row++){ matrix[row][right]=num; num++; } if(left\u0026lt;right\u0026amp;\u0026amp;top\u0026lt;bottom){ //从右往左 for(int column=right-1;column\u0026gt;left;column--){ matrix[bottom][column]=num; num++; } //从下到上 for(int row=bottom;row\u0026gt;top;row--){ matrix[row][left]=num; num++; } } left++; right--; bottom--; top++; } return matrix; } } ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E8%9E%BA%E6%97%8B%E7%9F%A9%E9%98%B5/%E8%9E%BA%E6%97%8B%E7%9F%A9%E9%98%B5/","section":"Algorithms","summary":"处理边界条件？\n循环不可靠！找到循环不变量！\n#include \u0026#34;../cunion.h\u0026#34; class Solution { public: vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; generateMatrix(int n) { int num = 1; //注意这里是全闭区间 vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; matrix(n, vector\u0026lt;int\u0026gt;(n)); int left = 0, right = n - 1, top = 0, bottom = n - 1; while (left \u0026lt;= right \u0026amp;\u0026amp; top \u0026lt;= bottom) { //从左往右 for (int column = left; column \u0026lt;= right; ++column) { matrix[top][column] = num; num++; } for (int row = top + 1; row \u0026lt;= bottom; ++row) { matrix[row][right] = num; num++; } //从右往左 if (left \u0026lt; right \u0026amp;\u0026amp; top \u0026lt; bottom) { for (int column = right - 1; column \u0026gt; left; --column) { matrix[bottom][column] = num; num++; } for (int row = bottom; row \u0026gt; top; --row) { matrix[row][left] = num; num++; } } left++; right--; top++; bottom--; } return matrix; } }; int main() { Solution *solution; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; vo = solution-\u0026gt;generateMatrix(4); for (int i = 0; i \u0026lt; vo.","title":"螺旋矩阵","type":"algorithm"},{"content":"\r面向对象设计原则 #\r**注意：**推荐完成JavaEE通关路线再开始学习。\n我们在进行软件开发时，不仅仅需要将最基本的业务给完成，还要考虑整个项目的可维护性和可复用性，我们开发的项目不单单需要我们自己来维护，同时也需要其他的开发者一起来进行共同维护，因此我们在编写代码时，应该尽可能的规范。如果我们在编写代码时不注重这些问题，整个团队项目就像一座屎山，随着项目的不断扩大，整体结构只会越来越遭。\n甚至到最后你会发现，我们的程序居然是稳定运行在BUG之上的\u0026hellip;\n所以，为了尽可能避免这种情况的发生，我们就来聊聊面向对象设计原则。\n单一职责原则 #\r单一职责原则（Simple Responsibility Pinciple，SRP）是最简单的面向对象设计原则，它用于控制类的粒度大小。\n一个对象应该只包含单一的职责，并且该职责被完整地封装在一个类中。\n比如我们现在有一个People类：\n//一个人类 public class People { /** * 人类会编程 */ public void coding(){ System.out.println(\u0026#34;int mian() {\u0026#34;); System.out.println(\u0026#34; printf(\\\u0026#34;Holle Wrold!\\\u0026#34;);\u0026#34;); System.out.println(\u0026#34;}\u0026#34;); System.out.println(\u0026#34;啊嘞，怎么运行不起？明明照着老师敲的啊\u0026#34;); } /** * 工厂打螺丝也会 */ public void work(){ System.out.println(\u0026#34;真开心，能进到富土康打螺丝\u0026#34;); System.out.println(\u0026#34;诶，怎么工友都提桶跑路了\u0026#34;); } /** * 送外卖也会 */ public void ride(){ System.out.println(\u0026#34;今天终于通过美团最终面，加入了梦寐以求的大厂了\u0026#34;); System.out.println(\u0026#34;感觉面试挺简单的，就是不知道为啥我同学是现场做一道力扣接雨水，而我是现场问会不会骑车\u0026#34;); System.out.println(\u0026#34;（迫不及待穿上外卖服装）\u0026#34;); } } 我们可以看到，这个People类可以说是十八般武艺样样精通了，啥都会，但是实际上，我们每个人最终都是在自己所擅长的领域工作，所谓闻道有先后，术业有专攻，会编程的就应该是程序员，会打螺丝的就应该是工人，会送外卖的应该是骑手，显然这个People太过臃肿（我们需要修改任意一种行为都需要修改People类，它拥有不止一个引起它变化的原因），所以根据单一职责原则，我们下需要进行更明确的划分，同种类型的操作我们一般才放在一起：\nclass Coder{ /** * 程序员会编程 */ public void coding(){ System.out.println(\u0026#34;int mian() {\u0026#34;); System.out.println(\u0026#34; printf(\\\u0026#34;Hello World!\\\u0026#34;)\u0026#34;); System.out.println(\u0026#34;}\u0026#34;); System.out.println(\u0026#34;啊嘞，怎么运行不起？明明照着老师敲的啊\u0026#34;); } } class Worker{ /** * 工人会打螺丝 */ public void work(){ System.out.println(\u0026#34;真开心，能进到富土康打螺丝\u0026#34;); System.out.println(\u0026#34;诶，怎么工友都提桶跑路了\u0026#34;); } } class Rider { /** * 骑手会送外卖 */ public void ride(){ System.out.println(\u0026#34;今天终于通过美团最终面，加入了梦寐以求的大厂\u0026#34;); System.out.println(\u0026#34;感觉面试挺简单的，就是不知道为啥我同学是现场做一道力扣接雨水，我是现场问会不会骑车\u0026#34;); System.out.println(\u0026#34;（迫不及待穿上外卖服装）\u0026#34;); } } 我们将类的粒度进行更近一步的划分，这样就很清晰了，包括我们以后在设计Mapper、Service、Controller等等，根据不同的业务进行划分，都可以采用单一职责原则，以它作为我们实现高内聚低耦合的指导方针。实际上我们的微服务也是参考了单一职责原则，每个微服务只应担负一个职责。\n开闭原则 #\r开闭原则（Open Close Principle）也是重要的面向对象设计原则。\n软件实体应当对扩展开放，对修改关闭。\n一个软件实体，比如类、模块和函数应该对扩展开放，对修改关闭。其中，对扩展开放是针对提供方来说的，对修改关闭是针对调用方来说的。\n比如我们的程序员分为Java程序员、C#程序员、C艹程序员、PHP程序员、前端程序员等，而他们要做的都是去打代码，而具体如何打代码是根据不同语言的程序员来决定的，我们可以将程序员打代码这一个行为抽象成一个统一的接口或是抽象类，这样我们就满足了开闭原则的第一个要求：对扩展开放，不同的程序员可以自由地决定他们该如何进行编程。而具体哪个程序员使用什么语言怎么编程，是自己在负责，不需要其他程序员干涉，所以满足第二个要求：对修改关闭，比如：\npublic abstract class Coder { public abstract void coding(); class JavaCoder extends Coder{ @Override public void coding() { System.out.println(\u0026#34;Java太卷了T_T，快去学Go吧！\u0026#34;); } } class PHPCoder extends Coder{ @Override public void coding() { System.out.println(\u0026#34;PHP是世界上最好的语言\u0026#34;); } } class C艹Coder extends Coder{ @Override public void coding() { System.out.println(\u0026#34;笑死，Java再牛逼底层不还得找我？\u0026#34;); } } } 通过提供一个Coder抽象类，定义出编程的行为，但是不进行实现，而是开放给其他具体类型的程序员来实现，这样就可以根据不同的业务进行灵活扩展了，具有较好的延续性。\n不过，回顾我们这一路的学习，好像处处都在使用开闭原则。\n里氏替换原则 #\r里氏替换原则（Liskov Substitution Principle）是对子类型的特别定义。它由芭芭拉·利斯科夫（Barbara Liskov）在1987年在一次会议上名为 \u0026ldquo;数据的抽象与层次\u0026rdquo; 的演说中首先提出。\n所有引用基类的地方必须能透明地使用其子类的对象。\n简单的说就是，子类可以扩展父类的功能，但不能改变父类原有的功能：\n子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。 子类可以增加自己特有的方法。 当子类的方法重载父类的方法时，方法的前置条件（即方法的输入/入参）要比父类方法的输入参数更宽松。 当子类的方法实现父类的方法时（重写/重载或实现抽象方法），方法的后置条件（即方法的输出/返回值）要比父类更严格或与父类一样。 比如我们下面的例子：\npublic abstract class Coder { public void coding() { System.out.println(\u0026#34;我会打代码\u0026#34;); } class JavaCoder extends Coder{ /** * 子类除了会打代码之外，还会打游戏 */ public void game(){ System.out.println(\u0026#34;艾欧尼亚最强王者已上号\u0026#34;); } } } 可以看到JavaCoder虽然继承自Coder，但是并没有对父类方法进行重写，并且还在父类的基础上进行额外扩展，符合里氏替换原则。但是我们再来看下面的这个例子：\npublic abstract class Coder { public void coding() { System.out.println(\u0026#34;我会打代码\u0026#34;); } class JavaCoder extends Coder{ public void game(){ System.out.println(\u0026#34;艾欧尼亚最强王者已上号\u0026#34;); } /** * 这里我们对父类的行为进行了重写，现在它不再具备父类原本的能力了 */ public void coding() { System.out.println(\u0026#34;我寒窗苦读十六年，到最后还不如培训班三个月出来的程序员\u0026#34;); System.out.println(\u0026#34;想来想去，房子车子结婚彩礼，为什么这辈子要活的这么累呢？\u0026#34;); System.out.println(\u0026#34;难道来到这世间走这一遭就为了花一辈子时间买个房子吗？一个人不是也能活的轻松快乐吗？\u0026#34;); System.out.println(\u0026#34;摆烂了，啊对对对\u0026#34;); //好了，emo结束，继续卷吧，人生因奋斗而美丽，这个世界虽然满目疮痍，但是还是有很多美好值得期待 } } } 可以看到，现在我们对父类的方法进行了重写，显然，父类的行为已经被我们给覆盖了，这个子类已经不具备父类的原本的行为，很显然违背了里氏替换原则。\n要是程序员连敲代码都不会了，还能叫做程序员吗？\n所以，对于这种情况，我们不需要再继承自Coder了，我们可以提升一下，将此行为定义到People中：\npublic abstract class People { public abstract void coding(); //这个行为还是定义出来，但是不实现 class Coder extends People{ @Override public void coding() { System.out.println(\u0026#34;我会打代码\u0026#34;); } } class JavaCoder extends People{ public void game(){ System.out.println(\u0026#34;艾欧尼亚最强王者已上号\u0026#34;); } public void coding() { System.out.println(\u0026#34;摆烂了，啊对对对\u0026#34;); } } } 里氏替换也是实现开闭原则的重要方式之一。\n依赖倒转原则 #\r依赖倒转原则（Dependence Inversion Principle）也是我们一直在使用的，最明显的就是我们的Spring框架了。\n高层模块不应依赖于底层模块，它们都应该依赖抽象。抽象不应依赖于细节，细节应该依赖于抽象。\n还记得我们在我们之前的学习中为什么要一直使用接口来进行功能定义，然后再去实现吗？我们回顾一下在使用Spring框架之前的情况：\npublic class Main { public static void main(String[] args) { UserController controller = new UserController(); //该怎么用就这么用 } static class UserMapper { //CRUD... } static class UserService { UserMapper mapper = new UserMapper(); //业务代码.... } static class UserController { UserService service = new UserService(); //业务代码.... } } 但是突然有一天，公司业务需求变化，现在用户相关的业务操作需要使用新的实现：\npublic class Main { public static void main(String[] args) { UserController controller = new UserController(); } static class UserMapper { //CRUD... } static class UserServiceNew { //由于UserServiceNew发生变化，会直接影响到其他高层模块 UserMapper mapper = new UserMapper(); //业务代码.... } static class UserController { //焯，干嘛改底层啊，我这又得重写了 UserService service = new UserService(); //哦豁，原来的不能用了 UserServiceNew serviceNew = new UserServiceNew(); //只能修改成新的了 //业务代码.... } } 我们发现，我们的各个模块之间实际上是具有强关联的，一个模块是直接指定依赖于另一个模块，虽然这样结构清晰，但是底层模块的变动，会直接影响到其他依赖于它的高层模块，如果我们的项目变得很庞大，那么这样的修改将是一场灾难。\n而有了Spring框架之后，我们的开发模式就发生了变化：\npublic class Main { public static void main(String[] args) { UserController controller = new UserController(); } interface UserMapper { //接口中只做CRUD方法定义 } static class UserMapperImpl implements UserMapper { //实现类完成CRUD具体实现 } interface UserService { //业务代码定义.... } static class UserServiceImpl implements UserService { @Resource //现在由Spring来为我们选择一个指定的实现类，然后注入，而不是由我们在类中硬编码进行指定 UserMapper mapper; //业务代码具体实现 } static class UserController { @Resource UserService service; //直接使用接口，就算你改实现，我也不需要再修改代码了 //业务代码.... } } 可以看到，通过使用接口，我们就可以将原有的强关联给弱化，我们只需要知道接口中定义了什么方法然后去使用即可，而具体的操作由接口的实现类来完成，并由Spring来为我们注入，而不是我们通过硬编码的方式去指定。\n接口隔离原则 #\r接口隔离原则（Interface Segregation Principle, ISP）实际上是对接口的细化。\n客户端不应依赖那些它不需要的接口。\n我们在定义接口的时候，一定要注意控制接口的粒度，比如下面的例子：\ninterface Device { String getCpu(); String getType(); String getMemory(); } //电脑就是一种电子设备，那么我们就实现此接口 class Computer implements Device { @Override public String getCpu() { return \u0026#34;i9-12900K\u0026#34;; } @Override public String getType() { return \u0026#34;电脑\u0026#34;; } @Override public String getMemory() { return \u0026#34;32G DDR5\u0026#34;; } } //电风扇也算是一种电子设备 class Fan implements Device { @Override public String getCpu() { return null; //就一个破风扇，还需要CPU？ } @Override public String getType() { return \u0026#34;风扇\u0026#34;; } @Override public String getMemory() { return null; //风扇也不需要内存吧 } } 虽然我们定义了一个Device接口，但是由于此接口的粒度不够细，虽然比较契合电脑这种设备，但是不适合风扇这种设备，因为风扇压根就不需要CPU和内存，所以风扇完全不需要这些方法。这时我们就必须要对其进行更细粒度的划分：\ninterface SmartDevice { //智能设备才有getCpu和getMemory String getCpu(); String getType(); String getMemory(); } interface NormalDevice { //普通设备只有getType String getType(); } //电脑就是一种电子设备，那么我们就继承此接口 class Computer implements SmartDevice { @Override public String getCpu() { return \u0026#34;i9-12900K\u0026#34;; } @Override public String getType() { return \u0026#34;电脑\u0026#34;; } @Override public String getMemory() { return \u0026#34;32G DDR5\u0026#34;; } } //电风扇也算是一种电子设备 class Fan implements NormalDevice { @Override public String getType() { return \u0026#34;风扇\u0026#34;; } } 这样，我们就将接口进行了细粒度的划分，不同类型的电子设备就可以根据划分去实现不同的接口了。当然，也不能划分得太小，还是要根据实际情况来进行决定。\n合成复用原则 #\r合成复用原则（Composite Reuse Principle）的核心就是委派。\n优先使用对象组合，而不是通过继承来达到复用的目的。\n在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分，新的对象通过向这些对象的委派达到复用已有功能的目的。实际上我们在考虑将某个类通过继承关系在子类得到父类已经实现的方法之外（比如A类实现了连接数据库的功能，恰巧B类中也需要，我们就可以通过继承来获得A已经写好的连接数据库的功能，这样就能直接复用A中已经写好的逻辑）我们应该应该优先地去考虑使用合成的方式来实现复用。\n比如下面这个例子：\nclass A { public void connectDatabase(){ System.out.println(\u0026#34;我是连接数据库操作！\u0026#34;); } } class B extends A{ //直接通过继承的方式，得到A的数据库连接逻辑 public void test(){ System.out.println(\u0026#34;我是B的方法，我也需要连接数据库！\u0026#34;); connectDatabase(); //直接调用父类方法就行 } } 虽然这样看起来没啥毛病，但是还是存在我们之前说的那个问题，耦合度太高了。\n可以看到通过继承的方式实现复用，我们是将类B直接指定继承自类A的，那么如果有一天，由于业务的更改，我们的数据库连接操作，不再由A来负责，而是由新来的C去负责，那么这个时候，我们就不得不将需要复用A中方法的子类全部进行修改，很显然这样是费时费力的。\n并且还有一个问题就是，通过继承子类会得到一些父类中的实现细节，比如某些字段或是方法，这样直接暴露给子类，并不安全。\n所以，当我们需要实现复用时，可以优先考虑以下操作：\nclass A { public void connectDatabase(){ System.out.println(\u0026#34;我是连接数据库操作！\u0026#34;); } } class B { //不进行继承，而是在用的时候给我一个A，当然也可以抽象成一个接口，更加灵活 public void test(A a){ System.out.println(\u0026#34;我是B的方法，我也需要连接数据库！\u0026#34;); a.connectDatabase(); //在通过传入的对象A去执行 } } 或是：\nclass A { public void connectDatabase(){ System.out.println(\u0026#34;我是连接数据库操作！\u0026#34;); } } class B { A a; public B(A a){ //在构造时就指定好 this.a = a; } public void test(){ System.out.println(\u0026#34;我是B的方法，我也需要连接数据库！\u0026#34;); a.connectDatabase(); //也是通过对象A去执行 } } 通过对象之间的组合，我们就大大降低了类之间的耦合度，并且A的实现细节我们也不会直接得到了。\n迪米特法则 #\r迪米特法则（Law of Demeter）又称最少知识原则，是对程序内部数据交互的限制。\n每一个软件单位对其他单位都只有最少的知识，而且局限于那些与本单位密切相关的软件单位。\n简单来说就是，一个类/模块对其他的类/模块有越少的交互越好。当一个类发生改动，那么，与其相关的类（比如用到此类啥方法的类）需要尽可能少的受影响（比如修改了方法名、字段名等，可能其他用到这些方法或是字段的类也需要跟着修改）这样我们在维护项目的时候会更加轻松一些。\n其实说白了，还是降低耦合度，我们还是来看一个例子：\npublic class Main { public static void main(String[] args) throws IOException { Socket socket = new Socket(\u0026#34;localhost\u0026#34;, 8080); //假设我们当前的程序需要进行网络通信 Test test = new Test(); test.test(socket); //现在需要执行test方法来做一些事情 } static class Test { /** * 比如test方法需要得到我们当前Socket连接的本地地址 */ public void test(Socket socket){ System.out.println(\u0026#34;IP地址：\u0026#34;+socket.getLocalAddress()); } } } 可以看到，虽然上面这种写法没有问题，我们提供直接提供一个Socket对象，然后再由test方法来取出IP地址，但是这样显然违背了迪米特法则，实际上这里的test方法只需要一个IP地址即可，我们完全可以直接传入一个字符串，而不是整个Socket对象，我们需要保证与其他类的交互尽可能的少。\n就像我们在餐厅吃完了饭，应该是我们自己扫码付款，而不是直接把手机交给老板来帮你操作付款。\n要是某一天，Socket类中的这些方法发生修改了，那我们就得连带着去修改这些类，很麻烦。\n所以，我们来改进改进：\npublic class Main { public static void main(String[] args) throws IOException { Socket socket = new Socket(\u0026#34;localhost\u0026#34;, 8080); Test test = new Test(); test.test(socket.getLocalAddress().getHostAddress()); //在外面解析好就行了 } static class Test { public void test(String str){ //一个字符串就能搞定，就没必要丢整个对象进来 System.out.println(\u0026#34;IP地址：\u0026#34;+str); } } } 这样，类与类之间的耦合度再次降低。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/design/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%80%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","section":"Docs","summary":"面向对象设计原则 #\r**注意：**推荐完成JavaEE通关路线再开始学习。\n我们在进行软件开发时，不仅仅需要将最基本的业务给完成，还要考虑整个项目的可维护性和可复用性，我们开发的项目不单单需要我们自己来维护，同时也需要其他的开发者一起来进行共同维护，因此我们在编写代码时，应该尽可能的规范。如果我们在编写代码时不注重这些问题，整个团队项目就像一座屎山，随着项目的不断扩大，整体结构只会越来越遭。\n甚至到最后你会发现，我们的程序居然是稳定运行在BUG之上的\u0026hellip;\n所以，为了尽可能避免这种情况的发生，我们就来聊聊面向对象设计原则。\n单一职责原则 #\r单一职责原则（Simple Responsibility Pinciple，SRP）是最简单的面向对象设计原则，它用于控制类的粒度大小。\n一个对象应该只包含单一的职责，并且该职责被完整地封装在一个类中。\n比如我们现在有一个People类：\n//一个人类 public class People { /** * 人类会编程 */ public void coding(){ System.out.println(\u0026#34;int mian() {\u0026#34;); System.out.println(\u0026#34; printf(\\\u0026#34;Holle Wrold!","title":"面向对象设计原则","type":"doc"},{"content":"","date":"1 January 0001","externalUrl":null,"permalink":"/series/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","section":"Series","summary":"","title":"设计模式","type":"series"},{"content":"待完成\u0026hellip;.\n","date":"1 January 0001","externalUrl":null,"permalink":"/media/","section":"","summary":"待完成\u0026hellip;.","title":"书影音","type":"sample"},{"content":"\r设计模式（行为型） #\r前面我们已经学习了12种设计模式，分为两类：\n创建型：关注对象创建 结构型：关注类和对象的结构组织 我们接着来看最后一种设计模式，也是最多的一种，行为型设计模式关注系统中对象之间的交互，研究系统在运行时对象之间的相互通信与协作，进一步明确对象的职责。\n解释器模式 #\r这种模式的使用场景较少，很少使用的一种设计模式，这里提一下就行。\n解释器顾名思义，就是对我们的语言进行解释，根据不同的语义来做不同的事情，比如我们在SE中学习的双栈计算器，正是根据我们输入的算式，去进行解析，并根据不同的运算符来不断进行计算。\n比如我们输入：1+2*3\n那么计算器就会进行解析然后根据语义优先计算2*3的结果然后在计算1+6最后得到7，详细实现请参考JavaSE篇双栈计算器实现。\n模板方法模式 #\r模板方法模式我们之前也见到过许多，我们先来看看什么是模板方法。\n有些时候，我们的业务可能需要经历很多个步骤来完成，比如我们生病了在医院看病，首先是去门诊挂号，然后等待叫号，然后是去找医生看病，确定病因后，就根据医生的处方去前台开药，最后付钱。这一整套流程看似是规规矩矩的，但是在这其中，某些步骤并不是确定的，比如医生看病这一步，由于不同的病因，可能会进行不同的处理，最后开出来的药方也会不同，所以，整套流程中，有些操作是固定的，有些操作可能需要根据具体情况而定。\n在我们的程序中也是如此，可能某些操作是固定的，我们就可以直接在类中对应方法进行编写，但是可能某些操作需要视情况而定，由不同的子类实现来决定，这时，我们就需要让这些操作由子类来延迟实现了。现在我们就需要用到模板方法模式。\n我们先来写个例子：\n/** * 抽象诊断方法，因为现在只知道挂号和看医生是固定模式，剩下的开处方和拿药都是不确定的 */ public abstract class AbstractDiagnosis { public void test(){ System.out.println(\u0026#34;今天头好晕，不想起床，开摆，先跟公司请个假\u0026#34;); System.out.println(\u0026#34;去医院看病了~\u0026#34;); System.out.println(\u0026#34;1 \u0026gt;\u0026gt; 先挂号\u0026#34;); System.out.println(\u0026#34;2 \u0026gt;\u0026gt; 等待叫号\u0026#34;); //由于现在不知道该开什么处方，所以只能先定义一下行为，然后具体由子类实现 //大致的流程先定义好就行 this.prescribe(); this.medicine(); //开药同理 } public abstract void prescribe(); //开处方操作根据具体病症决定了 public abstract void medicine(); //拿药也是根据具体的处方去拿 } 现在我们定义好了抽象方法，只是将具体的流程先定义出来了，但是部分方法需要根据实现决定：\n/** * 感冒相关的具体实现子类 */ public class ColdDiagnosis extends AbstractDiagnosis{ @Override public void prescribe() { System.out.println(\u0026#34;3 \u0026gt;\u0026gt; 一眼丁真，鉴定为假，你这不是感冒，纯粹是想摆烂\u0026#34;); } @Override public void medicine() { System.out.println(\u0026#34;4 \u0026gt;\u0026gt; 开点头孢回去吃吧\u0026#34;); } } 这样，我们就有了一个具体的实现类，并且由于看病的逻辑已经由父类定义好了，所以子类只需要实现需要实现的部分即可，这样我们就实现了简单的模板方法模式：\npublic static void main(String[] args) { AbstractDiagnosis diagnosis = new ColdDiagnosis(); diagnosis.test(); } 最后我们来看看在JUC中讲解AQS源码实现中出现的代码：\npublic final boolean release(int arg) { //AQS的锁释放操作 if (tryRelease(arg)) { //可以看到这里调用了tryRelease方法，但是此方法并不是在AQS实现的，而是不同的锁自行实现，因为AQS也不知道你这种类型的锁到底该怎么去解锁 Node h = head; if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); //AQS中不支持，需要延迟到具体的子类去实现 } 模板方法模式，实际上部分功能的实现是在子类完成的：\nprotected final boolean tryRelease(int releases) { //ReentrantLock中的AQS Sync实现类，对tryRelease方法进行了具体实现 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free; } 是不是现在感觉，这种层层套娃的写法，好像并不是这些大佬故意为了装逼才这样写的，而是真的在遵守规范编写，让代码更易懂一些，甚至你现在再回去推一遍会发现思路非常清晰。当然，除了这里之外，还有很多框架都使用了模板方法模式来设计类结构，还请各位小伙伴自行探索。\n责任链模式 #\r责任链模式也非常好理解，比如我们的钉钉审批，实际上就是一条流水线一样的操作，由你发起申请，然后经过多个部门主管审批，最后才能通过，所以你的申请表相当于是在一条责任链上传递。当然除了这样的直线型责任链之外，还有环形、树形等。\n实际上我们之前也遇到过很多种责任链，比如JavaWeb中学习的Filter过滤器，正是采用的责任链模式，通过将请求一级一级不断向下传递，来对我们所需要的请求进行过滤和处理。\n这里我们就使用责任链模式来模拟一个简单的面试过程，我们面试也是一面二面三面这样走的流程，这里我们先设计一下责任链上的各个处理器：\npublic abstract class Handler { protected Handler successor; //这里我们就设计责任链以单链表形式存在，这里存放后继节点 public Handler connect(Handler successor){ //拼接后续节点 this.successor = successor; return successor; //这里返回后继节点，方便我们一会链式调用 } public void handle(){ this.doHandle(); //由不同的子类实现具体处理过程 Optional .ofNullable(successor) .ifPresent(Handler::handle); //责任链上如果还有后继节点，就继续向下传递 } public abstract void doHandle(); //结合上节课学习的模板方法，交给子类实现 } 因为面试有很多轮，所以我们这里创建几个处理器的实现：\npublic class FirstHandler extends Handler{ //用于一面的处理器 @Override public void doHandle() { System.out.println(\u0026#34;============= 白马程序员一面 ==========\u0026#34;); System.out.println(\u0026#34;1. 谈谈你对static关键字的理解？\u0026#34;); System.out.println(\u0026#34;2. 内部类可以调用外部的数据吗？如果是静态的呢？\u0026#34;); System.out.println(\u0026#34;3. hashCode()方法是所有的类都有吗？默认返回的是什么呢？\u0026#34;); System.out.println(\u0026#34;以上问题会的，可以依次打在评论区\u0026#34;); } } public class SecondHandler extends Handler{ //二面 @Override public void doHandle() { System.out.println(\u0026#34;============= 白马程序员二面 ==========\u0026#34;); System.out.println(\u0026#34;1. 如果我们自己创建一个java.lang包并且编写一个String类，能否实现覆盖JDK默认的？\u0026#34;); System.out.println(\u0026#34;2. HashMap的负载因子有什么作用？变化规律是什么？\u0026#34;); System.out.println(\u0026#34;3. 线程池的运作机制是什么？\u0026#34;); System.out.println(\u0026#34;4. ReentrantLock公平锁和非公平锁的区别是什么？\u0026#34;); System.out.println(\u0026#34;以上问题会的，可以依次打在评论区\u0026#34;); } } public class ThirdHandler extends Handler{ @Override public void doHandle() { System.out.println(\u0026#34;============= 白马程序员三面 ==========\u0026#34;); System.out.println(\u0026#34;1. synchronized关键字了解吗？如何使用？底层是如何实现的？\u0026#34;); System.out.println(\u0026#34;2. IO和NIO的区别在哪里？NIO三大核心组件？\u0026#34;); System.out.println(\u0026#34;3. TCP握手和挥手流程？少一次握手可以吗？为什么？\u0026#34;); System.out.println(\u0026#34;4. 操作系统中PCB是做什么的？运行机制是什么？\u0026#34;); System.out.println(\u0026#34;以上问题会的，可以依次打在评论区\u0026#34;); } } 这样我们就编写好了每一轮的面试流程，现在我们就可以构建一个责任链了：\npublic static void main(String[] args) { Handler handler = new FirstHandler(); //一面首当其冲 handler .connect(new SecondHandler()) //继续连接二面和三面 .connect(new ThirdHandler()); handler.handle(); //开始面试 } 可以看到最后结果也是按照我们的责任链来进行的。\n命令模式 #\r大家有没有发现现在的家电都在趋向于智能化，通过一个中央控制器，我们就可以对家里的很多电器进行控制，比如国内做的比较好的小米智能家居系列，还有Apple的HomeKit等，我们只需要在一个终端上进行操作，就可以随便控制家里的电器。\n比如现在我们有很多的类，彩电、冰箱、空调、洗衣机、热水器等，既然现在我们要通过一个遥控器去控制他们，那么我们就需要将控制这些电器的指令都给设计好才行，并且还不能有太强的关联性。\n所有的电器肯定需要通过蓝牙或是红外线接受遥控器发送的请求，所以所有的电器都是接收者：\npublic interface Receiver { void action(); //具体行为，这里就写一个算了 } 接着我们要控制这些电器，那么肯定需要一个指令才能控制：\npublic abstract class Command { //指令抽象，不同的电器有指令 private final Receiver receiver; protected Command(Receiver receiver){ //指定此命令对应的电器（接受者） this.receiver = receiver; } public void execute() { receiver.action(); //执行命令，实际上就是让接收者开始干活 } } 最后我们来安排一个遥控器：\npublic class Controller { //遥控器只需要把我们的指令发出去就行了 public static void call(Command command){ command.execute(); } } 比如现在我们创建一个空调，那么它就是作为我们命令的接收者：\npublic class AirConditioner implements Receiver{ @Override public void action() { System.out.println(\u0026#34;空调已开启，呼呼呼\u0026#34;); } } 现在我们创建一个开启空调的命令：\npublic class OpenCommand extends Command { public OpenCommand(AirConditioner airConditioner) { super(airConditioner); } } 最后我们只需要通过遥控器发送出去就可以了：\npublic static void main(String[] args) { AirConditioner airConditioner = new AirConditioner(); //先创建一个空调 Controller.call(new OpenCommand(airConditioner)); //直接通过遥控器来发送空调开启命令 } 通过这种方式，遥控器这个角色并不需要知道具体会执行什么，只需要发送命令即可，遥控器和电器的关联性就不再那么强了。\n迭代器模式 #\r迭代器我们在JavaSE篇就已经讲解过了，迭代器可以说是我们学习Java语言的基础，没有迭代器，集合类的遍历就成了问题，正是因为有迭代器的存在，我们才能更加优雅的使用foreach语法。\n回顾我们之前使用迭代器的场景：\npublic static void main(String[] args) { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34;); for (String s : list) { //使用foreach语法糖进行迭代，依次获取每一个元素 System.out.println(s); //打印一下 } } 编译之后的代码如下：\npublic static void main(String[] args) { List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34;); Iterator var2 = list.iterator(); //实际上这里本质是通过List生成的迭代器来遍历我们每个元素的 while(var2.hasNext()) { //判断是否还有元素可以迭代，没有就false String s = (String)var2.next(); //通过next方法得到下一个元素，每调用一次，迭代器会向后移动一位 System.out.println(s); //打印一下 } } 可以看到，当我们使用迭代器对List进行遍历时，实际上就像一个指向列表头部的指针，我们通过不断向后移动指针来依次获取所指向的元素：\n这里，我们依照JDK提供的迭代器接口（JDK已经为我们定义好了一个迭代器的具体相关操作），也来设计一个迭代器：\npublic class ArrayCollection\u0026lt;T\u0026gt; { //首先设计一个简单的数组集合，一会我们就迭代此集合内的元素 private final T[] array; //底层使用一个数组来存放数据 private ArrayCollection(T[] array){ //private掉，自己用 this.array = array; } public static \u0026lt;T\u0026gt; ArrayCollection\u0026lt;T\u0026gt; of(T[] array){ //开个静态方法直接吧数组转换成ArrayCollection，其实和直接new一样，但是这样写好看一点 return new ArrayCollection\u0026lt;\u0026gt;(array); } } 现在我们就可以将数据存放在此集合中了：\npublic static void main(String[] args) { String[] arr = new String[]{\u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34;, \u0026#34;DDD\u0026#34;}; ArrayCollection\u0026lt;String\u0026gt; collection = ArrayCollection.of(arr); } 接着我们就可以来实现迭代器接口了：\npublic class ArrayCollection\u0026lt;T\u0026gt; implements Iterable\u0026lt;T\u0026gt;{ //实现Iterable接口表示此类是支持迭代的 ... @Override public Iterator\u0026lt;T\u0026gt; iterator() { //需要实现iterator方法，此方法会返回一个迭代器，用于迭代我们集合中的元素 return new ArrayIterator(); } public class ArrayIterator implements Iterator\u0026lt;T\u0026gt; { //这里实现一个，注意别用静态，需要使用对象中存放的数组 private int cur = 0; //这里我们通过一个指针表示当前的迭代位置 @Override public boolean hasNext() { //判断是否还有下一个元素 return cur \u0026lt; array.length; //如果指针大于或等于数组最大长度，就不能再继续了 } @Override public T next() { //返回当前指针位置的元素并向后移动一位 return array[cur++]; //正常返回对应位置的元素，并将指针自增 } } } 接着，我们就可以对我们自己编写的一个简单集合类进行迭代了：\npublic static void main(String[] args) { String[] arr = new String[]{\u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34;, \u0026#34;DDD\u0026#34;}; ArrayCollection\u0026lt;String\u0026gt; collection = ArrayCollection.of(arr); for (String s : collection) { //可以直接使用foreach语法糖，当然最后还是会变成迭代器调用 System.out.println(s); } } 最后编译出来的样子：\npublic static void main(String[] args) { String[] arr = new String[]{\u0026#34;AAA\u0026#34;, \u0026#34;BBB\u0026#34;, \u0026#34;CCC\u0026#34;, \u0026#34;DDD\u0026#34;}; ArrayCollection\u0026lt;String\u0026gt; collection = ArrayCollection.of(arr); Iterator var3 = collection.iterator(); //首先获取迭代器，实际上就是调用我们实现的iterator方法 while(var3.hasNext()) { String s = (String)var3.next(); //直接使用next()方法不断向下获取 System.out.println(s); } } 这样我们就实现了一个迭代器来遍历我们的元素。\n中介者模式 #\r在早期，我们想要和别人进行语音聊天，一般都是通过电话的方式，我们通过拨打他人的电话号码，来建立会话，不过这样有一个问题，比如我现在想要通知通知3个人某件事情，那么我就得依次给三个人打电话，甚至还会遇到一种情况，就是我们没有某个人的电话号码，但是其他人有，这时还需要告知这个人并进行转告，就很麻烦。\n但是现在我们有了Facetime、有了微信，我们可以同时让多个人参与到群通话中进行群聊，这样我们就不需要一个一个单独进行通话或是转达了。实际上正是依靠了一个中间商给我们提供了进行群体通话的平台，我们才能实现此功能，而这个平台实际上就是一个中间人。又比如我们想要去外面租房，但是我们怎么知道哪里有可以租的房子呢？于是我们就会上各大租房APP上去找房源，同样的，如果我们现在有房子需要出租，我们也不知道谁会想要租房子，同样的我们也会把房子挂在租房APP上展示，而当我们去租房时或是出租时，就会有一个称为中介的人来跟我们对接，实际上也是一种中介的模式。\n在我们的程序中，可能也会出现很多的对象，但是这些对象之间的相互调用关系错综复杂，可能一个对象要做什么事情就得联系好几个对象：\n但是如果我们在这中间搞一个中间人：\n这样当我们要联系其他人时，一律找中介就可以了，中介存储了所有人的联系方式，这样就不会像上面一样乱成一团了。这里我们就以房产中介的例子来编写：\npublic class Mediator { //房产中介 private final Map\u0026lt;String, User\u0026gt; userMap = new HashMap\u0026lt;\u0026gt;(); //在出售的房子需要存储一下 public void register(String address, User user){ //出售房屋的人，需要告诉中介他的房屋在哪里 userMap.put(address, user); } public User find(String address){ //通过此方法来看看有没有对应的房源 return userMap.get(address); } } 接着就是用户了，用户有两种角色，一种是租房，一种是出租：\npublic class User { //用户可以是出售房屋的一方，也可以是寻找房屋的一方 String name; String tel; public User(String name, String tel) { this.name = name; this.tel = tel; } public User find(String address, Mediator mediator){ //找房子的话，需要一个中介和你具体想找的地方 return mediator.find(address); } @Override public String toString() { return name+\u0026#34; (电话：\u0026#34;+tel+\u0026#34;)\u0026#34;; } } 现在我们来测试一下：\npublic static void main(String[] args) { User user0 = new User(\u0026#34;刘女士\u0026#34;, \u0026#34;10086\u0026#34;); //出租人 User user1 = new User(\u0026#34;李先生\u0026#34;, \u0026#34;10010\u0026#34;); //找房人 Mediator mediator = new Mediator(); //我是黑心中介 mediator.register(\u0026#34;成都市武侯区天府五街白马程序员\u0026#34;, user0); //先把房子给中介挂上去 User user = user1.find(\u0026#34;成都市武侯区天府五街下硅谷\u0026#34;, mediator); //开始找房子 if(user == null) System.out.println(\u0026#34;没有找到对应的房源\u0026#34;); user = user1.find(\u0026#34;成都市武侯区天府五街白马程序员\u0026#34;, mediator); //开始找房子 System.out.println(user); //成功找到对应房源 } 中介者模式优化了原有的复杂多对多关系，而是将其简化为一对多的关系，更容易理解一些。\n备忘录模式 #\r2021年10月1日下午，河南驻马店的一名13岁女中学生，因和同学发生不愉快喝下半瓶百草枯。\n10月5日，抢救四天情况恶化，家属泣不成声称“肺部一个小时一变”。\n10月6日下午，据武警河南省总队医院消息，“目前女孩仍在医院救治。”\n喝下百草枯，会给你后悔的时间，但是不会给你后悔的机会（百草枯含有剧毒物质，会直接导致肺部纤维化，这是不可逆的，一般死亡过程在一周左右，即使家里花了再多的钱，接受了再多的治疗，也无法逆转这一过程）相信如果再给这位小女孩一次机会，回到拿起百草枯的那一刻，一定不会再冲动地喝下了吧。\n备忘录模式，就为我们的软件提供了一个可回溯的时间节点，可能我们程序在运行过程中某一步出现了错误，这时我们就可以回到之前的某个被保存的节点上重新来过（就像艾克的大招），我们平时编辑文本的时候，当我们编辑出现错误时，就需要撤回，而我们只需要按下Ctrl+Z就可以回到上一步，这样就大大方便了我们的文本编辑。\n其实备忘录模式也可以应用到我们的程序中，如果你学习过安卓开发，安卓程序在很多情况下都会重新加载Activity，实际上安卓中Activity的onSaveInstanceState和onRestoreInstanceState就是用到了备忘录模式，分别用于保存和恢复，这样就算重新加载也可以恢复到之前的状态。\n这里我们就模拟一下对象的状态保存：\npublic class Student { private String currentWork; //当前正在做的事情 private int percentage; //当前的工作完成百分比 public void work(String currentWork) { this.currentWork = currentWork; this.percentage = new Random().nextInt(100); } @Override public String toString() { return \u0026#34;我现在正在做：\u0026#34;+currentWork+\u0026#34; (进度：\u0026#34;+percentage+\u0026#34;%)\u0026#34;; } } 接着我们需要保存它在某一时刻的状态，我们来编写一个状态保存类：\npublic class State { final String currentWork; final int percentage; State(String currentWork, int percentage) { //仅开放给同一个包下的Student类使用 this.currentWork = currentWork; this.percentage = percentage; } } 接着我们来将状态的保存和恢复操作都实现一下：\npublic class Student { ... public State save(){ return new State(currentWork, percentage); } public void restore(State state){ this.currentWork = state.currentWork; this.percentage = state.percentage; } ... } 现在我们来测试一下吧：\npublic static void main(String[] args) { Student student = new Student(); student.work(\u0026#34;学Java\u0026#34;); //开始学Java System.out.println(student); State savedState = student.save(); //保存一下当前的状态 student.work(\u0026#34;打电动\u0026#34;); //刚打开B站播放视频，学一半开始摆烂了 System.out.println(student); student.restore(savedState); //两级反转！回到上一个保存的状态 System.out.println(student); //回到学Java的状态 } 可以看到，虽然在学习Java的过程中，中途摆烂了，但是我们可以时光倒流，回到还没开始摆烂的时候，继续学习Java：\n不过备忘录模式为了去保存对象的状态，会占用大量的资源，尤其是那种属性很多的对象，我们需要合理的使用才能保证程序稳定运行。\n观察者模式 #\r牵一发而动全身，一幅有序摆放的多米诺骨牌，在我们推到第一个骨牌时，后面的骨牌会不断地被上一个骨牌推倒：\n在Java中，一个对象的状态发生改变，可能就会影响到其他的对象，与之相关的对象可能也会联动的进行改变。还有我们之前遇到过的监听器机制，当具体的事件触发时，我们在一开始创建的监听器就可以执行相关的逻辑。我们可以使用观察者模式来实现这样的功能，当对象发生改变时，观察者能够立即观察到并进行一些联动操作，我们先定义一个观察者接口：\npublic interface Observer { //观察者接口 void update(); //当对象有更新时，会回调此方法 } 接着我们来写一个支持观察者的实体类：\npublic class Subject { private final Set\u0026lt;Observer\u0026gt; observerSet = new HashSet\u0026lt;\u0026gt;(); public void observe(Observer observer) { //添加观察者 observerSet.add(observer); } public void modify() { //模拟对象进行修改 observerSet.forEach(Observer::update); //当对象发生修改时，会通知所有的观察者，并进行方法回调 } } 接着我们就可以测试一下了：\npublic static void main(String[] args) { Subject subject = new Subject(); subject.observe(() -\u0026gt; System.out.println(\u0026#34;我是一号观察者！\u0026#34;)); subject.observe(() -\u0026gt; System.out.println(\u0026#34;我是二号观察者！\u0026#34;)); subject.modify(); } 这样，我们就简单实现了一下观察者模式，当然JDK也为我们提供了实现观察者模式相关的接口：\nimport java.util.Observable; //java.util包下提供的观察者抽象类 public class Subject extends Observable { //继承此抽象类表示支持观察者 public void modify(){ System.out.println(\u0026#34;对对象进行修改！\u0026#34;); this.setChanged(); //当对对象修改后，需要setChanged来设定为已修改状态 this.notifyObservers(new Date()); //使用notifyObservers方法来通知所有的观察者 //注意只有已修改状态下通知观察者才会有效，并且可以给观察者传递参数，这里传递了一个时间对象 } } 我们来测试一下吧：\npublic static void main(String[] args) { Subject subject = new Subject(); subject.addObserver((o, arg) -\u0026gt; System.out.println(\u0026#34;监听到变化，并得到参数：\u0026#34;+arg)); //注意这里的Observer是java.util包下提供的 subject.modify(); //进行修改操作 } 状态模式 #\r在标准大气压下，水在0度时会结冰变成固态，在0-100度之间时，会呈现液态，100度以上会变成气态，水这种物质在不同的温度下呈现出不同的状态，而我们的对象，可能也会像这样存在很多种状态，甚至在不同的状态下会有不同的行为，我们就可以通过状态模式来实现。\n我们来设计一个学生类，然后学生的学习方法会根据状态不同而发生改变，我们先设计一个状态枚举：\npublic enum State { //状态直接使用枚举定义 NORMAL, LAZY } 接着我们来编写一个学生类：\npublic class Student { public class Student { private State state; //使用一个成员来存储状态 public void setState(State state) { this.state = state; } public void study(){ switch (state) { //根据不同的状态，学习方法会有不同的结果 case LAZY: System.out.println(\u0026#34;只要我不努力，老板就别想过上想要的生活，开摆！\u0026#34;); break; case NORMAL: System.out.println(\u0026#34;拼搏百天，我要上清华大学！\u0026#34;); break; } } } 我们来看看，在不同的状态下，是否学习会出现不同的效果：\npublic static void main(String[] args) { Student student = new Student(); student.setState(State.NORMAL); //先正常模式 student.study(); student.setState(State.LAZY); //开启摆烂模式 student.study(); } 状态模式更加强调当前的对象所处的状态，我们需要根据对象不同的状态决定其他的处理逻辑。\n策略模式 #\r对面卡兹克打野被开了，我们是去打小龙还是打大龙呢？这就要看我们团队这一局的打法策略了。\n我们可以为对象设定一种策略，这样对象之后的行为就会按照我们在一开始指定的策略而决定了，看起来和前面的状态模式很像，但是，它与状态模式的区别在于，这种转换是“主动”的，是由我们去指定，而状态模式，可能是在运行过程中自动切换的。\n其实策略模式我们之前也遇到过，比如线程池的拒绝策略：\npublic static void main(String[] args) { ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;\u0026gt;(), //这里不给排队 new ThreadPoolExecutor.AbortPolicy()); //当线程池无法再继续创建新任务时，我们可以自由决定使用什么拒绝策略 Runnable runnable = () -\u0026gt; { try { TimeUnit.SECONDS.sleep(60); } catch (InterruptedException e) { throw new RuntimeException(e); } }; executor.execute(runnable); //连续提交两次任务，肯定塞不下，这时就得走拒绝了 executor.execute(runnable); } 可以看到，我们如果使用AbortPolicy，那么就是直接抛出异常：\n我们也可以使用其他的策略：\npublic static void main(String[] args) { ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, 10, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;\u0026gt;(), new ThreadPoolExecutor.DiscardOldestPolicy()); //使用DiscardOldestPolicy策略从队列中丢弃 这种策略就会从等待队列中踢出一个之前的，不过我们这里的等待队列是没有容量的那种，所以会直接炸掉：\n至于具体原因，可以回去看看JUC篇视频教程。\n再比如我们现在有一个排序类，但是根据不同的策略，会使用不同的排序方案：\npublic interface Strategy { //策略接口，不同的策略实现也不同 Strategy SINGLE = Arrays::sort; //单线程排序方案 Strategy PARALLEL = Arrays::parallelSort; //并行排序方案 void sort(int[] array); } 现在我们编写一个排序类：\npublic class Sorter { private Strategy strategy; //策略 public void setStrategy(Strategy strategy) { this.strategy = strategy; } public void sort(int[] array){ strategy.sort(array); } } 现在我们就可以指定不同的策略进行排序了：\npublic static void main(String[] args) { Sorter sorter = new Sorter(); sorter.setStrategy(Strategy.PARALLEL); //指定为并行排序方案 sorter.sort(new int[]{9, 2, 4, 5, 1, 0, 3, 7}); } 访问者模式 #\r公园中存在多个景点，也存在多个游客，不同的游客对同一个景点的评价可能不同；医院医生开的处方单中包含多种药元素，査看它的划价员和药房工作人员对它的处理方式也不同，划价员根据处方单上面的药品名和数量进行划价，药房工作人员根据处方单的内容进行抓药，相对于处方单来说，划价员和药房工作人员就是它的访问者，不过访问者的访问方式可能会不同。\n在我们的Java程序中，也可能会出现这种情况，我们就可以通过访问者模式来进行设计。\n比如我们日以继夜地努力，终于在某某比赛赢得了冠军，而不同的人对于这分荣誉，却有着不同的反应：\npublic class Prize { //奖 String name; //比赛名称 String level; //等级 public Prize(String name, String level) { this.name = name; this.level = level; } public String getName() { return name; } public String getLevel() { return level; } } 我们首先定义一个访问者接口：\npublic interface Visitor { void visit(Prize prize); //visit方法来访问我们的奖项 } 然后就是访问者相关的实现了：\npublic class Teacher implements Visitor { //指导老师作为一个访问者 @Override public void visit(Prize prize) { //它只关心你得了什么奖以及是几等奖，这也关乎老师的荣誉 System.out.println(\u0026#34;你得奖是什么奖？\u0026#34;+prize.name); System.out.println(\u0026#34;你得了几等奖？\u0026#34;+prize.level); } } public class Boss implements Visitor{ //你的公司老板作为一个访问者 @Override public void visit(Prize prize) { //你的老板只关心这些能不能为公司带来什么效益，奖本身并不重要 System.out.println(\u0026#34;你的奖项大么，能够为公司带来什么效益么？\u0026#34;); System.out.println(\u0026#34;还不如老老实实加班给我多干干，别去搞这些没用的\u0026#34;); } } public class Classmate implements Visitor{ //你的同学也可以作为一个访问者 @Override public void visit(Prize prize) { //你的同学也关心你得了什么奖，不过是因为你是他的奖学金竞争对手，他其实并不希望你得奖 System.out.println(\u0026#34;你得了\u0026#34;+prize.name+\u0026#34;奖啊，还可以\u0026#34;); System.out.println(\u0026#34;不过这个奖没什么含金量，下次别去了\u0026#34;); } } public class Family implements Visitor{ //你的家人也可以是一个访问者 @Override public void visit(Prize prize) { //你的家人并不是最关心你得了什么奖，而是先关心你自己然后才是奖项，他们才是真正希望你好的人。这个世界很残酷，可能你会被欺负得遍体鳞伤，可能你会觉得活着如此艰难，但是你的背后至少还有爱你的人，为了他们，怎能就此驻足。 System.out.println(\u0026#34;孩子，辛苦了，有没有好好照顾自己啊\u0026#34;); System.out.println(\u0026#34;你得了什么奖啊？\u0026#34;+prize.name+\u0026#34;，很不错，要继续加油啊！\u0026#34;); } } 可以看到，这里我们就设计了四种访问者，但是不同的访问者对于某一件事务的处理可能会不同。访问者模式把数据结构和作用于结构上的操作解耦，使得操作集合可相对自由地演化，我们上面就是将奖项本身的属性和对于奖项的不同操作进行了分离。\n","date":"1 January 0001","externalUrl":null,"permalink":"/doc/design/%E8%A1%8C%E4%B8%BA%E5%9E%8B/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%B3%BB%E5%88%97-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9B%9B%E8%A1%8C%E4%B8%BA%E5%9E%8B/","section":"Docs","summary":"设计模式（行为型） #\r前面我们已经学习了12种设计模式，分为两类：\n创建型：关注对象创建 结构型：关注类和对象的结构组织 我们接着来看最后一种设计模式，也是最多的一种，行为型设计模式关注系统中对象之间的交互，研究系统在运行时对象之间的相互通信与协作，进一步明确对象的职责。\n解释器模式 #\r这种模式的使用场景较少，很少使用的一种设计模式，这里提一下就行。\n解释器顾名思义，就是对我们的语言进行解释，根据不同的语义来做不同的事情，比如我们在SE中学习的双栈计算器，正是根据我们输入的算式，去进行解析，并根据不同的运算符来不断进行计算。\n比如我们输入：1+2*3\n那么计算器就会进行解析然后根据语义优先计算2*3的结果然后在计算1+6最后得到7，详细实现请参考JavaSE篇双栈计算器实现。\n模板方法模式 #\r模板方法模式我们之前也见到过许多，我们先来看看什么是模板方法。\n有些时候，我们的业务可能需要经历很多个步骤来完成，比如我们生病了在医院看病，首先是去门诊挂号，然后等待叫号，然后是去找医生看病，确定病因后，就根据医生的处方去前台开药，最后付钱。这一整套流程看似是规规矩矩的，但是在这其中，某些步骤并不是确定的，比如医生看病这一步，由于不同的病因，可能会进行不同的处理，最后开出来的药方也会不同，所以，整套流程中，有些操作是固定的，有些操作可能需要根据具体情况而定。\n在我们的程序中也是如此，可能某些操作是固定的，我们就可以直接在类中对应方法进行编写，但是可能某些操作需要视情况而定，由不同的子类实现来决定，这时，我们就需要让这些操作由子类来延迟实现了。现在我们就需要用到模板方法模式。\n我们先来写个例子：\n/** * 抽象诊断方法，因为现在只知道挂号和看医生是固定模式，剩下的开处方和拿药都是不确定的 */ public abstract class AbstractDiagnosis { public void test(){ System.","title":"行为型","type":"doc"},{"content":"删除元素\n指的是覆盖而不是的的确确的删除\nC++ vector作为数组的封装\nerase函数：删除：O(n)\n双指针实现\nclass Solution { public: int removeElement(vector\u0026lt;int\u0026gt;\u0026amp; nums, int val) { //定义快慢指针 int fast = 0;//获取新元素 int slow = 0;//获取更改位置 for(fast = 0; fast \u0026lt; nums.size(); fast++){ if(nums[fast] != val){ nums[slow++]=nums[fast]; } } return slow; } }; ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E7%A7%BB%E9%99%A4%E5%85%83%E7%B4%A0/","section":"Algorithms","summary":"删除元素\n指的是覆盖而不是的的确确的删除\nC++ vector作为数组的封装\nerase函数：删除：O(n)\n双指针实现\nclass Solution { public: int removeElement(vector\u0026lt;int\u0026gt;\u0026amp; nums, int val) { //定义快慢指针 int fast = 0;//获取新元素 int slow = 0;//获取更改位置 for(fast = 0; fast \u0026lt; nums.","title":"移除元素","type":"algorithm"},{"content":"977\n有序数组的平方\n输入：nums = [-4,-1,0,3,10] 输出：[0,1,9,16,100] 解释：平方后，数组变为 [16,1,0,9,100] 排序后，数组变为 [0,1,9,16,100] 最大元素在两边，使用两个指针从两边到中间合拢\n更新方法从大到小\nvector\u0026lt;int\u0026gt;result(nums.size(),0); int k=nums.size()-1;//新数组的下标 int i=0,j=nums.size()-1; //分别从两边往中间取 while(i\u0026lt;=j){ if(nums[i]*nums[i]\u0026lt;nums[j]*nums[j]){ result[k--]=nums[j]*nums[j]; j--; } //num[i]*nums[i] \u0026gt;= nums[j]*nums[j] else { result[k--]=nums[i]*nums[i]; i++; } } return result; class Solution { public int[] sortedSquares(int[] nums) { int []res = new int [nums.length ]; int k = nums.length -1; int j=nums.length-1; int i =0; while(i\u0026lt;=j){ if(nums[i]*nums[i] \u0026gt; nums[j]*nums[j]){ res[k--] = nums[i]*nums[i]; i++; }else{ res[k--] = nums[j]*nums[j]; j--; } } return res; } } ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E5%B9%B3%E6%96%B9/","section":"Algorithms","summary":"977\n有序数组的平方\n输入：nums = [-4,-1,0,3,10] 输出：[0,1,9,16,100] 解释：平方后，数组变为 [16,1,0,9,100] 排序后，数组变为 [0,1,9,16,100] 最大元素在两边，使用两个指针从两边到中间合拢\n更新方法从大到小\nvector\u0026lt;int\u0026gt;result(nums.size(),0); int k=nums.size()-1;//新数组的下标 int i=0,j=nums.size()-1; //分别从两边往中间取 while(i\u0026lt;=j){ if(nums[i]*nums[i]\u0026lt;nums[j]*nums[j]){ result[k--]=nums[j]*nums[j]; j--; } //num[i]*nums[i] \u0026gt;= nums[j]*nums[j] else { result[k--]=nums[i]*nums[i]; i++; } } return result; class Solution { public int[] sortedSquares(int[] nums) { int []res = new int [nums.","title":"有序数组的平方","type":"algorithm"},{"content":"209\n给定一个含有 n 个正整数的数组和一个正整数 target 。\n找出该数组中满足其总和大于等于 target 的长度最小的 连续 子数组 [numsl, numsl+1, \u0026hellip;, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。\n输入：target = 7, nums = [2,3,1,2,4,3] 输出：2 解释：子数组 [4,3] 是该条件下的长度最小的子数组。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; class Solution { public: int minSubArrayLen(int target, vector\u0026lt;int\u0026gt;\u0026amp; nums) { int right = nums.size(); if(right == 0){ return 0; } int ans = INT_MAX; // vector\u0026lt;int\u0026gt; sums(right+1,0);//要多一个长度，前缀和 int *sums = (int *)malloc(sizeof(int) * (right + 1)); //计算前缀和 for(int i =1; i\u0026lt;=right; i++){ sums[i] = sums[i-1]+nums[i-1];//太妙了，这样就可以计算前缀和了 } //二分法 for(int i = 1;i \u0026lt;= right; i++){ int mid = target+sums[i-1]; int bound = lower_bounds(sums, 1, right, mid); if(bound != -1){ ans=min(ans,(bound - ( i - 1 ))); } } return ans == INT_MAX ? 0 : ans; } int lower_bounds(int *array, int l, int r, int q) { if (array[r] \u0026lt; q) return -1; while (l \u0026lt; r) { int mid = (l + r) \u0026gt;\u0026gt; 1; if (array[mid] \u0026gt;= q) { r = mid; } else { l = mid + 1; } } return l; } }; int main(){ vector\u0026lt;int\u0026gt; nums={2,3,1,2,4,3}; Solution *solution; printf(\u0026#34;%d\u0026#34;,solution-\u0026gt;minSubArrayLen(7,nums)); } 滑动窗口的办法\n确定如何移动起始位置\n由于是取最小的，所以使用函数min\n持续向后移动起始位置，更新sum\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; class Solution { public: int minSubArrayLen(int target, vector\u0026lt;int\u0026gt;\u0026amp; nums) { int len = nums.size(); int sum = 0; int index = 0; int ans = INT_MAX; for(int i = 0;i \u0026lt;= len -1; i++){ sum += nums[i];//求和 while(sum \u0026gt;= target){//大于target，往前减小找到符合的区间 int len = i-index + 1;//当前窗口的长度 sum -= nums[index]; ans = min(ans,len);//取最小的 index++; } } return ans==INT_MAX ? 0 : ans; } }; int main(){ vector\u0026lt;int\u0026gt; nums={2,3,1,2,4,3}; Solution *solution; printf(\u0026#34;%d\u0026#34;,solution-\u0026gt;minSubArrayLen(7,nums)); } ","date":"1 January 0001","externalUrl":null,"permalink":"/algorithm/%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E6%95%B0%E7%BB%84/","section":"Algorithms","summary":"209\n给定一个含有 n 个正整数的数组和一个正整数 target 。\n找出该数组中满足其总和大于等于 target 的长度最小的 连续 子数组 [numsl, numsl+1, \u0026hellip;, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。\n输入：target = 7, nums = [2,3,1,2,4,3] 输出：2 解释：子数组 [4,3] 是该条件下的长度最小的子数组。 #include \u0026lt;iostream\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; class Solution { public: int minSubArrayLen(int target, vector\u0026lt;int\u0026gt;\u0026amp; nums) { int right = nums.","title":"长度最小的数组","type":"algorithm"}]